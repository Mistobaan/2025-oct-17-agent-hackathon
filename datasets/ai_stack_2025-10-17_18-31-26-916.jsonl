{"url":"https://docs.stack-ai.com/","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/","loadedTime":"2025-10-17T18:27:59.529Z","referrerUrl":"https://docs.stack-ai.com/","depth":0,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai","title":"What Makes StackAI Unique | StackAI","description":"Quickly deploy agents for your enterprise company with a no-code platform anyone can use.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"What Makes StackAI Unique | StackAI"},{"property":"og:description","content":"Quickly deploy agents for your enterprise company with a no-code platform anyone can use."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"date":"Fri, 17 Oct 2025 18:27:58 GMT","content-type":"text/html; charset=utf-8","content-encoding":"br","cf-ray":"9901da5e5f00a338-SEA","cf-cache-status":"DYNAMIC","age":"1677","cache-control":"public, max-age=0, must-revalidate","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","referrer-policy":"no-referrer-when-downgrade","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"pdx1::iad1::4jdlz-1760725677854-2f17eb349a77","server":"cloudflare","alt-svc":"h3=\":443\"; ma=86400","x-firefox-spdy":"h2"}},"screenshotUrl":"https://api.apify.com/v2/key-value-stores/3K2WBdQQFTu6EGDhJ/records/SCREENSHOT-docs-stack-ai-com--a0b32020.jpg","text":"What Makes StackAI Unique | StackAI\nQuickly deploy agents for your enterprise company with a no-code platform anyone can use.\nStackAI is an enterprise platform for building and deploying AI agents, with a strong focus on governance and security.\nIT and Operations teams utilize StackAI to deploy internal applications that enhance and automate business processes, ranging from the simplest use cases, such as chatbots that retrieve information from databases like Microsoft SharePoint, to the most sophisticated automations, including performing in-depth research to generate investment memos.\nStackAI's powerful orchestration engine and extensive integrations simplify and accelerate the automation of business processes. We provide the observability and controls necessary to deploy AI Agents across your organization. That is why banks, defense companies, and governments trust us to accelerate their transition to an AI-first organization and streamline their productivity.\nEnd-to-End Experience\nStackAI offers an end-to-end experience, allowing users to build both the logic of the AI agent using a drag-and-drop workflow builder and the interface of the AI agent by selecting pre-built user interfaces. Once the AI Agent is configured, it can be deployed and monitored with a few clicks.\nAI Pipeline & Integrations\nAll components to build an AI application are available in StackAI with different levels of abstraction to help both non-technical and technical teams. The entire data pipeline needed for deploying AI applications can be configured in just a few steps.\nFrom document indexing to retrieval, users can build Retrieval Augmented Generation (RAG) systems by simply dragging a “Knowledge Base” node into their workflow, with default settings optimized for 90% of the use cases. This significantly streamlines the development of AI applications for both non-technical and technical users (i.e., IT teams new to AI development).\nFunction calling, implemented through the concept of “Tools,” is equally intuitive. Users only need to select the desired tools at the LLM level; no code or complex setup required.\nStackAI also offers a wide range of integrations with both established systems (such as SharePoint, SAP, Workday, Salesforce, etc) as well as modern SaaS companies (like Exa AI, Snowflake, and Miro), making data ingestion seamless and efficient.\nImplementation Support\nStackAI provides the platform and forward-deployment engineers to help customers build complex use cases and deploy those with confidence. Given the pace of innovation in AI, we offer the necessary guidance both with AI strategy as well as with tactical development advice, from testing new AI models to experimenting with different agentic architectures.\nStackAI supports all enterprise customers with weekly co-building sessions led by forward-deployed engineers, GenAI-focused hackathons (also known as Stackathons), and Quarterly Business Review (QBR) sessions to align on progress and roadmap priorities.\nAI Governance\nStackAI is SOC 2 Type II, HIPAA, and GDPR compliant, with ISO 27001 certification in progress. For organizations with strict data residency or sovereignty requirements, StackAI offers On-Premise deployment options, critical for industries like defense and finance. This capability sets us apart from most providers; since they force customers to use their cloud solution.\nGranular Role-Based Access Control (RBAC) enables admins to precisely govern who can modify and interact with LLMs, edit Knowledge Bases, or publish Workflows. Every component, from interfaces to citations, can be secured, authenticated (e.g. via SSO), and production-locked to ensure transparent accountability and control.\nAdmins can enforce approval flows, protect production environments from accidental edits, and ensure only reviewed agents are launched, with version control of all changes. Furthermore, Admins receive notifications of the status of their agents in production in real-time.\nLast updated 3 months ago","markdown":"# What Makes StackAI Unique | StackAI\n\nQuickly deploy agents for your enterprise company with a no-code platform anyone can use.\n\nStackAI is an enterprise platform for building and deploying AI agents, with a strong focus on governance and security.\n\nIT and Operations teams utilize StackAI to deploy internal applications that enhance and automate business processes, ranging from the simplest use cases, such as chatbots that retrieve information from databases like Microsoft SharePoint, to the most sophisticated automations, including performing in-depth research to generate investment memos.\n\nStackAI's powerful orchestration engine and extensive integrations simplify and accelerate the automation of business processes. We provide the observability and controls necessary to deploy AI Agents across your organization. That is why banks, defense companies, and governments trust us to accelerate their transition to an AI-first organization and streamline their productivity.\n\n### \n\nEnd-to-End Experience\n\nStackAI offers an end-to-end experience, allowing users to build both the logic of the AI agent using a drag-and-drop workflow builder and the interface of the AI agent by selecting pre-built user interfaces. Once the AI Agent is configured, it can be deployed and monitored with a few clicks.\n\n### \n\nAI Pipeline & Integrations\n\nAll components to build an AI application are available in StackAI with different levels of abstraction to help both non-technical and technical teams. The entire data pipeline needed for deploying AI applications can be configured in just a few steps.\n\nFrom document indexing to retrieval, users can build Retrieval Augmented Generation (RAG) systems by simply dragging a “Knowledge Base” node into their workflow, with default settings optimized for 90% of the use cases. This significantly streamlines the development of AI applications for both non-technical and technical users (i.e., IT teams new to AI development).\n\nFunction calling, implemented through the concept of “Tools,” is equally intuitive. Users only need to select the desired tools at the LLM level; no code or complex setup required.\n\nStackAI also offers a wide range of integrations with both established systems (such as SharePoint, SAP, Workday, Salesforce, etc) as well as modern SaaS companies (like Exa AI, Snowflake, and Miro), making data ingestion seamless and efficient.\n\n### \n\nImplementation Support\n\nStackAI provides the platform and forward-deployment engineers to help customers build complex use cases and deploy those with confidence. Given the pace of innovation in AI, we offer the necessary guidance both with AI strategy as well as with tactical development advice, from testing new AI models to experimenting with different agentic architectures.\n\nStackAI supports all enterprise customers with weekly co-building sessions led by forward-deployed engineers, GenAI-focused hackathons (also known as Stackathons), and Quarterly Business Review (QBR) sessions to align on progress and roadmap priorities.\n\n### \n\nAI Governance\n\nStackAI is SOC 2 Type II, HIPAA, and GDPR compliant, with ISO 27001 certification in progress. For organizations with strict data residency or sovereignty requirements, StackAI offers On-Premise deployment options, critical for industries like defense and finance. This capability sets us apart from most providers; since they force customers to use their cloud solution.\n\nGranular Role-Based Access Control (RBAC) enables admins to precisely govern who can modify and interact with LLMs, edit Knowledge Bases, or publish Workflows. Every component, from interfaces to citations, can be secured, authenticated (e.g. via SSO), and production-locked to ensure transparent accountability and control.\n\nAdmins can enforce approval flows, protect production environments from accidental edits, and ensure only reviewed agents are launched, with version control of all changes. Furthermore, Admins receive notifications of the status of their agents in production in real-time.\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"browser"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/mcp","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/mcp","loadedTime":"2025-10-17T18:28:10.618Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/mcp","title":"MCP | StackAI","description":"Learn how to use the MCP node in StackAI to connect and interact with Model Context Protocol servers, including input, configuration, and output details.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"MCP | StackAI"},{"property":"og:description","content":"Learn how to use the MCP node in StackAI to connect and interact with Model Context Protocol servers, including input, configuration, and output details."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"date":"Fri, 17 Oct 2025 18:28:07 GMT","content-type":"text/html; charset=utf-8","content-encoding":"br","cf-ray":"9901da944c1ea338-SEA","cf-cache-status":"DYNAMIC","age":"0","cache-control":"public, max-age=0, must-revalidate","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","referrer-policy":"no-referrer-when-downgrade","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"pdx1::iad1::4jdlz-1760725686475-1216e60e468c","server":"cloudflare","alt-svc":"h3=\":443\"; ma=86400","x-firefox-spdy":"h2"}},"screenshotUrl":"https://api.apify.com/v2/key-value-stores/3K2WBdQQFTu6EGDhJ/records/SCREENSHOT-docs-stack-ai-com-stack-ai-workflow-builder-apps-mcp-3547aece.jpg","text":"MCP | StackAI\nLearn how to use the MCP node in StackAI to connect and interact with Model Context Protocol servers, including input, configuration, and output details.\nTo use the MCP Node, you configure it to call a specific tool on an MCP server and pass any required parameters. The node will then execute the tool and return the results, which can be used in downstream nodes in your workflow. \nConnecting to public servers is easy! Choose the server you'd like to connect to here. Then, create a new connection with the server's URL. You should be able to then choose from a dropdown of available actions.\nExample of Usage\nSuppose you want to invoke a tool named \"web_search\" on your ExaAI MCP server and pass a text string to search the web. You would configure the MCP node as follows:\nTool Name: \"web_search\"\nParameters: { \"query\": \"StackAI is a powerful workflow automation platform...\" }\nThe node will return the summarized text in the output.\nCall MCP Server\nThis is the primary action available for the MCP node.\nDescription\nInvoke a tool hosted on an MCP server by specifying the tool name and any parameters required by that tool.\nInputs\nTool Name (tool_name)\nType: String\nRequired: No\nDescription: The name of the tool to invoke on the MCP server.\nExample: \"summarize_text\"\nParameters (parameters)\nType: Object\nRequired: No\nDescription: The parameters to pass to the specified tool. The structure depends on the tool being called.\nExample: { \"text\": \"Your input text here\" }\nConfigurations\nNo additional configurations are required for this action.\nOutputs\nResult (result)\nType: Object\nRequired: Yes\nDescription: The result returned from the tool invocation. The structure of this object depends on the tool you called.\nExample: { \"summary\": \"StackAI automates workflows efficiently.\" }\nSummary Table\nField\nType\nRequired\nDescription\nExample\nName of the tool to invoke\nParameters to pass to the tool\n{ \"text\": \"Your input text here\" }\nResult from the tool invocation\nBest Practices\nAlways check the documentation of the specific tool you are invoking for required parameters.\nUse the output of the MCP node as input for downstream nodes to build powerful, automated workflows.\nAdvanced users can run their own MCP server locally and expose it to the web using a tool like ngrok. Putting your ngrok URL when making a connection will allow you to connect to the local server in Stack!","markdown":"# MCP | StackAI\n\nLearn how to use the MCP node in StackAI to connect and interact with Model Context Protocol servers, including input, configuration, and output details.\n\nTo use the **MCP Node**, you configure it to call a specific tool on an MCP server and pass any required parameters. The node will then execute the tool and return the results, which can be used in downstream nodes in your workflow.\n\nConnecting to public servers is easy! Choose the server you'd like to connect to [here](https://mcpservers.org/). Then, create a new connection with the server's URL. You should be able to then choose from a dropdown of available actions.\n\n* * *\n\n**Example of Usage**\n\nSuppose you want to invoke a tool named \"web\\_search\" on your ExaAI MCP server and pass a text string to search the web. You would configure the MCP node as follows:\n\n*   Tool Name: \"web\\_search\"\n    \n*   Parameters: { \"query\": \"StackAI is a powerful workflow automation platform...\" }\n    \n\nThe node will return the summarized text in the output.\n\n* * *\n\n#### \n\nCall MCP Server\n\nThis is the primary action available for the MCP node.\n\n**Description**\n\nInvoke a tool hosted on an MCP server by specifying the tool name and any parameters required by that tool.\n\n**Inputs**\n\n*   **Tool Name** (tool\\_name)\n    \n    *   Type: String\n        \n    *   Required: No\n        \n    *   Description: The name of the tool to invoke on the MCP server.\n        \n    *   Example: \"summarize\\_text\"\n        \n    \n*   **Parameters** (parameters)\n    \n    *   Type: Object\n        \n    *   Required: No\n        \n    *   Description: The parameters to pass to the specified tool. The structure depends on the tool being called.\n        \n    *   Example: { \"text\": \"Your input text here\" }\n        \n    \n\n**Configurations**\n\n*   No additional configurations are required for this action.\n    \n\n**Outputs**\n\n*   **Result** (result)\n    \n    *   Type: Object\n        \n    *   Required: Yes\n        \n    *   Description: The result returned from the tool invocation. The structure of this object depends on the tool you called.\n        \n    *   Example: { \"summary\": \"StackAI automates workflows efficiently.\" }\n        \n    \n\n* * *\n\n**Summary Table**\n\nField\n\nType\n\nRequired\n\nDescription\n\nExample\n\nName of the tool to invoke\n\nParameters to pass to the tool\n\n{ \"text\": \"Your input text here\" }\n\nResult from the tool invocation\n\n* * *\n\n**Best Practices**\n\n*   Always check the documentation of the specific tool you are invoking for required parameters.\n    \n*   Use the output of the MCP node as input for downstream nodes to build powerful, automated workflows.\n    \n*   Advanced users can run their own MCP server locally and expose it to the web using a tool like ngrok. Putting your ngrok URL when making a connection will allow you to connect to the local server in Stack!","debug":{"requestHandlerMode":"browser"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/mongodb","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/mongodb","loadedTime":"2025-10-17T18:28:09.988Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/mongodb","title":"MongoDB | StackAI","description":"Learn how to use the MongoDB node in StackAI to query your MongoDB database, including required inputs, configuration, and output examples.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"MongoDB | StackAI"},{"property":"og:description","content":"Learn how to use the MongoDB node in StackAI to query your MongoDB database, including required inputs, configuration, and output examples."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"date":"Fri, 17 Oct 2025 18:28:07 GMT","content-type":"text/html; charset=utf-8","content-encoding":"br","cf-ray":"9901da96bf08a338-SEA","cf-cache-status":"DYNAMIC","age":"0","cache-control":"public, max-age=0, must-revalidate","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","referrer-policy":"no-referrer-when-downgrade","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"pdx1::iad1::c4djs-1760725686862-e10b9c7eb22d","server":"cloudflare","alt-svc":"h3=\":443\"; ma=86400","x-firefox-spdy":"h2"}},"screenshotUrl":"https://api.apify.com/v2/key-value-stores/3K2WBdQQFTu6EGDhJ/records/SCREENSHOT-docs-stack-ai-com-stack-ai-workflow-builder-apps-mongodb-5d218927.jpg","text":"MongoDB | StackAI\nLearn how to use the MongoDB node in StackAI to query your MongoDB database, including required inputs, configuration, and output examples.\nThe MongoDB Node in StackAI allows you to query a MongoDB database directly from your workflow. This node is ideal for retrieving data from your collections using flexible filters, making it easy to integrate database results into your AI-powered automations.\nHow to use it?\nTo use the MongoDB node, you need to provide the following required inputs and configurations:\nDatabase Name (Required Configuration)\nDescription: The name of the MongoDB database you want to query.\nExample: \"customer_data\"\nCollection Name (Required Configuration)\nDescription: The name of the collection within the database to query.\nExample: \"orders\"\nFilter (Required Input)\nDescription: The MongoDB query filter in JSON format. This determines which documents are returned.\nExample:\nTo find all orders for a specific user: {\"user_id\": \"499484bb-fd54-4fb0-93e5-4ad98bdcdf94\"}\nTo find users aged 18 or older: {\"age\": {\"$gte\": 18}}\nTo find orders with status \"active\" or \"pending\": {\"status\": {\"$in\": [\"active\", \"pending\"]}}\nTo find documents created after a certain date: {\"created_at\": {\"$gte\": \"2024-01-01T00:00:00Z\"}}\nExample of Usage\nSuppose you want to retrieve all active orders from the \"orders\" collection in the \"customer_data\" database:\nDatabase Name: \"customer_data\" (Required)\nCollection Name: \"orders\" (Required)\nFilter: {\"status\": \"active\"} (Required)\nExpected Output\nResults (Required Output)\nDescription: An array of objects, each representing a document from the collection that matches the filter.\nExample:\n{ \"results\": [ { \"order_id\": \"12345\", \"user_id\": \"abcde\", \"status\": \"active\", \"amount\": 99.99 }, { \"order_id\": \"12346\", \"user_id\": \"fghij\", \"status\": \"active\", \"amount\": 49.99 } ] }\nAvailable Actions\nQuery MongoDB\nDescription: Retrieve documents from a specified database and collection using a JSON filter.\nRequired Inputs:\nDatabase Name (string, required)\nCollection Name (string, required)\nFilter (string, required; JSON format)\nOutput:\nResults (array of objects, required): The documents matching your query.\nSummary\nThe MongoDB node in StackAI is a powerful tool for querying your MongoDB collections. By specifying the database, collection, and filter, you can retrieve exactly the data you need and use it in your automated workflows.\nLast updated 2 months ago","markdown":"# MongoDB | StackAI\n\nLearn how to use the MongoDB node in StackAI to query your MongoDB database, including required inputs, configuration, and output examples.\n\nThe **MongoDB Node** in StackAI allows you to query a MongoDB database directly from your workflow. This node is ideal for retrieving data from your collections using flexible filters, making it easy to integrate database results into your AI-powered automations.\n\n**How to use it?**\n\nTo use the MongoDB node, you need to provide the following required inputs and configurations:\n\n*   **Database Name (Required Configuration)**\n    \n    *   Description: The name of the MongoDB database you want to query.\n        \n    *   Example: \"customer\\_data\"\n        \n    \n*   **Collection Name (Required Configuration)**\n    \n    *   Description: The name of the collection within the database to query.\n        \n    *   Example: \"orders\"\n        \n    \n*   **Filter (Required Input)**\n    \n    *   Description: The MongoDB query filter in JSON format. This determines which documents are returned.\n        \n    *   Example:\n        \n        *   To find all orders for a specific user: {\"user\\_id\": \"499484bb-fd54-4fb0-93e5-4ad98bdcdf94\"}\n            \n        *   To find users aged 18 or older: {\"age\": {\"$gte\": 18}}\n            \n        *   To find orders with status \"active\" or \"pending\": {\"status\": {\"$in\": \\[\"active\", \"pending\"\\]}}\n            \n        *   To find documents created after a certain date: {\"created\\_at\": {\"$gte\": \"2024-01-01T00:00:00Z\"}}\n            \n        \n    \n\n**Example of Usage**\n\nSuppose you want to retrieve all active orders from the \"orders\" collection in the \"customer\\_data\" database:\n\n*   **Database Name:** \"customer\\_data\" (Required)\n    \n*   **Collection Name:** \"orders\" (Required)\n    \n*   **Filter:** {\"status\": \"active\"} (Required)\n    \n\n**Expected Output**\n\n*   **Results (Required Output)**\n    \n    *   Description: An array of objects, each representing a document from the collection that matches the filter.\n        \n    *   Example:\n        \n        ```\n        {\n          \"results\": [\n            {\n              \"order_id\": \"12345\",\n              \"user_id\": \"abcde\",\n              \"status\": \"active\",\n              \"amount\": 99.99\n            },\n            {\n              \"order_id\": \"12346\",\n              \"user_id\": \"fghij\",\n              \"status\": \"active\",\n              \"amount\": 49.99\n            }\n          ]\n        }\n        ```\n        \n    \n\n**Available Actions**\n\n*   **Query MongoDB**\n    \n    *   Description: Retrieve documents from a specified database and collection using a JSON filter.\n        \n    *   Required Inputs:\n        \n        *   Database Name (string, required)\n            \n        *   Collection Name (string, required)\n            \n        *   Filter (string, required; JSON format)\n            \n        \n    *   Output:\n        \n        *   Results (array of objects, required): The documents matching your query.\n            \n        \n    \n\n**Summary**\n\nThe MongoDB node in StackAI is a powerful tool for querying your MongoDB collections. By specifying the database, collection, and filter, you can retrieve exactly the data you need and use it in your automated workflows.\n\nLast updated 2 months ago","debug":{"requestHandlerMode":"browser"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/miro","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/miro","loadedTime":"2025-10-17T18:28:10.490Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/miro","title":"Miro | StackAI","description":"Comprehensive guide to the Miro node in StackAI: discover key actions, input requirements, configurations, and output examples for seamless Miro integration.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Miro | StackAI"},{"property":"og:description","content":"Comprehensive guide to the Miro node in StackAI: discover key actions, input requirements, configurations, and output examples for seamless Miro integration."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"date":"Fri, 17 Oct 2025 18:28:07 GMT","content-type":"text/html; charset=utf-8","content-encoding":"br","cf-ray":"9901da96ef3ea338-SEA","cf-cache-status":"DYNAMIC","age":"0","cache-control":"public, max-age=0, must-revalidate","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","referrer-policy":"no-referrer-when-downgrade","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"pdx1::iad1::dq8bn-1760725686901-01df596592a5","server":"cloudflare","alt-svc":"h3=\":443\"; ma=86400","x-firefox-spdy":"h2"}},"screenshotUrl":"https://api.apify.com/v2/key-value-stores/3K2WBdQQFTu6EGDhJ/records/SCREENSHOT-docs-stack-ai-com-stack-ai-workflow-builder-apps-miro-7ec9826e.jpg","text":"Miro | StackAI\nComprehensive guide to the Miro node in StackAI: discover key actions, input requirements, configurations, and output examples for seamless Miro integration.\nWhat is Miro?\nThe Miro node in StackAI enables seamless integration with the Miro collaborative whiteboard platform. It allows you to automate board management, content creation, and team collaboration directly from your StackAI workflows.\nHow to use it?\nTo use the Miro node, select the desired action, provide the required inputs and configurations, and connect your Miro account using a valid connection ID. The node can be used to automate board creation, manage content, and interact with Miro items programmatically.\nExample of Usage\nSuppose you want to automatically create a new Miro board for every new project. You would use the \"Create Board\" action, provide the board name as input, and optionally set a description or team ID. The output will include the board's unique ID and URL, which you can use in subsequent workflow steps.\nAvailable Actions\nBelow are the most commonly used Miro actions in StackAI, along with their input, configuration, and output details:\n1. Create Board\nDescription: Create a new Miro board in your workspace.\nInputs:\nname (Required): The name of the new board. Example: \"Project Kickoff Board\"\ndescription (Optional): A description for the board. Example: \"Board for the new project kickoff meeting.\"\nteam_id (Optional): The ID of the team to assign the board to. Example: \"345678\"\nConfigurations:\nconnection_id (Required): Your Miro connection ID for authentication.\nOutputs:\nid (Always returned): The unique identifier of the created board.\nname: The name of the board.\ndescription: The board description.\nviewLink: The URL to access the board.\n2. Get Boards\nDescription: Retrieve a list of all boards accessible to your account.\nInputs:\nteam_id (Optional): Filter boards by team ID.\nConfigurations:\nconnection_id (Required): Your Miro connection ID.\nOutputs:\nboards: An array of board objects, each containing:\nid: Board ID\nname: Board name\ndescription: Board description\nviewLink: Board URL\n3. Create Sticky Note Item\nDescription: Add a sticky note to a specific Miro board.\nInputs:\nboard_id (Required): The ID of the board to add the sticky note to.\ndata (Required): The content/text of the sticky note. Example: \"Discuss project milestones\"\nConfigurations:\nconnection_id (Required): Your Miro connection ID.\nOutputs:\nid: The unique identifier of the sticky note.\ndata: The content of the sticky note.\nposition: The coordinates of the sticky note on the board.\n4. Get Board\nDescription: Retrieve details of a specific Miro board.\nInputs:\nboard_id (Required): The ID of the board.\nConfigurations:\nconnection_id (Required): Your Miro connection ID.\nOutputs:\nid: Board ID\nname: Board name\ndescription: Board description\nviewLink: Board URL\n5. Create Shape Item\nDescription: Add a shape (rectangle, circle, etc.) to a Miro board.\nInputs:\nboard_id (Required): The ID of the board.\nshape (Required): The type of shape (e.g., \"rectangle\", \"circle\").\ntext (Optional): Text to display inside the shape.\nConfigurations:\nconnection_id (Required): Your Miro connection ID.\nOutputs:\nid: Shape item ID\nshape: Type of shape\ntext: Text inside the shape\nposition: Coordinates on the board\nBest Practices:\nAlways provide a valid connection ID for authentication.\nUse required inputs as specified for each action to avoid errors.\nUse the output IDs to reference created items in subsequent workflow steps.\nSummary Table\nAction\nRequired Inputs\nOptional Inputs\nOutput Highlights\nUse the Miro node in StackAI to automate and streamline your collaborative workflows, making project management and team collaboration more efficient.\nLast updated 3 months ago","markdown":"# Miro | StackAI\n\nComprehensive guide to the Miro node in StackAI: discover key actions, input requirements, configurations, and output examples for seamless Miro integration.\n\n**What is Miro?**\n\nThe Miro node in StackAI enables seamless integration with the Miro collaborative whiteboard platform. It allows you to automate board management, content creation, and team collaboration directly from your StackAI workflows.\n\n* * *\n\n**How to use it?**\n\nTo use the Miro node, select the desired action, provide the required inputs and configurations, and connect your Miro account using a valid connection ID. The node can be used to automate board creation, manage content, and interact with Miro items programmatically.\n\n* * *\n\n**Example of Usage**\n\nSuppose you want to automatically create a new Miro board for every new project. You would use the \"Create Board\" action, provide the board name as input, and optionally set a description or team ID. The output will include the board's unique ID and URL, which you can use in subsequent workflow steps.\n\n* * *\n\n**Available Actions**\n\nBelow are the most commonly used Miro actions in StackAI, along with their input, configuration, and output details:\n\n* * *\n\n#### \n\n1\\. Create Board\n\n**Description:** Create a new Miro board in your workspace.\n\n**Inputs:**\n\n*   **name** (Required): The name of the new board. _Example:_ `\"Project Kickoff Board\"`\n    \n*   **description** (Optional): A description for the board. _Example:_ `\"Board for the new project kickoff meeting.\"`\n    \n*   **team\\_id** (Optional): The ID of the team to assign the board to. _Example:_ `\"345678\"`\n    \n\n**Configurations:**\n\n*   **connection\\_id** (Required): Your Miro connection ID for authentication.\n    \n\n**Outputs:**\n\n*   **id** (Always returned): The unique identifier of the created board.\n    \n*   **name**: The name of the board.\n    \n*   **description**: The board description.\n    \n*   **viewLink**: The URL to access the board.\n    \n\n* * *\n\n#### \n\n2\\. Get Boards\n\n**Description:** Retrieve a list of all boards accessible to your account.\n\n**Inputs:**\n\n*   **team\\_id** (Optional): Filter boards by team ID.\n    \n\n**Configurations:**\n\n*   **connection\\_id** (Required): Your Miro connection ID.\n    \n\n**Outputs:**\n\n*   **boards**: An array of board objects, each containing:\n    \n    *   **id**: Board ID\n        \n    *   **name**: Board name\n        \n    *   **description**: Board description\n        \n    *   **viewLink**: Board URL\n        \n    \n\n* * *\n\n#### \n\n3\\. Create Sticky Note Item\n\n**Description:** Add a sticky note to a specific Miro board.\n\n**Inputs:**\n\n*   **board\\_id** (Required): The ID of the board to add the sticky note to.\n    \n*   **data** (Required): The content/text of the sticky note. _Example:_ `\"Discuss project milestones\"`\n    \n\n**Configurations:**\n\n*   **connection\\_id** (Required): Your Miro connection ID.\n    \n\n**Outputs:**\n\n*   **id**: The unique identifier of the sticky note.\n    \n*   **data**: The content of the sticky note.\n    \n*   **position**: The coordinates of the sticky note on the board.\n    \n\n* * *\n\n#### \n\n4\\. Get Board\n\n**Description:** Retrieve details of a specific Miro board.\n\n**Inputs:**\n\n*   **board\\_id** (Required): The ID of the board.\n    \n\n**Configurations:**\n\n*   **connection\\_id** (Required): Your Miro connection ID.\n    \n\n**Outputs:**\n\n*   **id**: Board ID\n    \n*   **name**: Board name\n    \n*   **description**: Board description\n    \n*   **viewLink**: Board URL\n    \n\n* * *\n\n#### \n\n5\\. Create Shape Item\n\n**Description:** Add a shape (rectangle, circle, etc.) to a Miro board.\n\n**Inputs:**\n\n*   **board\\_id** (Required): The ID of the board.\n    \n*   **shape** (Required): The type of shape (e.g., `\"rectangle\"`, `\"circle\"`).\n    \n*   **text** (Optional): Text to display inside the shape.\n    \n\n**Configurations:**\n\n*   **connection\\_id** (Required): Your Miro connection ID.\n    \n\n**Outputs:**\n\n*   **id**: Shape item ID\n    \n*   **shape**: Type of shape\n    \n*   **text**: Text inside the shape\n    \n*   **position**: Coordinates on the board\n    \n\n* * *\n\n**Best Practices:**\n\n*   Always provide a valid connection ID for authentication.\n    \n*   Use required inputs as specified for each action to avoid errors.\n    \n*   Use the output IDs to reference created items in subsequent workflow steps.\n    \n\n* * *\n\n**Summary Table**\n\nAction\n\nRequired Inputs\n\nOptional Inputs\n\nOutput Highlights\n\n* * *\n\nUse the Miro node in StackAI to automate and streamline your collaborative workflows, making project management and team collaboration more efficient.\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"browser"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/mysql","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/mysql","loadedTime":"2025-10-17T18:28:20.304Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/mysql","title":"MySQL | StackAI","description":"Learn how to use the MySQL node in StackAI to run database queries, including required inputs, configurations, and output details with practical examples.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"MySQL | StackAI"},{"property":"og:description","content":"Learn how to use the MySQL node in StackAI to run database queries, including required inputs, configurations, and output details with practical examples."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"date":"Fri, 17 Oct 2025 18:28:16 GMT","content-type":"text/html; charset=utf-8","content-encoding":"br","cf-ray":"9901dace0d93a338-SEA","cf-cache-status":"DYNAMIC","age":"0","cache-control":"public, max-age=0, must-revalidate","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","referrer-policy":"no-referrer-when-downgrade","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"pdx1::iad1::ckwv2-1760725695720-a3afc4ca13aa","server":"cloudflare","alt-svc":"h3=\":443\"; ma=86400","x-firefox-spdy":"h2"}},"screenshotUrl":"https://api.apify.com/v2/key-value-stores/3K2WBdQQFTu6EGDhJ/records/SCREENSHOT-docs-stack-ai-com-stack-ai-workflow-builder-apps-mysql-182bcae0.jpg","text":"MySQL | StackAI\nLearn how to use the MySQL node in StackAI to run database queries, including required inputs, configurations, and output details with practical examples.\nThe MySQL Node in StackAI allows you to query a MySQL database directly from your workflow. It is designed to execute queries—either in plain English or SQL format—against your database and return structured results.\nHow to use it?\nTo use the MySQL node, you need to provide two required inputs:\nSchema (Required):\nDescription: The full database schema, including tables, columns, and data types.\nExample:\nTABLE Customers ( CustomerID INT, Name TEXT, Email TEXT, Country TEXT ); TABLE Orders ( OrderID INT, CustomerID INT, Amount DECIMAL, OrderDate DATE );\nQuery (Required):\nDescription: The question or command you want to run. You can write this in plain English or as a SQL statement.\nExample:\n\"Show me all customers from Canada.\"\n\"SELECT * FROM Orders WHERE Amount > 1000;\"\nConfigurations There are no additional configuration parameters required for this node. All you need is the schema and the query.\nOutputs The MySQL node provides two outputs:\nQuery (Required):\nDescription: The actual SQL query that was executed, even if you provided a plain English question.\nResults (Required):\nDescription: The results of the query, returned as an array of objects (rows).\nExample of Usage\nSuppose you want to find all orders above $500:\nSchema:\nTABLE Orders ( OrderID INT, CustomerID INT, Amount DECIMAL, OrderDate DATE );\nQuery: \"Show me all orders where the amount is greater than 500.\"\nExpected Output:\nQuery: SELECT * FROM Orders WHERE Amount > 500;\nResults:\n[ { \"OrderID\": 101, \"CustomerID\": 1, \"Amount\": 750, \"OrderDate\": \"2024-06-01\" }, { \"OrderID\": 102, \"CustomerID\": 3, \"Amount\": 1200, \"OrderDate\": \"2024-06-02\" } ]\nAvailable Actions\ndatabase_query_mysql:\nDescription: Run a query (in plain English or SQL) against your MySQL database and get structured results.\nInputs for database_query_mysql:\nsql_schema (Required): The database schema (tables, columns, types, etc.).\nquery (Required): The query in plain English or SQL.\nOutputs for database_query_mysql:\nquery (Required): The SQL query that was executed.\nresults (Required): The results of the query as an array of objects.\nUse the MySQL node in StackAI to seamlessly integrate database queries into your automated workflows, making data retrieval and analysis easy and efficient.\nLast updated 2 months ago","markdown":"# MySQL | StackAI\n\nLearn how to use the MySQL node in StackAI to run database queries, including required inputs, configurations, and output details with practical examples.\n\nThe **MySQL Node** in StackAI allows you to query a MySQL database directly from your workflow. It is designed to execute queries—either in plain English or SQL format—against your database and return structured results.\n\n**How to use it?**\n\nTo use the MySQL node, you need to provide two required inputs:\n\n1.  **Schema** (Required):\n    \n    *   Description: The full database schema, including tables, columns, and data types.\n        \n    *   Example:\n        \n        ```\n        TABLE Customers (\n          CustomerID INT,\n          Name TEXT,\n          Email TEXT,\n          Country TEXT\n        );\n        TABLE Orders (\n          OrderID INT,\n          CustomerID INT,\n          Amount DECIMAL,\n          OrderDate DATE\n        );\n        ```\n        \n    \n2.  **Query** (Required):\n    \n    *   Description: The question or command you want to run. You can write this in plain English or as a SQL statement.\n        \n    *   Example:\n        \n        *   \"Show me all customers from Canada.\"\n            \n        *   \"SELECT \\* FROM Orders WHERE Amount > 1000;\"\n            \n        \n    \n\n**Configurations** There are no additional configuration parameters required for this node. All you need is the schema and the query.\n\n**Outputs** The MySQL node provides two outputs:\n\n1.  **Query** (Required):\n    \n    *   Description: The actual SQL query that was executed, even if you provided a plain English question.\n        \n    \n2.  **Results** (Required):\n    \n    *   Description: The results of the query, returned as an array of objects (rows).\n        \n    \n\n**Example of Usage**\n\nSuppose you want to find all orders above $500:\n\n*   **Schema**:\n    \n    ```\n    TABLE Orders (\n      OrderID INT,\n      CustomerID INT,\n      Amount DECIMAL,\n      OrderDate DATE\n    );\n    ```\n    \n*   **Query**: \"Show me all orders where the amount is greater than 500.\"\n    \n\n**Expected Output**:\n\n*   **Query**: `SELECT * FROM Orders WHERE Amount > 500;`\n    \n*   **Results**:\n    \n    ```\n    [\n      { \"OrderID\": 101, \"CustomerID\": 1, \"Amount\": 750, \"OrderDate\": \"2024-06-01\" },\n      { \"OrderID\": 102, \"CustomerID\": 3, \"Amount\": 1200, \"OrderDate\": \"2024-06-02\" }\n    ]\n    ```\n    \n\n**Available Actions**\n\n*   **database\\_query\\_mysql**:\n    \n    *   Description: Run a query (in plain English or SQL) against your MySQL database and get structured results.\n        \n    \n\n**Inputs for database\\_query\\_mysql**:\n\n*   **sql\\_schema** (Required): The database schema (tables, columns, types, etc.).\n    \n*   **query** (Required): The query in plain English or SQL.\n    \n\n**Outputs for database\\_query\\_mysql**:\n\n*   **query** (Required): The SQL query that was executed.\n    \n*   **results** (Required): The results of the query as an array of objects.\n    \n\nUse the MySQL node in StackAI to seamlessly integrate database queries into your automated workflows, making data retrieval and analysis easy and efficient.\n\nLast updated 2 months ago","debug":{"requestHandlerMode":"browser"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/outlook","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/outlook","loadedTime":"2025-10-17T18:28:29.703Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/outlook","title":"Outlook | StackAI","description":"Learn how to automate Outlook email tasks in StackAI. Discover available actions, required inputs, configurations, and output examples for seamless workflow integration.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Outlook | StackAI"},{"property":"og:description","content":"Learn how to automate Outlook email tasks in StackAI. Discover available actions, required inputs, configurations, and output examples for seamless workflow integration."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"date":"Fri, 17 Oct 2025 18:28:28 GMT","content-type":"text/html; charset=utf-8","content-encoding":"br","cf-ray":"9901db180ba08157-SEA","cf-cache-status":"DYNAMIC","age":"0","cache-control":"public, max-age=0, must-revalidate","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","referrer-policy":"no-referrer-when-downgrade","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"pdx1::iad1::sl6cs-1760725707560-3d1d39dc3b25","server":"cloudflare","alt-svc":"h3=\":443\"; ma=86400","x-firefox-spdy":"h2"}},"screenshotUrl":"https://api.apify.com/v2/key-value-stores/3K2WBdQQFTu6EGDhJ/records/SCREENSHOT-docs-stack-ai-com-stack-ai-workflow-builder-apps-outlook-488880e3.jpg","text":"Outlook | StackAI\nLearn how to automate Outlook email tasks in StackAI. Discover available actions, required inputs, configurations, and output examples for seamless workflow integration.\nWhat is Outlook?\nOutlook in StackAI is a powerful integration node that enables you to automate sending and managing emails directly through your Outlook account. This node streamlines communication workflows, allowing you to trigger email actions as part of your automated processes.\nHow to use it?\nTo use the Outlook node in StackAI, simply add it to your workflow and configure the desired action. Connect it to other nodes to dynamically generate email content, recipients, or attachments. You can use this node to send emails, search your mailbox, or automate other Outlook-related tasks.\nExample of Usage\nSuppose you want to automatically send a summary report to your team every week. You can connect a report-generating node to the Outlook node, configure the email details, and automate the process without manual intervention.\nAvailable Actions\nBelow are the most commonly used Outlook actions in StackAI:\n1. Send Email\nDescription: Send an email from your Outlook account to one or more recipients.\nInputs:\nto (Required): The recipient's email address(es). Accepts a single email or a list of emails.\nExample: \"to\": \"team@example.com\" or \"to\": [\"user1@example.com\", \"user2@example.com\"]\nsubject (Required): The subject line of the email.\nExample: \"subject\": \"Weekly Report\"\nbody (Required): The main content of the email. Supports plain text or HTML.\nExample: \"body\": \"Please find the attached weekly report.\"\ncc (Optional): Email address(es) to be copied.\nExample: \"cc\": \"manager@example.com\"\nbcc (Optional): Email address(es) to be blind copied.\nExample: \"bcc\": [\"hr@example.com\"]\nattachments (Optional): List of files to attach. Provide file paths or references from previous nodes.\nExample: \"attachments\": [\"{doc-0}\"]\nConfigurations:\nconnection_id (Required if you have multiple Outlook accounts): Specify the Outlook connection to use.\nExample: \"connection_id\": \"your-connection-id\"\nOutputs:\nmessage_id (Always returned): The unique ID of the sent email.\nstatus (Always returned): Confirmation of successful delivery or error details.\nExample:\n{ \"message_id\": \"abc123\", \"status\": \"sent\" }\n2. Search Emails\nDescription: Search your Outlook mailbox for emails matching specific criteria.\nInputs:\nquery (Required): The search query string (e.g., keywords, sender, date).\nExample: \"query\": \"from:boss@example.com subject:invoice\"\nfolder (Optional): Specify the folder to search in (e.g., Inbox, Sent).\nExample: \"folder\": \"Inbox\"\nmax_results (Optional): Limit the number of results.\nExample: \"max_results\": 10\nConfigurations:\nconnection_id (Required if you have multiple Outlook accounts): Specify the Outlook connection to use.\nOutputs:\nemails (Always returned): List of matching emails with details such as subject, sender, date, and body.\nExample:\n{ \"emails\": [ { \"subject\": \"Invoice Due\", \"from\": \"boss@example.com\", \"date\": \"2025-07-01\", \"body\": \"Please see the attached invoice.\" } ] }\nBest Practices\nAlways ensure required fields are filled to avoid errors.\nUse dynamic references (e.g., {llm-0} or {doc-0}) to personalize emails or attach generated content.\nFor attachments, connect a Files node or other relevant node to provide file paths.\nSummary Table\nAction\nRequired Inputs\nOptional Inputs\nOutputs\nAutomate your Outlook email workflows in StackAI to save time, reduce manual effort, and ensure consistent communication.\nLast updated 3 months ago","markdown":"# Outlook | StackAI\n\nLearn how to automate Outlook email tasks in StackAI. Discover available actions, required inputs, configurations, and output examples for seamless workflow integration.\n\n**What is Outlook?**\n\nOutlook in StackAI is a powerful integration node that enables you to automate sending and managing emails directly through your Outlook account. This node streamlines communication workflows, allowing you to trigger email actions as part of your automated processes.\n\n**How to use it?**\n\nTo use the Outlook node in StackAI, simply add it to your workflow and configure the desired action. Connect it to other nodes to dynamically generate email content, recipients, or attachments. You can use this node to send emails, search your mailbox, or automate other Outlook-related tasks.\n\n**Example of Usage**\n\nSuppose you want to automatically send a summary report to your team every week. You can connect a report-generating node to the Outlook node, configure the email details, and automate the process without manual intervention.\n\n* * *\n\n**Available Actions**\n\nBelow are the most commonly used Outlook actions in StackAI:\n\n#### \n\n1\\. Send Email\n\n**Description:** Send an email from your Outlook account to one or more recipients.\n\n**Inputs:**\n\n*   **to** (Required): The recipient's email address(es). Accepts a single email or a list of emails.\n    \n    *   Example: `\"to\": \"team@example.com\"` or `\"to\": [\"user1@example.com\", \"user2@example.com\"]`\n        \n    \n*   **subject** (Required): The subject line of the email.\n    \n    *   Example: `\"subject\": \"Weekly Report\"`\n        \n    \n*   **body** (Required): The main content of the email. Supports plain text or HTML.\n    \n    *   Example: `\"body\": \"Please find the attached weekly report.\"`\n        \n    \n*   **cc** (Optional): Email address(es) to be copied.\n    \n    *   Example: `\"cc\": \"manager@example.com\"`\n        \n    \n*   **bcc** (Optional): Email address(es) to be blind copied.\n    \n    *   Example: `\"bcc\": [\"hr@example.com\"]`\n        \n    \n*   **attachments** (Optional): List of files to attach. Provide file paths or references from previous nodes.\n    \n    *   Example: `\"attachments\": [\"{doc-0}\"]`\n        \n    \n\n**Configurations:**\n\n*   **connection\\_id** (Required if you have multiple Outlook accounts): Specify the Outlook connection to use.\n    \n    *   Example: `\"connection_id\": \"your-connection-id\"`\n        \n    \n\n**Outputs:**\n\n*   **message\\_id** (Always returned): The unique ID of the sent email.\n    \n*   **status** (Always returned): Confirmation of successful delivery or error details.\n    \n    *   Example:\n        \n        ```\n        {\n          \"message_id\": \"abc123\",\n          \"status\": \"sent\"\n        }\n        ```\n        \n    \n\n* * *\n\n#### \n\n2\\. Search Emails\n\n**Description:** Search your Outlook mailbox for emails matching specific criteria.\n\n**Inputs:**\n\n*   **query** (Required): The search query string (e.g., keywords, sender, date).\n    \n    *   Example: `\"query\": \"from:boss@example.com subject:invoice\"`\n        \n    \n*   **folder** (Optional): Specify the folder to search in (e.g., Inbox, Sent).\n    \n    *   Example: `\"folder\": \"Inbox\"`\n        \n    \n*   **max\\_results** (Optional): Limit the number of results.\n    \n    *   Example: `\"max_results\": 10`\n        \n    \n\n**Configurations:**\n\n*   **connection\\_id** (Required if you have multiple Outlook accounts): Specify the Outlook connection to use.\n    \n\n**Outputs:**\n\n*   **emails** (Always returned): List of matching emails with details such as subject, sender, date, and body.\n    \n    *   Example:\n        \n        ```\n        {\n          \"emails\": [\n            {\n              \"subject\": \"Invoice Due\",\n              \"from\": \"boss@example.com\",\n              \"date\": \"2025-07-01\",\n              \"body\": \"Please see the attached invoice.\"\n            }\n          ]\n        }\n        ```\n        \n    \n\n* * *\n\n**Best Practices**\n\n*   Always ensure required fields are filled to avoid errors.\n    \n*   Use dynamic references (e.g., `{llm-0}` or `{doc-0}`) to personalize emails or attach generated content.\n    \n*   For attachments, connect a Files node or other relevant node to provide file paths.\n    \n\n* * *\n\n**Summary Table**\n\nAction\n\nRequired Inputs\n\nOptional Inputs\n\nOutputs\n\n* * *\n\nAutomate your Outlook email workflows in StackAI to save time, reduce manual effort, and ensure consistent communication.\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"browser"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/netsuite","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/netsuite","loadedTime":"2025-10-17T18:28:31.391Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/netsuite","title":"NetSuite | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"NetSuite | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"date":"Fri, 17 Oct 2025 18:28:28 GMT","content-type":"text/html; charset=utf-8","content-encoding":"br","cf-ray":"9901db15ad1c8157-SEA","cf-cache-status":"DYNAMIC","age":"0","cache-control":"public, max-age=0, must-revalidate","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","referrer-policy":"no-referrer-when-downgrade","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"pdx1::iad1::7gfgw-1760725707204-ce289b2f9779","server":"cloudflare","alt-svc":"h3=\":443\"; ma=86400","x-firefox-spdy":"h2"}},"screenshotUrl":"https://api.apify.com/v2/key-value-stores/3K2WBdQQFTu6EGDhJ/records/SCREENSHOT-docs-stack-ai-com-stack-ai-workflow-builder-apps-netsuite-ab1d411d.jpg","text":"NetSuite | StackAI\nTo use the NetSuite Node in StackAI, use the Custom SuiteQL action. This action allows you to query Netsuite and retrieve any data stored there with a SQL query.\nCreating a Connection to NetSuite\nStackAI recommends creating connections using a dedicated user account with permissions scoped for the task in question. \nTo create a connection, select + NetSuite (OAuth). Then, log in with the user account. \nHere, you will be prompted to enter your Account ID, Client ID, and Client Secret.\nPermissions\nGive your service account user role permissions, and access to the necessary tables that you will be retrieving or writing data to. For access through StackAI, you may need to additionally give the service account permissions for \"Analytics and REST\" access to the table in question. For access to Messages for example, delegate permissions for Messages and also for Messages Analytics and REST\nTips\nAlways list the fields explicitly in your query:\nSELECT id, subject, author, recipient, activitydate FROM message WHERE activitydate >= '2025-01-01'\nYou may not be able to use SELECT * when querying Netsuite. Your user may not have permissions to all fields, causing an error. NetSuite is also not a traditional relational database; some fields are dynamically defined.","markdown":"# NetSuite | StackAI\n\nTo use the **NetSuite Node** in StackAI, use the Custom SuiteQL action. This action allows you to query Netsuite and retrieve any data stored there with a SQL query.\n\n### \n\n**Creating a Connection to NetSuite**\n\nStackAI recommends creating connections using a dedicated user account with permissions scoped for the task in question.\n\nTo create a connection, select **\\+ NetSuite (OAuth)**. Then, log in with the user account.\n\nHere, you will be prompted to enter your Account ID, Client ID, and Client Secret.\n\n#### \n\nPermissions\n\nGive your service account user role permissions, and access to the necessary tables that you will be retrieving or writing data to. For access through StackAI, you may need to additionally give the service account permissions for \"Analytics and REST\" access to the table in question. For access to `Messages` for example, delegate permissions for `Messages` and also for `Messages Analytics and REST`\n\n#### \n\nTips\n\nAlways **list the fields explicitly** in your query:\n\n```\nSELECT id, subject, author, recipient, activitydate\nFROM message\nWHERE activitydate >= '2025-01-01'\n```\n\nYou may not be able to use `SELECT *` when querying Netsuite. Your user may not have permissions to all fields, causing an error. NetSuite is also not a traditional relational database; some fields are dynamically defined.","debug":{"requestHandlerMode":"browser"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/notion","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/notion","loadedTime":"2025-10-17T18:28:32.062Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/notion","title":"Notion | StackAI","description":"Learn how to automate Notion page creation with StackAI: required inputs, configuration, and output details for seamless workflow integration.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Notion | StackAI"},{"property":"og:description","content":"Learn how to automate Notion page creation with StackAI: required inputs, configuration, and output details for seamless workflow integration."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"date":"Fri, 17 Oct 2025 18:28:28 GMT","content-type":"text/html; charset=utf-8","content-encoding":"br","cf-ray":"9901db1a9b528157-SEA","cf-cache-status":"DYNAMIC","age":"0","cache-control":"public, max-age=0, must-revalidate","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","referrer-policy":"no-referrer-when-downgrade","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"pdx1::iad1::8glq9-1760725707969-3c12bbcec0df","server":"cloudflare","alt-svc":"h3=\":443\"; ma=86400","x-firefox-spdy":"h2"}},"screenshotUrl":"https://api.apify.com/v2/key-value-stores/3K2WBdQQFTu6EGDhJ/records/SCREENSHOT-docs-stack-ai-com-stack-ai-workflow-builder-apps-notion-7a94fd40.jpg","text":"Notion | StackAI\nLearn how to automate Notion page creation with StackAI: required inputs, configuration, and output details for seamless workflow integration.\nWhat is Notion?\nNotion is a collaborative workspace that helps you organize, manage, and share information. With StackAI, you can automate the creation of Notion pages directly from your workflows, making it easy to generate structured content and knowledge bases.\nHow to use it?\nThe Notion node in StackAI allows you to create new pages in your Notion workspace. You must provide the parent page, a title, and the content for the new page. This node is ideal for automating documentation, meeting notes, or any structured data entry into Notion.\nExample of Usage\nSuppose you want to automatically create a project summary page in Notion after a workflow completes. You would use the Notion node to send the project details as a new page under a specific parent page.\nAvailable Actions\n1. Create Page\nCreate a new page in your Notion workspace under a specified parent page.\nInputs (All Required):\nParent Page (parent_page_id): Select the parent page under which the new page will be created. Example: \"d695667e-33c4-4b9d-9f93-8c01ec1d7b89\"\nTitle (title): The title of the new Notion page. Example: \"Weekly Project Update\"\nContent (content): The main content to be written as text blocks in the new page. Example: \"This week, we completed the following milestones...\"\nConfigurations: No additional configurations are required beyond the inputs above.\nOutputs (All Always Provided):\nPage ID (page_id): The unique identifier of the newly created Notion page. Example: \"b1a2c3d4e5f6g7h8i9j0\"\nMessage (message): A status message indicating the result of the operation. Example: \"Page created successfully.\"\nExample of Usage\nYou want to automate meeting notes creation:\nSet the Parent Page to your \"Meetings\" section.\nSet the Title to \"Team Sync - July 8, 2025\".\nSet the Content to the meeting summary generated by an LLM node.\nAfter execution, the Notion node will return the new page's ID, URL, and a success message, allowing you to share or reference the page in further workflow steps.\nLast updated 3 months ago","markdown":"# Notion | StackAI\n\nLearn how to automate Notion page creation with StackAI: required inputs, configuration, and output details for seamless workflow integration.\n\n**What is Notion?**\n\nNotion is a collaborative workspace that helps you organize, manage, and share information. With StackAI, you can automate the creation of Notion pages directly from your workflows, making it easy to generate structured content and knowledge bases.\n\n**How to use it?**\n\nThe Notion node in StackAI allows you to create new pages in your Notion workspace. You must provide the parent page, a title, and the content for the new page. This node is ideal for automating documentation, meeting notes, or any structured data entry into Notion.\n\n**Example of Usage**\n\nSuppose you want to automatically create a project summary page in Notion after a workflow completes. You would use the Notion node to send the project details as a new page under a specific parent page.\n\n* * *\n\n**Available Actions**\n\n#### \n\n1\\. Create Page\n\nCreate a new page in your Notion workspace under a specified parent page.\n\n**Inputs (All Required):**\n\n*   **Parent Page** (`parent_page_id`): Select the parent page under which the new page will be created. _Example:_ \"d695667e-33c4-4b9d-9f93-8c01ec1d7b89\"\n    \n*   **Title** (`title`): The title of the new Notion page. _Example:_ \"Weekly Project Update\"\n    \n*   **Content** (`content`): The main content to be written as text blocks in the new page. _Example:_ \"This week, we completed the following milestones...\"\n    \n\n**Configurations:** No additional configurations are required beyond the inputs above.\n\n**Outputs (All Always Provided):**\n\n*   **Page ID** (`page_id`): The unique identifier of the newly created Notion page. _Example:_ \"b1a2c3d4e5f6g7h8i9j0\"\n    \n\n*   **Message** (`message`): A status message indicating the result of the operation. _Example:_ \"Page created successfully.\"\n    \n\n* * *\n\n**Example of Usage**\n\nYou want to automate meeting notes creation:\n\n*   Set the Parent Page to your \"Meetings\" section.\n    \n*   Set the Title to \"Team Sync - July 8, 2025\".\n    \n*   Set the Content to the meeting summary generated by an LLM node.\n    \n\nAfter execution, the Notion node will return the new page's ID, URL, and a success message, allowing you to share or reference the page in further workflow steps.\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"browser"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/oracle","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/oracle","loadedTime":"2025-10-17T18:28:31.795Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/oracle","title":"Oracle | StackAI","description":"Learn how to use the Oracle node in StackAI to query Oracle databases using natural language or SQL, with clear input and output examples.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Oracle | StackAI"},{"property":"og:description","content":"Learn how to use the Oracle node in StackAI to query Oracle databases using natural language or SQL, with clear input and output examples."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"date":"Fri, 17 Oct 2025 18:28:28 GMT","content-type":"text/html; charset=utf-8","content-encoding":"br","cf-ray":"9901db1a29b98157-SEA","cf-cache-status":"DYNAMIC","age":"0","cache-control":"public, max-age=0, must-revalidate","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","referrer-policy":"no-referrer-when-downgrade","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"pdx1::iad1::8k5vh-1760725707919-0b7861c51c09","server":"cloudflare","alt-svc":"h3=\":443\"; ma=86400","x-firefox-spdy":"h2"}},"screenshotUrl":"https://api.apify.com/v2/key-value-stores/3K2WBdQQFTu6EGDhJ/records/SCREENSHOT-docs-stack-ai-com-stack-ai-workflow-builder-apps-oracle-566f0f6e.jpg","text":"Oracle | StackAI\nLearn how to use the Oracle node in StackAI to query Oracle databases using natural language or SQL, with clear input and output examples.\nLearn how to use the Oracle node in StackAI to query Oracle databases using natural language or SQL, with clear input and output examples.\nWhat is Oracle?\nThe Oracle node in StackAI allows you to query Oracle databases directly from your workflow. You can use plain English or SQL queries to retrieve data, making it easy to access and analyze your database information without writing complex code.\nHow to use it?\nTo use the Oracle node, you need to provide two required inputs:\nSchema: Describe your database schema, including tables, columns, and data types. This helps the node understand the structure of your database.\nQuery: Enter your question or request in plain English or as a SQL statement. The node will interpret your input, generate the appropriate SQL if needed, execute it, and return the results.\nExample of Usage\nSuppose you have a table called Employees with columns Name (TEXT), Department (TEXT), and Salary (REAL).\nSchema (Required):\nTABLE Employees ( Name TEXT, Department TEXT, Salary REAL );\nQuery (Required):\nWhat is the average salary in the Sales department?\nInputs\nName\nDescription\nRequired\nExample\nDatabase Schema (tables, columns, types, etc.)\nTABLE Employees (Name TEXT, Department TEXT, Salary REAL);\nEnter your query in plain English or SQL format to execute against database\nShow me all employees in the Engineering department\nConfigurations\nNo additional configurations are required for the Oracle node. All you need is the schema and the query.\nOutputs\nName\nDescription\nRequired\nExample\nThe SQL query that was executed\nSELECT AVG(Salary) FROM Employees WHERE Department = 'Sales';\nAvailable Actions\nQuery an Oracle Database: Execute a query (in plain English or SQL) against your Oracle database and retrieve the results.\nSummary Table\nAction Name\nDescription\nRequired Inputs\nOutputs\nRun queries on your Oracle database\nHow to use it in StackAI\nAdd the Oracle node to your workflow.\nFill in the Schema with your database structure.\nEnter your query in the Query field.\nConnect the node to downstream nodes to use the results.\nExample Output\nQuery: SELECT AVG(Salary) FROM Employees WHERE Department = 'Sales';\nResults: [{\"AVG(Salary)\": 85000}]\nThis makes it easy to integrate Oracle database queries into your StackAI workflows for reporting, analytics, and automation.\nLast updated 3 months ago","markdown":"# Oracle | StackAI\n\nLearn how to use the Oracle node in StackAI to query Oracle databases using natural language or SQL, with clear input and output examples.\n\nLearn how to use the Oracle node in StackAI to query Oracle databases using natural language or SQL, with clear input and output examples.\n\n**What is Oracle?**\n\nThe Oracle node in StackAI allows you to query Oracle databases directly from your workflow. You can use plain English or SQL queries to retrieve data, making it easy to access and analyze your database information without writing complex code.\n\n**How to use it?**\n\nTo use the Oracle node, you need to provide two required inputs:\n\n1.  **Schema**: Describe your database schema, including tables, columns, and data types. This helps the node understand the structure of your database.\n    \n2.  **Query**: Enter your question or request in plain English or as a SQL statement. The node will interpret your input, generate the appropriate SQL if needed, execute it, and return the results.\n    \n\n**Example of Usage**\n\nSuppose you have a table called Employees with columns Name (TEXT), Department (TEXT), and Salary (REAL).\n\n*   **Schema (Required):**\n    \n    ```\n    TABLE Employees (\n      Name TEXT,\n      Department TEXT,\n      Salary REAL\n    );\n    ```\n    \n*   **Query (Required):**\n    \n    ```\n    What is the average salary in the Sales department?\n    ```\n    \n\n**Inputs**\n\nName\n\nDescription\n\nRequired\n\nExample\n\nDatabase Schema (tables, columns, types, etc.)\n\n`TABLE Employees (Name TEXT, Department TEXT, Salary REAL);`\n\nEnter your query in plain English or SQL format to execute against database\n\n`Show me all employees in the Engineering department`\n\n**Configurations**\n\n*   No additional configurations are required for the Oracle node. All you need is the schema and the query.\n    \n\n**Outputs**\n\nName\n\nDescription\n\nRequired\n\nExample\n\nThe SQL query that was executed\n\n`SELECT AVG(Salary) FROM Employees WHERE Department = 'Sales';`\n\n**Available Actions**\n\n*   **Query an Oracle Database**: Execute a query (in plain English or SQL) against your Oracle database and retrieve the results.\n    \n\n**Summary Table**\n\nAction Name\n\nDescription\n\nRequired Inputs\n\nOutputs\n\nRun queries on your Oracle database\n\n**How to use it in StackAI**\n\n1.  Add the Oracle node to your workflow.\n    \n2.  Fill in the Schema with your database structure.\n    \n3.  Enter your query in the Query field.\n    \n4.  Connect the node to downstream nodes to use the results.\n    \n\n**Example Output**\n\n*   **Query**: `SELECT AVG(Salary) FROM Employees WHERE Department = 'Sales';`\n    \n*   **Results**: `[{\"AVG(Salary)\": 85000}]`\n    \n\nThis makes it easy to integrate Oracle database queries into your StackAI workflows for reporting, analytics, and automation.\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"browser"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/outreach","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/outreach","loadedTime":"2025-10-17T18:28:41.916Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/outreach","title":"Outreach | StackAI","description":"Learn how to use the Outreach integration node in StackAI, including available actions, input requirements, configuration, and output details.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Outreach | StackAI"},{"property":"og:description","content":"Learn how to use the Outreach integration node in StackAI, including available actions, input requirements, configuration, and output details."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"date":"Fri, 17 Oct 2025 18:28:38 GMT","content-type":"text/html; charset=utf-8","content-encoding":"br","cf-ray":"9901db556f788157-SEA","cf-cache-status":"DYNAMIC","age":"0","cache-control":"public, max-age=0, must-revalidate","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","referrer-policy":"no-referrer-when-downgrade","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"pdx1::iad1::khf8b-1760725717373-1f89cc91861e","server":"cloudflare","alt-svc":"h3=\":443\"; ma=86400","x-firefox-spdy":"h2"}},"screenshotUrl":"https://api.apify.com/v2/key-value-stores/3K2WBdQQFTu6EGDhJ/records/SCREENSHOT-docs-stack-ai-com-stack-ai-workflow-builder-apps-outreach-7ad12d5b.jpg","text":"Outreach | StackAI\nLearn how to use the Outreach integration node in StackAI, including available actions, input requirements, configuration, and output details.\nOutreach is a leading sales engagement platform. The Outreach Node allows you to automate and streamline sales operations, such as managing prospects, sequences, and tasks, directly from your StackAI workflows.\nHow to use it?\nTo use the Outreach node, select an action that matches your sales process needs (such as managing prospects or sequences). Configure the required connection and input parameters, then connect the node to other workflow steps to automate Outreach operations.\nInputs\nActionparams (string): a stringified JSON object that specifies the details required to add a prospect to a specific sequence in Outreach.\nAt a minimum, it typically defines:\nThe sequence ID (which Outreach sequence to add the prospect to)\nThe mailbox ID (which Outreach user account will send the sequence)\nOptionally, other fields like starting step, custom fields, or override settings\nExample: \"{\\\"sequence_id\\\":123456,\\\"mailbox_id\\\":987654}\"\nId (integer): This is the unique Prospect ID assigned by Outreach to the prospect you want to delete.\nIn Outreach, if you view a prospect's profile, the URL will look like: https://app.outreach.io/prospects/123456 . The number at the end (123456) is the Prospect ID.\nExamples: 123456, 987321, 456789\nSummary Table\nStatus code (integer), Headers (dict), Body (object)\nDelete An Existing Prospect By Id\nStatus code (integer), Headers (dict), Body (object)\nStatus code (integer), Headers (dict), Body (object)\nGet A Collection Of Prospects\nStatus code (integer), Headers (dict), Body (object)\nStatus code (integer), Headers (dict), Body (object)\nStatus code (integer), Headers (dict), Body (object)\nStatus code (integer), Headers (dict), Body (object)\nDelete An Existing Sequence By Id\nStatus code (integer), Headers (dict), Body (object)\nStatus code (integer), Headers (dict), Body (object)\nStatus code (integer), Headers (dict), Body (object)\nGet A Collection Of Sequences\nStatus code (integer), Headers (dict), Body (object)\nStatus code (integer), Headers (dict), Body (object)\nDelete An Existing Task By Id\nStatus code (integer), Headers (dict), Body (object)\nStatus code (integer), Headers (dict), Body (object)\nGet A Collection Of Tasks\nStatus code (integer), Headers (dict), Body (object)\nStatus code (integer), Headers (dict), Body (object)\nStatus code (integer), Headers (dict), Body (object)\nStatus code (integer), Headers (dict), Body (object)\nGet A Collection Of Users\nStatus code (integer), Headers (dict), Body (object)\nStatus code (integer), Headers (dict), Body (object)\nBest Practices:\nAlways ensure you provide the correct connection ID for authentication.\nRequired fields must be filled for the action to execute successfully.\nUse outputs from previous nodes (e.g., new lead data) as dynamic inputs for Outreach actions to automate your sales workflow.\nLast updated 2 months ago","markdown":"# Outreach | StackAI\n\nLearn how to use the Outreach integration node in StackAI, including available actions, input requirements, configuration, and output details.\n\nOutreach is a leading sales engagement platform. The **Outreach Node** allows you to automate and streamline sales operations, such as managing prospects, sequences, and tasks, directly from your StackAI workflows.\n\n**How to use it?**\n\nTo use the Outreach node, select an action that matches your sales process needs (such as managing prospects or sequences). Configure the required connection and input parameters, then connect the node to other workflow steps to automate Outreach operations.\n\n**Inputs**\n\n1.  **Actionparams** (string): a stringified JSON object that specifies the details required to add a prospect to a specific sequence in Outreach.\n    \n    At a minimum, it typically defines:\n    \n    *   The **sequence ID** (which Outreach sequence to add the prospect to)\n        \n    *   The **mailbox ID** (which Outreach user account will send the sequence)\n        \n    *   Optionally, other fields like **starting step**, **custom fields**, or **override settings**\n        \n    *   Example: `\"{\\\"sequence_id\\\":123456,\\\"mailbox_id\\\":987654}\"`\n        \n    \n2.  **Id** (integer): This is the **unique Prospect ID** assigned by Outreach to the prospect you want to delete.\n    \n    *   In Outreach, if you view a prospect's profile, the URL will look like: [`https://app.outreach.io/prospects/123456`](https://app.outreach.io/prospects/123456) . The number at the end (`123456`) is the Prospect ID.\n        \n    *   Examples: `123456`, `987321`, `456789`\n        \n    \n\n* * *\n\n**Summary Table**\n\nStatus code (integer), Headers (dict), Body (object)\n\nDelete An Existing Prospect By Id\n\nStatus code (integer), Headers (dict), Body (object)\n\nStatus code (integer), Headers (dict), Body (object)\n\nGet A Collection Of Prospects\n\nStatus code (integer), Headers (dict), Body (object)\n\nStatus code (integer), Headers (dict), Body (object)\n\nStatus code (integer), Headers (dict), Body (object)\n\nStatus code (integer), Headers (dict), Body (object)\n\nDelete An Existing Sequence By Id\n\nStatus code (integer), Headers (dict), Body (object)\n\nStatus code (integer), Headers (dict), Body (object)\n\nStatus code (integer), Headers (dict), Body (object)\n\nGet A Collection Of Sequences\n\nStatus code (integer), Headers (dict), Body (object)\n\nStatus code (integer), Headers (dict), Body (object)\n\nDelete An Existing Task By Id\n\nStatus code (integer), Headers (dict), Body (object)\n\nStatus code (integer), Headers (dict), Body (object)\n\nGet A Collection Of Tasks\n\nStatus code (integer), Headers (dict), Body (object)\n\nStatus code (integer), Headers (dict), Body (object)\n\nStatus code (integer), Headers (dict), Body (object)\n\nStatus code (integer), Headers (dict), Body (object)\n\nGet A Collection Of Users\n\nStatus code (integer), Headers (dict), Body (object)\n\nStatus code (integer), Headers (dict), Body (object)\n\n* * *\n\n**Best Practices:**\n\n*   Always ensure you provide the correct connection ID for authentication.\n    \n*   Required fields must be filled for the action to execute successfully.\n    \n*   Use outputs from previous nodes (e.g., new lead data) as dynamic inputs for Outreach actions to automate your sales workflow.\n    \n\nLast updated 2 months ago","debug":{"requestHandlerMode":"browser"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/pinecone","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/pinecone","loadedTime":"2025-10-17T18:28:42.617Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/pinecone","title":"Pinecone | StackAI","description":"The Pinecone node in your workflow is used to query a Pinecone vector database for similar vectors based on a text query.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Pinecone | StackAI"},{"property":"og:description","content":"The Pinecone node in your workflow is used to query a Pinecone vector database for similar vectors based on a text query."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"date":"Fri, 17 Oct 2025 18:28:40 GMT","content-type":"text/html; charset=utf-8","content-encoding":"br","cf-ray":"9901db60bbb48157-SEA","cf-cache-status":"DYNAMIC","age":"0","cache-control":"public, max-age=0, must-revalidate","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","referrer-policy":"no-referrer-when-downgrade","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"pdx1::iad1::n2v9f-1760725719195-dd5237426a96","server":"cloudflare","alt-svc":"h3=\":443\"; ma=86400","x-firefox-spdy":"h2"}},"screenshotUrl":"https://api.apify.com/v2/key-value-stores/3K2WBdQQFTu6EGDhJ/records/SCREENSHOT-docs-stack-ai-com-stack-ai-workflow-builder-apps-pinecone-4d243bef.jpg","text":"Pinecone | StackAI\nThe Pinecone node in your workflow is used to query a Pinecone vector database for similar vectors based on a text query.\nThe Pinecone Node allows you to search a Pinecone vector database for vectors that are most similar to a given text input. It returns a list of similar vectors along with their metadata.\nRequired Inputs for the Pinecone Node\nTo use the Pinecone node, you need to provide the following input parameters:\nQuery (string, required): The text you want to search for similar vectors. For example, \"AI marketing trends\".\nNumber of Results (top_k) (integer, required): How many similar vectors you want to retrieve. The default is 5.\nIndex Name (string, required): The name of the Pinecone index you want to query.\nNamespace (string, optional): An optional namespace within the Pinecone index to scope your query.\nOutput\nThe node outputs a field called Results, which contains the similar vectors found in the database, along with their metadata.\nExample Usage\nIf you want to find the top 5 most similar vectors to the phrase \"StackAI product launch\" in your \"company-updates\" index, you would set:\nQuery: \"StackAI product launch\"\nNumber of Results: 5\nIndex Name: \"company-updates\"\nNamespace: (leave blank or specify if needed)\nThe Pinecone node will then return the most relevant vectors, which you can use for recommendations, search, or further processing in your workflow.\nLast updated 3 months ago","markdown":"# Pinecone | StackAI\n\nThe Pinecone node in your workflow is used to query a Pinecone vector database for similar vectors based on a text query.\n\nThe **Pinecone Node** allows you to search a Pinecone vector database for vectors that are most similar to a given text input. It returns a list of similar vectors along with their metadata.\n\n#### \n\nRequired Inputs for the Pinecone Node\n\nTo use the Pinecone node, you need to provide the following input parameters:\n\n1.  **Query** (string, required): The text you want to search for similar vectors. For example, \"AI marketing trends\".\n    \n2.  **Number of Results (top\\_k)** (integer, required): How many similar vectors you want to retrieve. The default is 5.\n    \n3.  **Index Name** (string, required): The name of the Pinecone index you want to query.\n    \n4.  **Namespace** (string, optional): An optional namespace within the Pinecone index to scope your query.\n    \n\n#### \n\nOutput\n\n*   The node outputs a field called **Results**, which contains the similar vectors found in the database, along with their metadata.\n    \n\n**Example Usage**\n\n*   If you want to find the top 5 most similar vectors to the phrase \"StackAI product launch\" in your \"company-updates\" index, you would set:\n    \n    *   Query: \"StackAI product launch\"\n        \n    *   Number of Results: 5\n        \n    *   Index Name: \"company-updates\"\n        \n    *   Namespace: (leave blank or specify if needed)\n        \n    \n\nThe Pinecone node will then return the most relevant vectors, which you can use for recommendations, search, or further processing in your workflow.\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"browser"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/pitchbook","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/pitchbook","loadedTime":"2025-10-17T18:28:52.704Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/pitchbook","title":"Pitchbook | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Pitchbook | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"date":"Fri, 17 Oct 2025 18:28:50 GMT","content-type":"text/html; charset=utf-8","content-encoding":"br","cf-ray":"9901dba4ddd78157-SEA","cf-cache-status":"DYNAMIC","age":"0","cache-control":"public, max-age=0, must-revalidate","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","referrer-policy":"no-referrer-when-downgrade","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"pdx1::iad1::c4djs-1760725730087-7da71186d18d","server":"cloudflare","alt-svc":"h3=\":443\"; ma=86400","x-firefox-spdy":"h2"}},"screenshotUrl":"https://api.apify.com/v2/key-value-stores/3K2WBdQQFTu6EGDhJ/records/SCREENSHOT-docs-stack-ai-com-stack-ai-workflow-builder-apps-pitchbook-2b796816.jpg","text":"Pitchbook | StackAI\nThe PitchBook Node allows you to access private market intelligence, company, and deal data through PitchBook’s search capabilities. It is designed to help you find information about companies, deals, investors, and more from the PitchBook database.\nAvailable Actions\nPitchBook Search\nThis is the main action available for the PitchBook node.\nIt lets you search the PitchBook database using a text query and returns relevant results.\nRequired Inputs\nQuery (string, required): The search term or phrase you want to look up in PitchBook. Example: \"StackAI funding rounds\"\nTop K (integer, optional, default 10): The number of results to return (up to 100). Example: 5\nOutput\nQuery: The query you used.\nSearch Results: An array of results, where each result contains:\nTitle: The title of the PitchBook result.\nText: The text content or summary of the result.\nExample Usage\nSuppose you want to find recent deals involving \"StackAI\":\nSet the Query to \"StackAI deals\".\nOptionally set Top K to 5 if you only want the top 5 results.\nThe node will return a list of results, each with a title and a summary text, which you can then use in downstream nodes (like an LLM for summarization or an Output node for display).\nHow to Connect and Use in Your Workflow\nConnect an Input Node: Pass a user’s search term or a dynamic query from another node to the PitchBook node’s query input.\nConfigure Top K: Set how many results you want (optional).\nUse the Output: The results can be sent to an Output node, a Template node for formatting, or an LLM node for further analysis.\nSummary Table\nInput Name\nType\nRequired\nDescription\nThe search term for PitchBook\nNumber of results to return (max 100, default 10)\nOutput Name\nType\nDescription\nList of results (each with title and text)\nIf you want to use this node, just provide a search query (and optionally, the number of results), and connect the output to wherever you want to use the PitchBook data in your workflow! If you need a sample configuration or want to see how to wire it up, let me know.\nLast updated 3 months ago","markdown":"# Pitchbook | StackAI\n\nThe **PitchBook Node** allows you to access private market intelligence, company, and deal data through PitchBook’s search capabilities. It is designed to help you find information about companies, deals, investors, and more from the PitchBook database.\n\n* * *\n\n### \n\nAvailable Actions\n\n**PitchBook Search**\n\n*   This is the main action available for the PitchBook node.\n    \n*   It lets you search the PitchBook database using a text query and returns relevant results.\n    \n\n#### \n\nRequired Inputs\n\n*   **Query** (string, required): The search term or phrase you want to look up in PitchBook. _Example: \"StackAI funding rounds\"_\n    \n*   **Top K** (integer, optional, default 10): The number of results to return (up to 100). _Example: 5_\n    \n\n#### \n\nOutput\n\n*   **Query**: The query you used.\n    \n*   **Search Results**: An array of results, where each result contains:\n    \n    *   **Title**: The title of the PitchBook result.\n        \n    *   **Text**: The text content or summary of the result.\n        \n    \n\n* * *\n\n### \n\nExample Usage\n\nSuppose you want to find recent deals involving \"StackAI\":\n\n*   Set the **Query** to \"StackAI deals\".\n    \n*   Optionally set **Top K** to 5 if you only want the top 5 results.\n    \n\nThe node will return a list of results, each with a title and a summary text, which you can then use in downstream nodes (like an LLM for summarization or an Output node for display).\n\n* * *\n\n### \n\nHow to Connect and Use in Your Workflow\n\n1.  **Connect an Input Node**: Pass a user’s search term or a dynamic query from another node to the PitchBook node’s query input.\n    \n2.  **Configure Top K**: Set how many results you want (optional).\n    \n3.  **Use the Output**: The results can be sent to an Output node, a Template node for formatting, or an LLM node for further analysis.\n    \n\n* * *\n\n### \n\nSummary Table\n\nInput Name\n\nType\n\nRequired\n\nDescription\n\nThe search term for PitchBook\n\nNumber of results to return (max 100, default 10)\n\nOutput Name\n\nType\n\nDescription\n\nList of results (each with title and text)\n\n* * *\n\nIf you want to use this node, just provide a search query (and optionally, the number of results), and connect the output to wherever you want to use the PitchBook data in your workflow! If you need a sample configuration or want to see how to wire it up, let me know.\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"browser"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/power-bi","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/power-bi","loadedTime":"2025-10-17T18:28:54.502Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/power-bi","title":"Power BI | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Power BI | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"date":"Fri, 17 Oct 2025 18:28:51 GMT","content-type":"text/html; charset=utf-8","content-encoding":"br","cf-ray":"9901dba2f8b38157-SEA","cf-cache-status":"DYNAMIC","age":"0","cache-control":"public, max-age=0, must-revalidate","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","referrer-policy":"no-referrer-when-downgrade","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"pdx1::iad1::95xmg-1760725729793-a3664ab511f7","server":"cloudflare","alt-svc":"h3=\":443\"; ma=86400","x-firefox-spdy":"h2"}},"screenshotUrl":"https://api.apify.com/v2/key-value-stores/3K2WBdQQFTu6EGDhJ/records/SCREENSHOT-docs-stack-ai-com-stack-ai-workflow-builder-apps-power-bi-1566b32f.jpg","text":"Power BI | StackAI\nThe Power BI Node allows you to interact with your Power BI workspace directly from your workflow. You can retrieve information about datasets and reports, list all available datasets/reports, and get detailed metadata for each. This is useful for integrating business analytics, dashboards, and data insights into your automated processes.\nAvailable Actions\n1. List Datasets\nPurpose: Retrieve a list of all datasets in your Power BI workspace.\nInputs: None required.\nOutputs:\ndatasets: Array of datasets, each with:\nid: Dataset ID\nname: Dataset name\nis_refreshable: Whether the dataset can be refreshed\nconfigured_by: Who configured it\nis_on_prem_gateway_required: If an on-premises gateway is needed\nweb_url: Link to the dataset\ncount: Total number of datasets\n2. Get Dataset\nPurpose: Retrieve detailed information about a specific dataset.\nInputs:\ndataset_id (string, required): The ID of the dataset you want details for.\nOutputs:\ndataset: Object with:\nid, name, web_url, datasource_type, configured_by, created_date\n3. List Reports\nPurpose: Retrieve a list of all reports in your Power BI workspace.\nInputs: None required.\nOutputs:\nreports: Array of reports, each with:\nid: Report ID\nname: Report name\nweb_url: Link to view the report\nembed_url: URL for embedding\ndataset_id: Associated dataset\nreport_type: Type (PaginatedReport or PowerBIReport)\nis_owned_by_me: If you can modify/copy it\ncount: Total number of reports\n4. Get Report\nPurpose: Retrieve detailed information about a specific report.\nInputs:\nreport_id (string, required): The ID of the report you want details for.\nOutputs:\nreport: Object with:\nid, name, web_url, embed_url, dataset_id, report_type, description\nHow to Use the Power BI Node\nList Datasets/Reports:\nAdd the Power BI node and select the \"List Datasets\" or \"List Reports\" action.\nNo input is needed; the node will output a list of all datasets or reports in your workspace.\nGet Dataset/Report Details:\nFirst, use \"List Datasets\" or \"List Reports\" to get the IDs.\nAdd another Power BI node and select \"Get Dataset\" or \"Get Report\".\nProvide the dataset_id or report_id as input (can be referenced from the output of the previous node).\nConnect to Output or LLM:\nYou can send the results to an Output node for display, or to an LLM node for further analysis or summarization.\nUse a Connection ID:\nIf you have a Power BI connection, add the connection ID in the node’s configuration to access your specific workspace.\nExample Workflow\nStep 1: Use \"List Reports\" to get all reports.\nStep 2: Use \"Get Report\" with a selected report ID to get detailed info.\nStep 3: Send the report details to an Output node or summarize with an LLM.\nSummary Table\nAction\nInput(s)\nOutput(s)\nDescription\nList all datasets in workspace\nGet details for a specific dataset\nList all reports in workspace\nGet details for a specific report\nLast updated 3 months ago","markdown":"# Power BI | StackAI\n\nThe **Power BI Node** allows you to interact with your Power BI workspace directly from your workflow. You can retrieve information about datasets and reports, list all available datasets/reports, and get detailed metadata for each. This is useful for integrating business analytics, dashboards, and data insights into your automated processes.\n\n* * *\n\n### \n\nAvailable Actions\n\n#### \n\n1\\. List Datasets\n\n*   **Purpose:** Retrieve a list of all datasets in your Power BI workspace.\n    \n*   **Inputs:** None required.\n    \n*   **Outputs:**\n    \n    *   `datasets`: Array of datasets, each with:\n        \n        *   `id`: Dataset ID\n            \n        *   `name`: Dataset name\n            \n        *   `is_refreshable`: Whether the dataset can be refreshed\n            \n        *   `configured_by`: Who configured it\n            \n        *   `is_on_prem_gateway_required`: If an on-premises gateway is needed\n            \n        *   `web_url`: Link to the dataset\n            \n        \n    *   `count`: Total number of datasets\n        \n    \n\n* * *\n\n#### \n\n2\\. Get Dataset\n\n*   **Purpose:** Retrieve detailed information about a specific dataset.\n    \n*   **Inputs:**\n    \n    *   `dataset_id` (string, required): The ID of the dataset you want details for.\n        \n    \n*   **Outputs:**\n    \n    *   `dataset`: Object with:\n        \n        *   `id`, `name`, `web_url`, `datasource_type`, `configured_by`, `created_date`\n            \n        \n    \n\n* * *\n\n#### \n\n3\\. List Reports\n\n*   **Purpose:** Retrieve a list of all reports in your Power BI workspace.\n    \n*   **Inputs:** None required.\n    \n*   **Outputs:**\n    \n    *   `reports`: Array of reports, each with:\n        \n        *   `id`: Report ID\n            \n        *   `name`: Report name\n            \n        *   `web_url`: Link to view the report\n            \n        *   `embed_url`: URL for embedding\n            \n        *   `dataset_id`: Associated dataset\n            \n        *   `report_type`: Type (PaginatedReport or PowerBIReport)\n            \n        *   `is_owned_by_me`: If you can modify/copy it\n            \n        \n    *   `count`: Total number of reports\n        \n    \n\n* * *\n\n#### \n\n4\\. Get Report\n\n*   **Purpose:** Retrieve detailed information about a specific report.\n    \n*   **Inputs:**\n    \n    *   `report_id` (string, required): The ID of the report you want details for.\n        \n    \n*   **Outputs:**\n    \n    *   `report`: Object with:\n        \n        *   `id`, `name`, `web_url`, `embed_url`, `dataset_id`, `report_type`, `description`\n            \n        \n    \n\n* * *\n\n### \n\nHow to Use the Power BI Node\n\n1.  **List Datasets/Reports:**\n    \n    *   Add the Power BI node and select the \"List Datasets\" or \"List Reports\" action.\n        \n    *   No input is needed; the node will output a list of all datasets or reports in your workspace.\n        \n    \n2.  **Get Dataset/Report Details:**\n    \n    *   First, use \"List Datasets\" or \"List Reports\" to get the IDs.\n        \n    *   Add another Power BI node and select \"Get Dataset\" or \"Get Report\".\n        \n    *   Provide the `dataset_id` or `report_id` as input (can be referenced from the output of the previous node).\n        \n    \n3.  **Connect to Output or LLM:**\n    \n    *   You can send the results to an Output node for display, or to an LLM node for further analysis or summarization.\n        \n    \n4.  **Use a Connection ID:**\n    \n    *   If you have a Power BI connection, add the connection ID in the node’s configuration to access your specific workspace.\n        \n    \n\n* * *\n\n### \n\nExample Workflow\n\n*   **Step 1:** Use \"List Reports\" to get all reports.\n    \n*   **Step 2:** Use \"Get Report\" with a selected report ID to get detailed info.\n    \n*   **Step 3:** Send the report details to an Output node or summarize with an LLM.\n    \n\n* * *\n\n### \n\nSummary Table\n\nAction\n\nInput(s)\n\nOutput(s)\n\nDescription\n\nList all datasets in workspace\n\nGet details for a specific dataset\n\nList all reports in workspace\n\nGet details for a specific report\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"browser"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/reducto","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/reducto","loadedTime":"2025-10-17T18:28:54.505Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/reducto","title":"Reducto | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Reducto | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"date":"Fri, 17 Oct 2025 18:28:51 GMT","content-type":"text/html; charset=utf-8","content-encoding":"br","cf-ray":"9901dba80e808157-SEA","cf-cache-status":"DYNAMIC","age":"0","cache-control":"public, max-age=0, must-revalidate","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","referrer-policy":"no-referrer-when-downgrade","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"pdx1::iad1::qmdqd-1760725730586-c3417c8625a2","server":"cloudflare","alt-svc":"h3=\":443\"; ma=86400","x-firefox-spdy":"h2"}},"screenshotUrl":"https://api.apify.com/v2/key-value-stores/3K2WBdQQFTu6EGDhJ/records/SCREENSHOT-docs-stack-ai-com-stack-ai-workflow-builder-apps-reducto-ecda5a3f.jpg","text":"Reducto | StackAI\nReducto is an integration that provides advanced document and data processing capabilities. It is often used for parsing, extracting, editing, and splitting documents or data files, as well as managing asynchronous jobs related to these operations. Reducto is especially useful for workflows that require automated document understanding, transformation, or extraction.\nAvailable Actions\nAction Name\nDescription (Summary)\nParses a document or file to extract structured data or text.\nSubmits a document for parsing and returns a job ID for later retrieval.\nExtracts specific information or sections from a document.\nSubmits an extraction job and returns a job ID for asynchronous processing.\nApplies edits or transformations to a document.\nSubmits an edit job for asynchronous processing.\nSplits a document into multiple parts based on rules or structure.\nRetrieves the result of a previously submitted async parse job using its job ID.\nCancels an ongoing asynchronous job by job ID.\nSets up a webhook to receive notifications about job status or completion.\nHow to Use the Reducto Node\nChoose the Action:\nSelect the Reducto node in your workflow and pick the action that matches your use case (e.g., Parse, Extract, Edit, Split).\nProvide Inputs:\nFor most actions, you will need to provide a file, document, or text input. Some actions may require additional parameters (such as extraction rules, edit instructions, or split criteria).\nAsynchronous Jobs:\nFor async actions, you will receive a job ID. Use the \"Retrieve Parse Job\" or similar action to check the status or get the result when processing is complete.\nWebhooks (Optional):\nIf you want to be notified when a job is done, use the \"Configure Webhook\" action to set up a callback URL.\nConnect to Output or Downstream Nodes:\nThe results from Reducto actions can be sent to Output nodes, LLM nodes, or further processing nodes in your workflow.\nExample Use Cases\nDocument Parsing: Automatically extract tables, text, or metadata from uploaded PDFs or Word documents.\nData Extraction: Pull out specific fields (like names, dates, or totals) from invoices or forms.\nDocument Splitting: Break up large documents into smaller, manageable sections for further analysis.\nAutomated Editing: Redact sensitive information or reformat documents before sharing.\nLast updated 3 months ago","markdown":"# Reducto | StackAI\n\n**Reducto** is an integration that provides advanced document and data processing capabilities. It is often used for parsing, extracting, editing, and splitting documents or data files, as well as managing asynchronous jobs related to these operations. Reducto is especially useful for workflows that require automated document understanding, transformation, or extraction.\n\n* * *\n\n### \n\nAvailable Actions\n\nAction Name\n\nDescription (Summary)\n\nParses a document or file to extract structured data or text.\n\nSubmits a document for parsing and returns a job ID for later retrieval.\n\nExtracts specific information or sections from a document.\n\nSubmits an extraction job and returns a job ID for asynchronous processing.\n\nApplies edits or transformations to a document.\n\nSubmits an edit job for asynchronous processing.\n\nSplits a document into multiple parts based on rules or structure.\n\nRetrieves the result of a previously submitted async parse job using its job ID.\n\nCancels an ongoing asynchronous job by job ID.\n\nSets up a webhook to receive notifications about job status or completion.\n\n* * *\n\n### \n\nHow to Use the Reducto Node\n\n1.  **Choose the Action:**\n    \n    *   Select the Reducto node in your workflow and pick the action that matches your use case (e.g., Parse, Extract, Edit, Split).\n        \n    \n2.  **Provide Inputs:**\n    \n    *   For most actions, you will need to provide a file, document, or text input. Some actions may require additional parameters (such as extraction rules, edit instructions, or split criteria).\n        \n    \n3.  **Asynchronous Jobs:**\n    \n    *   For async actions, you will receive a job ID. Use the \"Retrieve Parse Job\" or similar action to check the status or get the result when processing is complete.\n        \n    \n4.  **Webhooks (Optional):**\n    \n    *   If you want to be notified when a job is done, use the \"Configure Webhook\" action to set up a callback URL.\n        \n    \n5.  **Connect to Output or Downstream Nodes:**\n    \n    *   The results from Reducto actions can be sent to Output nodes, LLM nodes, or further processing nodes in your workflow.\n        \n    \n\n* * *\n\n### \n\nExample Use Cases\n\n*   **Document Parsing:** Automatically extract tables, text, or metadata from uploaded PDFs or Word documents.\n    \n*   **Data Extraction:** Pull out specific fields (like names, dates, or totals) from invoices or forms.\n    \n*   **Document Splitting:** Break up large documents into smaller, manageable sections for further analysis.\n    \n*   **Automated Editing:** Redact sensitive information or reformat documents before sharing.\n    \n\nLast updated 3 months ago","debug":{"requestHandlerMode":"browser"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/postgresql","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/postgresql","loadedTime":"2025-10-17T18:28:55.016Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/postgresql","title":"PostgreSQL | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"PostgreSQL | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"date":"Fri, 17 Oct 2025 18:28:51 GMT","content-type":"text/html; charset=utf-8","content-encoding":"br","cf-ray":"9901dba72c548157-SEA","cf-cache-status":"DYNAMIC","age":"0","cache-control":"public, max-age=0, must-revalidate","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","referrer-policy":"no-referrer-when-downgrade","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"pdx1::iad1::27x57-1760725730453-deb018ceb731","server":"cloudflare","alt-svc":"h3=\":443\"; ma=86400","x-firefox-spdy":"h2"}},"screenshotUrl":"https://api.apify.com/v2/key-value-stores/3K2WBdQQFTu6EGDhJ/records/SCREENSHOT-docs-stack-ai-com-stack-ai-workflow-builder-apps-postgresql-5d8455d8.jpg","text":"PostgreSQL | StackAI\nThe PostgreSQL Node allows you to query a PostgreSQL database directly from your workflow. It is designed to take a user’s question (in plain English or SQL), convert it into a SQL query if needed, execute it against your connected PostgreSQL database, and return the results.\nRequired Inputs\nQuery (string, required)\nThis is the main input. You can enter your question in plain English (e.g., \"Show me the top 10 customers by revenue\") or provide a raw SQL query.\nThe node will interpret the plain English query and generate the appropriate SQL, or execute your SQL directly.\nSchema (array of strings, optional but recommended)\nThis is where you can provide the database schema (tables, columns, types, etc.) to help the node understand your database structure.\nExample:\nTABLE Customers (Name TEXT, Email TEXT, Revenue REAL); TABLE Orders (OrderID INT, CustomerID INT, Amount REAL);\nProviding the schema is especially helpful if you want the node to convert plain English to SQL accurately.\nOutput\nQuery: The actual SQL query that was executed.\nResults: The results of the query, returned as an array of objects (rows).\nExample Usage\nPlain English Query: Input: \"What is the total revenue for the year 2024?\" Output: The node will generate the SQL, run it, and return the result.\nSQL Query: Input: SELECT SUM(revenue) FROM sales WHERE year = 2024; Output: The node will execute this SQL and return the result.\nHow to Connect\nIf you have a PostgreSQL connection ID, you can add it to the node’s configuration to connect to your specific database.\nYou can connect the output of this node to downstream nodes (like an LLM for analysis, or an Output node for display).\nSummary Table\nInput Name\nType\nRequired\nDescription\nThe question or SQL to execute\nDatabase schema (tables, columns, types, etc.)\nOutput Name\nType\nDescription\nThe SQL query that was executed\nIf you want to use this node, just provide your question or SQL, and (optionally) the schema. The node will handle the rest—querying your PostgreSQL database and returning the results for use elsewhere in your workflow!\nLast updated 3 months ago","markdown":"# PostgreSQL | StackAI\n\nThe **PostgreSQL Node** allows you to query a PostgreSQL database directly from your workflow. It is designed to take a user’s question (in plain English or SQL), convert it into a SQL query if needed, execute it against your connected PostgreSQL database, and return the results.\n\n* * *\n\n#### \n\nRequired Inputs\n\n1.  **Query** (string, required)\n    \n    *   This is the main input. You can enter your question in plain English (e.g., \"Show me the top 10 customers by revenue\") or provide a raw SQL query.\n        \n    *   The node will interpret the plain English query and generate the appropriate SQL, or execute your SQL directly.\n        \n    \n2.  **Schema** (array of strings, optional but recommended)\n    \n    *   This is where you can provide the database schema (tables, columns, types, etc.) to help the node understand your database structure.\n        \n    *   Example:\n        \n        ```\n        TABLE Customers (Name TEXT, Email TEXT, Revenue REAL);\n        TABLE Orders (OrderID INT, CustomerID INT, Amount REAL);\n        ```\n        \n    *   Providing the schema is especially helpful if you want the node to convert plain English to SQL accurately.\n        \n    \n\n#### \n\nOutput\n\n*   **Query**: The actual SQL query that was executed.\n    \n*   **Results**: The results of the query, returned as an array of objects (rows).\n    \n\n* * *\n\n### \n\nExample Usage\n\n*   **Plain English Query:** Input: \"What is the total revenue for the year 2024?\" Output: The node will generate the SQL, run it, and return the result.\n    \n*   **SQL Query:** Input: `SELECT SUM(revenue) FROM sales WHERE year = 2024;` Output: The node will execute this SQL and return the result.\n    \n\n* * *\n\n### \n\nHow to Connect\n\n*   If you have a PostgreSQL connection ID, you can add it to the node’s configuration to connect to your specific database.\n    \n*   You can connect the output of this node to downstream nodes (like an LLM for analysis, or an Output node for display).\n    \n\n* * *\n\n### \n\nSummary Table\n\nInput Name\n\nType\n\nRequired\n\nDescription\n\nThe question or SQL to execute\n\nDatabase schema (tables, columns, types, etc.)\n\nOutput Name\n\nType\n\nDescription\n\nThe SQL query that was executed\n\n* * *\n\nIf you want to use this node, just provide your question or SQL, and (optionally) the schema. The node will handle the rest—querying your PostgreSQL database and returning the results for use elsewhere in your workflow!\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"browser"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/runwayml","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/runwayml","loadedTime":"2025-10-17T18:29:07.077Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/runwayml","title":"RunwayML | StackAI","description":"Discover how to use the RunwayML node in StackAI to generate AI-powered images and videos with customizable prompts, models, and output settings.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"RunwayML | StackAI"},{"property":"og:description","content":"Discover how to use the RunwayML node in StackAI to generate AI-powered images and videos with customizable prompts, models, and output settings."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1323","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dc0d8fead6a4-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:07 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::fvtkp-1760725746846-afe7cc947fc0"}},"screenshotUrl":null,"text":"RunwayML | StackAI\nDiscover how to use the RunwayML node in StackAI to generate AI-powered images and videos with customizable prompts, models, and output settings.\nWhat is RunwayML?\nRunwayML is an AI-powered node in StackAI that enables users to generate high-quality images and videos using advanced generative models. It supports both text-to-image and image-to-video workflows, making it ideal for creative projects, content generation, and multimedia automation.\nHow to use it?\nThe RunwayML node offers two main actions:\nGenerate Video from Image\nGenerate Image from Text\nEach action has its own set of inputs, configurations, and outputs. Below are detailed explanations and examples for each.\n1. Generate Video from Image\nCreate a video from an initial image, with optional text prompt guidance and customizable settings.\nInputs:\nImage URL (string, required): The publicly accessible URL of the image to use as the first frame of the video. Example: \"https://example.com/image.png\"\nPrompt (string, optional): A text prompt to guide the video generation. Example: \"A futuristic cityscape at sunset\"\nConfigurations:\nModel (select, optional, default: Gen4 Turbo): The model variant for video generation. Options: \"gen4_turbo\"\nDuration (select, optional, default: 5): The length of the generated video in seconds. Options: 5 or 10\nAspect Ratio (select, optional, default: 1280:720): The output video’s aspect ratio. Options:\n1280:720\n720:1280\n1104:832\n832:1104\n960:960\n1584:672\nSeed (number, optional): Random seed for reproducible results (0-4294967295), using the same seed will produce the same image if all inputs and configurations are the same. Example: 123456\nWatermark (boolean, optional, default: true): Whether to add a RunwayML watermark to the video. Options: true or false\nOutputs:\nVideo URL (string): The URL to download or view the generated video.\nTask ID (string): The unique identifier for the video generation task.\nExample of Usage:\n{ \"image_url\": \"https://example.com/image.png\", \"prompt\": \"A futuristic cityscape at sunset\", \"model\": \"gen4_turbo\", \"duration\": 10, \"aspect_ratio\": \"1280:720\", \"seed\": 123456, \"watermark\": false }\nOutput:\n{ \"video_url\": \"https://runwayml.com/generated/video123.mp4\", \"task_id\": \"task_abc123\" }\n2. Generate Image from Text\nCreate an image from a detailed text prompt, with options for model, resolution, and more.\nInputs:\nPrompt (string, required): A detailed text description of the image to generate. Example: \"A serene mountain landscape with a clear blue lake\"\nConfigurations:\nModel (select, optional, default: Gen4 Image): The model to use for image generation. Options: \"gen4_image\"\nResolution (select, optional, default: 1024:1024): The output image’s resolution/aspect ratio. Options include:\n1920:1080 (16:9)\n1080:1920 (9:16)\n1024:1024 (Square)\n1360:768 (Landscape)\n1080:1080 (Square)\n1168:880 (4:3)\n1440:1080 (4:3)\n1080:1440 (3:4)\n1808:768 (Wide)\n2112:912 (Ultra Wide)\n1280:720 (HD)\n720:1280 (Portrait HD)\n720:720 (Square HD)\n960:720 (4:3 HD)\n720:960 (3:4 HD)\n1680:720 (Cinematic)\nSeed (number, optional): Random seed for reproducible results (0-4294967295), using the same seed will produce the same image if all inputs and configurations are the same. Example: 78910\nPublic Figure Threshold (select, optional, default: auto): Content moderation strictness for public figures. Options: \"auto\", \"low\"\nReference Images (string array, optional): Array of image URLs to use as references for generation. Can help augment the style of the image created. Example: [\"https://example.com/ref1.jpg\", \"https://example.com/ref2.jpg\"]\nOutputs:\nImage URL (string): The URL to download or view the generated image.\nTask ID (string): The unique identifier for the image generation task.\nExample of Usage:\n{ \"prompt\": \"A serene mountain landscape with a clear blue lake\", \"model\": \"gen4_image\", \"resolution\": \"1920:1080\", \"seed\": 78910, \"public_figure_threshold\": \"auto\", \"reference_images\": [\"https://example.com/ref1.jpg\"] }\nOutput:\n{ \"image_url\": \"https://runwayml.com/generated/image456.png\", \"task_id\": \"task_def456\" }\nSummary Table\nAction\nRequired Inputs\nOptional Configurations\nOutputs (Required)\nprompt, model, duration, aspect_ratio, seed, watermark\nmodel, resolution, seed, public_figure_threshold, reference_images\nAdvanced Settings\nRetry on Failure: Enable retrying when the node execution fails\nFallback Branch: Create a separate branch that executes when this node fails, allowing you to handle errors gracefullyCreate a separate branch that executes when this node fails, allowing you to handle errors gracefully\nLast updated 2 months ago","markdown":"# RunwayML | StackAI\n\nDiscover how to use the RunwayML node in StackAI to generate AI-powered images and videos with customizable prompts, models, and output settings.\n\n**What is RunwayML?**\n\nRunwayML is an AI-powered node in StackAI that enables users to generate high-quality images and videos using advanced generative models. It supports both text-to-image and image-to-video workflows, making it ideal for creative projects, content generation, and multimedia automation.\n\n* * *\n\n**How to use it?**\n\nThe RunwayML node offers two main actions:\n\n1.  **Generate Video from Image**\n    \n2.  **Generate Image from Text**\n    \n\nEach action has its own set of inputs, configurations, and outputs. Below are detailed explanations and examples for each.\n\n* * *\n\n#### \n\n1\\. Generate Video **from Image**\n\nCreate a video from an initial image, with optional text prompt guidance and customizable settings.\n\n**Inputs:**\n\n*   **Image URL** (string, required): The publicly accessible URL of the image to use as the first frame of the video. _Example:_ `\"https://example.com/image.png\"`\n    \n*   **Prompt** (string, optional): A text prompt to guide the video generation. _Example:_ `\"A futuristic cityscape at sunset\"`\n    \n\n**Configurations:**\n\n*   **Model** (select, optional, default: Gen4 Turbo): The model variant for video generation. _Options:_ `\"gen4_turbo\"`\n    \n*   **Duration** (select, optional, default: 5): The length of the generated video in seconds. _Options:_ `5` or `10`\n    \n*   **Aspect Ratio** (select, optional, default: 1280:720): The output video’s aspect ratio. _Options:_\n    \n    *   1280:720\n        \n    *   720:1280\n        \n    *   1104:832\n        \n    *   832:1104\n        \n    *   960:960\n        \n    *   1584:672\n        \n    \n*   **Seed** (number, optional): Random seed for reproducible results (0-4294967295), using the same seed will produce the same image if all inputs and configurations are the same. _Example:_ `123456`\n    \n*   **Watermark** (boolean, optional, default: true): Whether to add a RunwayML watermark to the video. _Options:_ `true` or `false`\n    \n\n**Outputs:**\n\n*   **Video URL** (string): The URL to download or view the generated video.\n    \n*   **Task ID** (string): The unique identifier for the video generation task.\n    \n\n**Example of Usage:**\n\n```\n{\n  \"image_url\": \"https://example.com/image.png\",\n  \"prompt\": \"A futuristic cityscape at sunset\",\n  \"model\": \"gen4_turbo\",\n  \"duration\": 10,\n  \"aspect_ratio\": \"1280:720\",\n  \"seed\": 123456,\n  \"watermark\": false\n}\n```\n\n_Output:_\n\n```\n{\n  \"video_url\": \"https://runwayml.com/generated/video123.mp4\",\n  \"task_id\": \"task_abc123\"\n}\n```\n\n* * *\n\n#### \n\n2\\. Generate Image from Text\n\nCreate an image from a detailed text prompt, with options for model, resolution, and more.\n\n**Inputs:**\n\n*   **Prompt** (string, required): A detailed text description of the image to generate. _Example:_ `\"A serene mountain landscape with a clear blue lake\"`\n    \n\n**Configurations:**\n\n*   **Model** (select, optional, default: Gen4 Image): The model to use for image generation. _Options:_ `\"gen4_image\"`\n    \n*   **Resolution** (select, optional, default: 1024:1024): The output image’s resolution/aspect ratio. _Options include:_\n    \n    *   1920:1080 (16:9)\n        \n    *   1080:1920 (9:16)\n        \n    *   1024:1024 (Square)\n        \n    *   1360:768 (Landscape)\n        \n    *   1080:1080 (Square)\n        \n    *   1168:880 (4:3)\n        \n    *   1440:1080 (4:3)\n        \n    *   1080:1440 (3:4)\n        \n    *   1808:768 (Wide)\n        \n    *   2112:912 (Ultra Wide)\n        \n    *   1280:720 (HD)\n        \n    *   720:1280 (Portrait HD)\n        \n    *   720:720 (Square HD)\n        \n    *   960:720 (4:3 HD)\n        \n    *   720:960 (3:4 HD)\n        \n    *   1680:720 (Cinematic)\n        \n    \n*   **Seed** (number, optional): Random seed for reproducible results (0-4294967295), using the same seed will produce the same image if all inputs and configurations are the same. _Example:_ `78910`\n    \n*   **Public Figure Threshold** (select, optional, default: auto): Content moderation strictness for public figures. _Options:_ `\"auto\"`, `\"low\"`\n    \n*   **Reference Images** (string array, optional): Array of image URLs to use as references for generation. Can help augment the style of the image created. _Example:_ `[\"https://example.com/ref1.jpg\", \"https://example.com/ref2.jpg\"]`\n    \n\n**Outputs:**\n\n*   **Image URL** (string): The URL to download or view the generated image.\n    \n*   **Task ID** (string): The unique identifier for the image generation task.\n    \n\n**Example of Usage:**\n\n```\n{\n  \"prompt\": \"A serene mountain landscape with a clear blue lake\",\n  \"model\": \"gen4_image\",\n  \"resolution\": \"1920:1080\",\n  \"seed\": 78910,\n  \"public_figure_threshold\": \"auto\",\n  \"reference_images\": [\"https://example.com/ref1.jpg\"]\n}\n```\n\n_Output:_\n\n```\n{\n  \"image_url\": \"https://runwayml.com/generated/image456.png\",\n  \"task_id\": \"task_def456\"\n}\n```\n\n* * *\n\n**Summary Table**\n\nAction\n\nRequired Inputs\n\nOptional Configurations\n\nOutputs (Required)\n\nprompt, model, duration, aspect\\_ratio, seed, watermark\n\nmodel, resolution, seed, public\\_figure\\_threshold, reference\\_images\n\n* * *\n\n**Advanced Settings**\n\n*   Retry on Failure: Enable retrying when the node execution fails\n    \n*   Fallback Branch: Create a separate branch that executes when this node fails, allowing you to handle errors gracefullyCreate a separate branch that executes when this node fails, allowing you to handle errors gracefully\n    \n\nLast updated 2 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/salesforce","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/salesforce","loadedTime":"2025-10-17T18:29:10.271Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/salesforce","title":"Salesforce | StackAI","description":"Integrate Stack AI with Salesforce for smarter sales workflows. Automate tasks, capture leads, and enhance CRM functionality with AI-powered insights.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Salesforce | StackAI"},{"property":"og:description","content":"Integrate Stack AI with Salesforce for smarter sales workflows. Automate tasks, capture leads, and enhance CRM functionality with AI-powered insights."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"0","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dc1d196cc5c4-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:10 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"iad1::iad1::64l84-1760725749340-0d9817f645d6"}},"screenshotUrl":null,"text":"Salesforce | StackAI\nIntegrate Stack AI with Salesforce for smarter sales workflows. Automate tasks, capture leads, and enhance CRM functionality with AI-powered insights.\nThe Salesforce Node allows you to connect directly to your Salesforce CRM account and query structured sales and customer data. It supports SQL queries to retrieve contact, lead, opportunity, and account information, making it easier to automate workflows, analyze performance, or power downstream nodes like LLMs or VectorDBs.\nOnce connected, Stack AI can use this data to enhance sales processes, generate insights, and improve decision-making.\nStep-by-step guide for Salesforce connection credentials:\nObtain your login credentials:\nUsername: your Salesforce login name.\nPassword: your Salesforce account password.\nAfter logging in, click on your profile picture on the upper right.\nA dropdown menu will appear, click on Settings.\nOn the Settings page, on the left navigation, select Reset My Security Token.\nClick on Reset Security Token.\nOn click, the new Security token will be sent to the email associated to your Salesforce account.\nFinally, in the email, this will be the Security token that will be used for the connection.\nHow to connect it?\nSteps to connect:\nAdd the Salesforce node from the Apps section into your Stack AI project.\nSelect \"Query Salesforce\" as the Action.\nClick on \"Select a connection\" or create a new connection with your credentials.\nChoose the appropriate domain for your Salesforce environment:\nConnecting to production or developer orgs\nConnecting to a sandbox instance\nUsing a custom domain (recommended for SSO or OAuth setups)\nNote that the Username for your API is different from the email address you used to sign up for Salesforce.\nEnabling the \"sandbox\" toggle tells Stack AI to connect to your Salesforce sandbox environment instead of your main (production) Salesforce account.\nDisabling the \"sandbox\" toggle means Stack AI will connect to your production Salesforce environment.\nAdd your Salesforce Schema in the configurations of the node to define which table you want to extract.\nFor example: TABLE Contact (Id TEXT, Name TEXT, Industry TEXT);\nTo list tables from your Salesforce account, you can run the included Python script below on your local machine.\nShow Python Script\nlist_salesforce_schema_with_filter.py\nfrom simple_salesforce import Salesforce # Salesforce credentials (replace with environment variables in production) username = \"\" password = \"\" security_token = \"\" # 🔍 Specify object names to include (DANGER leaving the list empty will include ALL) included_objects = [\"Contact\", \"Account\", \"Opportunity\"] # Case-sensitive # Connect to Salesforce sf = Salesforce(username=username, password=password, security_token=security_token) # Mapping Salesforce field types to SQL types def map_salesforce_type(sf_type): mapping = { \"string\": \"TEXT\", \"textarea\": \"TEXT\", \"picklist\": \"TEXT\", \"id\": \"VARCHAR(18)\", \"boolean\": \"BOOLEAN\", \"int\": \"INTEGER\", \"double\": \"FLOAT\", \"currency\": \"DECIMAL(18,2)\", \"percent\": \"DECIMAL(5,2)\", \"date\": \"DATE\", \"datetime\": \"TIMESTAMP\", \"email\": \"TEXT\", \"phone\": \"TEXT\", \"url\": \"TEXT\", \"reference\": \"VARCHAR(18)\", \"base64\": \"BYTEA\", \"location\": \"TEXT\", } return mapping.get(sf_type, \"TEXT\") # Get all object descriptions objects = sf.describe()[\"sobjects\"] # Open file for writing schema output with open(\"salesforce_schema.txt\", \"w\") as file: for obj in objects: obj_name = obj[\"name\"] # Apply filter if specified if included_objects and obj_name not in included_objects: continue try: obj_details = sf.__getattr__(obj_name).describe() field_defs = [] for field in obj_details[\"fields\"]: field_name = field[\"name\"] field_type = map_salesforce_type(field[\"type\"]) field_defs.append(f\"{field_name} {field_type}\") field_list = \", \".join(field_defs) table_def = f\"TABLE {obj_name} ({field_list});\" print(table_def) file.write(table_def + \"\\n\") except Exception as e: error_msg = f\"-- Could not process {obj_name}: {e}\" print(error_msg) file.write(error_msg + \"\\n\") print(\"\\nFiltered schema has been saved to 'salesforce_schema.txt'\") \nConnect the input, it can be in natural language or SOQL query from an Input node or LLM.\nConnect the output to a downstream node like an Output node or directly to an LLM.\nVisual overview\nBelow are some examples of valid SQL queries for your Salesforce database, provided that it has been included in the Schema:\nSELECT Name, Email FROM Contact\nSELECT Id, Email FROM Contact WHERE Income > USD10000\nSELECT Id, Email FROM Contact WHERE LastName = 'Aceituno'\nSELECT Id, Email, Name, ParentAccount.Name FROM Contact\nAvailable Actions\n1. Salesforce Query\nPurpose: Query Salesforce using plain English or SOQL.\nInputs:\nsql_schema (required): The database schema (tables, columns, types, etc.).\nquery (required): Your question in plain English or a SOQL query.\n2. Create Case\nPurpose: Create a new case in Salesforce.\nInputs:\nsubject (required): The subject/title of the case.\nstatus (optional): Status of the case (e.g., New, Working, Closed).\npriority (optional): Priority level (e.g., High, Medium, Low).\norigin (optional): Source of the case (e.g., Web, Phone, Email).\ndescription (optional): Detailed description.\naccount_id (optional): Salesforce Account ID to associate.\ncontact_id (optional): Salesforce Contact ID to associate.\n3. Update Case\nPurpose: Update an existing case.\nInputs:\ncase_id (required): Salesforce Case ID to update.\nsubject (optional): New subject/title.\nstatus (optional): New status.\npriority (optional): New priority.\norigin (optional): New origin/source.\ndescription (optional): New description.\naccount_id (optional): New Account ID.\ncontact_id (optional): New Contact ID.\n4. Delete Case\nPurpose: Delete a case.\nInputs:\ncase_id (required): Salesforce Case ID to delete.\n5. Create Opportunity\nPurpose: Create a new opportunity.\nInputs:\nname (required): Name of the opportunity.\nstage_name (required): Sales stage (e.g., Prospecting, Closed Won).\nclose_date (required): Expected close date (YYYY-MM-DD).\namount (optional): Opportunity amount.\naccount_id (optional): Account ID to associate.\ndescription (optional): Description.\n6. Update Opportunity\nPurpose: Update an existing opportunity.\nInputs:\nopportunity_id (required): Salesforce Opportunity ID to update.\nname (optional): New name.\nstage_name (optional): New stage.\nclose_date (optional): New close date.\namount (optional): New amount.\ndescription (optional): New description.\n7. Delete Opportunity\nPurpose: Delete an opportunity.\nInputs:\nopportunity_id (required): Salesforce Opportunity ID to delete.\n8. Create Contact\nPurpose: Create a new contact.\nInputs:\nlast_name (required): Last name of the contact.\nfirst_name (optional): First name.\nemail (optional): Email address.\nphone (optional): Phone number.\naccount_id (optional): Account ID to associate.\ntitle (optional): Job title.\n9. Update Contact\nPurpose: Update an existing contact.\nInputs:\ncontact_id (required): Salesforce Contact ID to update.\nlast_name (optional): New last name.\nfirst_name (optional): New first name.\nemail (optional): New email.\nphone (optional): New phone.\ntitle (optional): New job title.\n10. Delete Contact\nPurpose: Delete a contact.\nInputs:\ncontact_id (required): Salesforce Contact ID to delete.\nHere are the details for the Salesforce actions you requested, in your specified format:\n11. Create Comment\nPurpose: Add a new comment to a Salesforce record (such as a Case, Opportunity, etc.).\nInputs:\nparent_id (required): The Salesforce ID of the parent record to associate the comment with (e.g., Case ID, Opportunity ID).\ncomment_body (required): The text content of the comment.\nis_published (optional): Boolean indicating if the comment should be published and visible to customers (default: true).\n12. Update Comment\nPurpose: Update the content or visibility of an existing Salesforce comment.\nInputs:\ncomment_id (required): The Salesforce ID of the comment to update.\ncomment_body (optional): The updated text content of the comment.\nis_published (optional): Boolean indicating if the comment should be published and visible to customers.\n13. Delete Comment\nPurpose: Remove a comment from Salesforce.\nInputs:\ncomment_id (required): The Salesforce ID of the comment to delete.\nLast updated 2 months ago","markdown":"# Salesforce | StackAI\n\nIntegrate Stack AI with Salesforce for smarter sales workflows. Automate tasks, capture leads, and enhance CRM functionality with AI-powered insights.\n\nThe **Salesforce** **Node** allows you to connect directly to your Salesforce CRM account and query structured sales and customer data. It supports SQL queries to retrieve contact, lead, opportunity, and account information, making it easier to automate workflows, analyze performance, or power downstream nodes like LLMs or VectorDBs.\n\nOnce connected, Stack AI can use this data to enhance sales processes, generate insights, and improve decision-making.\n\n### \n\nStep-by-step guide for Salesforce connection credentials:\n\n1.  **Obtain your login credentials**:\n    \n    *   **Username**: your Salesforce login name.\n        \n    *   **Password**: your Salesforce account password.\n        \n    \n\n1.  After logging in, click on your profile picture on the upper right.\n    \n\n1.  A dropdown menu will appear, click on **Settings**.\n    \n\n1.  On the **Settings** page, on the left navigation, select **Reset My Security Token**.\n    \n\n1.  Click on **Reset Security Token**.\n    \n\n1.  On click, the new Security token will be sent to the email associated to your Salesforce account.\n    \n\n1.  Finally, in the email, this will be the **Security token** that will be used for the connection.\n    \n\n### \n\nHow to connect it?\n\n#### \n\nSteps to connect:\n\n1.  Add the **Salesforce node** from the Apps section into your Stack AI project.\n    \n\n1.  Select **\"Query Salesforce\"** as the Action.\n    \n\n1.  Click on **\"Select a connection\"** or create a new connection with your credentials.\n    \n\n1.  Choose the appropriate domain for your Salesforce environment:\n    \n    Connecting to production or developer orgs\n    \n    Connecting to a sandbox instance\n    \n    Using a custom domain (recommended for SSO or OAuth setups)\n    \n\nNote that the Username for your API is different from the email address you used to sign up for Salesforce.\n\n*   **Enabling the \"sandbox\" toggle** tells Stack AI to connect to your Salesforce **sandbox environment** instead of your main (production) Salesforce account.\n    \n*   **Disabling the \"sandbox\" toggle** means Stack AI will connect to your **production** Salesforce environment.\n    \n\n1.  **Add your Salesforce Schema** in the configurations of the node to define which table you want to extract.\n    \n    *   For example: TABLE Contact (Id TEXT, Name TEXT, Industry TEXT);\n        \n    *   To list tables from your Salesforce account, you can run the included Python script below on your local machine.\n        \n    \n\nShow Python Script[](#show-python-script)\n\nlist\\_salesforce\\_schema\\_with\\_filter.py\n\n```\nfrom simple_salesforce import Salesforce\n\n# Salesforce credentials (replace with environment variables in production)\nusername = \"\"\npassword = \"\"\nsecurity_token = \"\"\n\n# 🔍 Specify object names to include (DANGER leaving the list empty will include ALL)\nincluded_objects = [\"Contact\", \"Account\", \"Opportunity\"]  # Case-sensitive\n\n# Connect to Salesforce\nsf = Salesforce(username=username, password=password, security_token=security_token)\n\n# Mapping Salesforce field types to SQL types\ndef map_salesforce_type(sf_type):\n    mapping = {\n        \"string\": \"TEXT\",\n        \"textarea\": \"TEXT\",\n        \"picklist\": \"TEXT\",\n        \"id\": \"VARCHAR(18)\",\n        \"boolean\": \"BOOLEAN\",\n        \"int\": \"INTEGER\",\n        \"double\": \"FLOAT\",\n        \"currency\": \"DECIMAL(18,2)\",\n        \"percent\": \"DECIMAL(5,2)\",\n        \"date\": \"DATE\",\n        \"datetime\": \"TIMESTAMP\",\n        \"email\": \"TEXT\",\n        \"phone\": \"TEXT\",\n        \"url\": \"TEXT\",\n        \"reference\": \"VARCHAR(18)\",\n        \"base64\": \"BYTEA\",\n        \"location\": \"TEXT\",\n    }\n    return mapping.get(sf_type, \"TEXT\")\n\n\n# Get all object descriptions\nobjects = sf.describe()[\"sobjects\"]\n\n# Open file for writing schema output\nwith open(\"salesforce_schema.txt\", \"w\") as file:\n    for obj in objects:\n        obj_name = obj[\"name\"]\n        \n        # Apply filter if specified\n        if included_objects and obj_name not in included_objects:\n            continue\n        \n        try:\n            obj_details = sf.__getattr__(obj_name).describe()\n            field_defs = []\n\n            for field in obj_details[\"fields\"]:\n                field_name = field[\"name\"]\n                field_type = map_salesforce_type(field[\"type\"])\n                field_defs.append(f\"{field_name} {field_type}\")\n\n            field_list = \", \".join(field_defs)\n            table_def = f\"TABLE {obj_name} ({field_list});\"\n            print(table_def)\n            file.write(table_def + \"\\n\")\n\n        except Exception as e:\n            error_msg = f\"-- Could not process {obj_name}: {e}\"\n            print(error_msg)\n            file.write(error_msg + \"\\n\")\n\nprint(\"\\nFiltered schema has been saved to 'salesforce_schema.txt'\")\n```\n\n1.  **Connect the input**, it can be in natural language or SOQL query from an Input node or LLM.\n    \n2.  **Connect the output** to a downstream node like an Output node or directly to an LLM.\n    \n\n### \n\nVisual overview\n\nBelow are some examples of valid SQL queries for your Salesforce database, provided that it has been included in the **Schema**:\n\n```\nSELECT Name, Email FROM Contact\n```\n\n```\nSELECT Id, Email FROM Contact WHERE Income > USD10000\n```\n\n```\nSELECT Id, Email FROM Contact WHERE LastName = 'Aceituno'\n```\n\n```\nSELECT Id, Email, Name, ParentAccount.Name FROM Contact\n```\n\n### \n\nAvailable Actions\n\n#### \n\n1\\. Salesforce Query\n\n*   **Purpose:** Query Salesforce using plain English or SOQL.\n    \n*   **Inputs:**\n    \n    *   **sql\\_schema** (required): The database schema (tables, columns, types, etc.).\n        \n    *   **query** (required): Your question in plain English or a SOQL query.\n        \n    \n\n* * *\n\n#### \n\n2\\. Create Case\n\n*   **Purpose:** Create a new case in Salesforce.\n    \n*   **Inputs:**\n    \n    *   **subject** (required): The subject/title of the case.\n        \n    *   **status** (optional): Status of the case (e.g., New, Working, Closed).\n        \n    *   **priority** (optional): Priority level (e.g., High, Medium, Low).\n        \n    *   **origin** (optional): Source of the case (e.g., Web, Phone, Email).\n        \n    *   **description** (optional): Detailed description.\n        \n    *   **account\\_id** (optional): Salesforce Account ID to associate.\n        \n    *   **contact\\_id** (optional): Salesforce Contact ID to associate.\n        \n    \n\n* * *\n\n#### \n\n3\\. Update Case\n\n*   **Purpose:** Update an existing case.\n    \n*   **Inputs:**\n    \n    *   **case\\_id** (required): Salesforce Case ID to update.\n        \n    *   **subject** (optional): New subject/title.\n        \n    *   **status** (optional): New status.\n        \n    *   **priority** (optional): New priority.\n        \n    *   **origin** (optional): New origin/source.\n        \n    *   **description** (optional): New description.\n        \n    *   **account\\_id** (optional): New Account ID.\n        \n    *   **contact\\_id** (optional): New Contact ID.\n        \n    \n\n* * *\n\n#### \n\n4\\. Delete Case\n\n*   **Purpose:** Delete a case.\n    \n*   **Inputs:**\n    \n    *   **case\\_id** (required): Salesforce Case ID to delete.\n        \n    \n\n* * *\n\n#### \n\n5\\. Create Opportunity\n\n*   **Purpose:** Create a new opportunity.\n    \n*   **Inputs:**\n    \n    *   **name** (required): Name of the opportunity.\n        \n    *   **stage\\_name** (required): Sales stage (e.g., Prospecting, Closed Won).\n        \n    *   **close\\_date** (required): Expected close date (YYYY-MM-DD).\n        \n    *   **amount** (optional): Opportunity amount.\n        \n    *   **account\\_id** (optional): Account ID to associate.\n        \n    *   **description** (optional): Description.\n        \n    \n\n* * *\n\n#### \n\n6\\. Update Opportunity\n\n*   **Purpose:** Update an existing opportunity.\n    \n*   **Inputs:**\n    \n    *   **opportunity\\_id** (required): Salesforce Opportunity ID to update.\n        \n    *   **name** (optional): New name.\n        \n    *   **stage\\_name** (optional): New stage.\n        \n    *   **close\\_date** (optional): New close date.\n        \n    *   **amount** (optional): New amount.\n        \n    *   **description** (optional): New description.\n        \n    \n\n* * *\n\n#### \n\n7\\. Delete Opportunity\n\n*   **Purpose:** Delete an opportunity.\n    \n*   **Inputs:**\n    \n    *   **opportunity\\_id** (required): Salesforce Opportunity ID to delete.\n        \n    \n\n* * *\n\n#### \n\n8\\. Create Contact\n\n*   **Purpose:** Create a new contact.\n    \n*   **Inputs:**\n    \n    *   **last\\_name** (required): Last name of the contact.\n        \n    *   **first\\_name** (optional): First name.\n        \n    *   **email** (optional): Email address.\n        \n    *   **phone** (optional): Phone number.\n        \n    *   **account\\_id** (optional): Account ID to associate.\n        \n    *   **title** (optional): Job title.\n        \n    \n\n* * *\n\n#### \n\n9\\. Update Contact\n\n*   **Purpose:** Update an existing contact.\n    \n*   **Inputs:**\n    \n    *   **contact\\_id** (required): Salesforce Contact ID to update.\n        \n    *   **last\\_name** (optional): New last name.\n        \n    *   **first\\_name** (optional): New first name.\n        \n    *   **email** (optional): New email.\n        \n    *   **phone** (optional): New phone.\n        \n    *   **title** (optional): New job title.\n        \n    \n\n* * *\n\n#### \n\n10\\. Delete Contact\n\n*   **Purpose:** Delete a contact.\n    \n*   **Inputs:**\n    \n    *   **contact\\_id** (required): Salesforce Contact ID to delete.\n        \n    \n\nHere are the details for the Salesforce actions you requested, in your specified format:\n\n* * *\n\n#### \n\n**11\\. Create Comment**\n\n*   **Purpose:** Add a new comment to a Salesforce record (such as a Case, Opportunity, etc.).\n    \n*   **Inputs:**\n    \n    *   **parent\\_id** (required): The Salesforce ID of the parent record to associate the comment with (e.g., Case ID, Opportunity ID).\n        \n    *   **comment\\_body** (required): The text content of the comment.\n        \n    *   **is\\_published** (optional): Boolean indicating if the comment should be published and visible to customers (default: true).\n        \n    \n\n* * *\n\n#### \n\n12\\. Update Comment\n\n*   **Purpose:** Update the content or visibility of an existing Salesforce comment.\n    \n*   **Inputs:**\n    \n    *   **comment\\_id** (required): The Salesforce ID of the comment to update.\n        \n    *   **comment\\_body** (optional): The updated text content of the comment.\n        \n    *   **is\\_published** (optional): Boolean indicating if the comment should be published and visible to customers.\n        \n    \n\n* * *\n\n#### \n\n13\\. Delete Comment\n\n*   **Purpose:** Remove a comment from Salesforce.\n    \n*   **Inputs:**\n    \n    *   **comment\\_id** (required): The Salesforce ID of the comment to delete.\n        \n    \n\nLast updated 2 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/regex","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/regex","loadedTime":"2025-10-17T18:29:09.295Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/regex","title":"Regex | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Regex | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"date":"Fri, 17 Oct 2025 18:29:08 GMT","content-type":"text/html; charset=utf-8","content-encoding":"br","cf-ray":"9901dc0dbd128157-SEA","cf-cache-status":"DYNAMIC","age":"0","cache-control":"public, max-age=0, must-revalidate","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","referrer-policy":"no-referrer-when-downgrade","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"pdx1::iad1::jhkkx-1760725746872-f36a0a403407","server":"cloudflare","alt-svc":"h3=\":443\"; ma=86400","x-firefox-spdy":"h2"}},"screenshotUrl":"https://api.apify.com/v2/key-value-stores/3K2WBdQQFTu6EGDhJ/records/SCREENSHOT-docs-stack-ai-com-stack-ai-workflow-builder-apps-regex-a081ed79.jpg","text":"Regex | StackAI\nThe Regex Node in your workflow uses the Regex Extract action. This tool allows you to extract specific patterns or information from a block of text using regular expressions (regex).\nAvailable Actions\nRegex Extract\nPurpose: Extracts content from text using a regular expression pattern you provide.\nProvider: Regex\nInputs Required\nContent (string, required)\nThe text you want to extract information from.\nExample: \"Order number: 12345, Date: 2025-07-10\"\nExpression (string, required)\nThe regular expression pattern to search for in the content.\nExample: \"Order number: (\\d+)\"\nOutput\nResult (string)\nThe extracted value(s) from the content that match your regex pattern.\nHow to Use the Regex Node\nConnect the node: Pass the text you want to analyze (from an LLM, input, or another node) into the Regex node.\nConfigure the action:\nSet the \"Content\" field to the text you want to search.\nSet the \"Expression\" field to your desired regex pattern.\nUse the output: The result will be available as {action-X.result} (where X is the node number) for downstream nodes.\nExample Usage\nSuppose you want to extract an order number from a message:\nContent: \"Order number: 12345, Date: 2025-07-10\"\nExpression: \"Order number: (\\d+)\"\nResult: \"12345\"\nYou can reference this result in other nodes using {action-3.result} if your Regex node is action-3.\nLast updated 3 months ago","markdown":"# Regex | StackAI\n\nThe **Regex Node** in your workflow uses the Regex Extract action. This tool allows you to extract specific patterns or information from a block of text using regular expressions (regex).\n\n#### \n\nAvailable Actions\n\n#### \n\nRegex Extract\n\n*   **Purpose:** Extracts content from text using a regular expression pattern you provide.\n    \n*   **Provider:** Regex\n    \n\n**Inputs Required**\n\n1.  **Content** (string, required)\n    \n    *   The text you want to extract information from.\n        \n    *   Example: \"Order number: 12345, Date: 2025-07-10\"\n        \n    \n2.  **Expression** (string, required)\n    \n    *   The regular expression pattern to search for in the content.\n        \n    *   Example: \"Order number: (\\\\d+)\"\n        \n    \n\n**Output**\n\n*   **Result** (string)\n    \n    *   The extracted value(s) from the content that match your regex pattern.\n        \n    \n\n#### \n\nHow to Use the Regex Node\n\n1.  **Connect the node:** Pass the text you want to analyze (from an LLM, input, or another node) into the Regex node.\n    \n2.  **Configure the action:**\n    \n    *   Set the \"Content\" field to the text you want to search.\n        \n    *   Set the \"Expression\" field to your desired regex pattern.\n        \n    \n3.  **Use the output:** The result will be available as {action-X.result} (where X is the node number) for downstream nodes.\n    \n\n**Example Usage**\n\nSuppose you want to extract an order number from a message:\n\n*   Content: \"Order number: 12345, Date: 2025-07-10\"\n    \n*   Expression: \"Order number: (\\\\d+)\"\n    \n*   Result: \"12345\"\n    \n\nYou can reference this result in other nodes using {action-3.result} if your Regex node is action-3.\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"browser"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/sap","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/sap","loadedTime":"2025-10-17T18:29:13.789Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/sap","title":"SAP | StackAI","description":"Comprehensive guide to the SAP node in StackAI: actions, required inputs, configurations, and outputs with clear examples.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"SAP | StackAI"},{"property":"og:description","content":"Comprehensive guide to the SAP node in StackAI: actions, required inputs, configurations, and outputs with clear examples."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"0","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dc306f6f578e-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:13 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"iad1::iad1::knzz7-1760725752436-989c0848f1b5"}},"screenshotUrl":null,"text":"SAP | StackAI\nComprehensive guide to the SAP node in StackAI: actions, required inputs, configurations, and outputs with clear examples.\nThe SAP Node in StackAI enables seamless integration with your SAP system, allowing you to automate, retrieve, and manage business data and processes directly within your workflows. It supports a wide range of actions for financial, project, and resource management.\nHow to use it?\nAdd the SAP node to your StackAI workflow.\nSelect the desired action (e.g. 'Get Entities From Financial Item Consumption').\nEstablish a connection to your SAP account.\nProvide the required input parameters and configurations.\nConnect the output to downstream nodes for further processing or reporting.\nEstablishing a Connection\nYou must already have access to a valid SAP account with the necessary permissions. \nConnection Name (string, required)\nWhat it is: A label you assign to your SAP connection. It helps you identify the connection in Stack AI, especially if you have multiple SAP environments (e.g., production, staging, test).\nExample:\nSam's Connection\nTest Connection\nSAP Host (string, required)\nWhat it is: The hostname or IP address of your SAP server. This tells Stack AI where to send API requests.\nExample:\nsap.company.com\n192.168.1.100\nsap-prod.internal.corp\nSAP Port (string, required)\nWhat it is: The network port on which your SAP server is listening for API or OData requests. Common SAP ports are 443 (HTTPS) or 50000+ for custom SAP services.\nExample:\n443 (for secure HTTPS)\n50000 (for SAP NetWeaver Gateway)\n8000 (for HTTP, not recommended for production)\nSAP Token URL (string, required)\nWhat it is: The URL endpoint used to obtain OAuth2 tokens for authenticating with SAP. This is required if your SAP system uses OAuth2 for secure API access.\nExample:\nhttps://sap.company.com/oauth2/token\nhttps://sap-prod.internal.corp:443/oauth/token\nhttps://192.168.1.100:50000/sap/bc/sec/oauth2/token\nSAP Client (string, required)\nWhat it is: The SAP client number is a three-digit code that identifies a logical partition within your SAP system. Each client is like a separate environment (e.g., 100 for production, 200 for test).\nExample:\n100 (Production)\n200 (Test)\n300 (Development)\nAction Summary\nName\nRequired Inputs\nOptional Inputs\nOutput\nGet Entities From Financial Planning Consumption Type\n$Top, $Skip, $Filter, $Inlinecount, $Orderby, $Select\nStatus Code, Headers, Body\nGet Entities From Financial Item Consumption\n$Top, $Skip, $Filter, $Inlinecount, $Orderby, $Select\nStatus Code, Headers, Body\nGet Entities From Team Project Consumption\n$Top, $Skip, $Filter, $Inlinecount, $Orderby, $Select\nStatus Code, Headers, Body\nGet Entities From Work Package Consumption\n$Top, $Skip, $Filter, $Inlinecount, $Orderby, $Select\nStatus Code, Headers, Body\nGet Entity From Financial Item Consumption By Key\nStatus Code, Headers, Body\nGet Entity From Financial Planning Consumption Type By Key\nStatus Code, Headers, Body\nGet Entity From Team Project Consumption By Key\nProjectguid, Hierarchyguid, Appobjectguid, Taskguid, Entityguid\nStatus Code, Headers, Body\nGet Entity From Work Package Consumption By Key\nStatus Code, Headers, Body\n$Top (integer)\nA data service URI with the $top system query option returns the first N entities from the collection identified by the URI’s resource path. N must be an integer ≥ 0; otherwise, the URI is considered malformed.\n$Skip (integer)\nA data service URI with the $skip query option returns entities starting from position N + 1 in the collection identified by the URI’s resource path. N must be an integer ≥ 0; otherwise, the URI is considered malformed.\n$Filter (string)\nA data service URI with the $filter query option returns entities from the specified EntitySet that satisfy a given boolean expression.\nSyntax: $filter=<bool expression>\nExample: /Orders?$filter=ShipCountry eq 'France' — returns orders shipped to France. /Orders?$filter=Customers/ContactName ne 'Fred' — returns orders where the customer’s contact name is not Fred.\n$Inlinecount (string)\nThe $inlinecount query option includes the total count of entities (after applying $filter) in the response.\nSyntax: $inlinecount=allpages (include count) or $inlinecount=none (exclude count). Counting behavior is implementation-specific.\n$Orderby (string_array)\nThe $orderby query option specifies how to sort entities in the EntitySet identified by the URI’s resource path.\nSyntax: $orderby=<expression> [asc|desc], <expression> [asc|desc], ... Default sort order is ascending (asc) if not specified.\n$Select (string_array)\nThe $select query option returns the same entities as without it, but limits the response to only the specified properties. The service may still include additional properties in the response.\nSAP Client (string)\nIn SAP, a client number is a unique, three-digit identifier that distinguishes different business entities or organizational units within a single SAP system. It allows for the separation of data and configurations for various companies or projects, even within the same physical system. Client numbers typically range from 000 to 999, allowing for up to 1000 clients within a single SAP system.\nGuid (string)\nIn SAP, a GUID (Globally Unique Identifier) is a unique key used to identify objects or components. It's a string of characters, often 32 hexadecimal characters long, that ensures uniqueness across different systems and databases. \nTo find the SAP GUID (Globally Unique Identifier) for an application object, you'll typically need to navigate to the specific transaction or object within the SAP system and access its properties or details. The exact location and method will depend on the specific SAP object you are working with.\nProjectguid (string)\nIn SAP systems, a Project GUID (Globally Unique Identifier) is a unique identifier used to distinguish projects, activities, and other related elements within the system. It is a 16-character identifier that is automatically generated by the SAP system.\nHierarchyguid (string)\nIn SAP, a \"Hierarchy GUID\" typically refers to a Globally Unique Identifier (GUID) used to uniquely identify a hierarchy within the system. This GUID acts as a primary key, ensuring that each hierarchy can be distinguished from others. It's often used in various applications and is a crucial element in data modeling and reporting within SAP. \nAppobjectguid (string)\nThe Application Object GUID specifically refers to the unique identifier for an \"application object\"—which could be a project, task, document, or any business object managed within SAP.\nTaskguid (string)\nTaskguid is a 128-bit Globally Unique Identifier (GUID) that uniquely identifies a task object in SAP's project system.\nIn SAP, projects are often broken down into multiple tasks or work packages. Each of these tasks is assigned a unique GUID to distinguish it from other tasks, even across different projects.\nEntityguid (string)\nIn SAP, an \"entity\" in this context typically refers to a specific record or object within the team project consumption module—such as a cost item, resource, or any other sub-object related to a project or task.\nThe Entityguid is a 128-bit unique identifier (GUID) that ensures you are referencing exactly the right entity, even if there are many similar records in the system.\nLast updated 2 months ago","markdown":"# SAP | StackAI\n\nComprehensive guide to the SAP node in StackAI: actions, required inputs, configurations, and outputs with clear examples.\n\nThe **SAP Node** in StackAI enables seamless integration with your SAP system, allowing you to automate, retrieve, and manage business data and processes directly within your workflows. It supports a wide range of actions for financial, project, and resource management.\n\n* * *\n\n**How to use it?**\n\n1.  Add the SAP node to your StackAI workflow.\n    \n2.  Select the desired action (e.g. 'Get Entities From Financial Item Consumption').\n    \n3.  Establish a connection to your SAP account.\n    \n4.  Provide the required input parameters and configurations.\n    \n5.  Connect the output to downstream nodes for further processing or reporting.\n    \n\n* * *\n\n**Establishing a Connection**\n\nYou must already have access to a valid SAP account with the necessary permissions.\n\n*   **Connection Name (string, required)**\n    \n    *   **What it is:** A label you assign to your SAP connection. It helps you identify the connection in Stack AI, especially if you have multiple SAP environments (e.g., production, staging, test).\n        \n    *   **Example:**\n        \n        *   `Sam's Connection`\n            \n        *   `Test Connection`\n            \n        \n    \n*   **SAP Host** **(string, required)**\n    \n    *   **What it is:** The hostname or IP address of your SAP server. This tells Stack AI where to send API requests.\n        \n    *   **Example:**\n        \n        *   `sap.company.com`\n            \n        *   `192.168.1.100`\n            \n        *   `sap-prod.internal.corp`\n            \n        \n    \n*   #### \n    \n    **SAP Port** (string, required)\n    \n    *   **What it is:** The network port on which your SAP server is listening for API or OData requests. Common SAP ports are 443 (HTTPS) or 50000+ for custom SAP services.\n        \n    *   **Example:**\n        \n        *   `443` (for secure HTTPS)\n            \n        *   `50000` (for SAP NetWeaver Gateway)\n            \n        *   `8000` (for HTTP, not recommended for production)\n            \n        \n    \n*   #### \n    \n    **SAP Token URL** (string, required)\n    \n    *   **What it is:** The URL endpoint used to obtain OAuth2 tokens for authenticating with SAP. This is required if your SAP system uses OAuth2 for secure API access.\n        \n    *   **Example:**\n        \n        *   `https://sap.company.com/oauth2/token`\n            \n        *   `https://sap-prod.internal.corp:443/oauth/token`\n            \n        *   `https://192.168.1.100:50000/sap/bc/sec/oauth2/token`\n            \n        \n    \n*   #### \n    \n    **SAP Client** (string, required)\n    \n    *   **What it is:** The SAP client number is a three-digit code that identifies a logical partition within your SAP system. Each client is like a separate environment (e.g., 100 for production, 200 for test).\n        \n    *   **Example:**\n        \n        *   `100` (Production)\n            \n        *   `200` (Test)\n            \n        *   `300` (Development)\n            \n        \n    \n\n* * *\n\n**Action Summary**\n\nName\n\nRequired Inputs\n\nOptional Inputs\n\nOutput\n\nGet Entities From Financial Planning Consumption Type\n\n$Top, $Skip, $Filter, $Inlinecount, $Orderby, $Select\n\nStatus Code, Headers, Body\n\nGet Entities From Financial Item Consumption\n\n$Top, $Skip, $Filter, $Inlinecount, $Orderby, $Select\n\nStatus Code, Headers, Body\n\nGet Entities From Team Project Consumption\n\n$Top, $Skip, $Filter, $Inlinecount, $Orderby, $Select\n\nStatus Code, Headers, Body\n\nGet Entities From Work Package Consumption\n\n$Top, $Skip, $Filter, $Inlinecount, $Orderby, $Select\n\nStatus Code, Headers, Body\n\nGet Entity From Financial Item Consumption By Key\n\nStatus Code, Headers, Body\n\nGet Entity From Financial Planning Consumption Type By Key\n\nStatus Code, Headers, Body\n\nGet Entity From Team Project Consumption By Key\n\nProjectguid, Hierarchyguid, Appobjectguid, Taskguid, Entityguid\n\nStatus Code, Headers, Body\n\nGet Entity From Work Package Consumption By Key\n\nStatus Code, Headers, Body\n\n*   **$Top** (integer)\n    \n    *   A data service URI with the `$top` system query option returns the first _N_ entities from the collection identified by the URI’s resource path. _N_ must be an integer ≥ 0; otherwise, the URI is considered malformed.\n        \n    \n*   **$Skip** (integer)\n    \n    *   A data service URI with the `$skip` query option returns entities starting from position _N + 1_ in the collection identified by the URI’s resource path. _N_ must be an integer ≥ 0; otherwise, the URI is considered malformed.\n        \n    \n*   **$Filter** (string)\n    \n    *   A data service URI with the `$filter` query option returns entities from the specified EntitySet that satisfy a given boolean expression.\n        \n        *   **Syntax:** `$filter=<bool expression>`\n            \n        *   **Example:** `/Orders?$filter=ShipCountry eq 'France'` — returns orders shipped to France. `/Orders?$filter=Customers/ContactName ne 'Fred'` — returns orders where the customer’s contact name is not Fred.\n            \n        \n    \n*   **$Inlinecount** (string)\n    \n    *   The `$inlinecount` query option includes the total count of entities (after applying `$filter`) in the response.\n        \n        *   **Syntax:** `$inlinecount=allpages` (include count) or `$inlinecount=none` (exclude count). Counting behavior is implementation-specific.\n            \n        \n    \n*   **$Orderby** (string\\_array)\n    \n    *   The `$orderby` query option specifies how to sort entities in the EntitySet identified by the URI’s resource path.\n        \n        *   **Syntax:** `$orderby=<expression> [asc|desc], <expression> [asc|desc], ...` Default sort order is ascending (`asc`) if not specified.\n            \n        \n    \n*   **$Select** (string\\_array)\n    \n    *   The `$select` query option returns the same entities as without it, but limits the response to only the specified properties. The service may still include additional properties in the response.\n        \n    \n*   **SAP Client** (string)\n    \n    *   In SAP, a client number is a unique, three-digit identifier that distinguishes different business entities or organizational units within a single SAP system. It allows for the separation of data and configurations for various companies or projects, even within the same physical system. Client numbers typically range from 000 to 999, allowing for up to 1000 clients within a single SAP system.\n        \n    \n*   **Guid** (string)\n    \n    *   In SAP, a GUID (Globally Unique Identifier) is a unique key used to identify objects or components. It's a string of characters, often 32 hexadecimal characters long, that ensures uniqueness across different systems and databases.\n        \n    *   To find the SAP GUID (Globally Unique Identifier) for an application object, you'll typically need to navigate to the specific transaction or object within the SAP system and access its properties or details. The exact location and method will depend on the specific SAP object you are working with.\n        \n    \n*   **Projectguid** (string)\n    \n    *   In SAP systems, a Project GUID (Globally Unique Identifier) is a unique identifier used to distinguish projects, activities, and other related elements within the system. It is a 16-character identifier that is automatically generated by the SAP system.\n        \n    \n*   **Hierarchyguid** (string)\n    \n    *   In SAP, a \"Hierarchy GUID\" typically refers to a Globally Unique Identifier (GUID) used to uniquely identify a hierarchy within the system. This GUID acts as a primary key, ensuring that each hierarchy can be distinguished from others. It's often used in various applications and is a crucial element in data modeling and reporting within SAP.\n        \n    \n*   **Appobjectguid** (string)\n    \n    *   The Application Object GUID specifically refers to the unique identifier for an \"application object\"—which could be a project, task, document, or any business object managed within SAP.\n        \n    \n*   **Taskguid** (string)\n    \n    *   Taskguid is a 128-bit Globally Unique Identifier (GUID) that uniquely identifies a task object in SAP's project system.\n        \n    *   In SAP, projects are often broken down into multiple tasks or work packages. Each of these tasks is assigned a unique GUID to distinguish it from other tasks, even across different projects.\n        \n    \n*   **Entityguid** (string)\n    \n    *   In SAP, an \"entity\" in this context typically refers to a specific record or object within the team project consumption module—such as a cost item, resource, or any other sub-object related to a project or task.\n        \n    *   The **Entityguid** is a 128-bit unique identifier (GUID) that ensures you are referencing exactly the right entity, even if there are many similar records in the system.\n        \n    \n\nLast updated 2 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/servicenow","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/servicenow","loadedTime":"2025-10-17T18:29:15.968Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/servicenow","title":"ServiceNow | StackAI","description":"Discover how to automate ServiceNow tasks in StackAI. Learn about the most common ServiceNow actions, their required inputs, configurations, and outputs with clear examples.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"ServiceNow | StackAI"},{"property":"og:description","content":"Discover how to automate ServiceNow tasks in StackAI. Learn about the most common ServiceNow actions, their required inputs, configurations, and outputs with clear examples."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1548","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dc453b41c942-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:15 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::fplnc-1760725755751-aa8aaaf10d6b"}},"screenshotUrl":null,"text":"ServiceNow | StackAI\nDiscover how to automate ServiceNow tasks in StackAI. Learn about the most common ServiceNow actions, their required inputs, configurations, and outputs with clear examples.\nEstablishing a Connection \n1. Connection Name\nA user-friendly name for your connection. This helps you identify it among other connections in Stack AI.\n2. Instance URL\nGo to developer.servicenow.com\nThe URL in your browser’s address bar is your instance URL. It usually looks like: https://<instance>.service-now.com\n3. Username\nIn that same card, copy the username that is underneath the URL.\n4. Password\nThis is the password for the ServiceNow user account above. This is used together with the username for authentication.\nCopy the password under \"Current password.\"\n5. Client ID\nIn the video below, you will find how to generate a Client ID and Client Secret by creating an OAuth API endpoint. To follow the steps in the video guide, go to the homepage of your ServiceNow instance: https://<instance>.service-now.com\n6. Client Secret\nTo get the client secret, click on the resource you've created and then click on the copy button to the right, next to Client Secret.","markdown":"# ServiceNow | StackAI\n\nDiscover how to automate ServiceNow tasks in StackAI. Learn about the most common ServiceNow actions, their required inputs, configurations, and outputs with clear examples.\n\n### \n\nEstablishing a Connection\n\n#### \n\n1\\. Connection Name\n\nA user-friendly name for your connection. This helps you identify it among other connections in Stack AI.\n\n#### \n\n2\\. Instance URL\n\nGo to [developer.servicenow.com](https://developer.servicenow.com/)\n\nThe URL in your browser’s address bar is your instance URL. It usually looks like: `https://<instance>.service-now.com`\n\n#### \n\n3\\. Username\n\nIn that same card, copy the username that is underneath the URL.\n\n#### \n\n4\\. Password\n\nThis is the password for the ServiceNow user account above. This is used together with the username for authentication.\n\nCopy the password under \"Current password.\"\n\n#### \n\n5\\. Client ID\n\nIn the video below, you will find how to generate a Client ID and Client Secret by creating an OAuth API endpoint. To follow the steps in the video guide, go to the homepage of your ServiceNow instance: `https://<instance>.service-now.com`\n\n#### \n\n6\\. Client Secret\n\nTo get the client secret, click on the resource you've created and then click on the copy button to the right, next to Client Secret.","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/serpapi","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/serpapi","loadedTime":"2025-10-17T18:29:16.280Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/serpapi","title":"SerpAPI | StackAI","description":"SerpAPI node enables real-time web search, news, and job search capabilities within StackAI workflows, providing structured and actionable search results.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"SerpAPI | StackAI"},{"property":"og:description","content":"SerpAPI node enables real-time web search, news, and job search capabilities within StackAI workflows, providing structured and actionable search results."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"0","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dc402d0d29b2-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:16 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"iad1::iad1::zbssk-1760725754963-a2cdb5c4c0fa"}},"screenshotUrl":null,"text":"SerpAPI | StackAI\nSerpAPI node enables real-time web search, news, and job search capabilities within StackAI workflows, providing structured and actionable search results.\nWhat is SerpAPI?\nSerpAPI is a powerful node in StackAI that allows you to perform real-time web searches, news searches, job searches, and website to markdown directly within your workflow. It leverages the SerpAPI platform to fetch up-to-date information from the internet, making it ideal for research, content generation, and data enrichment tasks.\nExample of Usage\nConnect a Text Input node to SerpAPI.\nSet the action to \"Web Search\".\nEnter a search query like \"latest AI trends\".\nThe node returns a list of relevant web results, which can be displayed or processed further.\nAvailable Actions\n1. Web Search\nDescription: Performs a real-time search on the web and returns a list of relevant results.\nInputs:\nQuery (string, required): The search term or phrase to look up (e.g., \"StackAI features\").\nNum (number, optional): Specify how many search results you want to retrieve (default: 5), needs to be at least 1.\nConfigurations:\nDevice (dropdown, optional): Choose whether to simulate search results as seen on desktop or mobile devices. Default is desktop. \nCountryCode (dropdown, optional): Select which country's search engine to use for results.\nLanguageCode (dropdown, optional): Choose the language for search results and interface.\nOutputs:\nWeb Search Results (object_array): A collection of web search results containing URLs, titles, and content snippets.\nExample: Input:\n{ \"query\": \"StackAI workflow automation\" }\nOutput:\n{ \"results\": [ { \"title\": \"How to Automate Workflows with StackAI\", \"link\": \"https://example.com/stackai-workflow\", \"snippet\": \"Learn how to automate your business processes using StackAI...\" } ], \"metadata\": { \"total_results\": 100000, \"search_time\": \"0.45s\" } }\n2. News Search\nDescription: Fetches the latest news articles related to a specific query.\nInputs:\nQuery (string, required): The search term or phrase to look up (e.g., \"AI news\").\nConfigurations:\nDevice (dropdown, optional): Choose whether to simulate search results as seen on desktop or mobile devices. Default is desktop. \nCountryCode (dropdown, optional): Select which country's search engine to use for results.\nLanguageCode (dropdown, optional): Choose the language for search results and interface.\nOutputs:\nResult (string): The result of the news search\nExample: Input:\n{ \"query\": \"AI breakthroughs\" }\nOutput:\n{ \"articles\": [ { \"title\": \"Recent Breakthroughs in AI\", \"link\": \"https://news.com/ai-breakthroughs\", \"source\": \"Tech News\", \"published_date\": \"2025-07-20\" } ], \"metadata\": { \"total_articles\": 50 } }\n3. Job Search\nDescription: Searches for job postings based on a given query and location.\nInputs:\nQuery (string, required): The search term or phrase to look up (e.g., \"Data Scientist\").\nNum (number, optional): Specify how many search results you want to retrieve (default: 5), needs to be at least 1.\nConfigurations:\nCountryCode (dropdown, optional): Select which country's search engine to use for results.\nLanguageCode (dropdown, optional): Choose the language for search results and interface.\nOutputs:\nJobs (string): List of jobs found.\nExample: Input:\n{ \"query\": \"machine learning engineer\", \"country_code\": \"UNITED_STATES\" }\nOutput:\n{ \"jobs\": [ { \"title\": \"Machine Learning Engineer\", \"company\": \"Tech Innovators\", \"location\": \"San Francisco, CA\", \"link\": \"https://jobs.com/ml-engineer\" } ], \"metadata\": { \"total_jobs\": 120 } }\n4. Website to Markdown\nDescription: This action takes a website URL and converts the entire page into a markdown-formatted document. It’s useful for extracting readable, structured content from any public web page.\nInputs:\nUrl (string, required): The URL of the website you want to convert to markdown.\nConfigurations:\nLocation (string, optional): The geographic location from which to perform the conversion (affects region-specific content). Default is US. \nOutputs:\nMarkdown (string): The markdown representation of the website\nExample: Input:\n{ \"url\": \"https://en.wikipedia.org/wiki/Markdown\" }\nOutput:\n{ \"markdown\": \"# Markdown\\nMarkdown is a lightweight markup language...\" }\nLast updated 2 months ago","markdown":"# SerpAPI | StackAI\n\nSerpAPI node enables real-time web search, news, and job search capabilities within StackAI workflows, providing structured and actionable search results.\n\n**What is SerpAPI?**\n\nSerpAPI is a powerful node in StackAI that allows you to perform real-time web searches, news searches, job searches, and website to markdown directly within your workflow. It leverages the SerpAPI platform to fetch up-to-date information from the internet, making it ideal for research, content generation, and data enrichment tasks.\n\n* * *\n\n**Example of Usage**\n\n*   Connect a Text Input node to SerpAPI.\n    \n*   Set the action to \"Web Search\".\n    \n*   Enter a search query like \"latest AI trends\".\n    \n*   The node returns a list of relevant web results, which can be displayed or processed further.\n    \n\n* * *\n\n### \n\n**Available Actions**\n\n#### \n\n1\\. Web Search\n\n**Description:** Performs a real-time search on the web and returns a list of relevant results.\n\n**Inputs:**\n\n*   **Query** (string, required): The search term or phrase to look up (e.g., \"StackAI features\").\n    \n*   **Num** (number, optional): Specify how many search results you want to retrieve (default: 5), needs to be at least 1.\n    \n\n**Configurations:**\n\n*   **Device** (dropdown, optional): Choose whether to simulate search results as seen on desktop or mobile devices. Default is desktop.\n    \n*   **CountryCode** (dropdown, optional): Select which country's search engine to use for results.\n    \n*   **LanguageCode** (dropdown, optional): Choose the language for search results and interface.\n    \n\n**Outputs:**\n\n*   **Web Search Results** (object\\_array): A collection of web search results containing URLs, titles, and content snippets.\n    \n\n**Example:** Input:\n\n```\n{\n  \"query\": \"StackAI workflow automation\"\n}\n```\n\nOutput:\n\n```\n{\n  \"results\": [\n    {\n      \"title\": \"How to Automate Workflows with StackAI\",\n      \"link\": \"https://example.com/stackai-workflow\",\n      \"snippet\": \"Learn how to automate your business processes using StackAI...\"\n    }\n  ],\n  \"metadata\": {\n    \"total_results\": 100000,\n    \"search_time\": \"0.45s\"\n  }\n}\n```\n\n#### \n\n2\\. News Search\n\n**Description:** Fetches the latest news articles related to a specific query.\n\n**Inputs:**\n\n*   **Query** (string, required): The search term or phrase to look up (e.g., \"AI news\").\n    \n\n**Configurations:**\n\n*   **Device** (dropdown, optional): Choose whether to simulate search results as seen on desktop or mobile devices. Default is desktop.\n    \n*   **CountryCode** (dropdown, optional): Select which country's search engine to use for results.\n    \n*   **LanguageCode** (dropdown, optional): Choose the language for search results and interface.\n    \n\n**Outputs:**\n\n*   **Result** (string): The result of the news search\n    \n\n**Example:** Input:\n\n```\n{\n  \"query\": \"AI breakthroughs\"\n}\n```\n\nOutput:\n\n```\n{\n  \"articles\": [\n    {\n      \"title\": \"Recent Breakthroughs in AI\",\n      \"link\": \"https://news.com/ai-breakthroughs\",\n      \"source\": \"Tech News\",\n      \"published_date\": \"2025-07-20\"\n    }\n  ],\n  \"metadata\": {\n    \"total_articles\": 50\n  }\n}\n```\n\n#### \n\n3\\. Job Search\n\n**Description:** Searches for job postings based on a given query and location.\n\n**Inputs:**\n\n*   **Query** (string, required): The search term or phrase to look up (e.g., \"Data Scientist\").\n    \n*   **Num** (number, optional): Specify how many search results you want to retrieve (default: 5), needs to be at least 1.\n    \n\n**Configurations:**\n\n*   **CountryCode** (dropdown, optional): Select which country's search engine to use for results.\n    \n*   **LanguageCode** (dropdown, optional): Choose the language for search results and interface.\n    \n\n**Outputs:**\n\n*   **Jobs** (string): List of jobs found.\n    \n\n**Example:** Input:\n\n```\n{\n  \"query\": \"machine learning engineer\",\n  \"country_code\": \"UNITED_STATES\"\n}\n```\n\nOutput:\n\n```\n{\n  \"jobs\": [\n    {\n      \"title\": \"Machine Learning Engineer\",\n      \"company\": \"Tech Innovators\",\n      \"location\": \"San Francisco, CA\",\n      \"link\": \"https://jobs.com/ml-engineer\"\n    }\n  ],\n  \"metadata\": {\n    \"total_jobs\": 120\n  }\n}\n```\n\n#### \n\n4\\. Website to Markdown\n\n**Description:** This action takes a website URL and converts the entire page into a markdown-formatted document. It’s useful for extracting readable, structured content from any public web page.\n\n**Inputs:**\n\n*   **Url** (string, required): The URL of the website you want to convert to markdown.\n    \n\n**Configurations:**\n\n*   **Location** (string, optional): The geographic location from which to perform the conversion (affects region-specific content). Default is US.\n    \n\n**Outputs:**\n\n*   **Markdown** (string): The markdown representation of the website\n    \n\n**Example:** Input:\n\n```\n{\n  \"url\": \"https://en.wikipedia.org/wiki/Markdown\"\n}\n```\n\nOutput:\n\n```\n{\n  \"markdown\": \"# Markdown\\nMarkdown is a lightweight markup language...\"\n}\n```\n\nLast updated 2 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/sharepoint","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/sharepoint","loadedTime":"2025-10-17T18:29:17.598Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/sharepoint","title":"SharePoint | StackAI","description":"Discover how to search and retrieve files from SharePoint using StackAI, including required inputs, configurations, and output details.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"SharePoint | StackAI"},{"property":"og:description","content":"Discover how to search and retrieve files from SharePoint using StackAI, including required inputs, configurations, and output details."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1550","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dc4efccc3950-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:17 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::4lrxl-1760725757331-89e2deb02463"}},"screenshotUrl":null,"text":"SharePoint | StackAI\nDiscover how to search and retrieve files from SharePoint using StackAI, including required inputs, configurations, and output details.\nThe SharePoint Node in StackAI allows you to search for files stored in your SharePoint environment. You can specify search queries, filter by file types, and control the number of results returned. This is ideal for automating document retrieval, content management, and knowledge discovery. Sharepoint allows you to search for files stored in your Sharepoint, as well as Sharepoint News.\nExample of Usage\nSuppose you want to find all PDF reports related to \"Quarterly Sales\" in your SharePoint. You would set up the node as follows:\nInput Example:\nSearch Query (string, required): \"Quarterly Sales\"\nFile Types (string array, optional): [\"pdf\"]\nMax Results (integer, optional): 10\nThe node will return a list of matching files, including their names, URLs, types, modification dates, and more.\nSetting Up A Connection \nTo use the the SharePoint node, you must connect your SharePoint account to Stack AI using OAuth2. This connection requires several key pieces of information, which are typically provided by your Microsoft Azure/SharePoint administrator:\n1. Client ID (string, required)\nWhat it is: A unique identifier for your Azure AD application (also called \"Application (client) ID\").\nWhere to find it: In the Azure portal, under \"Azure Active Directory\" > Under \"Manage\" select \"App registrations\" > [Your App] > \"Overview\".\nExample: b1a7c8e2-1234-4f56-9abc-1234567890ab\n2. Client Secret (string, required)\nWhat it is: A password-like value generated for your Azure AD application, used to authenticate your app.\nWhere to find it: In the Azure portal, under \"Azure Active Directory\" > \"App registrations\" > [Your App] > \"Certificates & secrets\". You must create a new client secret and copy the value.\nExample: wJ8Q~abc1234efgh5678ijklmnop9qrstuvwx\n3. Tenant ID (string, required)\nWhat it is: The unique identifier for your Microsoft 365 tenant (organization).\nWhere to find it: In the Azure portal, under \"Azure Active Directory\" > \"Overview\" > \"Tenant ID\".\nExample: 72f988bf-86f1-41af-91ab-2d7cd011db47\n4. SharePoint Site ID (string, optional)\nWhat it is: The unique identifier for the SharePoint site you want to access. This is not the site URL, but an internal ID.\nWhere to find it: You can get this via the Microsoft Graph API or from your SharePoint admin. Sometimes, it is in the format: contoso.sharepoint.com,12345678-90ab-cdef-1234-567890abcdef,abcdef12-3456-7890-abcd-ef1234567890\nExample: contoso.sharepoint.com,12345678-90ab-cdef-1234-567890abcdef,abcdef12-3456-7890-abcd-ef1234567890 \nAvailable Actions\n1. Search Files\nSearch for files and documents in SharePoint using a query and optional filters.\nInputs\nName\nDescription\nExample\nRequired\nThe search string to find files and documents\nList of file types to filter by\nMaximum number of results to return\nSearch Query (string, required): The keywords or phrase to search for in file names and content.\nFile Types (array of strings, optional): Filter results by file extensions (e.g., \"pdf\", \"docx\", \"xlsx\").\nYou can include any file extension that is supported by your SharePoint environment.\nCommon examples include:\n\"pdf\" (PDF documents)\n\"docx\" (Word documents)\n\"xlsx\" (Excel spreadsheets)\n\"pptx\" (PowerPoint presentations)\n\"txt\" (Text files)\n\"csv\" (Comma-separated values)\n\"jpg\", \"png\", \"gif\" (Image files)\n\"zip\" (Compressed archives)\n...and any other file extension that your SharePoint instance stores\nMax Results (integer, optional, default: 20): Limit the number of files returned.\nOutputs\nEach file in the output includes:\nFile ID (string): Unique identifier for the file.\nFile Name (string): Name of the file.\nFile URL (string): Direct link to access the file.\nFile Type (string): File extension/type (e.g., \"pdf\").\nModified Date (string): Last modified date.\nSize (integer): File size in bytes.\nAuthor (string): File author or creator.\nExample Output:\n{ \"files\": [ { \"file_id\": \"12345\", \"file_name\": \"Quarterly_Report_Q1.pdf\", \"file_url\": \"https://contoso.sharepoint.com/sites/finance/Shared%20Documents/Quarterly_Report_Q1.pdf\", \"file_type\": \"pdf\", \"modified_date\": \"2025-06-15T10:23:45Z\", \"size\": 1048576, \"author\": \"Jane Doe\" }, { \"file_id\": \"67890\", \"file_name\": \"Budget_2025.pdf\", \"file_url\": \"https://contoso.sharepoint.com/sites/finance/Shared%20Documents/Budget_2025.pdf\", \"file_type\": \"pdf\", \"modified_date\": \"2025-07-01T14:05:12Z\", \"size\": 2097152, \"author\": \"John Smith\" } ], \"total_count\": 2 }\n2. Search Files\nThis action creates a new Microsoft Word (DOCX) file in a specified SharePoint site and folder, with the content you provide (in Markdown format). Typically used to automate report generation, meeting notes, or any document creation directly into your SharePoint library.\nInputs\nName\nDescription\nExample\nRequired\nName of the Word document to create (must end in .docx).\nSharePoint site hostname (e.g., your company’s SharePoint domain).\nSharePoint site name (e.g., sites/YourSiteName).\nDocument body text in Markdown format.\nDestination folder path within the site. If omitted, saves to root folder.\n/Shared Documents/Reports\nOutputs\nOn success, the action returns:\nFile ID (string): Unique identifier of the created file.\nFile URL (string): URL to open the document in SharePoint/OneDrive.\nAdvanced Settings\nRetry on Failure: Enable retrying when the node execution fails\nFallback Branch (integer): Create a separate branch that executed when this node fails, allowing you to handle errors gracefully\nSummary Table\nAction Name\nDescription\nRequired Inputs\nOptional Inputs\nOutputs\nSearch for files in SharePoint\nCreates a word document in SharePoint\nHostname, Site Name, Folder Path\nBest Practices\nAlways provide a clear and specific search query for best results.\nUse file type filters to narrow down results when searching for specific document formats.\nAdjust the max results parameter to control the volume of data returned.","markdown":"# SharePoint | StackAI\n\nDiscover how to search and retrieve files from SharePoint using StackAI, including required inputs, configurations, and output details.\n\nThe **SharePoint Node** in StackAI allows you to search for files stored in your SharePoint environment. You can specify search queries, filter by file types, and control the number of results returned. This is ideal for automating document retrieval, content management, and knowledge discovery. Sharepoint allows you to search for files stored in your Sharepoint, as well as Sharepoint News.\n\n**Example of Usage**\n\nSuppose you want to find all PDF reports related to \"Quarterly Sales\" in your SharePoint. You would set up the node as follows:\n\n*   **Input Example:**\n    \n    *   Search Query (string, required): \"Quarterly Sales\"\n        \n    *   File Types (string array, optional): \\[\"pdf\"\\]\n        \n    *   Max Results (integer, optional): 10\n        \n    \n\nThe node will return a list of matching files, including their names, URLs, types, modification dates, and more.\n\n* * *\n\n**Setting Up A Connection**\n\nTo use the the SharePoint node, you must connect your SharePoint account to Stack AI using OAuth2. This connection requires several key pieces of information, which are typically provided by your Microsoft Azure/SharePoint administrator:\n\n**1\\. Client ID** (string, required)\n\n*   **What it is:** A unique identifier for your Azure AD application (also called \"Application (client) ID\").\n    \n*   **Where to find it:** In the Azure portal, under \"Azure Active Directory\" > Under \"Manage\" select \"App registrations\" > \\[Your App\\] > \"Overview\".\n    \n*   **Example:** `b1a7c8e2-1234-4f56-9abc-1234567890ab`\n    \n\n**2\\. Client Secret** (string, required)\n\n*   **What it is:** A password-like value generated for your Azure AD application, used to authenticate your app.\n    \n*   **Where to find it:** In the Azure portal, under \"Azure Active Directory\" > \"App registrations\" > \\[Your App\\] > \"Certificates & secrets\". You must create a new client secret and copy the value.\n    \n*   **Example:** `wJ8Q~abc1234efgh5678ijklmnop9qrstuvwx`\n    \n\n**3\\. Tenant ID** (string, required)\n\n*   **What it is:** The unique identifier for your Microsoft 365 tenant (organization).\n    \n*   **Where to find it:** In the Azure portal, under \"Azure Active Directory\" > \"Overview\" > \"Tenant ID\".\n    \n*   **Example:** `72f988bf-86f1-41af-91ab-2d7cd011db47`\n    \n\n**4\\. SharePoint Site ID** (string, optional)\n\n*   **What it is:** The unique identifier for the SharePoint site you want to access. This is not the site URL, but an internal ID.\n    \n*   **Where to find it:** You can get this via the Microsoft Graph API or from your SharePoint admin. Sometimes, it is in the format: `contoso.sharepoint.com,12345678-90ab-cdef-1234-567890abcdef,abcdef12-3456-7890-abcd-ef1234567890`\n    \n*   **Example:** `contoso.sharepoint.com,12345678-90ab-cdef-1234-567890abcdef,abcdef12-3456-7890-abcd-ef1234567890`\n    \n\n* * *\n\n**Available Actions**\n\n#### \n\n1\\. Search Files\n\nSearch for files and documents in SharePoint using a query and optional filters.\n\n**Inputs**\n\nName\n\nDescription\n\nExample\n\nRequired\n\nThe search string to find files and documents\n\nList of file types to filter by\n\nMaximum number of results to return\n\n*   **Search Query** (string, required): The keywords or phrase to search for in file names and content.\n    \n*   **File Types** (array of strings, optional): Filter results by file extensions (e.g., \"pdf\", \"docx\", \"xlsx\").\n    \n    *   You can include any file extension that is supported by your SharePoint environment.\n        \n    *   Common examples include:\n        \n        *   `\"pdf\"` (PDF documents)\n            \n        *   `\"docx\"` (Word documents)\n            \n        *   `\"xlsx\"` (Excel spreadsheets)\n            \n        *   `\"pptx\"` (PowerPoint presentations)\n            \n        *   `\"txt\"` (Text files)\n            \n        *   `\"csv\"` (Comma-separated values)\n            \n        *   `\"jpg\"`, `\"png\"`, `\"gif\"` (Image files)\n            \n        *   `\"zip\"` (Compressed archives)\n            \n        *   ...and any other file extension that your SharePoint instance stores\n            \n        \n    \n*   **Max Results** (integer, optional, default: 20): Limit the number of files returned.\n    \n\n**Outputs**\n\nEach file in the output includes:\n\n*   **File ID** (string): Unique identifier for the file.\n    \n*   **File Name** (string): Name of the file.\n    \n*   **File URL** (string): Direct link to access the file.\n    \n*   **File Type** (string): File extension/type (e.g., \"pdf\").\n    \n*   **Modified Date** (string): Last modified date.\n    \n*   **Size** (integer): File size in bytes.\n    \n*   **Author** (string): File author or creator.\n    \n\n**Example Output:**\n\n```\n{\n  \"files\": [\n    {\n      \"file_id\": \"12345\",\n      \"file_name\": \"Quarterly_Report_Q1.pdf\",\n      \"file_url\": \"https://contoso.sharepoint.com/sites/finance/Shared%20Documents/Quarterly_Report_Q1.pdf\",\n      \"file_type\": \"pdf\",\n      \"modified_date\": \"2025-06-15T10:23:45Z\",\n      \"size\": 1048576,\n      \"author\": \"Jane Doe\"\n    },\n    {\n      \"file_id\": \"67890\",\n      \"file_name\": \"Budget_2025.pdf\",\n      \"file_url\": \"https://contoso.sharepoint.com/sites/finance/Shared%20Documents/Budget_2025.pdf\",\n      \"file_type\": \"pdf\",\n      \"modified_date\": \"2025-07-01T14:05:12Z\",\n      \"size\": 2097152,\n      \"author\": \"John Smith\"\n    }\n  ],\n  \"total_count\": 2\n}\n```\n\n#### \n\n2\\. Search Files\n\nThis action creates a new Microsoft Word (DOCX) file in a specified SharePoint site and folder, with the content you provide (in Markdown format). Typically used to automate report generation, meeting notes, or any document creation directly into your SharePoint library.\n\n**Inputs**\n\nName\n\nDescription\n\nExample\n\nRequired\n\nName of the Word document to create (must end in `.docx`).\n\nSharePoint site hostname (e.g., your company’s SharePoint domain).\n\nSharePoint site name (e.g., `sites/YourSiteName`).\n\nDocument body text in **Markdown** format.\n\nDestination folder path within the site. If omitted, saves to root folder.\n\n`/Shared Documents/Reports`\n\n#### \n\nOutputs\n\nOn success, the action returns:\n\n*   **File ID** (string): Unique identifier of the created file.\n    \n*   **File URL** (string): URL to open the document in SharePoint/OneDrive.\n    \n\n* * *\n\n**Advanced Settings**\n\n1.  Retry on Failure: Enable retrying when the node execution fails\n    \n2.  Fallback Branch (integer): Create a separate branch that executed when this node fails, allowing you to handle errors gracefully\n    \n\n* * *\n\n**Summary Table**\n\nAction Name\n\nDescription\n\nRequired Inputs\n\nOptional Inputs\n\nOutputs\n\nSearch for files in SharePoint\n\nCreates a word document in SharePoint\n\nHostname, Site Name, Folder Path\n\n* * *\n\n**Best Practices**\n\n*   Always provide a clear and specific search query for best results.\n    \n*   Use file type filters to narrow down results when searching for specific document formats.\n    \n*   Adjust the max results parameter to control the volume of data returned.","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/slack","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/slack","loadedTime":"2025-10-17T18:29:18.106Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/slack","title":"Slack | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Slack | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1550","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dc51de51c489-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:17 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::mbd2n-1760725757824-c44be9b7d778"}},"screenshotUrl":null,"text":"Slack | StackAI\nThe Slack Node allows you to connect with your Slack account and retrieve data from specific channels, so you can feed an AI assistant with that data. You can either use the pre-configured StackAI bot (recommended for faster deployment and compliance-ready permissions) or deploy a custom bot for full control over branding and configuration.\nAdding StackAI's Slack App\nThe StackAI App for Slack can be added to both private and shared channels in your Slack workspace. Please review our privacy policy before you install the application. Below, we'll guide you through the steps required:\nStep 1: Select Slack (OAuth2) as a New Connection\nStep 2: Choose a Channel and Allow Access\nYou will see a pop-up window with StackAI requesting access.\nSelect a channel to validate the connection. This is the channel your app will be able to post to. Your app will also inherit your user permissions and be able to read from all the channels you have access to. \nStep 3: Ensure the Connection is Selected\nYou can test the connection to make sure you are connected using the \"Test\" button.\nStep 4: Use Your Slack App\nSelect the actions you would like to use in Slack. To run the actions, make sure you have the parameters filled out. \nCreating Your Own Slack App\nIf you prefer not to use OAuth2, you can connect via a custom Slack App using a Bot Token and a Channel ID.\n⚠️ Important: Each action or trigger in Slack requires specific permissions. When connecting via API tokens, you are responsible for configuring the right scopes in your Slack App. Missing permissions may prevent certain actions, triggers, or even configuration selectors from working as expected. For this reason, we recommend using the OAuth2 connection whenever possible, as it comes pre-configured with all the necessary permissions and ensures full functionality.\nStep 1: Create a Slack App Go to Slack API: Your Apps and create a new app in your workspace.\nStep 2: Configure OAuth & Permissions (add all the ones they need!) Under OAuth & Permissions, add the following scopes to your Bot Token:\napp_mentions:read assistant:write bookmarks:read bookmarks:write calls:read calls:write canvases:read canvases:write channels:read channels:write.invites channels:write.topic channels:join channels:manage channels:history conversations.connect:write conversations.connect:manage conversations.connect:read chat:write chat:write.customize chat:write.public commands dnd:read emoji:read files:read files:write groups:read groups:history groups:write groups:write.topic groups:write.invites im:read im:history im:write im:write.topic incoming-webhook lists:read lists:write links:read links:write links.embed:write metadata.message:read mpim:read mpim:history mpim:write mpim:write.topic pins:read pins:write reactions:read reactions:write reminders:read reminders:write remote_files:read remote_files:write remote_files:share team:read team.billing:read team.preferences:read triggers:read triggers:write usergroups:read usergroups:write users:read users:read.email users:write users.profile:read workflow.steps:execute workflows.templates:read workflows.templates:write\nUnder the User Token Scopes:\nOnce added, install (or reinstall) the app in your workspace to apply these permissions.\nStep 3: Include the URL for Interactivity:\nSome actions, like Send & Wait for Response, require to include the url https://api.stack-ai.com/workflow/v1/resume in the Interactivity & Shortcuts to work out. If you do not include that url, you will not be able to resume workflows using that particular action.\nSo now, it is time to include the URL. For that, enable Interactivity and include the URL, as follows:\nStep 4: Add the Integration to a Channel\nOnce the app is installed in your workspace, you need to invite it to the channel where it should operate.\nOpen Slack and go to the target channel.\nIn the message box, type:\nHit Enter. The bot is now a member of the channel and will be able to read/write messages according to the permissions you configured.\nStep 5: Retrieve Your Bot Token Copy the Bot User OAuth Token (starts with xoxb-). This token uniquely identifies your bot when making requests. Here more information on how to get it: Official guide.\nYou can also copy the User Token, highly recommended if you want to perform Search Messages.\nStep 6: Find Your Channel ID Locate the ID of the Slack channel you want to connect. Here more information on how to get it: Guide to finding Channel IDs\nStep 7: Configure the Connection in StackAI Enter the Bot Token and Channel ID in the connection form. Optionally, you can also provide a User Token (starts with xoxp-) for user-level search operations.\nOnce saved, the connection will be validated and ready for use in actions and triggers.\nAvailable Actions\n1. Search Slack Messages (slack_search_messages)\nDescription: Search for messages across the Slack workspace using query parameters with optional channel filtering.\nInputs:\nquery (string, required): Search query to find messages in the Slack workspace. Supports advanced search syntax like 'from:@user', 'in:#channel', date ranges, etc. Example: \"project update from:@John\nchannels (array of strings, optional): List of channel IDs to filter search results. We simplify the process by adding a multi-selector that automatically retrieves all the available channels. If empty, searches all accessible channels\ncount (number, optional): Maximum number of search results to return. Default: 20, Maximum: 100\nsort (string, optional): Sort results by timestamp or relevance score. Default: \"timestamp\"\nsort_dir (string, optional): Sort direction. Options: \"asc\" or \"desc\". Default: \"desc\"\nhighlight (boolean, optional): Whether to highlight matching terms in results. Default: true\nOutputs:\nquery (string): The search query that was executed (with channel filters applied)\ntotal_matches (number): Total number of messages matching the search query\nmessages (array): List of messages matching the search query. Each message contains: text, user, username, timestamp, channel_id, channel_name, permalink, is_thread_reply, parent_timestamp\nhas_more (boolean): Whether there are more results available\n2. Send a Message (slack_message)\nDescription: Send a message to a Slack channel.\nInputs:\nmessage (string, required): Content/body of the message you want to send\nchannel_id (string, required): The Slack channel to send the message to\nDynamic options populated from available channels\nOutputs:\nchannel_id (string): The Slack channel ID where the message was sent\nresults (string): The status of the message sent (confirmation or error)\nmessage_ts (string): Slack message timestamp (unique identifier)\n3. Send Message and Wait for Response (slack_send_and_wait_block_kit)\nDescription: Send a Slack message that collects an approval or free-text response using modern Block Kit.\nInputs:\nmessage (string, required): Content/body of the interactive message\nchannel_id (string, required): The Slack channel to send the interactive message to\nresponse_type (string, required): Choose response type. Options: \"approval\" (buttons) or \"free_text\" (opens modal to collect text). Default: \"approval\"\nbutton_text (string, optional): Text displayed on the primary interactive button. Default: \"Approve\"\ninclude_disapprove (boolean, optional): If true, include a Disapprove button. Default: true\ndisapprove_button_text (string, optional): Text displayed on the disapprove button. Default: \"Disapprove\"\nfree_text_placeholder (string, optional): Placeholder for the modal's text input. Used when response_type is \"free_text\"\nblock_id (string, optional): Unique identifier for the top section block\nbutton_style (string, optional): Visual style. Options: \"primary\", \"danger\" or default\nOutputs:\nchannel_id (string): The Slack channel ID where the interactive message was sent\nresults (string): The status of the interactive message sent\nmessage_ts (string): Slack message timestamp (unique identifier)\nresume_output (object, optional): User interaction data when workflow resumes\nNote: Remember if you are using your own connection to enable Interactivity and include the https://api.stack-ai.com/workflow/v1/resume url, as explained in the connection. This is critical, otherwise you will not be able to resume the workflow.\n4. Upload File (slack_upload_file)\nDescription: Upload files to Slack using modern external upload workflow with multiple source options.\nInputs:\nsource_url (string, optional): URL to download file from.\nbytes_b64 (string, optional): Base64 encoded file content.\ntext (string, optional): Raw text content to upload as a file.\nfilename (string, optional): Name of the file. Required for bytes_b64 and text modes. Optional for source_url (inferred from URL).\ntitle (string, optional): Title for the file (defaults to filename).\ncontent_type (string, optional): MIME type of the file. Auto-set to 'text/plain' for text mode.\nchannel_id (string, optional): Channel to share the file. Leave empty to keep file private.\nthread_ts (string, optional): Timestamp of thread to reply in.\ninitial_comment (string, optional): Initial comment with the file.\nunfurl_links (boolean, optional): Auto-unfurl links in comment. Default: true.\nunfurl_media (boolean, optional): Auto-unfurl media in comment. Default: true.\nOutputs:\nsuccess (boolean): Whether the file was uploaded successfully.\nfile_id (string): Unique ID of the uploaded file.\nfile_url (string): Private URL to access the file.\npermalink (string): Permanent link to the file.\nsharing_summary (string): Summary of where the file was shared.\nupload_method (string): Method used for upload.\n5. Delete Slack File (slack_delete_file)\nDescription: Delete a file from the Slack workspace permanently.\nInputs: \nfile_id (string, required): The unique ID of the file to delete.\nOutputs:\nsuccess (boolean): Whether the file was successfully deleted.\nfile_id (string): The ID of the file that was deleted.\nmessage (string): Message describing the deletion result.\n6. Get Slack File Info (slack_get_file_info)\nDescription: Get detailed information about a specific Slack file.\nInputs:\nfile_id (string, required): The unique ID of the file to get information about.\nOutputs:\nfile (object): Detailed information about the file.\nIncludes: id, name, title, mimetype, filetype, size, created, user, urls, etc.\naccess_urls (object): URLs for accessing the file (require Authorization header).\nsharing_info (object): Information about where the file is shared.\n7. List Files (slack_list_files)\nDescription: List files in the Slack workspace with filtering options.\nInputs:\nuser (string, optional): Filter files by specific user ID.\nchannel (string, optional): Filter files by specific channel.\nts_from (string, optional): Filter files created after this timestamp (Unix timestamp).\nts_to (string, optional): Filter files created before this timestamp (Unix timestamp).\ntypes (string, optional): Filter by file types. Options: \"all\", \"spaces\", \"snippets\", \"images\", \"gdocs\", \"zips\", \"pdfs\".\ncount (number, optional): Maximum number of files to return. Default: 20, Maximum: 1000.\nshow_files_hidden_by_limit (boolean, optional): Show files hidden by 5GB limit in free workspaces. Default: false.\nOutputs:\nfiles (array): List of files matching the criteria. Each file contains: id, name, title, mimetype, size, created, user, etc.\ntotal_count (number): Total number of files found.\nhas_more (boolean): Whether there are more files available.\npaging (object): Pagination information.\n8. Query Slack Channel (slack_query)\nDescription: Retrieve messages from a Slack channel. Query and retrieve messages from a pre-configured Slack channel.\nInputs:\nNo required input parameters (the channel is typically configured in the connection or node settings).\nOutputs:\nchannel_id: The Slack channel ID that was queried.\nresults: The messages retrieved from the Slack channel. Includes main messages and thread replies. Each message contains: id, text, timestamp, is_thread_reply, parent_ts.","markdown":"# Slack | StackAI\n\nThe **Slack Node** allows you to connect with your Slack account and retrieve data from specific channels, so you can feed an AI assistant with that data. You can either use the pre-configured StackAI bot (recommended for faster deployment and compliance-ready permissions) or deploy a custom bot for full control over branding and configuration.\n\n### \n\nAdding StackAI's Slack App\n\nThe StackAI App for Slack can be added to both private and shared channels in your Slack workspace. Please [review our privacy policy](https://www.stack-ai.com/privacy) before you install the application. Below, we'll guide you through the steps required:\n\n#### \n\nStep 1: Select Slack (OAuth2) as a New Connection\n\n#### \n\nStep 2: Choose a Channel and Allow Access\n\nYou will see a pop-up window with StackAI requesting access.\n\nSelect a channel to validate the connection. This is the channel your app will be able to post to. Your app will also inherit your user permissions and be able to read from all the channels you have access to.\n\n#### \n\nStep 3: Ensure the Connection is Selected\n\nYou can test the connection to make sure you are connected using the \"Test\" button.\n\n#### \n\nStep 4: Use Your Slack App\n\nSelect the actions you would like to use in Slack. To run the actions, make sure you have the parameters filled out.\n\n### \n\nCreating Your Own Slack App\n\nIf you prefer not to use OAuth2, you can connect via a custom Slack App using a **Bot Token** and a **Channel ID**.\n\n⚠️ **Important:** Each action or trigger in Slack requires specific permissions. When connecting via API tokens, you are responsible for configuring the right scopes in your Slack App. Missing permissions may prevent certain actions, triggers, or even configuration selectors from working as expected. For this reason, we **recommend using the OAuth2 connection** whenever possible, as it comes pre-configured with all the necessary permissions and ensures full functionality.\n\n**Step 1: Create a Slack App** Go to [Slack API: Your Apps](https://api.slack.com/apps) and create a new app in your workspace.\n\n**Step 2: Configure OAuth & Permissions (add all the ones they need!)** Under **OAuth & Permissions**, add the following scopes to your Bot Token:\n\n```\napp_mentions:read\nassistant:write\nbookmarks:read\nbookmarks:write\ncalls:read\ncalls:write\ncanvases:read\ncanvases:write\nchannels:read\nchannels:write.invites\nchannels:write.topic\nchannels:join\nchannels:manage\nchannels:history\nconversations.connect:write\nconversations.connect:manage\nconversations.connect:read\nchat:write\nchat:write.customize\nchat:write.public\ncommands\ndnd:read\nemoji:read\nfiles:read\nfiles:write\ngroups:read\ngroups:history\ngroups:write\ngroups:write.topic\ngroups:write.invites\nim:read\nim:history\nim:write\nim:write.topic\nincoming-webhook\nlists:read\nlists:write\nlinks:read\nlinks:write\nlinks.embed:write\nmetadata.message:read\nmpim:read\nmpim:history\nmpim:write\nmpim:write.topic\npins:read\npins:write\nreactions:read\nreactions:write\nreminders:read\nreminders:write\nremote_files:read\nremote_files:write\nremote_files:share\nteam:read\nteam.billing:read\nteam.preferences:read\ntriggers:read\ntriggers:write\nusergroups:read\nusergroups:write\nusers:read\nusers:read.email\nusers:write\nusers.profile:read\nworkflow.steps:execute\nworkflows.templates:read\nworkflows.templates:write\n```\n\nUnder the **User Token Scopes**:\n\nOnce added, install (or reinstall) the app in your workspace to apply these permissions.\n\n**Step 3: Include the URL for Interactivity:**\n\nSome actions, like Send & Wait for Response, require to include the url `https://api.stack-ai.com/workflow/v1/resume` in the Interactivity & Shortcuts to work out. If you do not include that url, you will not be able to resume workflows using that particular action.\n\nSo now, it is time to include the URL. For that, enable Interactivity and include the URL, as follows:\n\n**Step 4: Add the Integration to a Channel**\n\nOnce the app is installed in your workspace, you need to invite it to the channel where it should operate.\n\n1.  Open Slack and go to the target channel.\n    \n2.  In the message box, type:\n    \n3.  Hit **Enter**. The bot is now a member of the channel and will be able to read/write messages according to the permissions you configured.\n    \n\n**Step 5: Retrieve Your Bot Token** Copy the **Bot User OAuth Token** (starts with `xoxb-`). This token uniquely identifies your bot when making requests. Here more information on how to get it: [Official guide](https://api.slack.com/tutorials/tracks/getting-a-token).\n\nYou can also copy the User Token, highly recommended if you want to perform Search Messages.\n\n**Step 6: Find Your Channel ID** Locate the ID of the Slack channel you want to connect. Here more information on how to get it: [Guide to finding Channel IDs](https://help.socialintents.com/article/148-how-to-find-your-slack-team-id-and-slack-channel-id)\n\n**Step 7: Configure the Connection in StackAI** Enter the **Bot Token** and **Channel ID** in the connection form. Optionally, you can also provide a **User Token** (starts with `xoxp-`) for user-level search operations.\n\nOnce saved, the connection will be validated and ready for use in actions and triggers.\n\n* * *\n\n### \n\nAvailable Actions\n\n#### \n\n1\\. Search Slack Messages (slack\\_search\\_messages)\n\n*   **Description:** Search for messages across the Slack workspace using query parameters with optional channel filtering.\n    \n*   **Inputs:**\n    \n    *   `query` (string, required): Search query to find messages in the Slack workspace. Supports advanced search syntax like 'from:@user', 'in:#channel', date ranges, etc. Example: \"project update from:@John\n        \n    *   `channels` (array of strings, optional): List of channel IDs to filter search results. We simplify the process by adding a multi-selector that automatically retrieves all the available channels. If empty, searches all accessible channels\n        \n    *   `count` (number, optional): Maximum number of search results to return. Default: 20, Maximum: 100\n        \n    *   `sort` (string, optional): Sort results by timestamp or relevance score. Default: \"timestamp\"\n        \n    *   `sort_dir` (string, optional): Sort direction. Options: \"asc\" or \"desc\". Default: \"desc\"\n        \n    *   `highlight` (boolean, optional): Whether to highlight matching terms in results. Default: true\n        \n    \n*   **Outputs:**\n    \n    *   `query` (string): The search query that was executed (with channel filters applied)\n        \n    *   `total_matches` (number): Total number of messages matching the search query\n        \n    *   `messages` (array): List of messages matching the search query. Each message contains: text, user, username, timestamp, channel\\_id, channel\\_name, permalink, is\\_thread\\_reply, parent\\_timestamp\n        \n    *   `has_more` (boolean): Whether there are more results available\n        \n    \n\n#### \n\n2\\. Send a Message (`slack_message`)\n\n*   **Description:** Send a message to a Slack channel.\n    \n*   **Inputs:**\n    \n    *   `message` (string, required): Content/body of the message you want to send\n        \n    *   `channel_id` (string, required): The Slack channel to send the message to\n        \n    *   Dynamic options populated from available channels\n        \n    \n*   **Outputs:**\n    \n    *   `channel_id` (string): The Slack channel ID where the message was sent\n        \n    *   results (string): The status of the message sent (confirmation or error)\n        \n    *   message\\_ts (string): Slack message timestamp (unique identifier)\n        \n    \n\n#### \n\n3\\. Send Message and Wait for Response (`slack_send_and_wait_block_kit`)\n\n*   **Description:** Send a Slack message that collects an approval or free-text response using modern Block Kit.\n    \n*   **Inputs:**\n    \n    *   `message` (string, required): Content/body of the interactive message\n        \n    *   `channel_id` (string, required): The Slack channel to send the interactive message to\n        \n    *   `response_type` (string, required): Choose response type. Options: \"approval\" (buttons) or \"free\\_text\" (opens modal to collect text). Default: \"approval\"\n        \n    *   `button_text` (string, optional): Text displayed on the primary interactive button. Default: \"Approve\"\n        \n    *   `include_disapprove` (boolean, optional): If true, include a Disapprove button. Default: true\n        \n    *   `disapprove_button_text` (string, optional): Text displayed on the disapprove button. Default: \"Disapprove\"\n        \n    *   `free_text_placeholder` (string, optional): Placeholder for the modal's text input. Used when response\\_type is \"free\\_text\"\n        \n    *   `block_id` (string, optional): Unique identifier for the top section block\n        \n    *   `button_style` (string, optional): Visual style. Options: \"primary\", \"danger\" or default\n        \n    \n*   **Outputs:**\n    \n    *   `channel_id` (string): The Slack channel ID where the interactive message was sent\n        \n    *   `results` (string): The status of the interactive message sent\n        \n    *   `message_ts` (string): Slack message timestamp (unique identifier)\n        \n    *   `resume_output` (object, optional): User interaction data when workflow resumes\n        \n    \n\n> Note: Remember if you are using your own connection to enable Interactivity and include the `https://api.stack-ai.com/workflow/v1/resume` url, as explained in the connection. This is critical, otherwise you will not be able to resume the workflow.\n\n#### \n\n4\\. Upload File (`slack_upload_file`)\n\n*   **Description:** Upload files to Slack using modern external upload workflow with multiple source options.\n    \n*   **Inputs:**\n    \n    *   `source_url` (string, optional): URL to download file from.\n        \n    *   `bytes_b64` (string, optional): Base64 encoded file content.\n        \n    *   `text` (string, optional): Raw text content to upload as a file.\n        \n    *   `filename` (string, optional): Name of the file. Required for bytes\\_b64 and text modes. Optional for source\\_url (inferred from URL).\n        \n    *   `title` (string, optional): Title for the file (defaults to filename).\n        \n    *   `content_type` (string, optional): MIME type of the file. Auto-set to 'text/plain' for text mode.\n        \n    *   `channel_id` (string, optional): Channel to share the file. Leave empty to keep file private.\n        \n    *   `thread_ts` (string, optional): Timestamp of thread to reply in.\n        \n    *   `initial_comment` (string, optional): Initial comment with the file.\n        \n    *   `unfurl_links` (boolean, optional): Auto-unfurl links in comment. Default: true.\n        \n    *   `unfurl_media` (boolean, optional): Auto-unfurl media in comment. Default: true.\n        \n    \n*   #### \n    \n    Outputs:\n    \n    *   `success` (boolean): Whether the file was uploaded successfully.\n        \n    *   `file_id` (string): Unique ID of the uploaded file.\n        \n    *   `file_url` (string): Private URL to access the file.\n        \n    *   `permalink` (string): Permanent link to the file.\n        \n    *   `sharing_summary` (string): Summary of where the file was shared.\n        \n    *   `upload_method` (string): Method used for upload.\n        \n    \n\n#### \n\n5\\. Delete Slack File (`slack_delete_file`)\n\n*   **Description:** Delete a file from the Slack workspace permanently.\n    \n*   **Inputs:**\n    \n    *   `file_id` (string, required): The unique ID of the file to delete.\n        \n    \n*   **Outputs:**\n    \n    *   `success` (boolean): Whether the file was successfully deleted.\n        \n    *   `file_id` (string): The ID of the file that was deleted.\n        \n    *   `message` (string): Message describing the deletion result.\n        \n    \n\n#### \n\n6\\. Get Slack File Info (`slack_get_file_info`)\n\n*   **Description:** Get detailed information about a specific Slack file.\n    \n*   **Inputs:**\n    \n    *   `file_id` (string, required): The unique ID of the file to get information about.\n        \n    \n*   **Outputs:**\n    \n    *   `file` (object): Detailed information about the file.\n        \n    *   `Includes`: id, name, title, mimetype, filetype, size, created, user, urls, etc.\n        \n    *   `access_urls` (object): URLs for accessing the file (require Authorization header).\n        \n    *   `sharing_info` (object): Information about where the file is shared.\n        \n    \n\n#### \n\n7\\. List Files (`slack_list_files`)\n\n*   **Description:** List files in the Slack workspace with filtering options.\n    \n*   **Inputs:**\n    \n    *   `user` (string, optional): Filter files by specific user ID.\n        \n    *   `channel` (string, optional): Filter files by specific channel.\n        \n    *   `ts_from` (string, optional): Filter files created after this timestamp (Unix timestamp).\n        \n    *   `ts_to` (string, optional): Filter files created before this timestamp (Unix timestamp).\n        \n    *   `types` (string, optional): Filter by file types. Options: \"all\", \"spaces\", \"snippets\", \"images\", \"gdocs\", \"zips\", \"pdfs\".\n        \n    *   `count` (number, optional): Maximum number of files to return. Default: 20, Maximum: 1000.\n        \n    *   `show_files_hidden_by_limit` (boolean, optional): Show files hidden by 5GB limit in free workspaces. Default: false.\n        \n    \n*   **Outputs:**\n    \n    *   `files` (array): List of files matching the criteria. Each file contains: id, name, title, mimetype, size, created, user, etc.\n        \n    *   `total_count` (number): Total number of files found.\n        \n    *   `has_more` (boolean): Whether there are more files available.\n        \n    *   `paging` (object): Pagination information.\n        \n    \n\n#### \n\n8\\. Query Slack Channel (`slack_query`)\n\n*   **Description:** Retrieve messages from a Slack channel. Query and retrieve messages from a pre-configured Slack channel.\n    \n*   **Inputs:**\n    \n    *   No required input parameters (the channel is typically configured in the connection or node settings).\n        \n    \n*   **Outputs:**\n    \n    *   `channel_id`: The Slack channel ID that was queried.\n        \n    *   `results`: The messages retrieved from the Slack channel. Includes main messages and thread replies. Each message contains: id, text, timestamp, is\\_thread\\_reply, parent\\_ts.","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/snowflake","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/snowflake","loadedTime":"2025-10-17T18:29:18.412Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/snowflake","title":"Snowflake | StackAI","description":"This guide walks you through how to create a new connection to a Snowflake account","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Snowflake | StackAI"},{"property":"og:description","content":"This guide walks you through how to create a new connection to a Snowflake account"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1554","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dc546afcd635-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:18 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::qq4hq-1760725758193-f5eddbf41f5b"}},"screenshotUrl":null,"text":"Snowflake | StackAI\nThis guide walks you through how to create a new connection to a Snowflake account\nThe Snowflake Node allows you to interact with a Snowflake database—either by querying data or inserting new records.\nConnecting to Snowflake\nClick the node to open its settings, then select New connection.\nEnter the required connection details into the form according to the table and notes below:\nThis is whatever you want to name the connection\nYour chosen Snowflake account username\nYour chosen Snowflake account password\nOnly if using key-pair authentication\nnqxzcwd-ab12345 (see where to find below)\nDUMMY_WAREHOUSE (see where to find below)\nACCOUNTADMIN (see where to find below)\nDUMMY_DB (see where to find below)\nDUMMY_SCHEMA (see where to find below)\nNote: You need to enter at least one of the two optional fields\nAccount\nThis is your account identifier. Find it here:\nWarehouse\nFind it here:\nRole\nFind it here:\nDatabase\nFind it here:\nSchema\nFind it here:\nAvailable Actions\n1. Query a Snowflake Database (database_query_snowflake)\nDescription: Run queries against your Snowflake database and retrieve results.\nInputs:\nsql_schema (array of strings, required): The schema of your database (tables, columns, types, etc.). Example:\nTABLE MyTable (Name TEXT, Email TEXT, Weight REAL, Height REAL);\nquery (string, required): The query you want to run. This can be in plain English or SQL. Example:\n\"What is the total revenue for the year 2024?\"\n\"Show me the top 10 customers by revenue\"\n\"SELECT * FROM MyTable WHERE Name = 'John'\"\nOutputs:\nsql_query (string): The SQL query that was executed.\nresults (array of objects): The results of the query.\n2. Insert Data into Snowflake (database_insert_snowflake)\nDescription: Insert new records into a table in your Snowflake database.\nInputs:\ntable_name (string, required): The name of the table where you want to insert data.\ndata (object/dictionary, required): The data to insert, as key-value pairs where keys are column names and values are the data. Example:\nOutputs:\nsql_query (string): The INSERT SQL query that was executed.\nrows_affected (integer): Number of rows affected by the insert.\nsuccess (boolean): Whether the insert was successful.\nSummary Table\nAction Name\nDescription\nKey Inputs\nKey Outputs\nRun queries and get results\nInsert Data into Snowflake\nInsert new records into a table\nsql_query, rows_affected, success\nLast updated 3 months ago","markdown":"# Snowflake | StackAI\n\nThis guide walks you through how to create a new connection to a Snowflake account\n\nThe **Snowflake Node** allows you to interact with a Snowflake database—either by querying data or inserting new records.\n\n* * *\n\n### \n\nConnecting to Snowflake\n\nClick the node to open its settings, then select **New connection**.\n\n![](https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3697023207-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FFSlso1Kjob5CLDrh0dVn%252Fuploads%252Fu2gH4mUA2IKV46iUiBI3%252Fimage.png%3Falt%3Dmedia%26token%3Db6e5e2f0-dc86-4f5f-8da9-ca9306a6630b&width=300&dpr=4&quality=100&sign=2b05c8f3&sv=2)\n\nEnter the required connection details into the form according to the table and notes below:\n\nThis is whatever you want to name the connection\n\nYour chosen Snowflake account username\n\nYour chosen Snowflake account password\n\nOnly if using key-pair authentication\n\n`nqxzcwd-ab12345` (see where to find below)\n\n`DUMMY_WAREHOUSE` (see where to find below)\n\n`ACCOUNTADMIN` (see where to find below)\n\n`DUMMY_DB` (see where to find below)\n\n`DUMMY_SCHEMA` (see where to find below)\n\n**Note**: You need to enter at least one of the two optional fields\n\n### \n\nAccount\n\nThis is your account identifier. Find it here:\n\n### \n\nWarehouse\n\nFind it here:\n\n### \n\nRole\n\nFind it here:\n\n### \n\nDatabase\n\nFind it here:\n\n### \n\nSchema\n\nFind it here:\n\n### \n\nAvailable Actions\n\n#### \n\n1\\. Query a Snowflake Database (`database_query_snowflake`)\n\n*   **Description:** Run queries against your Snowflake database and retrieve results.\n    \n*   **Inputs:**\n    \n    *   `sql_schema` (array of strings, required): The schema of your database (tables, columns, types, etc.). Example:\n        \n        ```\n        TABLE MyTable (Name TEXT, Email TEXT, Weight REAL, Height REAL);\n        ```\n        \n    *   `query` (string, required): The query you want to run. This can be in plain English or SQL. Example:\n        \n        *   \"What is the total revenue for the year 2024?\"\n            \n        *   \"Show me the top 10 customers by revenue\"\n            \n        *   \"SELECT \\* FROM MyTable WHERE Name = 'John'\"\n            \n        \n    \n*   **Outputs:**\n    \n    *   `sql_query` (string): The SQL query that was executed.\n        \n    *   `results` (array of objects): The results of the query.\n        \n    \n\n#### \n\n2\\. Insert Data into Snowflake (`database_insert_snowflake`)\n\n*   **Description:** Insert new records into a table in your Snowflake database.\n    \n*   **Inputs:**\n    \n    *   `table_name` (string, required): The name of the table where you want to insert data.\n        \n    *   `data` (object/dictionary, required): The data to insert, as key-value pairs where keys are column names and values are the data. Example:\n        \n    \n*   **Outputs:**\n    \n    *   `sql_query` (string): The INSERT SQL query that was executed.\n        \n    *   `rows_affected` (integer): Number of rows affected by the insert.\n        \n    *   `success` (boolean): Whether the insert was successful.\n        \n    \n\n* * *\n\n### \n\nSummary Table\n\nAction Name\n\nDescription\n\nKey Inputs\n\nKey Outputs\n\nRun queries and get results\n\nInsert Data into Snowflake\n\nInsert new records into a table\n\nsql\\_query, rows\\_affected, success\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/stackai","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/stackai","loadedTime":"2025-10-17T18:29:19.722Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/stackai","title":"StackAI | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"StackAI | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1552","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dc5ccf93d650-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:19 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::x9ptz-1760725759547-80ca257f8f13"}},"screenshotUrl":null,"text":"StackAI | StackAI\nThe StackAI Node allows you to perform a variety of tasks within your workflow by leveraging built-in Stack AI tools. Each action is designed for a specific use case, and you can configure the node to perform the action you need by selecting the appropriate action ID and providing the required inputs.\nAvailable Actions\n1. Analysis Tool\nPurpose: Analyze data, create charts, and translate natural language queries into Python code.\nHow to use: Provide a self-contained query describing the analysis you want to perform. The tool will generate and execute Python code in a stateless environment (no memory of previous runs).\nInputs:\nQuery (string, required): The natural language description of the analysis or chart you want.\nOutputs:\nSuccess (boolean): Whether the code ran successfully.\nCode (string): The Python code that was executed.\nResult (string): The result of the code execution.\nChart URL (string, optional): A public URL to any chart generated.\n2. Send Email\nPurpose: Send an email to a specified recipient.\nHow to use: Provide the subject, content (HTML supported), and recipient's email address.\nInputs:\nSubject (string, required): The subject line of the email.\nContent (string, required): The main body of the email (HTML supported).\nTo (string, required): The recipient's email address.\nOutputs:\nStatus (string): Success or error.\nMessage (string): A human-readable message about the result.\nDetails (string): A summary of the sent email (from, to, subject, content).\n3. StackAI Project\nPurpose: Execute another Stack AI project as a subflow.\nHow to use: Select a Stack AI project and provide input data (as a list). Optionally, enable loop mode to run the project for each item in the list.\nInputs:\nProject (select, required): The Stack AI project to execute.\nLoop Mode (boolean, optional): If enabled, runs the project for each item in the input list.\nInput Data (array of strings, required): The data to pass to the project.\nOutputs:\nResults (array of objects): The results from the project execution.\n4. Send HTTP Request\nPurpose: Make a custom API call to any HTTP endpoint.\nHow to use: Specify the URL, HTTP method, and optionally headers, query parameters, and request body.\nInputs:\nURL (string, required): The endpoint to call.\nHTTP Method (select, required): GET, POST, PUT, DELETE, PATCH, HEAD, or OPTIONS.\nHeaders (object, optional): HTTP headers as key-value pairs.\nQueries (object, optional): Query parameters as key-value pairs.\nRequest Body (object, optional): Data to send as JSON.\nOutputs:\nStatus Code (integer): The HTTP status code.\nHeaders (object): The response headers.\nBody (object/string/array): The response body.\n5. Create Slides\nPurpose: Generate HTML slides from a prompt.\nHow to use: Provide a prompt describing the slides you want to create.\nInputs:\nQuery (string, required): The prompt for the slides.\nOutputs:\nSuccess (boolean): Whether the slides were created.\nSlides (array): The generated slides (each with a title and content).\nTitle (string): The title of the slide deck.\n6. Image to Image\nPurpose: Transform an image using a vision model, guided by a prompt.\nHow to use: Provide the URL of the source image, a prompt describing the transformation, and select a model.\nInputs:\nSource Image URL (string, required): The image to transform.\nTransformation Prompt (string, required): Description of the desired transformation.\nVision Model (select, required): The model to use (e.g., Flux Kontext Max).\nOutputs:\nTransformed Image URL (string): The URL of the transformed image.\n7. List Actions\nPurpose: List all available actions for every provider.\nHow to use: No input required.\nOutputs:\nActions by Provider (object): A mapping of provider IDs to lists of available action IDs.\n8. Get Actions Info\nPurpose: Get detailed information about a specific action (input/output schema, etc.).\nHow to use: Provide the provider ID and action ID.\nInputs:\nProvider ID (string, required): The provider (e.g., stackai, gmail, slack).\nAction ID (string, required): The action (e.g., send_email, list_actions).\nOutputs:\nAction Info (object): Complete information about the action, including input and output schemas.\n9. Generate Workflow\nPurpose: Validate and generate a workflow structure from a list of nodes and edges.\nHow to use: Provide arrays of nodes and edges as dictionaries.\nInputs:\nNodes (array, required): List of workflow nodes.\nEdges (array, required): List of workflow edges.\nOutputs:\nNodes (array): The validated list of workflow nodes.\nEdges (array): The validated list of workflow edges.\nLast updated 3 months ago","markdown":"# StackAI | StackAI\n\nThe **StackAI Node** allows you to perform a variety of tasks within your workflow by leveraging built-in Stack AI tools. Each action is designed for a specific use case, and you can configure the node to perform the action you need by selecting the appropriate action ID and providing the required inputs.\n\n* * *\n\n### \n\nAvailable Actions\n\n#### \n\n1\\. **Analysis Tool**\n\n*   **Purpose:** Analyze data, create charts, and translate natural language queries into Python code.\n    \n*   **How to use:** Provide a self-contained query describing the analysis you want to perform. The tool will generate and execute Python code in a stateless environment (no memory of previous runs).\n    \n*   **Inputs:**\n    \n    *   **Query (string, required):** The natural language description of the analysis or chart you want.\n        \n    \n*   **Outputs:**\n    \n    *   **Success (boolean):** Whether the code ran successfully.\n        \n    *   **Code (string):** The Python code that was executed.\n        \n    *   **Result (string):** The result of the code execution.\n        \n    *   **Chart URL (string, optional):** A public URL to any chart generated.\n        \n    \n\n* * *\n\n#### \n\n2\\. **Send Email**\n\n*   **Purpose:** Send an email to a specified recipient.\n    \n*   **How to use:** Provide the subject, content (HTML supported), and recipient's email address.\n    \n*   **Inputs:**\n    \n    *   **Subject (string, required):** The subject line of the email.\n        \n    *   **Content (string, required):** The main body of the email (HTML supported).\n        \n    *   **To (string, required):** The recipient's email address.\n        \n    \n*   **Outputs:**\n    \n    *   **Status (string):** Success or error.\n        \n    *   **Message (string):** A human-readable message about the result.\n        \n    *   **Details (string):** A summary of the sent email (from, to, subject, content).\n        \n    \n\n* * *\n\n#### \n\n3\\. **StackAI Project**\n\n*   **Purpose:** Execute another Stack AI project as a subflow.\n    \n*   **How to use:** Select a Stack AI project and provide input data (as a list). Optionally, enable loop mode to run the project for each item in the list.\n    \n*   **Inputs:**\n    \n    *   **Project (select, required):** The Stack AI project to execute.\n        \n    *   **Loop Mode (boolean, optional):** If enabled, runs the project for each item in the input list.\n        \n    *   **Input Data (array of strings, required):** The data to pass to the project.\n        \n    \n*   **Outputs:**\n    \n    *   **Results (array of objects):** The results from the project execution.\n        \n    \n\n* * *\n\n#### \n\n4\\. **Send HTTP Request**\n\n*   **Purpose:** Make a custom API call to any HTTP endpoint.\n    \n*   **How to use:** Specify the URL, HTTP method, and optionally headers, query parameters, and request body.\n    \n*   **Inputs:**\n    \n    *   **URL (string, required):** The endpoint to call.\n        \n    *   **HTTP Method (select, required):** GET, POST, PUT, DELETE, PATCH, HEAD, or OPTIONS.\n        \n    *   **Headers (object, optional):** HTTP headers as key-value pairs.\n        \n    *   **Queries (object, optional):** Query parameters as key-value pairs.\n        \n    *   **Request Body (object, optional):** Data to send as JSON.\n        \n    \n*   **Outputs:**\n    \n    *   **Status Code (integer):** The HTTP status code.\n        \n    *   **Headers (object):** The response headers.\n        \n    *   **Body (object/string/array):** The response body.\n        \n    \n\n* * *\n\n#### \n\n5\\. **Create Slides**\n\n*   **Purpose:** Generate HTML slides from a prompt.\n    \n*   **How to use:** Provide a prompt describing the slides you want to create.\n    \n*   **Inputs:**\n    \n    *   **Query (string, required):** The prompt for the slides.\n        \n    \n*   **Outputs:**\n    \n    *   **Success (boolean):** Whether the slides were created.\n        \n    *   **Slides (array):** The generated slides (each with a title and content).\n        \n    *   **Title (string):** The title of the slide deck.\n        \n    \n\n* * *\n\n#### \n\n6\\. **Image to Image**\n\n*   **Purpose:** Transform an image using a vision model, guided by a prompt.\n    \n*   **How to use:** Provide the URL of the source image, a prompt describing the transformation, and select a model.\n    \n*   **Inputs:**\n    \n    *   **Source Image URL (string, required):** The image to transform.\n        \n    *   **Transformation Prompt (string, required):** Description of the desired transformation.\n        \n    *   **Vision Model (select, required):** The model to use (e.g., Flux Kontext Max).\n        \n    \n*   **Outputs:**\n    \n    *   **Transformed Image URL (string):** The URL of the transformed image.\n        \n    \n\n* * *\n\n#### \n\n7\\. **List Actions**\n\n*   **Purpose:** List all available actions for every provider.\n    \n*   **How to use:** No input required.\n    \n*   **Outputs:**\n    \n    *   **Actions by Provider (object):** A mapping of provider IDs to lists of available action IDs.\n        \n    \n\n* * *\n\n#### \n\n8\\. **Get Actions Info**\n\n*   **Purpose:** Get detailed information about a specific action (input/output schema, etc.).\n    \n*   **How to use:** Provide the provider ID and action ID.\n    \n*   **Inputs:**\n    \n    *   **Provider ID (string, required):** The provider (e.g., stackai, gmail, slack).\n        \n    *   **Action ID (string, required):** The action (e.g., send\\_email, list\\_actions).\n        \n    \n*   **Outputs:**\n    \n    *   **Action Info (object):** Complete information about the action, including input and output schemas.\n        \n    \n\n* * *\n\n#### \n\n9\\. **Generate Workflow**\n\n*   **Purpose:** Validate and generate a workflow structure from a list of nodes and edges.\n    \n*   **How to use:** Provide arrays of nodes and edges as dictionaries.\n    \n*   **Inputs:**\n    \n    *   **Nodes (array, required):** List of workflow nodes.\n        \n    *   **Edges (array, required):** List of workflow edges.\n        \n    \n*   **Outputs:**\n    \n    *   **Nodes (array):** The validated list of workflow nodes.\n        \n    *   **Edges (array):** The validated list of workflow edges.\n        \n    \n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/platform-overview","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/platform-overview","loadedTime":"2025-10-17T18:29:22.459Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/platform-overview","title":"Platform Overview | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Platform Overview | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1617","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dc6deccd0bfe-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:22 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::4569t-1760725762268-e660b0d51233"}},"screenshotUrl":null,"text":"Platform Overview | StackAI\nProjects Dashboard\nLet's start by creating a new project in Stack AI dashboard. Click on the \"New Project\" button in the top right corner of the dashboard.\nTemplates\nCreate a Quick Start project to open a blank project, or browse through a list of pre-built templates. You can choose the \"Chat with Knowledge Base\" template to build an application where your users can ask questions on a knowledge base you've uploaded. \nYou can search for a specific application you would like to integrate with a Large Language Model, like \"Gmail,\" or you can look through the list of use cases on the left side of the screen.\nWorkflow View\nOnce you create a project, you will see an interface with 3 main components:\nWorkflow View\nCanvas: the main component of the Stack AI tool, a 2D canvas where you can drag and drop nodes and connect them to build your workflow.\nSidebar: a large variety of functionality blocks, also called nodes, can be found on the left hand side. These nodes represent components in the flow where data is received, processed, and returned from different services. Chat with Workflow on the bottom of the sidebar for advice on how to build or to learn about what an existing project does.\nControl bar: a set of commands at the top right hand side with buttons to 'Save' (save the current version), 'Run' (execute the workflow as it is in the canvas), 'Share' (share the current version with another Stack AI user), and 'Publish' (make your workflow available externally).\nThe Workflow View is where you can build your project, by dragging and connecting the necessary nodes to create your agent. Once you are ready to deploy your agent to users, hit 'Publish' in the top right corner. If its your first time publishing your project, you will be prompted to enter the Export View to choose an interface for your agent.\nOther Important Views\nExport View\nBy clicking the 'Export' button in the top left side bar, you will see a view with different interface options.\nWe offer pre-built interfaces for your AI chatbots that can be easily customized to match your brand's look and feel.\nYou can choose from a ChatGPT-style interface, a website chatbot, a voice interface, or deploy your chatbot via Slack, WhatsApp, or SMS. We offer the option to use Stack AI as a backend process, leveraging our APIs to send inputs, receive results, and build your own custom UI.\nYou will find different customization options in the Export tab (name, logo, colors, etc.). Configure a custom domain if required and protect your chatbot with SSO or password.\nAn URL is generated for you to share with your colleagues.\nIMPORTANT: whenever you make changes to your project in the Builder View, always remember to click the Publish button. This will update the assistant's user interface.\nAnalytics View\nClicking on the 'Analytics' button in the top left sidebar will display a summary of your workflow usage.\nThis page features four graphs that provide an overview of workflow utilization, along with a complete list of execution logs. The logs include valuable information such as the execution status, runtime, tokens consumed, and the workflow's inputs and outputs. Additionally, you can filter the analytics by date using the selector in the top left corner.\nManager View\nClicking the 'Manager' button in the top left sidebar will take you to a view with all user conversations with your workflow. To download all conversations, click the \"Download\" button. To clear the conversation history, click \"Delete\".\nEvaluator View\nClick 'Evaluator' to enter the Evaluator View. This view allows you to test your agent on a batch of inputs uploaded in a CSV file. You can have the output be graded by another LLM, who will judge whether your agent outputs desirable results. You can also have the LLM compare the output of your agent to a gold standard answer, or make suggestions. Just edit the prompt on the right side of the screen.\nLast updated 3 months ago","markdown":"# Platform Overview | StackAI\n\n### \n\nProjects Dashboard\n\nLet's start by creating a new project in Stack AI dashboard. Click on the \"New Project\" button in the top right corner of the dashboard.\n\n#### \n\nTemplates\n\nCreate a Quick Start project to open a blank project, or browse through a list of pre-built templates. You can choose the \"Chat with Knowledge Base\" template to build an application where your users can ask questions on a knowledge base you've uploaded.\n\nYou can search for a specific application you would like to integrate with a Large Language Model, like \"Gmail,\" or you can look through the list of use cases on the left side of the screen.\n\n### \n\nWorkflow View\n\nOnce you create a project, you will see an interface with 3 main components:\n\n**Workflow View**\n\n*   **Canvas:** the main component of the Stack AI tool, a 2D canvas where you can drag and drop nodes and connect them to build your workflow.\n    \n*   **Sidebar:** a large variety of functionality blocks, also called nodes, can be found on the left hand side. These nodes represent components in the flow where data is received, processed, and returned from different services. Chat with Workflow on the bottom of the sidebar for advice on how to build or to learn about what an existing project does.\n    \n*   **Control bar:** a set of commands at the top right hand side with buttons to **'Save'** (save the current version), **'Run'** (execute the workflow as it is in the canvas), **'Share'** (share the current version with another Stack AI user), and **'Publish'** (make your workflow available externally).\n    \n\nThe Workflow View is where you can build your project, by dragging and connecting the necessary nodes to create your agent. Once you are ready to deploy your agent to users, hit **'Publish'** in the top right corner. If its your first time publishing your project, you will be prompted to enter the Export View to choose an interface for your agent.\n\n### \n\nOther Important Views\n\n**Export View**\n\nBy clicking the **'Export'** button in the top left side bar, you will see a view with different interface options.\n\nWe offer pre-built interfaces for your AI chatbots that can be easily customized to match your brand's look and feel.\n\nYou can choose from a **ChatGPT-style interface**, a **website chatbot**, a **voice interface**, or deploy your chatbot via **Slack, WhatsApp, or SMS**. We offer the option to use Stack AI as a backend process, **leveraging our APIs** to send inputs, receive results, and **build your own custom UI**.\n\nYou will find different customization options in the Export tab **(name, logo, colors, etc.)**. Configure a **custom domain** if required and protect your chatbot with **SSO or password**.\n\nAn URL is generated for you to share with your colleagues.\n\n**IMPORTANT:** whenever you make changes to your project in the **Builder View**, always remember to click the **Publish** button. This will update the assistant's user interface.\n\n#### \n\nAnalytics View\n\nClicking on the **'Analytics'** button in the top left sidebar will display a summary of your workflow usage.\n\nThis page features four graphs that provide an overview of workflow utilization, along with a complete list of execution logs. The logs include valuable information such as the execution status, runtime, tokens consumed, and the workflow's inputs and outputs. Additionally, you can filter the analytics by date using the selector in the top left corner.\n\n#### \n\nManager View\n\nClicking the **'Manager'** button in the top left sidebar will take you to a view with all user conversations with your workflow. To download all conversations, click the **\"Download\"** button. To clear the conversation history, click **\"Delete\"**.\n\n**Evaluator View**\n\nClick 'Evaluator' to enter the Evaluator View. This view allows you to test your agent on a batch of inputs uploaded in a CSV file. You can have the output be graded by another LLM, who will judge whether your agent outputs desirable results. You can also have the LLM compare the output of your agent to a gold standard answer, or make suggestions. Just edit the prompt on the right side of the screen.\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/security-and-privacy","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/security-and-privacy","loadedTime":"2025-10-17T18:29:22.603Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/security-and-privacy","title":"Security & Privacy | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Security & Privacy | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1617","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dc6efe49c9a1-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:22 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::59gcl-1760725762434-7bda8afa59dc"}},"screenshotUrl":null,"text":"Security & Privacy | StackAI\nStackAI prioritizes data protection and compliance, making it suitable for industries with stringent regulatory requirements. Key security features include:\nCompliance Certifications: Adherence to SOC 2 Type II, HIPAA, and GDPR standards ensures that data handling meets global regulatory requirements.\nGuardrails: LLMs can deviate from their initial requirements by answering questions they were not prompted to answer. Guardrails allow our customers to ensure LLMs do not answer questions and topics they are not supposed to reply.\nPII Protection: Built-in mechanisms detect and mask Personally Identifiable Information (PII), safeguarding sensitive data during processing.\nPII protection at the LLM node:\nData Retention Policies: Organizations can define data retention durations, ensuring data is stored only as long as necessary.\nNo Data Training: StackAI ensures that user data is not used to train AI models as part of its enterprise agreements with providers, maintaining data confidentiality.\nMulti-Factor Authentication\nTo turn on MFA, go to Settings -> Feature Access -> Authentication. Click manage and turn on MFA. This will apply to all users in your organization.\nLast updated 2 months ago","markdown":"# Security & Privacy | StackAI\n\nStackAI prioritizes data protection and compliance, making it suitable for industries with stringent regulatory requirements. Key security features include:\n\n*   **Compliance Certifications**: Adherence to SOC 2 Type II, HIPAA, and GDPR standards ensures that data handling meets global regulatory requirements.\n    \n*   **Guardrails**: LLMs can deviate from their initial requirements by answering questions they were not prompted to answer. Guardrails allow our customers to ensure LLMs do not answer questions and topics they are not supposed to reply.\n    \n*   **PII Protection**: Built-in mechanisms detect and mask Personally Identifiable Information (PII), safeguarding sensitive data during processing.\n    \n\n[PII protection at the LLM node](https://docs.stack-ai.com/stack-ai/workflow-builder/llms/llm-provider-governance):\n\n*   Data Retention Policies: Organizations can define data retention durations, ensuring data is stored only as long as necessary.\n    \n*   No Data Training: StackAI ensures that user data is not used to train AI models as part of its enterprise agreements with providers, maintaining data confidentiality.\n    \n\n#### \n\nMulti-Factor Authentication\n\nTo turn on MFA, go to Settings -> Feature Access -> Authentication. Click manage and turn on MFA. This will apply to all users in your organization.\n\nLast updated 2 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/ai-governance","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/ai-governance","loadedTime":"2025-10-17T18:29:24.991Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/ai-governance","title":"AI Governance | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"AI Governance | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1620","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dc7da89ec9b8-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:24 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::mbd2n-1760725764770-18f480c78c8e"}},"screenshotUrl":null,"text":"AI Governance | StackAI\nTo manage AI deployments effectively, StackAI offers governance features like:\nRole-Based Access Control (RBAC): Define user permissions at granular levels, including access to the knowledge base and connections.\nSingle Sign-On (SSO): Integrate with identity providers like Okta and Entra ID for user authentication and inheritance of groups and permissions.\nProject Publishing Controls: Restrict project publishing capabilities to authorized personnel, ensuring oversight.\nCentralized Monitoring: A unified dashboard allows administrators to monitor agent activities, usage metrics, and error logs in real-time.\nBelow is a comprehensive guide to StackAI’s governance model, designed for teams that need speed without losing control.\nThe StackAI Governance Model (8 Layers)\n1) Role-Based Access Control (RBAC) and Groups\nAdmins can create groups (e.g., “Legal,” “HR,” “Capture Team”) and assign them to workspaces/projects for coarse-grained control.\n2) Workspace and Folder Access (Scope Control)\nEasily create private group folders with specific allowlists. Only assigned users or groups can see what’s inside—others see nothing.\nEasily view project owners and editors as well, by hovering over a project or in a list view.\n3) Project Controls (Edit, Lock, Versioning)\nCreators can lock a project (only the owner edits; admins can override).\nAll changes made to projects can be tracked with version control and diffs, so you can see exactly who changed what and when, and roll back. You can easily see all previously published versions of a project; and versions can be tagged with a commit message to clarify what changes were made. Easily go back to a previous version if desired.\n4) Interface-Level Security (How You Publish)\nWhen you export an agent (advanced form, chatbot, Slackbot, etc.), you can:\nEnable one-click SSO on the interface editor\nSet a password for external collaborators.\nRestrict by allowed origins/URLs and even a user allowlist.\n5) Global Governance and Admin Policy (Feature Access and Guardrails)\nOrg admins can set cross-cutting policy:\nRequire SSO on all interfaces.\nRestrict who can publish, so that non-admins don't publish projects.\nEnable an approval/feature-flag workflow for changes, wherein users request for their project to be reviewed and published by admin.\nAllow/deny specific tools, connectors, and more through Feature Access (e.g., block Notion/Box across the org).\nSet usage limits (e.g., token caps) as a security throttle.\nAssigning user roles.\nDisabling LLMs and adding default connections (i.e., your company’s API keys).\nYou can also build policy by group (e.g., “only Legal can access the Legal agents”).\n6) Connection and Knowledge-Base Permissions\nConnections (SharePoint, Dropbox, ServiceNow, etc.) are owned by their creator, with private details and credentials encrypted and hidden from others. Owners and admins can share a connection org-wide or limit it to specific users or groups.\nKnowledge bases support the same allowlisting, so only authorized teams can reference sensitive content.\n7) Production Analytics and Auditing\nDownloadable project analytics show who ran what, when, with which models, token counts, latency, and per-step traces (inputs, KB hits, outputs). Builders can mask or disable logs when required, or limit visibility to the owner. For certain cases of external security tooling, StackAI can deliver scheduled exports and can post to a customer webhook (e.g., daily digests) for alerting pipelines.\nBelow are some of the most widely used governance features, developed in close collaboration with our customers:\nLearn more about Analytics here.\n8) Authentication and MFA\nOrganizations can use email/password (when enabled) or SSO (recommended). Enabling SSO means protecting any or all interfaces from access by members outside of your organization; further, SSO allows you to capture the email addresses of all users of your interfaces to easily keep track of who is using your workflows. You can also require SSO for all interfaces. By default, SSO users land as users until granted higher roles.","markdown":"# AI Governance | StackAI\n\nTo manage AI deployments effectively, StackAI offers governance features like:\n\n*   Role-Based Access Control (RBAC): Define user permissions at granular levels, including access to the knowledge base and connections.\n    \n*   Single Sign-On (SSO): Integrate with identity providers like Okta and Entra ID for user authentication and inheritance of groups and permissions.\n    \n*   Project Publishing Controls: Restrict project publishing capabilities to authorized personnel, ensuring oversight.\n    \n*   Centralized Monitoring: A unified dashboard allows administrators to monitor agent activities, usage metrics, and error logs in real-time.\n    \n\nBelow is a comprehensive guide to StackAI’s governance model, designed for teams that need **speed without losing control**.\n\n## \n\nThe StackAI Governance Model (8 Layers)\n\n**1) Role-Based Access Control (RBAC) and Groups**\n\nAdmins can create **groups** (e.g., “Legal,” “HR,” “Capture Team”) and assign them to workspaces/projects for coarse-grained control.\n\n**2) Workspace and Folder Access (Scope Control)**\n\nEasily create private group folders with specific allowlists. Only assigned users or groups can see what’s inside—others see nothing.\n\nEasily view project owners and editors as well, by hovering over a project or in a list view.\n\n**3) Project Controls (Edit, Lock, Versioning)**\n\nCreators can **lock** a project (only the owner edits; admins can override).\n\nAll changes made to projects can be tracked with **version control** and diffs, so you can see exactly who changed what and when, and roll back. You can easily see all previously published versions of a project; and versions can be tagged with a commit message to clarify what changes were made. Easily go back to a previous version if desired.\n\n**4) Interface-Level Security (How You Publish)**\n\nWhen you export an agent (advanced form, chatbot, Slackbot, etc.), you can:\n\n*   Enable one-click SSO on the interface editor\n    \n*   Set a **password** for external collaborators.\n    \n*   Restrict by **allowed origins/URLs** and even a **user allowlist**.\n    \n\n**5) Global Governance and Admin Policy (Feature Access and Guardrails)**\n\nOrg admins can set cross-cutting policy:\n\n*   Require SSO on all interfaces.\n    \n*   Restrict who can **publish**, so that non-admins don't publish projects.\n    \n\n*   Enable an **approval/feature-flag** workflow for changes, wherein users request for their project to be reviewed and published by admin.\n    \n\n*   Allow/deny specific **tools, connectors, and more through Feature Access** (e.g., block Notion/Box across the org).\n    \n\n*   Set **usage limits** (e.g., token caps) as a security throttle.\n    \n*   Assigning user roles.\n    \n\n*   Disabling LLMs and adding default connections (i.e., your company’s API keys).\n    \n\nYou can also build **policy by group** (e.g., “only Legal can access the Legal agents”).\n\n**6) Connection and Knowledge-Base Permissions**\n\nConnections (SharePoint, Dropbox, ServiceNow, etc.) are owned by their creator, with private details and credentials encrypted and hidden from others. Owners and admins can share a connection org-wide or limit it to specific users or groups.\n\nKnowledge bases support the same allowlisting, so only authorized teams can reference sensitive content.\n\n**7) Production Analytics and Auditing**\n\nDownloadable project analytics show **who ran what, when, with which models**, token counts, latency, and per-step traces (inputs, KB hits, outputs). Builders can **mask or disable logs** when required, or limit visibility to the owner. For certain cases of **external security tooling**, StackAI can deliver **scheduled exports** and can **post to a customer webhook** (e.g., daily digests) for alerting pipelines.\n\nBelow are some of the most widely used governance features, developed in close collaboration with our customers:\n\nLearn more about Analytics [here](https://docs.stack-ai.com/stack-ai/other-views/analytics).\n\n**8) Authentication and MFA**\n\nOrganizations can use **email/password** (when enabled) or **SSO** (recommended). Enabling SSO means protecting **any or all** interfaces from access by members outside of your organization; further, SSO allows you to capture the email addresses of all users of your interfaces to easily keep track of who is using your workflows. You can also require SSO for all interfaces. By default, SSO users land as **users** until granted higher roles.","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/new-to-generative-ai","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/new-to-generative-ai","loadedTime":"2025-10-17T18:29:25.094Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/new-to-generative-ai","title":"New to Generative AI? | StackAI","description":"Understand how it works.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"New to Generative AI? | StackAI"},{"property":"og:description","content":"Understand how it works."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1620","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dc7e2844d6a4-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:25 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::zp2jd-1760725764865-3372ab236fa6"}},"screenshotUrl":null,"text":"New to Generative AI? | StackAI\nWhat is Generative AI?\nGenerative AI refers to a type of artificial intelligence that is capable of generating content. It involves the use of models trained to generate new data that mimic the distribution of the training data. Generative AI can create a wide array of content, including but not limited to text, images, music, and even synthetic voices.\nWhat is an LLM?\nLLM stands for Large Language Model. These models, such as GPT-4, are a type of artificial intelligence model that uses machine learning to produce human-like text. Large Language Models are trained on vast amounts of text data and can generate sentences by predicting the likelihood of a word given the previous words used in the text. They can be fine-tuned for a variety of tasks, including translation, question-answering, and writing assistance. These models are called \"large\" because they have a huge number of parameters. For example, GPT-4, one of the largest models as of today, has about 1.8 trillion adjustable parameters. Their large parameter count allows these models to capture a wide range of language patterns and nuances, but also makes them computationally expensive to train and use.\nWhat type of applications can I build with Generative AI?\nGenerative AI models have a wide range of potential applications across numerous fields. Here are some examples:\nContent Creation: These models can generate new pieces of text, music, or artwork. For example, AI could create music for a video game, generate a script for a movie, or produce articles or reports.\nChatbots and Virtual Assistants: Generative models can be used to create conversational agents that can carry on a dialogue with users, generating responses to user queries in a natural, human-like manner.\nImage Generation and Editing: Generative Adversarial Networks (GANs) can generate realistic images, design graphics, or even modify existing images in significant ways, such as changing day to night or generating a person's image in the style of a specific artist.\nProduct Design: AI can be used to generate new product designs or modify existing ones, potentially speeding up the design process and introducing new possibilities that human designers might not consider.\nMedical Applications: Generative AI can be used to create synthetic medical data, simulate patient conditions, or predict the development of diseases.\nPersonalized Recommendations: AI models can generate personalized content or product recommendations based on user data.\nData Augmentation: In situations where data is scarce, generative models can be used to create synthetic data to supplement real data for training other machine learning models.\nWhat is an embedding?\nEmbeddings are numerical representations of concepts converted to number sequences, which make it easy for computers to understand the relationships between those concepts. They are capable of capturing the context of a word in a document, its semantic and syntactic similarity, and its relation with other words.\nWhat is a vector store?\nA vector store in the context of machine learning is a storage system or database designed to handle vector data efficiently. Vector data is commonly used in fields like natural language processing and computer vision, where high-dimensional vectors are used to represent complex data like words, sentences, or images. Vectors stores are often optimized for operations that are common in machine learning, like nearest neighbor search, which involves finding the vectors in the store that are closest to a given vector. This is particularly useful in tasks like recommendation systems, where you might want to find the items that are most similar to a given item.\nWhat is a multimodal model?\nA multimodal model in the field of artificial intelligence is a model that can handle and integrate data from multiple different modalities, or types, of input. These types of inputs can include text, images, audio, video, and more. The main advantage of multimodal models is that they can leverage the strengths of different data types to make better predictions. For example, a model that takes both text and image data as input might be able to understand the context better than a model that only uses one or the other.\nWhat is the memory of an LLM?\nA Large Language Model (LLM) can generate text based on what it has seen before if it has memory. The term \"memory\" in this context refers to how much of the previous text the model can consider when producing new text. Memory is a different concept than the training set used to train the model. The model can answer things from what it knows given the training set that is was given. Additionally, considering that you are chatting with chatGPT, the model will respond to your queries considering the last responses and queries as well. This \"memory\" of the model is indeed crucial when dealing with long pieces of text or conversations, as it determines how much of the previous context the model can use to generate accurate and coherent responses.\nLast updated 3 months ago","markdown":"# New to Generative AI? | StackAI\n\n### \n\nWhat is Generative AI?\n\nGenerative AI refers to a type of artificial intelligence that is capable of generating content. It involves the use of models trained to generate new data that mimic the distribution of the training data. Generative AI can create a wide array of content, including but not limited to text, images, music, and even synthetic voices.\n\n### \n\nWhat is an LLM?\n\nLLM stands for Large Language Model. These models, such as GPT-4, are a type of artificial intelligence model that uses machine learning to produce human-like text. Large Language Models are trained on vast amounts of text data and can generate sentences by predicting the likelihood of a word given the previous words used in the text. They can be fine-tuned for a variety of tasks, including translation, question-answering, and writing assistance. These models are called \"large\" because they have a huge number of parameters. For example, GPT-4, one of the largest models as of today, has about 1.8 trillion adjustable parameters. Their large parameter count allows these models to capture a wide range of language patterns and nuances, but also makes them computationally expensive to train and use.\n\n### \n\nWhat type of applications can I build with Generative AI?\n\nGenerative AI models have a wide range of potential applications across numerous fields. Here are some examples:\n\n1.  **Content Creation:** These models can generate new pieces of text, music, or artwork. For example, AI could create music for a video game, generate a script for a movie, or produce articles or reports.\n    \n2.  **Chatbots and Virtual Assistants:** Generative models can be used to create conversational agents that can carry on a dialogue with users, generating responses to user queries in a natural, human-like manner.\n    \n3.  **Image Generation and Editing:** Generative Adversarial Networks (GANs) can generate realistic images, design graphics, or even modify existing images in significant ways, such as changing day to night or generating a person's image in the style of a specific artist.\n    \n4.  **Product Design:** AI can be used to generate new product designs or modify existing ones, potentially speeding up the design process and introducing new possibilities that human designers might not consider.\n    \n5.  **Medical Applications:** Generative AI can be used to create synthetic medical data, simulate patient conditions, or predict the development of diseases.\n    \n6.  **Personalized Recommendations:** AI models can generate personalized content or product recommendations based on user data.\n    \n7.  **Data Augmentation:** In situations where data is scarce, generative models can be used to create synthetic data to supplement real data for training other machine learning models.\n    \n\n### \n\nWhat is an embedding?\n\nEmbeddings are numerical representations of concepts converted to number sequences, which make it easy for computers to understand the relationships between those concepts. They are capable of capturing the context of a word in a document, its semantic and syntactic similarity, and its relation with other words.\n\n### \n\nWhat is a vector store?\n\nA vector store in the context of machine learning is a storage system or database designed to handle vector data efficiently. Vector data is commonly used in fields like natural language processing and computer vision, where high-dimensional vectors are used to represent complex data like words, sentences, or images. Vectors stores are often optimized for operations that are common in machine learning, like nearest neighbor search, which involves finding the vectors in the store that are closest to a given vector. This is particularly useful in tasks like recommendation systems, where you might want to find the items that are most similar to a given item.\n\n### \n\nWhat is a multimodal model?\n\nA multimodal model in the field of artificial intelligence is a model that can handle and integrate data from multiple different modalities, or types, of input. These types of inputs can include text, images, audio, video, and more. The main advantage of multimodal models is that they can leverage the strengths of different data types to make better predictions. For example, a model that takes both text and image data as input might be able to understand the context better than a model that only uses one or the other.\n\n### \n\nWhat is the memory of an LLM?\n\nA Large Language Model (LLM) can generate text based on what it has seen before if it has memory. The term \"memory\" in this context refers to how much of the previous text the model can consider when producing new text. Memory is a different concept than the training set used to train the model. The model can answer things from what it knows given the training set that is was given. Additionally, considering that you are chatting with chatGPT, the model will respond to your queries considering the last responses and queries as well. This \"memory\" of the model is indeed crucial when dealing with long pieces of text or conversations, as it determines how much of the previous context the model can use to generate accurate and coherent responses.\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/on-premise","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/on-premise","loadedTime":"2025-10-17T18:29:25.174Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/on-premise","title":"On-Premise | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"On-Premise | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1620","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dc7e285686f1-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:25 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::6g2kw-1760725764985-25307bb6db1d"}},"screenshotUrl":null,"text":"On-Premise | StackAI\nStackAI's on-premise deployment offers enterprise-grade control, performance, and security by running entirely within your organization's infrastructure. This allows customers to have full control over their data, and deploy local LLMs that can be orchestrated in StackAI, resulting in fully controlled AI applications.\nOur on-premise deployment includes Single Sign-On (SSO), and can be deployed in most cloud providers (including AWS, GCP, and Azure) or in your organization's servers.\nLast updated 3 months ago","markdown":"# On-Premise | StackAI\n\nStackAI's on-premise deployment offers enterprise-grade control, performance, and security by running entirely within your organization's infrastructure. This allows customers to have full control over their data, and deploy local LLMs that can be orchestrated in StackAI, resulting in fully controlled AI applications.\n\nOur on-premise deployment includes Single Sign-On (SSO), and can be deployed in most cloud providers (including AWS, GCP, and Azure) or in your organization's servers.\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/stripe","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/stripe","loadedTime":"2025-10-17T18:29:22.021Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/stripe","title":"Stripe | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Stripe | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"date":"Fri, 17 Oct 2025 18:29:21 GMT","content-type":"text/html; charset=utf-8","content-encoding":"br","cf-ray":"9901dc6538e98157-SEA","cf-cache-status":"DYNAMIC","age":"1553","cache-control":"public, max-age=0, must-revalidate","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","referrer-policy":"no-referrer-when-downgrade","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"pdx1::iad1::5twhb-1760725760867-7cf1bc97e85c","server":"cloudflare","alt-svc":"h3=\":443\"; ma=86400","x-firefox-spdy":"h2"}},"screenshotUrl":"https://api.apify.com/v2/key-value-stores/3K2WBdQQFTu6EGDhJ/records/SCREENSHOT-docs-stack-ai-com-stack-ai-workflow-builder-apps-stripe-6575980e.jpg","text":"Stripe | StackAI\nThe Stripe Node allows you to interact with Stripe, a payment processing platform. In Stack AI, you can use this node to automate tasks such as creating customers, processing payments, issuing refunds, and more.\nAvailable Actions\nHere are some of the main actions you can perform with the Stripe node:\nCreate Customer: Add a new customer to your Stripe account.\nCreate Payment: Charge a customer or process a payment.\nList Charges: Retrieve a list of past charges.\nSearch Customer: Find customers by email or other criteria.\nSend Refund: Issue a refund for a specific charge.\nExample: Create Customer\nInputs\nTo create a customer, you need to provide:\nCustomer Name (customer_name): The name of the customer to create. (Required)\nCustomer Email (customer_email): The email address of the customer. (Required)\nYou can reference other nodes for these values, for example: {in-0} for user input, or {llm-0} for AI-generated content.\nOutputs\nAfter running, the node will output:\nCustomer ID (customer_id): The unique Stripe ID for the new customer.\nCustomer Name (customer_name): The name you provided.\nCustomer Email (customer_email): The email you provided.\nCustomer Created At (customer_created_at): The timestamp of creation.\nYou can reference these outputs in downstream nodes using the syntax {action-8.customer_id} (if your Stripe node is action-8).\nHow to Use the Stripe Node\nAdd the Stripe node to your workflow.\nSelect the desired action (e.g., \"Create Customer\").\nFill in the required input fields (e.g., customer name and email).\nYou can use static values or reference outputs from other nodes.\nConnect the output of the Stripe node to other nodes (e.g., to send a confirmation email, log the customer, or trigger another action).\n(Optional) Add your Stripe connection ID if you have a custom Stripe account you want to use.\nExample Usage Scenario\nCollect user details with an Input node.\nPass those details to the Stripe node to create a customer.\nUse the output (customer ID) to process a payment or send a welcome email.\nLast updated 3 months ago","markdown":"# Stripe | StackAI\n\nThe **Stripe Node** allows you to interact with Stripe, a payment processing platform. In Stack AI, you can use this node to automate tasks such as creating customers, processing payments, issuing refunds, and more.\n\n* * *\n\n### \n\nAvailable Actions\n\nHere are some of the main actions you can perform with the Stripe node:\n\n*   **Create Customer**: Add a new customer to your Stripe account.\n    \n*   **Create Payment**: Charge a customer or process a payment.\n    \n*   **List Charges**: Retrieve a list of past charges.\n    \n*   **Search Customer**: Find customers by email or other criteria.\n    \n*   **Send Refund**: Issue a refund for a specific charge.\n    \n\n* * *\n\n### \n\nExample: Create Customer\n\n#### \n\nInputs\n\nTo create a customer, you need to provide:\n\n*   **Customer Name** (`customer_name`): The name of the customer to create. (Required)\n    \n*   **Customer Email** (`customer_email`): The email address of the customer. (Required)\n    \n\nYou can reference other nodes for these values, for example: `{in-0}` for user input, or `{llm-0}` for AI-generated content.\n\n#### \n\nOutputs\n\nAfter running, the node will output:\n\n*   **Customer ID** (`customer_id`): The unique Stripe ID for the new customer.\n    \n*   **Customer Name** (`customer_name`): The name you provided.\n    \n*   **Customer Email** (`customer_email`): The email you provided.\n    \n*   **Customer Created At** (`customer_created_at`): The timestamp of creation.\n    \n\nYou can reference these outputs in downstream nodes using the syntax `{action-8.customer_id}` (if your Stripe node is `action-8`).\n\n* * *\n\n### \n\nHow to Use the Stripe Node\n\n1.  **Add the Stripe node to your workflow.**\n    \n2.  **Select the desired action** (e.g., \"Create Customer\").\n    \n3.  **Fill in the required input fields** (e.g., customer name and email).\n    \n    *   You can use static values or reference outputs from other nodes.\n        \n    \n4.  **Connect the output of the Stripe node to other nodes** (e.g., to send a confirmation email, log the customer, or trigger another action).\n    \n5.  **(Optional) Add your Stripe connection ID** if you have a custom Stripe account you want to use.\n    \n\n* * *\n\n### \n\nExample Usage Scenario\n\n*   Collect user details with an Input node.\n    \n*   Pass those details to the Stripe node to create a customer.\n    \n*   Use the output (customer ID) to process a payment or send a welcome email.\n    \n\nLast updated 3 months ago","debug":{"requestHandlerMode":"browser"}}
{"url":"https://docs.stack-ai.com/stack-ai/stackai-academy","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/stackai-academy","loadedTime":"2025-10-17T18:29:27.598Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/stackai-academy","title":"StackAI Academy | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"StackAI Academy | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1621","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dc8dc862311e-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:27 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::sf4qr-1760725767388-259c20c52ad5"}},"screenshotUrl":null,"text":"StackAI Academy | StackAI\nHere you will Learn how to build, deploy, and manage secure AI agents using StackAI, the orchestration platform built for modern teams. This Academy is designed for anyone using StackAI.\nIn this series, you’ll explore everything from connecting data and building workflows to customizing interfaces and applying advanced logic, all without needing to reinvent the wheel.\n▶️ Start learning below. \nVideo modules include: \n1. Platform Overview \n2. Building Your First Workflow \n3. Agent Builder \n4. Deep Dive into UI \n5. Connecting your Data to an AI Agent \n6. Agentic Tools \n7. Using LLMs \n8. Logic Nodes \n9. Developer Capabilities \n10. Apps & Integrations \n11. Governance \n12. Handling Data\n🔗 Try StackAI: https://stack-ai.com\nLast updated 3 months ago","markdown":"# StackAI Academy | StackAI\n\nHere you will Learn how to build, deploy, and manage secure AI agents using StackAI, the orchestration platform built for modern teams. This Academy is designed for anyone using StackAI.\n\nIn this series, you’ll explore everything from connecting data and building workflows to customizing interfaces and applying advanced logic, all without needing to reinvent the wheel.\n\n▶️ Start learning below.\n\nVideo modules include:\n\n1\\. Platform Overview\n\n2\\. Building Your First Workflow\n\n3\\. Agent Builder\n\n4\\. Deep Dive into UI\n\n5\\. Connecting your Data to an AI Agent\n\n6\\. Agentic Tools\n\n7\\. Using LLMs\n\n8\\. Logic Nodes\n\n9\\. Developer Capabilities\n\n10\\. Apps & Integrations\n\n11\\. Governance\n\n12\\. Handling Data\n\n🔗 Try StackAI: https://stack-ai.com\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/best-practices/prompt-engineering","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/best-practices/prompt-engineering","loadedTime":"2025-10-17T18:29:27.692Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/best-practices/prompt-engineering","title":"Prompt Engineering | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Prompt Engineering | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1620","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dc8de85a0cef-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:27 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::6t79l-1760725767374-8cce487e606b"}},"screenshotUrl":null,"text":"Prompt Engineering | StackAI\nPrompt Engineering and Context Management\nPrompt Customization: Each LLM node can have its own prompt and system message. Tailor these to the specific sub-task each LLM is handling.\nContext Passing: Use node references (e.g., {llm-0}) in prompts to pass context or results between LLMs.\nPrompting Best Practices\nClarity, Specificity, and Explicitness\nMinimize Ambiguity: Vague requests lead to off-target responses. Instead of \"Summarize this document,\" specify \"Summarize this document in 3 bullet points focusing on the main challenges discussed.\"\nUse Imperative Language: Frame prompts as direct commands (e.g., \"Generate,\" \"Summarize,\" \"Translate\"). Avoid conversational phrases.\nDefine Constraints: Clearly state desired length (\"Use a 3 to 5 sentence paragraph\"), tone (\"Use a friendly and conversational tone\"), or style (\"in the style of a {famous poet}\").\nPositive Framing: Instruct the model on what it should do, rather than what it should not do. For instance, instead of \"DO NOT ASK for a username or password,\" state: \"The agent will attempt to diagnose the problem... whilst refraining from asking any questions related to PII. Instead of asking for PII, such as username or password, refer the user to the help article [www.samplewebsite.com/help/faq](https://www.samplewebsite.com/help/faq).\"\nStructuring the Prompt for Optimal Parsing and Reliability\nUse Delimiters: Employ characters or symbols (e.g., `\"\"\"`, `###`, `<tag>`) to clearly separate sections like instructions, context, and examples. This prevents information \"bleeding.\"\nPlace Instructions at the Beginning: Start your prompt with instructions for clear parsing.\nRequest JSON Format for Machine-Readable Output: For structured data, explicitly ask for JSON. Provide a complete example with desired keys and value types. Consider using API's \"JSON mode\" if available.\nAdopt JSON Output by Default: Always request JSON, even for single fields, to allow for easy expansion later.\nUse Hierarchical Structures: For complex prompts, organize content with headings, subheadings, and bullet points.\nIn-Context Learning (ICL): Guiding by Demonstration\nStart with Zero-Shot Prompting: For simple tasks, provide only the task description without examples.\nUse Few-Shot Prompting when Needed: If zero-shot isn't sufficient, include one or more input-output examples to demonstrate the desired output structure, style, or pattern.\nCurate Diverse Examples: Ensure few-shot examples are representative and varied to avoid bias.\nStrategic Allocation (System vs. User Prompts)\nUtilize the System Prompt: Use for high-level, foundational instructions defining the AI's core behavior, persona, and persistent constraints (e.g., role-prompting, ethical guidance, tool-use instructions).\nUse the User Prompt: This is for dynamic, task-oriented instructions, specific questions, task-specific context, few-shot examples relevant to the current task, and response formatting instructions for that single interaction.\nSeparate Concerns: This modular approach improves clarity, maintainability, and model performance.\nWhen using tools in an LLM Node, include them in your prompt with the @ sign.\nFor long prompts, or prompts that reference multiple inputs, group them with XML tags. Grouping signals to the LLM where certain associated blocks of information begin and end.","markdown":"# Prompt Engineering | StackAI\n\n#### \n\nPrompt Engineering and Context Management\n\n*   **Prompt Customization:** Each LLM node can have its own prompt and system message. Tailor these to the specific sub-task each LLM is handling.\n    \n*   **Context Passing:** Use node references (e.g., `{llm-0}`) in prompts to pass context or results between LLMs.\n    \n\n### \n\nPrompting Best Practices\n\nClarity, Specificity, and Explicitness\n\n*   **Minimize Ambiguity:** Vague requests lead to off-target responses. Instead of \"Summarize this document,\" specify \"Summarize this document in 3 bullet points focusing on the main challenges discussed.\"\n    \n*   **Use Imperative Language:** Frame prompts as direct commands (e.g., \"Generate,\" \"Summarize,\" \"Translate\"). Avoid conversational phrases.\n    \n*   **Define Constraints:** Clearly state desired length (\"Use a 3 to 5 sentence paragraph\"), tone (\"Use a friendly and conversational tone\"), or style (\"in the style of a {famous poet}\").\n    \n*   **Positive Framing:** Instruct the model on what it _should_ do, rather than what it _should not_ do. For instance, instead of \"DO NOT ASK for a username or password,\" state: \"The agent will attempt to diagnose the problem... whilst refraining from asking any questions related to PII. Instead of asking for PII, such as username or password, refer the user to the help article \\[www.samplewebsite.com/help/faq\\](https://www.samplewebsite.com/help/faq).\"\n    \n\nStructuring the Prompt for Optimal Parsing and Reliability\n\n*   **Use Delimiters:** Employ characters or symbols (e.g., \\`\"\"\"\\`, \\`###\\`, \\`<tag>\\`) to clearly separate sections like instructions, context, and examples. This prevents information \"bleeding.\"\n    \n*   **Place Instructions at the Beginning:** Start your prompt with instructions for clear parsing.\n    \n*   **Request JSON Format for Machine-Readable Output:** For structured data, explicitly ask for JSON. Provide a complete example with desired keys and value types. Consider using API's \"JSON mode\" if available.\n    \n*   **Adopt JSON Output by Default:** Always request JSON, even for single fields, to allow for easy expansion later.\n    \n*   **Use Hierarchical Structures:** For complex prompts, organize content with headings, subheadings, and bullet points.\n    \n\nIn-Context Learning (ICL): Guiding by Demonstration\n\n*   **Start with Zero-Shot Prompting:** For simple tasks, provide only the task description without examples.\n    \n*   **Use Few-Shot Prompting when Needed:** If zero-shot isn't sufficient, include one or more input-output examples to demonstrate the desired output structure, style, or pattern.\n    \n*   **Curate Diverse Examples:** Ensure few-shot examples are representative and varied to avoid bias.\n    \n\nStrategic Allocation (System vs. User Prompts)\n\n*   **Utilize the System Prompt:** Use for high-level, foundational instructions defining the AI's core behavior, persona, and persistent constraints (e.g., role-prompting, ethical guidance, tool-use instructions).\n    \n*   **Use the User Prompt:** This is for dynamic, task-oriented instructions, specific questions, task-specific context, few-shot examples relevant to the current task, and response formatting instructions for that single interaction.\n    \n*   **Separate Concerns:** This modular approach improves clarity, maintainability, and model performance.\n    \n\nWhen using tools in an LLM Node, include them in your prompt with the @ sign.\n\nFor long prompts, or prompts that reference multiple inputs, group them with XML tags. Grouping signals to the LLM where certain associated blocks of information begin and end.","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/interactive-tutorials","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/interactive-tutorials","loadedTime":"2025-10-17T18:29:27.784Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/interactive-tutorials","title":"Interactive Tutorials | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Interactive Tutorials | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1621","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dc8ddca0dddf-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:27 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::7cx6x-1760725767367-b4e5cfb4d5c2"}},"screenshotUrl":null,"text":"Interactive Tutorials | StackAI\nPreviousStackAI AcademyNextPrompt Engineering\nWas this helpful?","markdown":"# Interactive Tutorials | StackAI\n\n[PreviousStackAI Academy](https://docs.stack-ai.com/stack-ai/stackai-academy)[NextPrompt Engineering](https://docs.stack-ai.com/stack-ai/best-practices/prompt-engineering)\n\nWas this helpful?","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/best-practices/instruction-vs-prompt","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/best-practices/instruction-vs-prompt","loadedTime":"2025-10-17T18:29:29.721Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/best-practices/instruction-vs-prompt","title":"Instruction vs Prompt | StackAI","description":"Master LLMs: Know the difference between instruction, system prompt, and user prompt to guide AI behavior and get top results. It's not just what you ask - it's how you ask it.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Instruction vs Prompt | StackAI"},{"property":"og:description","content":"Master LLMs: Know the difference between instruction, system prompt, and user prompt to guide AI behavior and get top results. It's not just what you ask - it's how you ask it."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1623","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dc9ace141315-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:29 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::p6f7c-1760725769473-b47432a7bad8"}},"screenshotUrl":null,"text":"Instruction vs Prompt | StackAI\nMaster LLMs: Know the difference between instruction, system prompt, and user prompt to guide AI behavior and get top results. It's not just what you ask - it's how you ask it.\nInstruction vs Prompt (System Prompt vs User Prompt)\nIn the world of Large Language Models (LLMs), understanding the difference between \"Instruction\" and \"Prompt\" (often referred to as \"System Prompt\" and \"User Prompt\") is key to getting the best results. It's not just about what you ask, but how you set up the AI's overall behavior and then provide specific tasks.\nThe System Prompt: The AI's Job Description Think of the System Prompt as the AI's \"job description\" or its persistent identity. It's a high-level, foundational set of instructions that defines the AI's core behavior, its persona, and any rules it should always follow throughout an entire conversation or session.\nWhat goes in a System Prompt?\nRole Prompting: This sets the AI's persona, like \"You are a seasoned data scientist\" or \"You are a helpful and informative AI assistant specializing in technology.\" This helps the AI interpret all subsequent requests through that specific lens.\nEthical Guidance and Constraints: This is where you establish non-negotiable rules, such as avoiding certain topics (\"Avoid discussing political opinions\") or refusing harmful requests.\nDefining Scope: You can specify the areas of expertise the AI should draw from and what's out of bounds.\nTool-Use Instructions: For more advanced applications, you can define what external tools the AI has access to and when it should use them.\nThe System Prompt is stable and typically remains consistent across many interactions, providing a steady framework for the AI's operation.\nThe User Prompt: The Task-Specific Request In contrast, the User Prompt is dynamic and task-oriented. It contains the specific question, command, or data for a single interaction within the conversation. It's the immediate \"what\" you want the AI to do right now.\nWhat goes in a User Prompt?\nSpecific Questions and Commands: This is where you put your direct query, like \"What are some eco-friendly travel destinations in South America?\" or \"Translate this text to French.\"\nTask-Specific Context: Any details relevant only to the current turn of the conversation, such as \"I'm planning a trip in June and prefer destinations with hikes.\"\nFew-Shot Examples: If you need to show the AI examples of input-output pairs for a specific task, these are best placed in the User Prompt.\nResponse Formatting Instructions: While general style can be in the System Prompt, specific output formats for a single response (e.g., \"Please provide the information in a list format,\" or \"Answer in JSON format\") are often more effective here.\nWhy the Separation Matters This deliberate separation into System and User prompts is a critical architectural choice for building robust and scalable LLM applications.\nClarity and Maintainability: Separating concerns makes your prompts easier to read, debug, and update. Your core AI configuration (system prompt) is distinct from the varying user inputs.\nOptimized Model Performance: LLMs are often specifically trained to handle these distinct roles. Adhering to this structure is believed to provide a performance benefit, leading to more accurate and reliable outputs.\nFuture-Proofing: As your application evolves, having a modular prompt structure allows for easier modifications and additions of new features without overhauling your entire prompting logic.\nBy understanding and effectively using both system and user prompts, you can better control LLMs, making your applications more predictable, reliable, and powerful for various tasks.\nLast updated 3 months ago","markdown":"# Instruction vs Prompt | StackAI\n\nMaster LLMs: Know the difference between instruction, system prompt, and user prompt to guide AI behavior and get top results. It's not just what you ask - it's how you ask it.\n\n### \n\nInstruction vs Prompt (System Prompt vs User Prompt)\n\nIn the world of Large Language Models (LLMs), understanding the difference between \"Instruction\" and \"Prompt\" (often referred to as \"System Prompt\" and \"User Prompt\") is key to getting the best results. It's not just about what you ask, but _how_ you set up the AI's overall behavior and then provide specific tasks.\n\nThe System Prompt: The AI's Job Description Think of the **System Prompt** as the AI's \"job description\" or its persistent identity. It's a high-level, foundational set of instructions that defines the AI's core behavior, its persona, and any rules it should always follow throughout an entire conversation or session.\n\n**What goes in a System Prompt?**\n\n*   **Role Prompting:** This sets the AI's persona, like \"You are a seasoned data scientist\" or \"You are a helpful and informative AI assistant specializing in technology.\" This helps the AI interpret all subsequent requests through that specific lens.\n    \n*   **Ethical Guidance and Constraints:** This is where you establish non-negotiable rules, such as avoiding certain topics (\"Avoid discussing political opinions\") or refusing harmful requests.\n    \n*   **Defining Scope:** You can specify the areas of expertise the AI should draw from and what's out of bounds.\n    \n*   **Tool-Use Instructions:** For more advanced applications, you can define what external tools the AI has access to and when it should use them.\n    \n\nThe System Prompt is **stable** and typically remains consistent across many interactions, providing a steady framework for the AI's operation.\n\nThe User Prompt: The Task-Specific Request In contrast, the **User Prompt** is dynamic and task-oriented. It contains the specific question, command, or data for a _single_ interaction within the conversation. It's the immediate \"what\" you want the AI to do right now.\n\n**What goes in a User Prompt?**\n\n*   **Specific Questions and Commands:** This is where you put your direct query, like \"What are some eco-friendly travel destinations in South America?\" or \"Translate this text to French.\"\n    \n*   **Task-Specific Context:** Any details relevant only to the current turn of the conversation, such as \"I'm planning a trip in June and prefer destinations with hikes.\"\n    \n*   **Few-Shot Examples:** If you need to show the AI examples of input-output pairs for a specific task, these are best placed in the User Prompt.\n    \n*   **Response Formatting Instructions:** While general style can be in the System Prompt, specific output formats for a single response (e.g., \"Please provide the information in a list format,\" or \"Answer in JSON format\") are often more effective here.\n    \n\n**Why the Separation Matters** This deliberate separation into System and User prompts is a critical architectural choice for building robust and scalable LLM applications.\n\n*   **Clarity and Maintainability:** Separating concerns makes your prompts easier to read, debug, and update. Your core AI configuration (system prompt) is distinct from the varying user inputs.\n    \n*   **Optimized Model Performance:** LLMs are often specifically trained to handle these distinct roles. Adhering to this structure is believed to provide a performance benefit, leading to more accurate and reliable outputs.\n    \n*   **Future-Proofing:** As your application evolves, having a modular prompt structure allows for easier modifications and additions of new features without overhauling your entire prompting logic.\n    \n\nBy understanding and effectively using both system and user prompts, you can better control LLMs, making your applications more predictable, reliable, and powerful for various tasks.\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/best-practices/using-multiple-llms","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/best-practices/using-multiple-llms","loadedTime":"2025-10-17T18:29:29.928Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/best-practices/using-multiple-llms","title":"Using Multiple LLMs | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Using Multiple LLMs | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1623","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dc9ca942ef64-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:29 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::78d54-1760725769770-25283ef31118"}},"screenshotUrl":null,"text":"Using Multiple LLMs | StackAI\nWhen using multiple LLMs in one project, there are important points to consider in order to ensure they work well together.\nClear Input/Output Flow\nExplicit Connections: Each LLM node should have clearly defined input and output connections. Use Input nodes (in-0, in-1, etc.) to gather user data, and connect them to the relevant LLM nodes.\nOutput Handling: Route the output of each LLM node to Output nodes or downstream processing nodes (like Template or Python nodes) for further formatting or logic.\nSequential vs. Parallel LLMs\nSequential Orchestration: If the output of one LLM is needed as input for another, connect them in sequence (e.g., llm-0 → llm-1). This is useful for multi-step reasoning or refinement. Having initial LLMs give structured outputs to downstream LLMs can be helpful.\nParallel Orchestration: If you want to compare or aggregate results from multiple LLMs, connect the same input to several LLM nodes in parallel, then merge their outputs downstream using the Combine Node or a third LLM that will summarize and logically merge the two outputs\nMemory and State\nSliding Window Memory: Use the memory feature in LLM nodes to maintain context across turns or steps, especially in multi-turn workflows.\nStateful Processing: If you need to track or update state, consider using Python nodes between LLMs to manipulate or store intermediate results.\nError Handling and Fallbacks\nOn Failure Branches: Configure on_failure_branch and retry settings for each LLM node to handle errors gracefully.\nFallback LLMs: Use the fallback options to specify alternative models/providers if the primary LLM fails.\nData Formatting and Validation\nTemplate Nodes: Use Template nodes to format or merge outputs from multiple LLMs before presenting to the user.\nOutput Validation: If LLMs are expected to return structured data (e.g., JSON), use the json_schema parameter to enforce output format and validate results.\nChaining with Other Nodes\nIntegration with Actions: LLM outputs can be passed to Action nodes (e.g., sending emails, updating databases) for real-world effects.\nCustom Logic: Insert Python nodes between LLMs for custom logic, filtering, or aggregation.\nCitations and Traceability\nCitations: Enable citations in LLM nodes if you want to track sources or provide references in the output.\nAuditability: Use Output nodes and logs to trace the flow of data and decisions across multiple LLMs.\nPerformance and Latency\nParallelization: Where possible, run LLMs in parallel to reduce overall latency.\nToken and Cost Management: Set appropriate max_tokens and temperature settings to control cost and response quality.\nSummary Table:\nUse explicit node connections and references\nChoose sequential or parallel based on use case\nCustomize prompts and use context passing\nUse memory features and Python nodes for stateful logic\nConfigure retries, fallbacks, and failure branches\nUse Template nodes and output validation\nConnect to Action nodes and use Python for custom logic\nEnable citations and use Output nodes for auditability\nParallelize where possible, manage tokens and latency\nLast updated 2 months ago","markdown":"# Using Multiple LLMs | StackAI\n\nWhen using multiple LLMs in one project, there are important points to consider in order to ensure they work well together.\n\n* * *\n\n### \n\nClear Input/Output Flow\n\n*   **Explicit Connections:** Each LLM node should have clearly defined input and output connections. Use Input nodes (`in-0`, `in-1`, etc.) to gather user data, and connect them to the relevant LLM nodes.\n    \n*   **Output Handling:** Route the output of each LLM node to Output nodes or downstream processing nodes (like Template or Python nodes) for further formatting or logic.\n    \n\n### \n\nSequential vs. Parallel LLMs\n\n*   **Sequential Orchestration:** If the output of one LLM is needed as input for another, connect them in sequence (e.g., `llm-0` → `llm-1`). This is useful for multi-step reasoning or refinement. Having initial LLMs give structured outputs to downstream LLMs can be helpful.\n    \n*   **Parallel Orchestration:** If you want to compare or aggregate results from multiple LLMs, connect the same input to several LLM nodes in parallel, then merge their outputs downstream using the Combine Node or a third LLM that will summarize and logically merge the two outputs\n    \n\n### \n\nMemory and State\n\n*   **Sliding Window Memory:** Use the memory feature in LLM nodes to maintain context across turns or steps, especially in multi-turn workflows.\n    \n*   **Stateful Processing:** If you need to track or update state, consider using Python nodes between LLMs to manipulate or store intermediate results.\n    \n\n### \n\nError Handling and Fallbacks\n\n*   **On Failure Branches:** Configure `on_failure_branch` and retry settings for each LLM node to handle errors gracefully.\n    \n*   **Fallback LLMs:** Use the fallback options to specify alternative models/providers if the primary LLM fails.\n    \n\n### \n\nData Formatting and Validation\n\n*   **Template Nodes:** Use Template nodes to format or merge outputs from multiple LLMs before presenting to the user.\n    \n*   **Output Validation:** If LLMs are expected to return structured data (e.g., JSON), use the `json_schema` parameter to enforce output format and validate results.\n    \n\n### \n\nChaining with Other Nodes\n\n*   **Integration with Actions:** LLM outputs can be passed to Action nodes (e.g., sending emails, updating databases) for real-world effects.\n    \n*   **Custom Logic:** Insert Python nodes between LLMs for custom logic, filtering, or aggregation.\n    \n\n### \n\nCitations and Traceability\n\n*   **Citations:** Enable citations in LLM nodes if you want to track sources or provide references in the output.\n    \n*   **Auditability:** Use Output nodes and logs to trace the flow of data and decisions across multiple LLMs.\n    \n\n### \n\nPerformance and Latency\n\n*   **Parallelization:** Where possible, run LLMs in parallel to reduce overall latency.\n    \n*   **Token and Cost Management:** Set appropriate `max_tokens` and temperature settings to control cost and response quality.\n    \n\n* * *\n\n**Summary Table:**\n\nUse explicit node connections and references\n\nChoose sequential or parallel based on use case\n\nCustomize prompts and use context passing\n\nUse memory features and Python nodes for stateful logic\n\nConfigure retries, fallbacks, and failure branches\n\nUse Template nodes and output validation\n\nConnect to Action nodes and use Python for custom logic\n\nEnable citations and use Output nodes for auditability\n\nParallelize where possible, manage tokens and latency\n\nLast updated 2 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/best-practices/chunking","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/best-practices/chunking","loadedTime":"2025-10-17T18:29:30.117Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/best-practices/chunking","title":"Chunking | StackAI","description":"Best practices for implementing document chunking for RAG","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Chunking | StackAI"},{"property":"og:description","content":"Best practices for implementing document chunking for RAG"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1622","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dc9dbbe078b1-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:30 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::hbmcr-1760725769909-cc0506f406bd"}},"screenshotUrl":null,"text":"Chunking | StackAI\nBest practices for implementing document chunking for RAG\nChunking: Optimizing Data Retrieval in Stack AI Workflows\nChunking is a key technique in AI-powered document processing. In StackAI, using the right chunking strategy can greatly enhance how effectively machine learning models understand and extract data from documents.\nWhat is Chunking in StackAI?\nChunking = Breaking large documents into smaller, manageable parts.\nUsed in StackAI’s \"Files\" and \"Documents\" nodes.\nEnsures input fits within AI model token limits.\nCan be configured via the gear icon in relevant nodes.\nChunking Methods\n1. Naïve Chunking (Fixed-Length)\nSplits text by character, word, or token count.\nPros:\nFast and simple to implement\nPredictable processing time\nCons:\nMay break sentences or ideas\nCan reduce AI comprehension\n2. Sentence-Based Chunking\nSplits text along natural sentence boundaries.\nPros:\nPreserves meaning and structure\nEnhances AI understanding\nCons:\nMore computationally intensive\nChunk sizes can vary\nOptimizing Chunk Configuration\nChunk Size\nChoose based on your model's capabilities.\nTradeoff:\nLarger chunks = better context but risk hitting token limits.\nSmaller chunks = faster, but may lose coherence.\nRecommended: 200–1,000 tokens\nChunk Overlap\nAdds continuity between chunks.\nSuggested: 15–30% overlap\nBest Practices for Stack AI Users\nUse sentence-based chunking for documents with rich content.\nTune chunk size to match your AI model's limits.\nExperiment with overlap percentages to preserve context.\nIteratively test to ensure optimal results.\nTechnical Tips\nConfigure chunking inside \"Files\" and \"Documents\" nodes.\nContinuously monitor model performance as you adjust settings.\nAlign your chunking strategy with your specific ML model needs.\nWhy It Matters\nMastering chunking helps:\nImprove document comprehension for AI\nBoost data extraction accuracy\nDeliver better performance across document-based workflows in StackAI\nLast updated 2 months ago","markdown":"# Chunking | StackAI\n\nBest practices for implementing document chunking for RAG\n\n### \n\n**Chunking: Optimizing Data Retrieval in Stack AI Workflows**\n\nChunking is a key technique in AI-powered document processing. In **StackAI**, using the right chunking strategy can greatly enhance how effectively machine learning models understand and extract data from documents.\n\n* * *\n\n#### \n\n**What is Chunking in StackAI?**\n\n**Chunking** = Breaking large documents into smaller, manageable parts.\n\n*   Used in StackAI’s **\"Files\"** and **\"Documents\"** nodes.\n    \n*   Ensures input fits within AI model token limits.\n    \n*   Can be configured via the gear icon in relevant nodes.\n    \n\n* * *\n\n#### \n\n**Chunking Methods**\n\n**1\\. Naïve Chunking (Fixed-Length)**\n\nSplits text by character, word, or token count.\n\n*   Pros:\n    \n    *   Fast and simple to implement\n        \n    *   Predictable processing time\n        \n    \n*   Cons:\n    \n    *   May break sentences or ideas\n        \n    *   Can reduce AI comprehension\n        \n    \n\n* * *\n\n**2\\. Sentence-Based Chunking**\n\nSplits text along natural sentence boundaries.\n\n*   Pros:\n    \n    *   Preserves meaning and structure\n        \n    *   Enhances AI understanding\n        \n    \n*   Cons:\n    \n    *   More computationally intensive\n        \n    *   Chunk sizes can vary\n        \n    \n\n* * *\n\n#### \n\n**Optimizing Chunk Configuration**\n\n**Chunk Size**\n\n*   Choose based on your model's capabilities.\n    \n*   Tradeoff:\n    \n    *   **Larger chunks** = better context but risk hitting token limits.\n        \n    *   **Smaller chunks** = faster, but may lose coherence.\n        \n    \n*   Recommended: **200–1,000 tokens**\n    \n\n**Chunk Overlap**\n\n*   Adds continuity between chunks.\n    \n*   Suggested: **15–30% overlap**\n    \n\n* * *\n\n#### \n\n**Best Practices for Stack AI Users**\n\n*   Use **sentence-based chunking** for documents with rich content.\n    \n*   Tune **chunk size** to match your AI model's limits.\n    \n*   Experiment with **overlap percentages** to preserve context.\n    \n*   **Iteratively test** to ensure optimal results.\n    \n\n* * *\n\n#### \n\n**Technical Tips**\n\n*   Configure chunking inside \"Files\" and \"Documents\" nodes.\n    \n*   Continuously monitor model performance as you adjust settings.\n    \n*   Align your chunking strategy with your specific ML model needs.\n    \n\n* * *\n\n#### \n\n**Why It Matters**\n\nMastering chunking helps:\n\n*   Improve document comprehension for AI\n    \n*   Boost data extraction accuracy\n    \n*   Deliver better performance across document-based workflows in StackAI\n    \n\nLast updated 2 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/interactive-tutorials-1/compliance-chatbot","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/interactive-tutorials-1/compliance-chatbot","loadedTime":"2025-10-17T18:29:30.742Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/interactive-tutorials-1/compliance-chatbot","title":"Compliance Chatbot | StackAI","description":"Building a Compliance Chatbot in Stack AI","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Compliance Chatbot | StackAI"},{"property":"og:description","content":"Building a Compliance Chatbot in Stack AI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1623","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dca1bee5e615-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:30 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::q9nzc-1760725770554-4151b2db72dc"}},"screenshotUrl":null,"text":"Compliance Chatbot | StackAI\nBuilding a Compliance Chatbot in Stack AI\nPreviousChunkingNextIT Support Chatbot\nLast updated 4 days ago\nWas this helpful?","markdown":"# Compliance Chatbot | StackAI\n\nBuilding a Compliance Chatbot in Stack AI\n\n[PreviousChunking](https://docs.stack-ai.com/stack-ai/best-practices/chunking)[NextIT Support Chatbot](https://docs.stack-ai.com/stack-ai/interactive-tutorials-1/it-support-chatbot)\n\nLast updated 4 days ago\n\nWas this helpful?","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/interactive-tutorials-1/it-support-chatbot","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/interactive-tutorials-1/it-support-chatbot","loadedTime":"2025-10-17T18:29:31.709Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/interactive-tutorials-1/it-support-chatbot","title":"IT Support Chatbot | StackAI","description":"Build an IT support chatbot in Stack AI","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"IT Support Chatbot | StackAI"},{"property":"og:description","content":"Build an IT support chatbot in Stack AI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1623","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dca7d8f9ef5e-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:31 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::t5vwf-1760725771522-e04adc7c4055"}},"screenshotUrl":null,"text":"IT Support Chatbot | StackAI\nBuild an IT support chatbot in Stack AI\nPreviousCompliance ChatbotNextPartnerships Agent\nLast updated 4 days ago\nWas this helpful?","markdown":"# IT Support Chatbot | StackAI\n\nBuild an IT support chatbot in Stack AI\n\n[PreviousCompliance Chatbot](https://docs.stack-ai.com/stack-ai/interactive-tutorials-1/compliance-chatbot)[NextPartnerships Agent](https://docs.stack-ai.com/stack-ai/interactive-tutorials-1/partnerships-agent)\n\nLast updated 4 days ago\n\nWas this helpful?","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/interactive-tutorials-1/partnerships-agent","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/interactive-tutorials-1/partnerships-agent","loadedTime":"2025-10-17T18:29:31.882Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/interactive-tutorials-1/partnerships-agent","title":"Partnerships Agent | StackAI","description":"Build a strategic partnerships agent in Stack AI","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Partnerships Agent | StackAI"},{"property":"og:description","content":"Build a strategic partnerships agent in Stack AI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1623","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dca91cd9d6bc-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:31 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::9gpxz-1760725771733-6d90b1d3eb7c"}},"screenshotUrl":null,"text":"Partnerships Agent | StackAI\nBuild a strategic partnerships agent in Stack AI\nPreviousIT Support ChatbotNextPolicy Chatbot\nLast updated 4 days ago\nWas this helpful?","markdown":"# Partnerships Agent | StackAI\n\nBuild a strategic partnerships agent in Stack AI\n\n[PreviousIT Support Chatbot](https://docs.stack-ai.com/stack-ai/interactive-tutorials-1/it-support-chatbot)[NextPolicy Chatbot](https://docs.stack-ai.com/stack-ai/interactive-tutorials-1/policy-chatbot)\n\nLast updated 4 days ago\n\nWas this helpful?","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/interactive-tutorials-1/policy-chatbot","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/interactive-tutorials-1/policy-chatbot","loadedTime":"2025-10-17T18:29:32.230Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/interactive-tutorials-1/policy-chatbot","title":"Policy Chatbot | StackAI","description":"Build a policy chatbot in Stack AI","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Policy Chatbot | StackAI"},{"property":"og:description","content":"Build a policy chatbot in Stack AI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1623","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dcaacdbc201b-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:32 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::6dtz5-1760725772016-c62dd053ad8c"}},"screenshotUrl":null,"text":"Policy Chatbot | StackAI\nBuild a policy chatbot in Stack AI\nPreviousPartnerships AgentNextSalesforce\nLast updated 4 days ago\nWas this helpful?","markdown":"# Policy Chatbot | StackAI\n\nBuild a policy chatbot in Stack AI\n\n[PreviousPartnerships Agent](https://docs.stack-ai.com/stack-ai/interactive-tutorials-1/partnerships-agent)[NextSalesforce](https://docs.stack-ai.com/stack-ai/interactive-tutorials-1/salesforce)\n\nLast updated 4 days ago\n\nWas this helpful?","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/interactive-tutorials-1/salesforce","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/interactive-tutorials-1/salesforce","loadedTime":"2025-10-17T18:29:32.775Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/interactive-tutorials-1/salesforce","title":"Salesforce | StackAI","description":"Build a Salesforce agent in Stack AI","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Salesforce | StackAI"},{"property":"og:description","content":"Build a Salesforce agent in Stack AI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1623","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dcaeab45e619-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:32 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::kwtl2-1760725772636-5924bb3a4fa1"}},"screenshotUrl":null,"text":"Salesforce | StackAI\nBuild a Salesforce agent in Stack AI\nPreviousPolicy ChatbotNextTerm Extraction\nLast updated 4 days ago\nWas this helpful?","markdown":"# Salesforce | StackAI\n\nBuild a Salesforce agent in Stack AI\n\n[PreviousPolicy Chatbot](https://docs.stack-ai.com/stack-ai/interactive-tutorials-1/policy-chatbot)[NextTerm Extraction](https://docs.stack-ai.com/stack-ai/interactive-tutorials-1/term-extraction)\n\nLast updated 4 days ago\n\nWas this helpful?","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/interactive-tutorials-1/web-research","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/interactive-tutorials-1/web-research","loadedTime":"2025-10-17T18:29:34.502Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/interactive-tutorials-1/web-research","title":"Web Research | StackAI","description":"Build a web research agent in Stack AI","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Web Research | StackAI"},{"property":"og:description","content":"Build a web research agent in Stack AI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1772","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dcb8b88ce641-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:34 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::7gjjh-1760725774248-2058accbfc58"}},"screenshotUrl":null,"text":"Web Research | StackAI\nBuild a web research agent in Stack AI\nPreviousTerm ExtractionNextGet Started with Workflow Builder\nLast updated 4 days ago\nWas this helpful?","markdown":"# Web Research | StackAI\n\nBuild a web research agent in Stack AI\n\n[PreviousTerm Extraction](https://docs.stack-ai.com/stack-ai/interactive-tutorials-1/term-extraction)[NextGet Started with Workflow Builder](https://docs.stack-ai.com/stack-ai/workflow-builder/get-started-with-workflow-builder)\n\nLast updated 4 days ago\n\nWas this helpful?","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/get-started-with-workflow-builder","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/get-started-with-workflow-builder","loadedTime":"2025-10-17T18:29:34.919Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/get-started-with-workflow-builder","title":"Get Started with Workflow Builder | StackAI","description":"A guide to the Workflow View","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Get Started with Workflow Builder | StackAI"},{"property":"og:description","content":"A guide to the Workflow View"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1776","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dcbb4b118284-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:34 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::q4lcq-1760725774648-a9898e8f860a"}},"screenshotUrl":null,"text":"Get Started with Workflow Builder\nA guide to the Workflow View\nOur no-code approach is anchored in a visual workflow builder that prioritizes ease of use. This is achieved through an intuitive drag-and-drop interface, with built-in chatbot assistance, and an optimal level of abstraction that caters to both technical and non-technical teams. Search for nodes in the menu on the left, drop them onto the canvas, select parts of your workflow, and even copy/paste nodes across projects!\nTechnical teams can extend capabilities even further by using a custom “Code” node (e.g. Python), a custom “API” node, or by building their own tools to orchestrate LLM-driven actions.\nOur users can integrate with a broad ecosystem of applications, enabling support for the most common use cases across departments.\nPower BI, BigQuery, Databricks, Snowflake, Fred, Excel (Sharepoint), GSheets, Typeform, etc.\nGithub, Regex, SerpAPI, Weaviate, etc.\nE2B, Pinecone, Wolfram Alpha, HyperBrowser, Reducto, VLM\nSalesforce, HubSpot, LinkedIn, PitchBook, Yahoo Finance\nHubSpot, LinkedIn, Gmail, Outlook, YouTube\nProject & Task Management\nAsana, Clickup, Jira, Notion, Make, Coda, Miro\nCollaboration & Communication\nSlack, Loom, Gmail, Outlook, GDocs, Knowledge Base\nERP & Business Operations\nOracle, NetSuite, Workday, Veeva\nGoogle Drive, Dropbox, OneDrive, SharePoint, SharePoint (NTLM), Azure Blob Storage, AWS S3\nExcel, Airtable, Power BI, Yahoo Finance\nWorkday, Outlook, LinkedIn\nYouTube, Firecrawl, Exa AI\nOur users can connect to a wide range of AI models:\nOpenAI, Anthropic, Google, Meta, xAI, Mistral, Perplexity, TogetherAI, Cerebras, Replicate, Groq, Azure, Bedrock, any local LLM via end-point, StackAI’s fine-tuned text-to-SQL model\nStackAI also supports connections with MCP servers, allowing your workflows to use not only integrations developed by StackAI’s team, but also integrate with tools served by third parties using the MCP protocol.\nMaking LLMs take autonomous actions is very easy. Users can add ‘tools’ (e.g., function calling) directly in the LLM node by selecting the one they want from a long list of possible actions. More advanced users can also add their own custom tools.\nAsk Workflow\nUsers can interact with the assistant directly within the workflow builder to ask questions, get suggestions for improving their project, and easily access documentation for specific features.","markdown":"# Get Started with Workflow Builder\n\nA guide to the Workflow View\n\nOur no-code approach is anchored in a visual workflow builder that prioritizes ease of use. This is achieved through an intuitive drag-and-drop interface, with built-in chatbot assistance, and an optimal level of abstraction that caters to both technical and non-technical teams. Search for nodes in the menu on the left, drop them onto the canvas, select parts of your workflow, and even copy/paste nodes across projects!\n\nTechnical teams can extend capabilities even further by using a custom “Code” node (e.g. Python), a custom “API” node, or by building their own tools to orchestrate LLM-driven actions.\n\nOur users can integrate with a broad ecosystem of applications, enabling support for the most common use cases across departments.\n\nPower BI, BigQuery, Databricks, Snowflake, Fred, Excel (Sharepoint), GSheets, Typeform, etc.\n\nGithub, Regex, SerpAPI, Weaviate, etc.\n\nE2B, Pinecone, Wolfram Alpha, HyperBrowser, Reducto, VLM\n\nSalesforce, HubSpot, LinkedIn, PitchBook, Yahoo Finance\n\nHubSpot, LinkedIn, Gmail, Outlook, YouTube\n\nProject & Task Management\n\nAsana, Clickup, Jira, Notion, Make, Coda, Miro\n\nCollaboration & Communication\n\nSlack, Loom, Gmail, Outlook, GDocs, Knowledge Base\n\nERP & Business Operations\n\nOracle, NetSuite, Workday, Veeva\n\nGoogle Drive, Dropbox, OneDrive, SharePoint, SharePoint (NTLM), Azure Blob Storage, AWS S3\n\nExcel, Airtable, Power BI, Yahoo Finance\n\nWorkday, Outlook, LinkedIn\n\nYouTube, Firecrawl, Exa AI\n\nOur users can connect to a wide range of AI models:\n\nOpenAI, Anthropic, Google, Meta, xAI, Mistral, Perplexity, TogetherAI, Cerebras, Replicate, Groq, Azure, Bedrock, any local LLM via end-point, StackAI’s fine-tuned text-to-SQL model\n\nStackAI also supports connections with MCP servers, allowing your workflows to use not only integrations developed by StackAI’s team, but also integrate with tools served by third parties using the MCP protocol.\n\nMaking LLMs take autonomous actions is very easy. Users can add ‘tools’ (e.g., function calling) directly in the LLM node by selecting the one they want from a long list of possible actions. More advanced users can also add their own custom tools.\n\n### \n\nAsk Workflow\n\nUsers can interact with the assistant directly within the workflow builder to ask questions, get suggestions for improving their project, and easily access documentation for specific features.","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/inputs","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/inputs","loadedTime":"2025-10-17T18:29:37.590Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/inputs","title":"Inputs | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Inputs | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"date":"Fri, 17 Oct 2025 18:29:35 GMT","content-type":"text/html; charset=utf-8","content-encoding":"br","cf-ray":"9901dcbf68848157-SEA","cf-cache-status":"DYNAMIC","age":"1774","cache-control":"public, max-age=0, must-revalidate","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","referrer-policy":"no-referrer-when-downgrade","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"pdx1::iad1::ndnqf-1760725775283-68b8883442a2","server":"cloudflare","alt-svc":"h3=\":443\"; ma=86400","x-firefox-spdy":"h2"}},"screenshotUrl":"https://api.apify.com/v2/key-value-stores/3K2WBdQQFTu6EGDhJ/records/SCREENSHOT-docs-stack-ai-com-stack-ai-workflow-builder-inputs-8acf466b.jpg","text":"Inputs | StackAI\nInput NodeFiles NodeTrigger NodeURL Input NodeAudio Input NodeImage Input Node\nPreviousGet Started with Workflow BuilderNextInput Node\nWas this helpful?","markdown":"# Inputs | StackAI\n\n[Input Node](https://docs.stack-ai.com/stack-ai/workflow-builder/inputs/input-node)[Files Node](https://docs.stack-ai.com/stack-ai/workflow-builder/inputs/files-node)[Trigger Node](https://docs.stack-ai.com/stack-ai/workflow-builder/inputs/trigger-node)[URL Input Node](https://docs.stack-ai.com/stack-ai/workflow-builder/inputs/url-input-node)[Audio Input Node](https://docs.stack-ai.com/stack-ai/workflow-builder/inputs/audio-input-node)[Image Input Node](https://docs.stack-ai.com/stack-ai/workflow-builder/inputs/image-input-node)\n\n[PreviousGet Started with Workflow Builder](https://docs.stack-ai.com/stack-ai/workflow-builder/get-started-with-workflow-builder)[NextInput Node](https://docs.stack-ai.com/stack-ai/workflow-builder/inputs/input-node)\n\nWas this helpful?","debug":{"requestHandlerMode":"browser"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/inputs/trigger-node","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/inputs/trigger-node","loadedTime":"2025-10-17T18:29:42.176Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/inputs/trigger-node","title":"Trigger Node | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Trigger Node | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"894","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dce91f7caa75-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:42 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::t5769-1760725781963-01d30ed48809"}},"screenshotUrl":null,"text":"Trigger Node | StackAI\nThe Trigger Node allows you to automatically run your workflow based on certain triggers. The currently available triggers are:\nGithub\nGmail\nOutlook\nStackAI\nStripe\nTime\nTypeform\nZendesk\nA Trigger Node will start your workflow when a certain event occurs, such as an email being received in your Gmail account, or a pull request created on Github. You can also use a Trigger Node to start your project at the same time every day, or when another StackAI project completes a run.\nEmail triggers like Gmail or Outlook will monitor your Gmail or Outlook inbox and activate your workflow whenever a new email arrives. They extract key information from the email such as sender, subject, body content, thread ID, and any attachments, making this data available for downstream nodes to process.\nSome Trigger Nodes like Gmail, Typeform, or Zendesk may ask you to establish a new connection if you are using them for the first time. This allows them to access your personal account on those platforms.\nOutputs\nWhen an trigger occurs, the Trigger Node may give you outputs, depending on the trigger. To see these outputs, click on the Trigger Node, then select which trigger you would like to add. Hover over the trigger and you will see the its output fields. \nSender (string): The email address of the sender of the email\nSubject (string): The subject line of the email\nBody (string): The full text content of the email body\nThread ID (string): The thread ID of the email, which can be used to reply to the email in a SendEmail action\nAttachments (files): Email attachments stored in the data pool for use by other nodes\nHow to set up the Email Trigger Node\nAdd an Email Trigger node to your workflow\nConnect your Gmail or Outlook account:\nClick \"New Connection\" if no connection exists\nSelect an existing connection from the dropdown if available\nConfigure any test values (these are only used in the workflow builder)\nConnect the Email Trigger node to downstream nodes in your workflow\nPublish your workflow to activate the trigger\nImportant Notes\nThe trigger will not work until you publish the workflow\nYou must configure a Gmail or Outlook connection before the trigger can be used\nThe Email Trigger node requires permission to access your Gmail or Outlook inbox\nTest values are only used during workflow design and testing; they don't affect the actual trigger configuration\nUsing Email Data in Your Workflow\nYou can reference the email data in downstream nodes by:\nSelecting the Email Trigger node as an input source\nUsing specific email fields (Sender, Subject, Body, Thread ID, Attachments) in your workflow logic\nProcessing email content with AI nodes or other actions\nCommon Use Cases\nAuto-reply to specific types of emails\nExtract and process information from structured emails\nCreate tasks or tickets based on email content\nFilter and categorize incoming emails by sender or subject\nProcess email attachments\nAutomatically process and route new leads from contact forms\nCreate support tickets from feedback or help request forms\nProcess event signups and send confirmation emails\nAnalyze survey responses and generate insights\nAdd new contacts to your CRM system automatically\nHandle product orders or service requests\nCollect and categorize customer feedback\nReview and route job applications or membership requests\nStore form responses in databases or spreadsheets\nDaily Reports: Generate and send daily, weekly, or monthly reports\nData Backups: Automatically backup databases or files at regular intervals\nSystem Maintenance: Run cleanup tasks, cache clearing, or system health checks\nContent Publishing: Schedule blog posts, social media updates, or newsletters\nMonitoring and Alerts: Check system status and send alerts if issues are detected\nTroubleshooting\nEnsure your workflow is published for the trigger to be active\nVerify that your connection has the necessary permissions (if applicable)\nConfirm that webhooks are properly configured (usually handled automatically)\nMonitor workflow execution logs for any connection or processing errors\nTest with sample data first before relying on live form submissions\nEnsure your account has webhook capabilities (if applicable)\nLast updated 3 months ago","markdown":"# Trigger Node | StackAI\n\nThe **Trigger Node** allows you to automatically run your workflow based on certain triggers. The currently available triggers are:\n\n*   Github\n    \n*   Gmail\n    \n*   Outlook\n    \n*   StackAI\n    \n*   Stripe\n    \n*   Time\n    \n*   Typeform\n    \n*   Zendesk\n    \n\nA Trigger Node will start your workflow when a certain event occurs, such as an email being received in your Gmail account, or a pull request created on Github. You can also use a Trigger Node to start your project at the same time every day, or when another StackAI project completes a run.\n\nEmail triggers like Gmail or Outlook will monitor your Gmail or Outlook inbox and activate your workflow whenever a new email arrives. They extract key information from the email such as sender, subject, body content, thread ID, and any attachments, making this data available for downstream nodes to process.\n\nSome Trigger Nodes like Gmail, Typeform, or Zendesk may ask you to establish a **new connection** if you are using them for the first time. This allows them to access your personal account on those platforms.\n\n### \n\nOutputs\n\nWhen an trigger occurs, the Trigger Node may give you outputs, depending on the trigger. To see these outputs, click on the Trigger Node, then select which trigger you would like to add. Hover over the trigger and you will see the its output fields.\n\n*   **Sender** (string): The email address of the sender of the email\n    \n*   **Subject** (string): The subject line of the email\n    \n*   **Body** (string): The full text content of the email body\n    \n*   **Thread ID** (string): The thread ID of the email, which can be used to reply to the email in a SendEmail action\n    \n*   **Attachments** (files): Email attachments stored in the data pool for use by other nodes\n    \n\n### \n\nHow to set up the Email Trigger Node\n\n1.  Add an Email Trigger node to your workflow\n    \n2.  Connect your Gmail or Outlook account:\n    \n    *   Click \"New Connection\" if no connection exists\n        \n    *   Select an existing connection from the dropdown if available\n        \n    \n3.  Configure any test values (these are only used in the workflow builder)\n    \n4.  Connect the Email Trigger node to downstream nodes in your workflow\n    \n5.  Publish your workflow to activate the trigger\n    \n\n### \n\nImportant Notes\n\n*   The trigger will not work until you publish the workflow\n    \n*   You must configure a Gmail or Outlook connection before the trigger can be used\n    \n*   The Email Trigger node requires permission to access your Gmail or Outlook inbox\n    \n*   Test values are only used during workflow design and testing; they don't affect the actual trigger configuration\n    \n\n### \n\nUsing Email Data in Your Workflow\n\nYou can reference the email data in downstream nodes by:\n\n1.  Selecting the Email Trigger node as an input source\n    \n2.  Using specific email fields (Sender, Subject, Body, Thread ID, Attachments) in your workflow logic\n    \n3.  Processing email content with AI nodes or other actions\n    \n\n### \n\nCommon Use Cases\n\n*   **Auto-reply** to specific types of emails\n    \n*   **Extract** and process information from structured emails\n    \n*   **Create tasks** or tickets based on email content\n    \n*   Filter and **categorize incoming emails** by sender or subject\n    \n*   **Process email attachments**\n    \n*   Automatically process and **route new leads** from contact forms\n    \n*   **Create support tickets** from feedback or help request forms\n    \n*   Process **event signups** and send confirmation emails\n    \n*   **Analyze survey responses** and generate insights\n    \n*   **Add new contacts** to your CRM system automatically\n    \n*   **Handle product orders** or service requests\n    \n*   Collect and **categorize customer feedback**\n    \n*   Review and **route job applications** or membership requests\n    \n*   **Store form responses in databases** or spreadsheets\n    \n*   **Daily Reports**: Generate and send daily, weekly, or monthly reports\n    \n*   **Data Backups**: Automatically backup databases or files at regular intervals\n    \n*   **System Maintenance**: Run cleanup tasks, cache clearing, or system health checks\n    \n*   **Content Publishing**: Schedule blog posts, social media updates, or newsletters\n    \n*   **Monitoring and Alerts**: Check system status and send alerts if issues are detected\n    \n\n### \n\nTroubleshooting\n\n*   Ensure your workflow is published for the trigger to be active\n    \n*   Verify that your connection has the necessary permissions (if applicable)\n    \n*   Confirm that webhooks are properly configured (usually handled automatically)\n    \n*   Monitor workflow execution logs for any connection or processing errors\n    \n*   Test with sample data first before relying on live form submissions\n    \n*   Ensure your account has webhook capabilities (if applicable)\n    \n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/inputs/input-node","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/inputs/input-node","loadedTime":"2025-10-17T18:29:39.028Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/inputs/input-node","title":"Input Node | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Input Node | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"date":"Fri, 17 Oct 2025 18:29:37 GMT","content-type":"text/html; charset=utf-8","content-encoding":"br","cf-ray":"9901dcc6bc7d8157-SEA","cf-cache-status":"DYNAMIC","age":"0","cache-control":"public, max-age=0, must-revalidate","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","referrer-policy":"no-referrer-when-downgrade","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"pdx1::iad1::bdlpl-1760725776463-973992caa9e1","server":"cloudflare","alt-svc":"h3=\":443\"; ma=86400","x-firefox-spdy":"h2"}},"screenshotUrl":"https://api.apify.com/v2/key-value-stores/3K2WBdQQFTu6EGDhJ/records/SCREENSHOT-docs-stack-ai-com-stack-ai-workflow-builder-inputs-input-node-212a0004.jpg","text":"Input Node | StackAI\nAn Input Node allows you and your end-users to send text queries to any node that accepts text strings as input.\nThe most popular nodes accepting inputs are:\nThe LLM nodes (adding the input as part of their prompt).\nThe Knowledge Base nodes (they use the input as a prompt to retrieve information from their contents)\nHere are a few quick facts:\nInputs can be text fields of any length and are passed to their connected node in the flow.\nWhile inputs can be of any length, you should be mindful that LLM prompts have a limit on how long of an input they can process. To handle long inputs, consider using the Text Data Loader.\nTo expose an Input node to your users, you will need to set it up in the Export tab.\nExposing Inputs Externally\nIf you'd like an input to be automatically populated when the user open's your agent's interface, you can expose inputs externally. This is useful in cases where you automatically want to capture the user's id or other metadata about the user, like their timezone. To do this, first publish your project and head to the Export View. See here for detailed instructions.\nLast updated 3 months ago","markdown":"# Input Node | StackAI\n\nAn **Input Node** allows you and your end-users to send text queries to any node that accepts text strings as input.\n\nThe most popular nodes accepting inputs are:\n\n1.  The LLM nodes (adding the input as part of their prompt).\n    \n2.  The Knowledge Base nodes (they use the input as a prompt to retrieve information from their contents)\n    \n\nHere are a few quick facts:\n\n*   Inputs can be text fields of any length and are passed to their connected node in the flow.\n    \n*   While inputs can be of any length, you should be mindful that LLM prompts have a limit on how long of an input they can process. To handle long inputs, consider using the Text Data Loader.\n    \n*   To expose an Input node to your users, you will need to set it up in the **Export** tab.\n    \n\n### \n\nExposing Inputs Externally\n\nIf you'd like an input to be automatically populated when the user open's your agent's interface, you can expose inputs externally. This is useful in cases where you automatically want to capture the user's id or other metadata about the user, like their timezone. To do this, first publish your project and head to the **Export View**. [See here](https://docs.stack-ai.com/stack-ai/export-options/exposed-inputs) for detailed instructions.\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"browser"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/inputs/files-node","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/inputs/files-node","loadedTime":"2025-10-17T18:29:44.393Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/inputs/files-node","title":"Files Node | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Files Node | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"0","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dce919150580-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:44 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"iad1::iad1::779g4-1760725781986-c4bc52053b03"}},"screenshotUrl":null,"text":"Files Node | StackAI\nThe File Node allows users to upload a file to the flow and use it as an input to the LLM. The File Node is not a Knowledge Base like the Documents Node; RAG will not be performed over the files. Instead, the file will always be given directly to the LLM as context.\nExpose as Input: This toggle displays the file node as an available input on the user-facing interface, allowing the user to upload their own file. Toggle this OFF to keep the files static. The workflow will then always use the files you uploaded, and the user won't be able to change this.\nFiles Node Settings\nClick on the node to see the available settings.\nChunking Settings\nChunking Algorithm: Defines how the data is split (e.g., Sentence-based).\nChunk Overlap: The number of overlapping tokens between chunks.\nChunk Length: Max length of each chunk sent to the LLM.\nAdditional Features\nAdvanced Data Extraction: Enable more precise field-level parsing (toggle option).\nText in Images (OCR): Extract and include text from images (toggle option)\nHow to Use the File Node\nAdd a File node to your flow.\nConnect the File node to an LLM node.\nMention the File node in the LLM node by pressing \"/\" and selecting the File node.\nFiles (documents) is a reference to the contents (text) of the file, split into chunks\nFiles (raw_text) is a reference to the contents of the file, completely unchunked\nFiles (file_urls) is a reference to the actual file--useful if you need to instruct the LLM to attach the file to an email or send the file using SFTP.\nAdd an Output node to your flow.\nConnect the Output node to the LLM node.\nHow to Expose the File Node to your Users\nGo to the Export tab.\nEnable the file node in the Inputs section.\nPress Save Interface to save your changes.\nYour users should now see an upload button in the interface.","markdown":"# Files Node | StackAI\n\nThe File Node allows users to upload a file to the flow and use it as an input to the LLM. The File Node is not a Knowledge Base like the Documents Node; RAG will not be performed over the files. Instead, the file will always be given directly to the LLM as context.\n\n**Expose as Input:** This toggle displays the file node as an available input on the user-facing interface, allowing the user to upload their own file. Toggle this OFF to keep the files static. The workflow will then always use the files you uploaded, and the user won't be able to change this.\n\n### \n\nFiles Node Settings\n\nClick on the node to see the available settings.\n\n**Chunking Settings**\n\n*   **Chunking Algorithm**: Defines how the data is split (e.g., Sentence-based).\n    \n*   **Chunk Overlap**: The number of overlapping tokens between chunks.\n    \n*   **Chunk Length**: Max length of each chunk sent to the LLM.\n    \n\n**Additional Features**\n\n*   **Advanced Data Extraction**: Enable more precise field-level parsing (toggle option).\n    \n*   **Text in Images (OCR)**: Extract and include text from images (toggle option)\n    \n\n### \n\nHow to Use the File Node\n\n1.  Add a File node to your flow.\n    \n2.  Connect the File node to an LLM node.\n    \n3.  Mention the File node in the LLM node by pressing **\"/\"** and selecting the File node.\n    \n    1.  **Files (documents)** is a reference to the contents (text) of the file, split into chunks\n        \n    2.  **Files (raw\\_text)** is a reference to the contents of the file, completely unchunked\n        \n    3.  **Files (file\\_urls)** is a reference to the actual file--useful if you need to instruct the LLM to attach the file to an email or send the file using SFTP.\n        \n    \n4.  Add an Output node to your flow.\n    \n5.  Connect the Output node to the LLM node.\n    \n\n### \n\nHow to Expose the File Node to your Users\n\n1.  Go to the **Export** tab.\n    \n2.  Enable the file node in the **Inputs** section.\n    \n3.  Press **Save Interface** to save your changes.\n    \n4.  Your users should now see an upload button in the interface.","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/inputs/url-input-node","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/inputs/url-input-node","loadedTime":"2025-10-17T18:29:44.651Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/inputs/url-input-node","title":"URL Input Node | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"URL Input Node | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"0","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dcf8ee722902-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:44 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::4lrxl-1760725784487-47e0ffe5eee9"}},"screenshotUrl":null,"text":"URL Input Node | StackAI\nWhat is a URL Node?\nThe URL Node allows users to add a URL to the flow and scrape the HTML or Metadata of a website to use as an input to the LLM. If an LLM node returns a URL as its output, it can feed into the URL node to scrape a website in a more complex workflow. The entire output of the URL Node will be given to the LLM as context.\nMode\nDefines what type of content to fetch from the provided URL.\nPage HTML: Downloads the full HTML content of the page. Suitable for use cases like content parsing, summarization, or extraction of visible page elements.\nMetadata only: Fetches only metadata (e.g., <title>, <meta> tags such as description and Open Graph data). Useful for lightweight previews or indexing.\nScrape Subpages\nWhen enabled, the node will attempt to crawl and include linked subpages within the same domain.\nEnable URL as Input\nWhen checked, this enables dynamic input of URLs via upstream nodes or user input, rather than hardcoding a static value in the interface.\nHow to use the URL Node\nAdd a URL node to your flow.\nConnect the URL node to an LLM node.\nMention the URL node in the LLM node by pressing \"/\" and selecting the URL node.\nAdd an Output node to your flow.\nConnect the Output node to the LLM node.\nURL Node Settings\nIf you click the gear icon in the node, you will see the available settings.\nChunking Settings\nChunking Algorithm: Defines how the data is split (e.g., Sentence-based).\nChunk Overlap: The number of overlapping tokens between chunks.\nChunk Length: Max length of each chunk sent to the LLM.\nAdditional Features\nAdvanced Data Extraction: Enable more precise field-level parsing (toggle option).\nText in Images (OCR): Extract and include text from profile images or banners (toggle option)\nLast updated 3 months ago","markdown":"# URL Input Node | StackAI\n\n### \n\nWhat is a URL Node?\n\nThe URL Node allows users to add a URL to the flow and scrape the HTML or Metadata of a website to use as an input to the LLM. If an LLM node returns a URL as its output, it can feed into the URL node to scrape a website in a more complex workflow. The entire output of the URL Node will be given to the LLM as context.\n\n#### \n\n**Mode**\n\nDefines what type of content to fetch from the provided URL.\n\n*   `Page HTML`: Downloads the full HTML content of the page. Suitable for use cases like content parsing, summarization, or extraction of visible page elements.\n    \n*   `Metadata only`: Fetches only metadata (e.g., `<title>`, `<meta>` tags such as description and Open Graph data). Useful for lightweight previews or indexing.\n    \n\n#### \n\n**Scrape Subpages**\n\nWhen enabled, the node will attempt to crawl and include linked subpages within the same domain.\n\n#### \n\n**Enable URL as Input**\n\nWhen checked, this enables dynamic input of URLs via upstream nodes or user input, rather than hardcoding a static value in the interface.\n\n### \n\nHow to use the URL Node\n\n1.  Add a URL node to your flow.\n    \n2.  Connect the URL node to an LLM node.\n    \n3.  Mention the URL node in the LLM node by pressing **\"/\"** and selecting the URL node.\n    \n4.  Add an Output node to your flow.\n    \n5.  Connect the Output node to the LLM node.\n    \n\n### \n\nURL Node Settings\n\nIf you click the gear icon in the node, you will see the available settings.\n\n**Chunking Settings**\n\n*   **Chunking Algorithm**: Defines how the data is split (e.g., Sentence-based).\n    \n*   **Chunk Overlap**: The number of overlapping tokens between chunks.\n    \n*   **Chunk Length**: Max length of each chunk sent to the LLM.\n    \n\n**Additional Features**\n\n*   **Advanced Data Extraction**: Enable more precise field-level parsing (toggle option).\n    \n*   **Text in Images (OCR)**: Extract and include text from profile images or banners (toggle option)\n    \n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/time","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/time","loadedTime":"2025-10-17T18:29:46.032Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/time","title":"Time | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Time | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1576","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dd00dd5305cb-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:45 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::zdbbv-1760725785793-bab5cba19fa4"}},"screenshotUrl":null,"text":"Time | StackAI\nThe Time Node provides tools for working with time and scheduling in your Stack AI workflows. It is especially useful for automating tasks based on time, retrieving the current time in various formats and timezones, and determining the day of the week for any date.\nAvailable Actions\n1. Task Scheduler\nPurpose: Schedule tasks to run other tools or actions at specific times using cron expressions.\nInputs:\ncron_expression (required): The cron schedule (e.g., \"0 9 * * *\" for 9am daily).\nNote: You cannot schedule more frequently than daily.\ntitle (required): A short, descriptive title for the scheduled task (do not include time info here).\nhuman_expression (required): A human-readable description of the schedule (e.g., \"every Monday at 9am\").\ninstructions (required): Detailed instructions for what the scheduled task should do (do not include timing info here).\ntimezone (optional, default \"UTC\"): The timezone for the schedule (e.g., \"America/New_York\").\nOutputs:\nid: The ID of the scheduled task.\ncron_id: The cron job’s unique identifier.\nresult_msg: A message describing the result of the scheduling action.\nWhen to use:\nTo automate recurring tasks (e.g., daily reports, weekly reminders, periodic data scraping).\nWhen you want to trigger actions at specific times or intervals.\n2. Current Time\nPurpose: Retrieve the current time in a specified timezone and format.\nInputs:\ntimezone (optional, default \"UTC\"): The timezone for the current time (e.g., \"Asia/Tokyo\").\nformat (optional, default \"%Y-%m-%d %H:%M:%S\"): The output format for the time (e.g., \"YYYY-MM-DD HH:MM:SS\").\nOutputs:\ncurrent_time: The current time as a string, formatted as specified.\nWhen to use:\nWhen you need to timestamp actions, logs, or outputs.\nTo display or use the current time in a specific timezone.\nFor time-based logic in your workflow.\n3. Weekday\nPurpose: Determine the day of the week for a given date.\nInputs:\nyear (required): The year (e.g., 2025).\nmonth (required): The month (1-12).\nday (required): The day (1-31).\nOutputs:\nweekday: The name of the weekday (e.g., \"Monday\").\nWhen to use:\nFor scheduling or logic that depends on the day of the week.\nTo check if a date falls on a weekend or a specific weekday.\nFor calendar-based automations.\nHow to Use the Time Action Node\nAdd the Time action node to your workflow.\nSelect the desired action (Task Scheduler, Current Time, or Weekday).\nFill in the required input fields as described above.\nConnect the node to other nodes as needed (e.g., to trigger actions, provide time info to LLMs, or control workflow logic).\nExample Use Cases\nTask Scheduler: Automate scraping a website every Monday at 9am.\nCurrent Time: Add a timestamp to a generated report in the user’s local timezone.\nWeekday: Only send notifications if today is a weekday.\nLast updated 3 months ago","markdown":"# Time | StackAI\n\nThe **Time Node** provides tools for working with time and scheduling in your Stack AI workflows. It is especially useful for automating tasks based on time, retrieving the current time in various formats and timezones, and determining the day of the week for any date.\n\n* * *\n\n### \n\nAvailable Actions\n\n#### \n\n1\\. Task Scheduler\n\n**Purpose:** Schedule tasks to run other tools or actions at specific times using cron expressions.\n\n**Inputs:**\n\n*   **cron\\_expression** (required): The cron schedule (e.g., \"0 9 \\* \\* \\*\" for 9am daily).\n    \n    *   Note: You cannot schedule more frequently than daily.\n        \n    \n*   **title** (required): A short, descriptive title for the scheduled task (do not include time info here).\n    \n*   **human\\_expression** (required): A human-readable description of the schedule (e.g., \"every Monday at 9am\").\n    \n*   **instructions** (required): Detailed instructions for what the scheduled task should do (do not include timing info here).\n    \n*   **timezone** (optional, default \"UTC\"): The timezone for the schedule (e.g., \"America/New\\_York\").\n    \n\n**Outputs:**\n\n*   **id**: The ID of the scheduled task.\n    \n*   **cron\\_id**: The cron job’s unique identifier.\n    \n*   **result\\_msg**: A message describing the result of the scheduling action.\n    \n\n**When to use:**\n\n*   To automate recurring tasks (e.g., daily reports, weekly reminders, periodic data scraping).\n    \n*   When you want to trigger actions at specific times or intervals.\n    \n\n* * *\n\n#### \n\n2\\. Current Time\n\n**Purpose:** Retrieve the current time in a specified timezone and format.\n\n**Inputs:**\n\n*   **timezone** (optional, default \"UTC\"): The timezone for the current time (e.g., \"Asia/Tokyo\").\n    \n*   **format** (optional, default \"%Y-%m-%d %H:%M:%S\"): The output format for the time (e.g., \"YYYY-MM-DD HH:MM:SS\").\n    \n\n**Outputs:**\n\n*   **current\\_time**: The current time as a string, formatted as specified.\n    \n\n**When to use:**\n\n*   When you need to timestamp actions, logs, or outputs.\n    \n*   To display or use the current time in a specific timezone.\n    \n*   For time-based logic in your workflow.\n    \n\n* * *\n\n#### \n\n3\\. Weekday\n\n**Purpose:** Determine the day of the week for a given date.\n\n**Inputs:**\n\n*   **year** (required): The year (e.g., 2025).\n    \n*   **month** (required): The month (1-12).\n    \n*   **day** (required): The day (1-31).\n    \n\n**Outputs:**\n\n*   **weekday**: The name of the weekday (e.g., \"Monday\").\n    \n\n**When to use:**\n\n*   For scheduling or logic that depends on the day of the week.\n    \n*   To check if a date falls on a weekend or a specific weekday.\n    \n*   For calendar-based automations.\n    \n\n* * *\n\n### \n\nHow to Use the Time Action Node\n\n*   **Add the Time action node** to your workflow.\n    \n*   **Select the desired action** (Task Scheduler, Current Time, or Weekday).\n    \n*   **Fill in the required input fields** as described above.\n    \n*   **Connect the node** to other nodes as needed (e.g., to trigger actions, provide time info to LLMs, or control workflow logic).\n    \n\n* * *\n\n### \n\nExample Use Cases\n\n*   **Task Scheduler:** Automate scraping a website every Monday at 9am.\n    \n*   **Current Time:** Add a timestamp to a generated report in the user’s local timezone.\n    \n*   **Weekday:** Only send notifications if today is a weekday.\n    \n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/synapse","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/synapse","loadedTime":"2025-10-17T18:29:46.145Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/synapse","title":"Synapse | StackAI","description":"Learn how to use the Synapse node in StackAI to query your Synapse database using natural language or SQL, with clear input and output examples.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Synapse | StackAI"},{"property":"og:description","content":"Learn how to use the Synapse node in StackAI to query your Synapse database using natural language or SQL, with clear input and output examples."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1578","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dd00ed52602a-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:45 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::sbz7b-1760725785802-9ed3974e3b9e"}},"screenshotUrl":null,"text":"Synapse | StackAI\nLearn how to use the Synapse node in StackAI to query your Synapse database using natural language or SQL, with clear input and output examples.\nWhat is Synapse?\nThe Synapse node in StackAI allows you to query your Synapse database using either plain English or SQL. It automatically translates your request into a SQL query, executes it, and returns the results, making data access simple and intuitive for users of all technical backgrounds.\nHow to use it?\nTo use the Synapse node, you need to provide two required inputs:\nSchema (Required): The structure of your database, including tables, columns, and data types. This helps the node understand how to interpret your query.\nQuery (Required): Your question or command, written in plain English or SQL. The node will process this and generate the appropriate SQL to fetch your data.\nExample of Usage\nSuppose you have a table called Customers with columns Name (TEXT), Email (TEXT), and Revenue (REAL).\nSchema Example:\nTABLE Customers ( Name TEXT, Email TEXT, Revenue REAL );\nQuery Example (Plain English):\nWhat is the total revenue for all customers?\nQuery Example (SQL):\nSELECT SUM(Revenue) FROM Customers;\nInputs\nName\nDescription\nRequired\nExample\nDatabase Schema (tables, columns, types, etc.)\nTABLE Customers (Name TEXT, Email TEXT, Revenue REAL);\nEnter your query in plain English or SQL format to execute against database\nWhat is the total revenue for all customers? or SELECT SUM(Revenue) FROM Customers;\nConfigurations\nNo additional configurations are required. All you need is the schema and the query.\nOutputs\nName\nDescription\nRequired\nExample\nThe SQL query that was executed\nSELECT SUM(Revenue) FROM Customers;\nResults of the Synapse query\n[{\"SUM(Revenue)\": 100000}]\nAvailable Actions\nQuery a Synapse Database: This is the primary action, allowing you to run queries and retrieve results from your Synapse database.\nSummary Table\nAction Name\nDescription\nRequired Inputs\nOutputs\nRun a query on your Synapse DB\nBest Practices\nAlways provide an accurate and up-to-date schema for best results.\nYou can use either plain English or SQL for your queries.\nReview the output SQL to ensure it matches your intent.\nUse Case Example\nIf you want to find the top 5 customers by revenue, provide the schema and use the query:\nShow me the top 5 customers by revenue.\nThe node will generate the SQL, execute it, and return the results.\nThe Synapse node in StackAI streamlines database querying, making it accessible and efficient for all users.\nLast updated 3 months ago","markdown":"# Synapse | StackAI\n\nLearn how to use the Synapse node in StackAI to query your Synapse database using natural language or SQL, with clear input and output examples.\n\n**What is Synapse?**\n\nThe Synapse node in StackAI allows you to query your Synapse database using either plain English or SQL. It automatically translates your request into a SQL query, executes it, and returns the results, making data access simple and intuitive for users of all technical backgrounds.\n\n**How to use it?**\n\nTo use the Synapse node, you need to provide two required inputs:\n\n1.  **Schema** (Required): The structure of your database, including tables, columns, and data types. This helps the node understand how to interpret your query.\n    \n2.  **Query** (Required): Your question or command, written in plain English or SQL. The node will process this and generate the appropriate SQL to fetch your data.\n    \n\n**Example of Usage**\n\nSuppose you have a table called Customers with columns Name (TEXT), Email (TEXT), and Revenue (REAL).\n\n*   **Schema Example:**\n    \n    ```\n    TABLE Customers (\n      Name TEXT,\n      Email TEXT,\n      Revenue REAL\n    );\n    ```\n    \n*   **Query Example (Plain English):**\n    \n    ```\n    What is the total revenue for all customers?\n    ```\n    \n*   **Query Example (SQL):**\n    \n    ```\n    SELECT SUM(Revenue) FROM Customers;\n    ```\n    \n\n**Inputs**\n\nName\n\nDescription\n\nRequired\n\nExample\n\nDatabase Schema (tables, columns, types, etc.)\n\n`TABLE Customers (Name TEXT, Email TEXT, Revenue REAL);`\n\nEnter your query in plain English or SQL format to execute against database\n\n`What is the total revenue for all customers?` or `SELECT SUM(Revenue) FROM Customers;`\n\n**Configurations**\n\n*   No additional configurations are required. All you need is the schema and the query.\n    \n\n**Outputs**\n\nName\n\nDescription\n\nRequired\n\nExample\n\nThe SQL query that was executed\n\n`SELECT SUM(Revenue) FROM Customers;`\n\nResults of the Synapse query\n\n`[{\"SUM(Revenue)\": 100000}]`\n\n**Available Actions**\n\n*   **Query a Synapse Database**: This is the primary action, allowing you to run queries and retrieve results from your Synapse database.\n    \n\n**Summary Table**\n\nAction Name\n\nDescription\n\nRequired Inputs\n\nOutputs\n\nRun a query on your Synapse DB\n\n**Best Practices**\n\n*   Always provide an accurate and up-to-date schema for best results.\n    \n*   You can use either plain English or SQL for your queries.\n    \n*   Review the output SQL to ensure it matches your intent.\n    \n\n**Use Case Example**\n\nIf you want to find the top 5 customers by revenue, provide the schema and use the query:\n\n```\nShow me the top 5 customers by revenue.\n```\n\nThe node will generate the SQL, execute it, and return the results.\n\n* * *\n\nThe Synapse node in StackAI streamlines database querying, making it accessible and efficient for all users.\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/vlm","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/vlm","loadedTime":"2025-10-17T18:29:47.007Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/vlm","title":"Vlm | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Vlm | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1577","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dd067dad2720-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:46 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::6dmrw-1760725786664-1f2a4ce67ddf"}},"screenshotUrl":null,"text":"Vlm | StackAI\nThe Vlm Node represents an integration with a Visual Language Model (VLM) provider. This type of node is typically used for advanced AI tasks that involve both visual and language understanding, such as analyzing images, generating text from images, creating images from text, or performing multimodal reasoning.\nWhat the Vlm Node Is Best Used For\nImage Analysis: Extracting information, objects, or text from images.\nImage Generation: Creating new images based on text prompts or modifying existing images.\nDocument Understanding: Reading and summarizing visual documents (e.g., PDFs, scanned pages).\nMultimodal Tasks: Combining text and image inputs for richer AI outputs (e.g., answering questions about a chart or diagram).\nFile Management: Uploading, downloading, and managing files for use in AI workflows.\nEstablishing a Connection\nThe Vlm Node requires establishing a new connection using an API key before use. \nAvailable Actions (Exhaustive List)\nHere are all the actions available for the Vlm provider:\nGet Files – Get a list of files.\nUpload File – Upload a file.\nGet File (by ID) – Get a file by its ID.\nGet File (by Hash) – Get a file by its hash.\nGenerate Presigned URL – Generate a presigned URL for file upload.\nVerify File Upload – Verify a file upload.\nCheck Health – Check the health of the OpenAI VLM service.\nchat_completions_v1_openai_chat_completions_post – Generate chat completions (multimodal).\nmodels_v1_openai_models_get – List available models.\nmodel_info_v1_openai_models__model__get – Get information about a specific model.\ninfo_v1_hub_info_get – Get hub information.\nlist_domains_v1_hub_domains_get – List available domains.\nget_domain_schema_v1_hub_schema_post – Get the schema for a domain.\nimage_generate_v1_image_generate_post – Generate an image from a prompt.\nschema_generate_image_v1_image_schema_post – Get the schema for image generation.\ndocument_generate_v1_document_generate_post – Generate a document from a prompt.\ndocument_execute_v1_document_execute_post – Execute a document generation task.\nschema_generate_document_v1_document_schema_post – Get the schema for document generation.\nvideo_generate_v1_video_generate_post – Generate a video from a prompt.\naudio_generate_v1_audio_generate_post – Generate audio from a prompt.\nagent_execute_v1_agent_execute_post – Execute an agent task (multimodal agent).\nget_predictions_v1_predictions_get – List predictions.\nget_prediction_v1_predictions__id__get – Get a specific prediction.\nget_prediction_domain_v1_predictions__id__domain_get – Get the domain of a prediction.\nhealth_v1_health_get – General health check.\nget_models_v1_models_get – List all models.\nget_domains_v1_domains_get – List all domains.\nget_schema_v1_schema_post – Get a schema for a task.\nNote: Each action is designed for a specific type of multimodal or file-related task. Some are for file management, others for generating or analyzing content, and some for managing or querying models and domains.\nLast updated 3 months ago","markdown":"# Vlm | StackAI\n\nThe **Vlm Node** represents an integration with a Visual Language Model (VLM) provider. This type of node is typically used for advanced AI tasks that involve both visual and language understanding, such as analyzing images, generating text from images, creating images from text, or performing multimodal reasoning.\n\n#### \n\nWhat the Vlm Node Is Best Used For\n\n*   **Image Analysis:** Extracting information, objects, or text from images.\n    \n*   **Image Generation:** Creating new images based on text prompts or modifying existing images.\n    \n*   **Document Understanding:** Reading and summarizing visual documents (e.g., PDFs, scanned pages).\n    \n*   **Multimodal Tasks:** Combining text and image inputs for richer AI outputs (e.g., answering questions about a chart or diagram).\n    \n*   **File Management:** Uploading, downloading, and managing files for use in AI workflows.\n    \n\n### \n\nEstablishing a Connection\n\nThe Vlm Node requires establishing a new connection using an API key before use.\n\n#### \n\nAvailable Actions (Exhaustive List)\n\nHere are all the actions available for the Vlm provider:\n\n1.  **Get Files** – Get a list of files.\n    \n2.  **Upload File** – Upload a file.\n    \n3.  **Get File (by ID)** – Get a file by its ID.\n    \n4.  **Get File (by Hash)** – Get a file by its hash.\n    \n5.  **Generate Presigned URL** – Generate a presigned URL for file upload.\n    \n6.  **Verify File Upload** – Verify a file upload.\n    \n7.  **Check Health** – Check the health of the OpenAI VLM service.\n    \n8.  **chat\\_completions\\_v1\\_openai\\_chat\\_completions\\_post** – Generate chat completions (multimodal).\n    \n9.  **models\\_v1\\_openai\\_models\\_get** – List available models.\n    \n10.  **model\\_info\\_v1\\_openai\\_models\\_\\_model\\_\\_get** – Get information about a specific model.\n    \n11.  **info\\_v1\\_hub\\_info\\_get** – Get hub information.\n    \n12.  **list\\_domains\\_v1\\_hub\\_domains\\_get** – List available domains.\n    \n13.  **get\\_domain\\_schema\\_v1\\_hub\\_schema\\_post** – Get the schema for a domain.\n    \n14.  **image\\_generate\\_v1\\_image\\_generate\\_post** – Generate an image from a prompt.\n    \n15.  **schema\\_generate\\_image\\_v1\\_image\\_schema\\_post** – Get the schema for image generation.\n    \n16.  **document\\_generate\\_v1\\_document\\_generate\\_post** – Generate a document from a prompt.\n    \n17.  **document\\_execute\\_v1\\_document\\_execute\\_post** – Execute a document generation task.\n    \n18.  **schema\\_generate\\_document\\_v1\\_document\\_schema\\_post** – Get the schema for document generation.\n    \n19.  **video\\_generate\\_v1\\_video\\_generate\\_post** – Generate a video from a prompt.\n    \n20.  **audio\\_generate\\_v1\\_audio\\_generate\\_post** – Generate audio from a prompt.\n    \n21.  **agent\\_execute\\_v1\\_agent\\_execute\\_post** – Execute an agent task (multimodal agent).\n    \n22.  **get\\_predictions\\_v1\\_predictions\\_get** – List predictions.\n    \n23.  **get\\_prediction\\_v1\\_predictions\\_\\_id\\_\\_get** – Get a specific prediction.\n    \n24.  **get\\_prediction\\_domain\\_v1\\_predictions\\_\\_id\\_\\_domain\\_get** – Get the domain of a prediction.\n    \n25.  **health\\_v1\\_health\\_get** – General health check.\n    \n26.  **get\\_models\\_v1\\_models\\_get** – List all models.\n    \n27.  **get\\_domains\\_v1\\_domains\\_get** – List all domains.\n    \n28.  **get\\_schema\\_v1\\_schema\\_post** – Get a schema for a task.\n    \n\n> **Note:** Each action is designed for a specific type of multimodal or file-related task. Some are for file management, others for generating or analyzing content, and some for managing or querying models and domains.\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/weaviate","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/weaviate","loadedTime":"2025-10-17T18:29:51.663Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/weaviate","title":"Weaviate | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Weaviate | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1582","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dd248dc1d6ed-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:51 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::s67dl-1760725791486-f69dc45f8a75"}},"screenshotUrl":null,"text":"Weaviate | StackAI\nThe Weaviate Node in Stack AI is used to query a Weaviate vector database. Weaviate is a popular open-source vector database that allows you to store and search data using vector embeddings, which is especially useful for semantic search, recommendation systems, and AI-powered retrieval tasks.\nHere’s a detailed explanation of Vector Search in Weaviate and how to establish a connection in Stack AI:\nAvailable Actions\nVector Search in Weaviate allows you to search for objects (such as documents, images, or data entries) that are most similar to a given query, using vector embeddings. This is especially useful for semantic search, recommendations, and AI-powered retrieval.\nHow the \"Vector Search\" Action Works\nAction Name: Vector Search\nProvider: Weaviate\nPurpose: Search for similar vectors in a Weaviate database.\nRequired Input Parameters\nClass Name (class_name): The name of the Weaviate class (collection/table) you want to search in. Example: \"Article\", \"Document\", \"Product\"\nProperties (properties): Comma-separated list of properties to return in the results. Example: \"title,description,url\"\nQuery (query): The search query (text) to find similar vectors. Example: \"AI workflow automation\"\nNumber of Results (top_k): How many results to return. Example: 5 or 10\nOutput\nResults (results): The results of the vector search query, typically a list of objects with the requested properties.\nHow to Establish a Connection to Weaviate\nTo connect Stack AI to your Weaviate instance, you need to provide connection details. Here’s how:\nConnection ID: If you have a private Weaviate instance, you’ll need a connection ID. This is usually set up in your Stack AI integrations or connections panel.\nIn the action node’s action_configurations, add:\n{ \"connection_id\": \"<your-weaviate-connection-id>\" }\nIf you’re using the default Stack AI Weaviate instance, you may not need to set this.\nConfigure the Action Node:\nSet the required input parameters (class_name, properties, query, top_k).\nIf you want to use dynamic input (e.g., from an Input node or LLM), reference the node like {in-0} or {llm-0} in the query field.\nSummary Table\nParameter\nDescription\nExample Value\nProperties to return (comma-separated)\nSearch query (text or node reference)\nNumber of results to return\n(Optional) Connection ID for private Weaviate\nHow to Use the Weaviate Node\nConnect to a Weaviate Database: You typically need to configure the node with a connection to your Weaviate instance (this may require a connection ID if you have a private instance).\nSet Query Parameters: Define what you want to search for—this usually involves providing a query vector or text, and specifying parameters like the number of results (top_k), the class or collection to search, and any filters.\nInput Data: The node can take input from other nodes (like an LLM or Input node) to dynamically generate queries.\nUse Output: The results from the Weaviate node can be passed to downstream nodes, such as an LLM for summarization or an Output node for display.\nExample Workflow\nUser provides a search query (Input node).\nThe query is embedded (optionally by an LLM or embedding node).\nThe Weaviate node performs a vector search using the embedding.\nThe results are passed to an LLM for summarization or directly to the Output node.\nWhen to Use the Weaviate Node\nWhen you need to perform advanced, AI-powered search over large datasets.\nWhen you want to build applications that require semantic understanding, such as chatbots, document search, or recommendation engines.\nLast updated 3 months ago","markdown":"# Weaviate | StackAI\n\nThe **Weaviate Node** in Stack AI is used to query a Weaviate vector database. Weaviate is a popular open-source vector database that allows you to store and search data using vector embeddings, which is especially useful for semantic search, recommendation systems, and AI-powered retrieval tasks.\n\nHere’s a detailed explanation of Vector Search in Weaviate and how to establish a connection in Stack AI:\n\n* * *\n\n### \n\nAvailable Actions\n\n**Vector Search** in Weaviate allows you to search for objects (such as documents, images, or data entries) that are most similar to a given query, using vector embeddings. This is especially useful for semantic search, recommendations, and AI-powered retrieval.\n\n#### \n\nHow the \"Vector Search\" Action Works\n\n*   **Action Name:** Vector Search\n    \n*   **Provider:** Weaviate\n    \n*   **Purpose:** Search for similar vectors in a Weaviate database.\n    \n\n**Required Input Parameters**\n\n1.  **Class Name** (`class_name`): The name of the Weaviate class (collection/table) you want to search in. _Example: \"Article\", \"Document\", \"Product\"_\n    \n2.  **Properties** (`properties`): Comma-separated list of properties to return in the results. _Example: \"title,description,url\"_\n    \n3.  **Query** (`query`): The search query (text) to find similar vectors. _Example: \"AI workflow automation\"_\n    \n4.  **Number of Results** (`top_k`): How many results to return. _Example: 5 or 10_\n    \n\n**Output**\n\n*   **Results** (`results`): The results of the vector search query, typically a list of objects with the requested properties.\n    \n\n* * *\n\n### \n\nHow to Establish a Connection to Weaviate\n\nTo connect Stack AI to your Weaviate instance, you need to provide connection details. Here’s how:\n\n1.  **Connection ID:** If you have a private Weaviate instance, you’ll need a connection ID. This is usually set up in your Stack AI integrations or connections panel.\n    \n    *   In the action node’s `action_configurations`, add:\n        \n        ```\n        { \"connection_id\": \"<your-weaviate-connection-id>\" }\n        ```\n        \n    *   If you’re using the default Stack AI Weaviate instance, you may not need to set this.\n        \n    \n2.  **Configure the Action Node:**\n    \n    *   Set the required input parameters (`class_name`, `properties`, `query`, `top_k`).\n        \n    *   If you want to use dynamic input (e.g., from an Input node or LLM), reference the node like `{in-0}` or `{llm-0}` in the `query` field.\n        \n    \n\n* * *\n\n### \n\nSummary Table\n\nParameter\n\nDescription\n\nExample Value\n\nProperties to return (comma-separated)\n\nSearch query (text or node reference)\n\nNumber of results to return\n\n(Optional) Connection ID for private Weaviate\n\nHow to Use the Weaviate Node\n\n1.  **Connect to a Weaviate Database**: You typically need to configure the node with a connection to your Weaviate instance (this may require a connection ID if you have a private instance).\n    \n2.  **Set Query Parameters**: Define what you want to search for—this usually involves providing a query vector or text, and specifying parameters like the number of results (`top_k`), the class or collection to search, and any filters.\n    \n3.  **Input Data**: The node can take input from other nodes (like an LLM or Input node) to dynamically generate queries.\n    \n4.  **Use Output**: The results from the Weaviate node can be passed to downstream nodes, such as an LLM for summarization or an Output node for display.\n    \n\n#### \n\nExample Workflow\n\n*   User provides a search query (Input node).\n    \n*   The query is embedded (optionally by an LLM or embedding node).\n    \n*   The Weaviate node performs a vector search using the embedding.\n    \n*   The results are passed to an LLM for summarization or directly to the Output node.\n    \n\n#### \n\nWhen to Use the Weaviate Node\n\n*   When you need to perform advanced, AI-powered search over large datasets.\n    \n*   When you want to build applications that require semantic understanding, such as chatbots, document search, or recommendation engines.\n    \n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/web-search","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/web-search","loadedTime":"2025-10-17T18:29:51.747Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/web-search","title":"Web Search | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Web Search | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1582","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dd24992ce63d-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:51 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::29zd8-1760725791476-5401732e365b"}},"screenshotUrl":null,"text":"Web Search | StackAI\nThe Web Search Node allows you to search the web for information and retrieve a list of relevant results. It is highly configurable, letting you tailor the search to specific countries, languages, devices, and more.\nWeb Search\nPurpose: Search the web for any query and return a list of results, including URLs, titles, and content snippets, you may also include or exclude domains when specified.\nProvider: websearch\nInput Parameters\nquery (required): The search terms you want to look up on the web.\nnum (optional, default 5): How many search results to retrieve.\nlocation (optional, default \"US\"): The geographic location to use for location-based search results (e.g., \"US\", \"GB\", \"IN\", etc.).\ndevice (optional, default \"desktop\"): Simulate search results as seen on \"desktop\" or \"mobile\" devices.\ngl (optional, default \"US\"): Which country’s search engine to use for results.\nhl (optional, default \"en\"): The language for search results and interface (e.g., \"en\" for English, \"fr\" for French, etc.).\nOutput\nsearch_results: An array of results, each containing:\nurl: The web address of the result.\ntitle: The title of the webpage (may be null if unavailable).\ntext: The content snippet or extracted content from the page.\nfavicon: The favicon of the website (may be null if unavailable).\nOther Actions Available in the Web Search Provider\nBesides the standard web search, the websearch provider also offers these actions:\nJob Search: Search for job listings on the web.\nGet Markdown: Retrieve web content and convert it to markdown format.\nNews Search: Search for news articles.\nDeep Research: Perform a more in-depth research query, often returning more comprehensive or summarized results.\nEach of these actions has its own specific input and output parameters, but all are designed to help you retrieve and process information from the web in different formats or for different use cases.\nSummary Table\nAction Name\nDescription\nTypical Use Case\nGeneral web search for any query\nFind websites, articles, or info\nFind open positions on the web\nConvert web content to markdown\nExtract readable content for processing\nTrack news on a topic or company\nIn-depth research and summarization\nGet comprehensive answers or summaries","markdown":"# Web Search | StackAI\n\nThe **Web Search Node** allows you to search the web for information and retrieve a list of relevant results. It is highly configurable, letting you tailor the search to specific countries, languages, devices, and more.\n\n#### \n\nWeb Search\n\n*   **Purpose:** Search the web for any query and return a list of results, including URLs, titles, and content snippets, you may also include or exclude domains when specified.\n    \n*   **Provider:** websearch\n    \n\n**Input Parameters**\n\n*   **query** (required): The search terms you want to look up on the web.\n    \n*   **num** (optional, default 5): How many search results to retrieve.\n    \n*   **location** (optional, default \"US\"): The geographic location to use for location-based search results (e.g., \"US\", \"GB\", \"IN\", etc.).\n    \n*   **device** (optional, default \"desktop\"): Simulate search results as seen on \"desktop\" or \"mobile\" devices.\n    \n*   **gl** (optional, default \"US\"): Which country’s search engine to use for results.\n    \n*   **hl** (optional, default \"en\"): The language for search results and interface (e.g., \"en\" for English, \"fr\" for French, etc.).\n    \n\n**Output**\n\n*   **search\\_results**: An array of results, each containing:\n    \n    *   **url**: The web address of the result.\n        \n    *   **title**: The title of the webpage (may be null if unavailable).\n        \n    *   **text**: The content snippet or extracted content from the page.\n        \n    *   **favicon**: The favicon of the website (may be null if unavailable).\n        \n    \n\n* * *\n\n### \n\nOther Actions Available in the Web Search Provider\n\nBesides the standard web search, the websearch provider also offers these actions:\n\n1.  **Job Search**: Search for job listings on the web.\n    \n2.  **Get Markdown**: Retrieve web content and convert it to markdown format.\n    \n3.  **News Search**: Search for news articles.\n    \n4.  **Deep Research**: Perform a more in-depth research query, often returning more comprehensive or summarized results.\n    \n\nEach of these actions has its own specific input and output parameters, but all are designed to help you retrieve and process information from the web in different formats or for different use cases.\n\n* * *\n\n#### \n\nSummary Table\n\nAction Name\n\nDescription\n\nTypical Use Case\n\nGeneral web search for any query\n\nFind websites, articles, or info\n\nFind open positions on the web\n\nConvert web content to markdown\n\nExtract readable content for processing\n\nTrack news on a topic or company\n\nIn-depth research and summarization\n\nGet comprehensive answers or summaries","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/workday","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/workday","loadedTime":"2025-10-17T18:29:51.849Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/workday","title":"Workday | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Workday | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1581","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dd249e85d630-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:51 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::lr5r6-1760725791518-9270df5b3800"}},"screenshotUrl":null,"text":"Workday | StackAI\nThe Workday Node connects your workflow to Workday, a popular platform for HR, finance, and planning data. This node allows you to run queries against your Workday data using Workday Query Language (WQL), which is similar to SQL but tailored for Workday’s data model.\nWhat is it used for?\nHR Data Retrieval: Get lists of employees, their statuses, contact info, and more.\nFinance Data: Query cost centers, organizations, and financial structures.\nPlanning & Operations: Retrieve positions, organizational hierarchies, and other planning data.\nCustom Reports: Build custom queries to extract exactly the data you need from Workday\nEstablish a Connection to Workday\nTo use this node, you must first establish a connection to your Workday account.\n1. Obtain Workday API Credentials\nTo connect to Workday, you’ll need:\nWorkday REST API Endpoint (e.g., https://<your-tenant>.workday.com/ccx/api/v1/)\nClient ID and Client Secret (for OAuth 2.0 authentication)\nWorkday Username and Password (if using basic authentication, but OAuth is recommended)\nAPI Scopes/Permissions (ensure your integration system user has the right permissions for the data you want to access)\n2. Register an Integration System User (ISU) in Workday\nIn Workday, create an Integration System User (ISU) with the necessary security group assignments.\nAssign the ISU to a security group with access to the relevant Workday APIs and data domains.\n3. Create an OAuth 2.0 Client (Recommended)\nIn Workday, register an OAuth 2.0 client for your integration.\nNote the Client ID and Client Secret.\nSet the allowed scopes (e.g., WorkdayWebServices, WorkdayREST).\n4. Get the API Endpoint\nThe base URL for the Workday REST API is typically:\nhttps://<your-tenant>.workday.com/ccx/api/v1/\nReplace <your-tenant> with your Workday tenant name.\n5. Authenticate and Obtain an Access Token\nUse the OAuth 2.0 client credentials to request an access token.\nExample token request (using curl):\ncurl -X POST \\ -u \"<client_id>:<client_secret>\" \\ -d \"grant_type=client_credentials\" \\ \"https://<your-tenant>.workday.com/ccx/oauth2/<client_id>/token\"\nThe response will include an access_token to use in API requests.\n6. Configure the Connection in Stack AI\nIn your Stack AI workflow, when adding a Workday action node, you’ll need to provide the connection details.\nIf Stack AI supports custom connections for Workday, you would enter:\nThe API endpoint\nThe OAuth 2.0 client ID and secret\nThe access token (or the credentials to obtain one)\nIf you have a connection ID for Workday, you can add it to the action_configurations of your Workday node:\n\"action_configurations\": { \"connection_id\": \"<your-workday-connection-id>\" }\n(You do not currently have a Workday connection ID listed. You may need to create one in your Stack AI integrations dashboard.)\n7. Test the Connection\nUse a simple WQL query (e.g., SELECT workday_id FROM workers LIMIT 1) to verify that the connection works and returns data.\nOfficial documentation: Workday REST API Guide\nAvailable Actions\nWQL Query\nInputs\nwql_query (required): The Workday Query Language (WQL) query you want to run.\nExample:\nSELECT workday_id, first_name, last_name FROM workers WHERE worker_status = 'Active'\nSELECT organization_name, organization_code FROM organizations\nSELECT position_title, worker_id FROM positions WHERE filled = true\nSELECT cost_center_name, cost_center_code FROM cost_centers\nNote: WQL is similar to SQL, but you should refer to Workday’s documentation for exact syntax.\nlimit (optional, default 100): The maximum number of results to return.\nOutputs\nquery: The WQL query that was executed.\nresults: An array of result objects, each representing a row from your query.\ntotal_results: The total number of results returned.\nExample Use Cases\nGet all active employees: SELECT workday_id, first_name, last_name, email_address FROM workers WHERE worker_status = 'Active'\nList all cost centers: SELECT cost_center_name, cost_center_code FROM cost_centers\nFind filled positions: SELECT position_title, worker_id FROM positions WHERE filled = true\nHow to use in your workflow\nAdd the Workday node.\nEnter your WQL query and (optionally) a result limit.\nConnect the output to a Template, Output, or LLM node for further processing or display.\nSummary Table\nThe WQL query to run (required)\nMax results to return (optional, default: 100)\nThe query that was executed\nTotal number of results returned\nLast updated 3 months ago","markdown":"# Workday | StackAI\n\nThe **Workday Node** connects your workflow to Workday, a popular platform for HR, finance, and planning data. This node allows you to run queries against your Workday data using Workday Query Language (WQL), which is similar to SQL but tailored for Workday’s data model.\n\n* * *\n\n#### \n\nWhat is it used for?\n\n*   **HR Data Retrieval:** Get lists of employees, their statuses, contact info, and more.\n    \n*   **Finance Data:** Query cost centers, organizations, and financial structures.\n    \n*   **Planning & Operations:** Retrieve positions, organizational hierarchies, and other planning data.\n    \n*   **Custom Reports:** Build custom queries to extract exactly the data you need from Workday\n    \n\n* * *\n\n### \n\nEstablish a Connection to Workday\n\nTo use this node, you must first establish a connection to your Workday account.\n\n#### \n\n1\\. **Obtain Workday API Credentials**\n\nTo connect to Workday, you’ll need:\n\n*   **Workday REST API Endpoint** (e.g., `https://<your-tenant>.workday.com/ccx/api/v1/`)\n    \n*   **Client ID and Client Secret** (for OAuth 2.0 authentication)\n    \n*   **Workday Username and Password** (if using basic authentication, but OAuth is recommended)\n    \n*   **API Scopes/Permissions** (ensure your integration system user has the right permissions for the data you want to access)\n    \n\n#### \n\n2\\. **Register an Integration System User (ISU) in Workday**\n\n*   In Workday, create an Integration System User (ISU) with the necessary security group assignments.\n    \n*   Assign the ISU to a security group with access to the relevant Workday APIs and data domains.\n    \n\n#### \n\n3\\. **Create an OAuth 2.0 Client (Recommended)**\n\n*   In Workday, register an OAuth 2.0 client for your integration.\n    \n*   Note the **Client ID** and **Client Secret**.\n    \n*   Set the allowed scopes (e.g., `WorkdayWebServices`, `WorkdayREST`).\n    \n\n#### \n\n4\\. **Get the API Endpoint**\n\n*   The base URL for the Workday REST API is typically:\n    \n    ```\n    https://<your-tenant>.workday.com/ccx/api/v1/\n    ```\n    \n*   Replace `<your-tenant>` with your Workday tenant name.\n    \n\n#### \n\n5\\. **Authenticate and Obtain an Access Token**\n\n*   Use the OAuth 2.0 client credentials to request an access token.\n    \n*   Example token request (using `curl`):\n    \n    ```\n    curl -X POST \\\n      -u \"<client_id>:<client_secret>\" \\\n      -d \"grant_type=client_credentials\" \\\n      \"https://<your-tenant>.workday.com/ccx/oauth2/<client_id>/token\"\n    ```\n    \n*   The response will include an `access_token` to use in API requests.\n    \n\n#### \n\n6\\. **Configure the Connection in Stack AI**\n\n*   In your Stack AI workflow, when adding a Workday action node, you’ll need to provide the connection details.\n    \n*   If Stack AI supports custom connections for Workday, you would enter:\n    \n    *   The API endpoint\n        \n    *   The OAuth 2.0 client ID and secret\n        \n    *   The access token (or the credentials to obtain one)\n        \n    \n*   If you have a connection ID for Workday, you can add it to the `action_configurations` of your Workday node:\n    \n    ```\n    \"action_configurations\": {\n      \"connection_id\": \"<your-workday-connection-id>\"\n    }\n    ```\n    \n*   (You do not currently have a Workday connection ID listed. You may need to create one in your Stack AI integrations dashboard.)\n    \n\n#### \n\n7\\. **Test the Connection**\n\n*   Use a simple WQL query (e.g., `SELECT workday_id FROM workers LIMIT 1`) to verify that the connection works and returns data.\n    \n\nOfficial documentation: [Workday REST API Guide](https://community.workday.com/sites/default/files/file-hosting/restapi/)\n\n* * *\n\n### \n\nAvailable Actions\n\n#### \n\nWQL Query\n\n**Inputs**\n\n*   **wql\\_query** (required): The Workday Query Language (WQL) query you want to run.\n    \n    *   Example:\n        \n        *   `SELECT workday_id, first_name, last_name FROM workers WHERE worker_status = 'Active'`\n            \n        *   `SELECT organization_name, organization_code FROM organizations`\n            \n        *   `SELECT position_title, worker_id FROM positions WHERE filled = true`\n            \n        *   `SELECT cost_center_name, cost_center_code FROM cost_centers`\n            \n        \n    *   Note: WQL is similar to SQL, but you should refer to Workday’s documentation for exact syntax.\n        \n    \n*   **limit** (optional, default 100): The maximum number of results to return.\n    \n\n**Outputs**\n\n*   **query**: The WQL query that was executed.\n    \n*   **results**: An array of result objects, each representing a row from your query.\n    \n*   **total\\_results**: The total number of results returned.\n    \n\n* * *\n\n#### \n\nExample Use Cases\n\n*   **Get all active employees:** `SELECT workday_id, first_name, last_name, email_address FROM workers WHERE worker_status = 'Active'`\n    \n*   **List all cost centers:** `SELECT cost_center_name, cost_center_code FROM cost_centers`\n    \n*   **Find filled positions:** `SELECT position_title, worker_id FROM positions WHERE filled = true`\n    \n\n* * *\n\n#### \n\nHow to use in your workflow\n\n1.  Add the Workday node.\n    \n2.  Enter your WQL query and (optionally) a result limit.\n    \n3.  Connect the output to a Template, Output, or LLM node for further processing or display.\n    \n\n* * *\n\n**Summary Table**\n\nThe WQL query to run (required)\n\nMax results to return (optional, default: 100)\n\nThe query that was executed\n\nTotal number of results returned\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/wolfram-alpha","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/wolfram-alpha","loadedTime":"2025-10-17T18:29:51.952Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/wolfram-alpha","title":"Wolfram Alpha | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Wolfram Alpha | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1582","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dd249cb05803-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:51 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::fd5vl-1760725791520-04f8caf15b77"}},"screenshotUrl":null,"text":"Wolfram Alpha | StackAI\nThe Wolfram Alpha Node connects your workflow to the WolframAlpha computational knowledge engine. This allows you to ask complex questions and receive answers that are computed in real time, leveraging WolframAlpha’s vast database of facts, algorithms, and computational power.\nAvailable Actions\nWolfram Alpha Query\nThis action takes a natural language query (for example, a math problem, a scientific fact, a data lookup, or a general knowledge question) and returns the computed result as a string.\nInput Parameters\nquery (required): The question or computation you want to ask WolframAlpha. Examples:\n\"What is the population of France?\"\n\"Integrate x^2 dx from 0 to 10\"\n\"Weather in New York on July 4, 2020\"\n\"Prime factors of 123456\"\nOutput\nresult: The answer or computed result from WolframAlpha, returned as a string.\nBest Use Cases\nMathematical Computation: Instantly solve equations, perform calculus, or get step-by-step solutions.\nScientific Facts: Retrieve up-to-date scientific data, constants, or conversions.\nData Lookup: Get real-time data on countries, populations, weather, finance, and more.\nGeneral Knowledge: Ask factual questions and get authoritative answers.\nWorkflow Automation: Use as a “computation engine” in your workflow to process user queries, validate answers, or enrich data.\nExample Usage\nInput: query: \"Derivative of sin(x) * e^x\"\nOutput: result: \"e^x * sin(x) + e^x * cos(x)\"\nAvailable Actions\nThe Wolfram Alpha node has a single, powerful action:\nAction Name\nAction ID\nDescription\nRuns any query against the WolframAlpha engine and returns the computed result.\nHow to Use in a Workflow\nAdd the Wolfram Alpha node.\nSet the query input (can be static or from an Input node).\nConnect the output to an Output node, LLM node, or Template node for further processing or display.\nSummary: The Wolfram Alpha node is best used for any scenario where you need authoritative, computed answers to factual, mathematical, or scientific questions. It’s a universal “ask anything” computational tool for your workflow.\nLast updated 3 months ago","markdown":"# Wolfram Alpha | StackAI\n\nThe **Wolfram Alpha Node** connects your workflow to the WolframAlpha computational knowledge engine. This allows you to ask complex questions and receive answers that are computed in real time, leveraging WolframAlpha’s vast database of facts, algorithms, and computational power.\n\n* * *\n\n### \n\nAvailable Actions\n\n#### \n\nWolfram Alpha Query\n\nThis action takes a natural language query (for example, a math problem, a scientific fact, a data lookup, or a general knowledge question) and returns the computed result as a string.\n\n* * *\n\n#### \n\nInput Parameters\n\n*   **query** (required): The question or computation you want to ask WolframAlpha. Examples:\n    \n    *   \"What is the population of France?\"\n        \n    *   \"Integrate x^2 dx from 0 to 10\"\n        \n    *   \"Weather in New York on July 4, 2020\"\n        \n    *   \"Prime factors of 123456\"\n        \n    \n\n* * *\n\n#### \n\nOutput\n\n*   **result**: The answer or computed result from WolframAlpha, returned as a string.\n    \n\n* * *\n\n#### \n\nBest Use Cases\n\n*   **Mathematical Computation:** Instantly solve equations, perform calculus, or get step-by-step solutions.\n    \n*   **Scientific Facts:** Retrieve up-to-date scientific data, constants, or conversions.\n    \n*   **Data Lookup:** Get real-time data on countries, populations, weather, finance, and more.\n    \n*   **General Knowledge:** Ask factual questions and get authoritative answers.\n    \n*   **Workflow Automation:** Use as a “computation engine” in your workflow to process user queries, validate answers, or enrich data.\n    \n\n* * *\n\n#### \n\nExample Usage\n\n*   **Input:** `query`: \"Derivative of sin(x) \\* e^x\"\n    \n*   **Output:** `result`: \"e^x \\* sin(x) + e^x \\* cos(x)\"\n    \n\n* * *\n\n#### \n\nAvailable Actions\n\nThe Wolfram Alpha node has a single, powerful action:\n\nAction Name\n\nAction ID\n\nDescription\n\nRuns any query against the WolframAlpha engine and returns the computed result.\n\n* * *\n\n#### \n\nHow to Use in a Workflow\n\n1.  Add the Wolfram Alpha node.\n    \n2.  Set the `query` input (can be static or from an Input node).\n    \n3.  Connect the output to an Output node, LLM node, or Template node for further processing or display.\n    \n\n* * *\n\n**Summary:** The Wolfram Alpha node is best used for any scenario where you need authoritative, computed answers to factual, mathematical, or scientific questions. It’s a universal “ask anything” computational tool for your workflow.\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/interactive-tutorials-1/term-extraction","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/interactive-tutorials-1/term-extraction","loadedTime":"2025-10-17T18:29:47.203Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/interactive-tutorials-1/term-extraction","title":"Term Extraction | StackAI","description":"Build a term extraction agent in Stack AI","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Term Extraction | StackAI"},{"property":"og:description","content":"Build a term extraction agent in Stack AI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":[{"@context":"http://schema.org/","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://app.arcade.software/share/bvnazk4qdRmf8H7C3uiK"},"author":{"@type":"Organization","name":"StackAI"},"publisher":{"@type":"Organization","name":"Arcade Software","logo":{"@type":"ImageObject","url":"https://cdn.arcade.software/images/button-logo-128.png"}},"headline":"Build a Tender Insights Agent","image":"https://app.arcade.software/og/bvnazk4qdRmf8H7C3uiK","datePublished":"2025-09-24T21:33:23.190Z","dateModified":"2025-09-24T21:49:47.415Z"}],"headers":{"date":"Fri, 17 Oct 2025 18:29:34 GMT","content-type":"text/html; charset=utf-8","content-encoding":"br","cf-ray":"9901dcb9ba3c8157-SEA","cf-cache-status":"DYNAMIC","age":"1773","cache-control":"public, max-age=0, must-revalidate","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","referrer-policy":"no-referrer-when-downgrade","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"pdx1::iad1::m9kcx-1760725774405-c9e70dfe5c22","server":"cloudflare","alt-svc":"h3=\":443\"; ma=86400","x-firefox-spdy":"h2"}},"screenshotUrl":"https://api.apify.com/v2/key-value-stores/3K2WBdQQFTu6EGDhJ/records/SCREENSHOT-docs-stack-ai-com-stack-ai-interactive-tutorials-1-term-extraction-3e84fbe5.jpg","text":"Term Extraction | StackAI\nBuild a Tender Insights Agent\nLearn how to design and deploy an AI agent to extract data from tender documents and generate a report in Google Docs.","markdown":"# Term Extraction | StackAI\n\n## Build a Tender Insights Agent\n\n## Learn how to design and deploy an AI agent to extract data from tender documents and generate a report in Google Docs.","debug":{"requestHandlerMode":"browser"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/zapier","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/zapier","loadedTime":"2025-10-17T18:29:55.990Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/zapier","title":"Zapier | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Zapier | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1584","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dd3c1efc0588-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:55 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::84772-1760725795272-8d70c5f4d0e4"}},"screenshotUrl":null,"text":"Zapier | StackAI\nThe Zapier Node allows you to connect with Zapier and send your outputs to thousands of apps. Zapier is a tool that allows you to connect apps you use every day to automate tasks and save time. You can connect any of Zapier's 2,000+ integrated apps together to make your own automations.\nSet up a New Connection\nTo utilize the Zapier node, you must setup webhook through the Zapier node and paste the webhook URL into Zapier.\nExample of usage\nA practical application of Zapier node involves sending summaries to the a Notion page via Zapier.\nSending summaries to Notion via Zapier\nTo construct this workflow, employ an LLM to generate the summaries from documents. Add a Zapier node to the LLM so that results can be sent to Notion.\nSystem prompt (LLM)\nYou are a helpful AI assistant. You summarize the documents attached in one page. The summary will then be sent to Notion though a Zapier node. \nPrompt (LLM)\nAnswer the following question: {in-0} Use the following information as context: {docemb-0} \nLast updated 3 months ago","markdown":"# Zapier | StackAI\n\nThe **Zapier Node** allows you to connect with Zapier and send your outputs to thousands of apps. Zapier is a tool that allows you to connect apps you use every day to automate tasks and save time. You can connect any of Zapier's 2,000+ integrated apps together to make your own automations.\n\n#### \n\nSet up a New Connection\n\nTo utilize the Zapier node, you must setup webhook through the Zapier node and paste the webhook URL into Zapier.\n\n### \n\nExample of usage\n\nA practical application of Zapier node involves sending summaries to the a Notion page via Zapier.\n\n#### \n\nSending summaries to Notion via Zapier\n\nTo construct this workflow, employ an LLM to generate the summaries from documents. Add a Zapier node to the LLM so that results can be sent to Notion.\n\n#### \n\nSystem prompt (LLM)\n\n```\nYou are a helpful AI assistant. You summarize the documents attached in one page.\nThe summary will then be sent to Notion though a Zapier node.\n```\n\n#### \n\nPrompt (LLM)\n\n```\nAnswer the following question: {in-0}\n\nUse the following information as context: {docemb-0}\n```\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/yahoo-finance","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/yahoo-finance","loadedTime":"2025-10-17T18:29:56.094Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/yahoo-finance","title":"Yahoo Finance | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Yahoo Finance | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1585","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dd3be92905dc-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:55 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::5tlv8-1760725795267-cefce7d2b46f"}},"screenshotUrl":null,"text":"Yahoo Finance | StackAI\nThe Yahoo Finance Node allows you to retrieve comprehensive financial data, news, and analytics for stocks and companies using Yahoo Finance’s public data. This is useful for building dashboards, financial analysis tools, or integrating real-time market data into your workflows.\nAvailable Actions\n1. Get Stock Ticker Data\nThis action retrieves detailed information about a specific stock ticker symbol. It provides not only the current price, but also company details, market analytics, and key financial metrics.\nInput Parameters\nsymbol (required): The stock ticker symbol you want to look up (e.g., AAPL for Apple, GOOGL for Alphabet/Google, TSLA for Tesla).\nOutput Fields\nThe output is a rich object with the following fields (all are always present, but some may be null if data is unavailable):\nsymbol: The stock ticker symbol.\nshort_name: The short name of the company.\nlong_name: The full name of the company.\naddress_first_line, city, state, zip, country, phone, website: Company contact and location details.\nindustry, industry_key: The industry and its key.\nsector, sector_key, sector_disp: The sector and its display name.\nlong_business_summary: A detailed business summary.\nfull_time_employees: Number of full-time employees.\ncurrent_price: The current trading price.\nrecommendation_key: Analyst recommendation (e.g., \"buy\", \"hold\", \"sell\").\nnumber_of_analyst_opinions: Number of analyst opinions.\ntotal_cash: Total cash on hand.\ntrailing_pe: Trailing price-to-earnings ratio.\nregular_market_change, regular_market_change_percent: Price change and percent change in the regular market session.\nmarket_cap: Market capitalization.\ndividend_yield: Dividend yield (in basis points).\nvolume: Trading volume.\nHere’s a detailed explanation of the Yahoo Finance Analytics action, in the same format as before:\n2. Analytics Action\nThis action retrieves summarized analytics for a specific stock ticker over a given date range. It provides statistical summaries (mean, min, max) for prices and trading volume, broken down by time segments within the selected period. This is useful for trend analysis, reporting, and visualizations.\nInput Parameters\nsymbol (required): The stock ticker symbol to analyze (e.g., AAPL, TSLA, GOOGL).\nstart_date (required): The start date for the analytics period (format: YYYY-MM-DD, e.g., 2020-01-01).\nend_date (required): The end date for the analytics period (format: YYYY-MM-DD, e.g., 2024-01-01).\nOutput Fields\nThe output is an array called summary_data, where each item represents a time segment (e.g., a week or month) and contains the following fields:\nsegment_start_date: Start date of the segment.\nsegment_end_date: End date of the segment.\nclosing_price_mean: Average closing price during the segment.\ntrading_volume_mean: Average trading volume during the segment.\nopening_price_mean: Average opening price during the segment.\nhigh_price_mean: Average high price during the segment.\nlow_price_mean: Average low price during the segment.\nclosing_price_max: Maximum closing price in the segment.\nclosing_price_min: Minimum closing price in the segment.\ntrading_volume_max: Maximum trading volume in the segment.\ntrading_volume_min: Minimum trading volume in the segment.\nopening_price_max: Maximum opening price in the segment.\nopening_price_min: Minimum opening price in the segment.\nhigh_price_max: Maximum high price in the segment.\nhigh_price_min: Minimum high price in the segment.\nExample Use Cases\nTrend Analysis\nAnalyze how a stock’s average closing price and volume have changed over time.\nPerformance Reporting\nGenerate weekly or monthly summaries for investor updates or dashboards.\nComparative Analytics\nCompare the volatility (min/max) and average prices of different stocks over the same period.\nVisualization\nUse the summary data to plot price and volume trends in charts.\nExample Use Cases\nStock Dashboard\nInput: AAPL\nOutput: Current price, market cap, business summary, and more for Apple Inc.\nFinancial Analysis\nUse the node to pull in data for multiple tickers and compare metrics like P/E ratio, market cap, or analyst recommendations.\nCompany Research\nRetrieve the business summary, sector, and industry for a company to include in investment reports or presentations.\nAlerting and Monitoring\nCombine with a scheduler node to check price changes or analyst recommendations at regular intervals and trigger notifications.\nAutomated Reporting\nUse the output fields to generate daily or weekly financial reports for a list of companies.\nHow to Use in a Workflow\nAdd the Yahoo Finance node.\nSet the symbol input (can be static or from an Input node).\nConnect the output to an Output node, LLM node, or Template node for further processing or display.\nExample: To get the current price of Tesla, set symbol to TSLA. To summarize the business of Microsoft, set symbol to MSFT and use {action-X.long_business_summary} in a downstream node.\nSummary Table\nStock ticker symbol (e.g., AAPL)\nAnalyst recommendation (buy/hold/sell)\nLast updated 3 months ago","markdown":"# Yahoo Finance | StackAI\n\nThe **Yahoo Finance Node** allows you to retrieve comprehensive financial data, news, and analytics for stocks and companies using Yahoo Finance’s public data. This is useful for building dashboards, financial analysis tools, or integrating real-time market data into your workflows.\n\n* * *\n\n### \n\nAvailable Actions\n\n#### \n\n1\\. Get Stock Ticker Data\n\nThis action retrieves detailed information about a specific stock ticker symbol. It provides not only the current price, but also company details, market analytics, and key financial metrics.\n\n#### \n\nInput Parameters\n\n*   **symbol** (required): The stock ticker symbol you want to look up (e.g., `AAPL` for Apple, `GOOGL` for Alphabet/Google, `TSLA` for Tesla).\n    \n\n#### \n\nOutput Fields\n\nThe output is a rich object with the following fields (all are always present, but some may be null if data is unavailable):\n\n*   **symbol**: The stock ticker symbol.\n    \n*   **short\\_name**: The short name of the company.\n    \n*   **long\\_name**: The full name of the company.\n    \n*   **address\\_first\\_line, city, state, zip, country, phone, website**: Company contact and location details.\n    \n*   **industry, industry\\_key**: The industry and its key.\n    \n*   **sector, sector\\_key, sector\\_disp**: The sector and its display name.\n    \n*   **long\\_business\\_summary**: A detailed business summary.\n    \n*   **full\\_time\\_employees**: Number of full-time employees.\n    \n*   **current\\_price**: The current trading price.\n    \n*   **recommendation\\_key**: Analyst recommendation (e.g., \"buy\", \"hold\", \"sell\").\n    \n*   **number\\_of\\_analyst\\_opinions**: Number of analyst opinions.\n    \n*   **total\\_cash**: Total cash on hand.\n    \n*   **trailing\\_pe**: Trailing price-to-earnings ratio.\n    \n*   **regular\\_market\\_change, regular\\_market\\_change\\_percent**: Price change and percent change in the regular market session.\n    \n*   **market\\_cap**: Market capitalization.\n    \n*   **dividend\\_yield**: Dividend yield (in basis points).\n    \n*   **volume**: Trading volume.\n    \n\nHere’s a detailed explanation of the Yahoo Finance Analytics action, in the same format as before:\n\n* * *\n\n#### \n\n2\\. Analytics Action\n\nThis action retrieves summarized analytics for a specific stock ticker over a given date range. It provides statistical summaries (mean, min, max) for prices and trading volume, broken down by time segments within the selected period. This is useful for trend analysis, reporting, and visualizations.\n\n* * *\n\n#### \n\nInput Parameters\n\n*   **symbol** (required): The stock ticker symbol to analyze (e.g., `AAPL`, `TSLA`, `GOOGL`).\n    \n*   **start\\_date** (required): The start date for the analytics period (format: `YYYY-MM-DD`, e.g., `2020-01-01`).\n    \n*   **end\\_date** (required): The end date for the analytics period (format: `YYYY-MM-DD`, e.g., `2024-01-01`).\n    \n\n* * *\n\n#### \n\nOutput Fields\n\nThe output is an array called `summary_data`, where each item represents a time segment (e.g., a week or month) and contains the following fields:\n\n*   **segment\\_start\\_date**: Start date of the segment.\n    \n*   **segment\\_end\\_date**: End date of the segment.\n    \n*   **closing\\_price\\_mean**: Average closing price during the segment.\n    \n*   **trading\\_volume\\_mean**: Average trading volume during the segment.\n    \n*   **opening\\_price\\_mean**: Average opening price during the segment.\n    \n*   **high\\_price\\_mean**: Average high price during the segment.\n    \n*   **low\\_price\\_mean**: Average low price during the segment.\n    \n*   **closing\\_price\\_max**: Maximum closing price in the segment.\n    \n*   **closing\\_price\\_min**: Minimum closing price in the segment.\n    \n*   **trading\\_volume\\_max**: Maximum trading volume in the segment.\n    \n*   **trading\\_volume\\_min**: Minimum trading volume in the segment.\n    \n*   **opening\\_price\\_max**: Maximum opening price in the segment.\n    \n*   **opening\\_price\\_min**: Minimum opening price in the segment.\n    \n*   **high\\_price\\_max**: Maximum high price in the segment.\n    \n*   **high\\_price\\_min**: Minimum high price in the segment.\n    \n\n* * *\n\n#### \n\nExample Use Cases\n\n1.  **Trend Analysis**\n    \n    *   Analyze how a stock’s average closing price and volume have changed over time.\n        \n    \n2.  **Performance Reporting**\n    \n    *   Generate weekly or monthly summaries for investor updates or dashboards.\n        \n    \n3.  **Comparative Analytics**\n    \n    *   Compare the volatility (min/max) and average prices of different stocks over the same period.\n        \n    \n4.  **Visualization**\n    \n    *   Use the summary data to plot price and volume trends in charts.\n        \n    \n\n* * *\n\n### \n\nExample Use Cases\n\n1.  **Stock Dashboard**\n    \n    *   Input: `AAPL`\n        \n    *   Output: Current price, market cap, business summary, and more for Apple Inc.\n        \n    \n2.  **Financial Analysis**\n    \n    *   Use the node to pull in data for multiple tickers and compare metrics like P/E ratio, market cap, or analyst recommendations.\n        \n    \n3.  **Company Research**\n    \n    *   Retrieve the business summary, sector, and industry for a company to include in investment reports or presentations.\n        \n    \n4.  **Alerting and Monitoring**\n    \n    *   Combine with a scheduler node to check price changes or analyst recommendations at regular intervals and trigger notifications.\n        \n    \n5.  **Automated Reporting**\n    \n    *   Use the output fields to generate daily or weekly financial reports for a list of companies.\n        \n    \n\n* * *\n\n### \n\nHow to Use in a Workflow\n\n*   Add the Yahoo Finance node.\n    \n*   Set the `symbol` input (can be static or from an Input node).\n    \n*   Connect the output to an Output node, LLM node, or Template node for further processing or display.\n    \n\n**Example:** To get the current price of Tesla, set `symbol` to `TSLA`. To summarize the business of Microsoft, set `symbol` to `MSFT` and use `{action-X.long_business_summary}` in a downstream node.\n\n* * *\n\n### \n\nSummary Table\n\nStock ticker symbol (e.g., AAPL)\n\nAnalyst recommendation (buy/hold/sell)\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/youtube","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/youtube","loadedTime":"2025-10-17T18:29:56.200Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/youtube","title":"Youtube | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Youtube | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1585","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dd3c8c31d648-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:29:55 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::dzh4w-1760725795321-fe7cf436e73d"}},"screenshotUrl":null,"text":"Youtube | StackAI\nThe YouTube Node allows you to extract the transcript (captions) from a YouTube video, which is useful for summarization, analysis, or further AI processing.\nAvailable Actions\nExtract YouTube Transcript\nThis action retrieves the transcript (captions) from a specified YouTube video in your chosen language. It returns both a structured array of transcript segments and a plain text version.\nInput Parameters\nvideo_url_or_id (required): The YouTube video URL (e.g., https://www.youtube.com/watch?v=dQw4w9WgXcQ) or just the video ID (e.g., dQw4w9WgXcQ).\nlanguage (required): The language code for the transcript you want to extract (ISO 639-1 format, e.g., en for English, es for Spanish, etc.).\nSupported languages include: en, es, de, fr, it, pt, ru, ja, zh, ar, hi, bn, ur, ko, nl, sv, no, da, fi, pl, el, tr, cs, hu, th, vi.\nOutput\nstatus: Indicates if the extraction was successful (\"success\") or failed (\"error\").\nmessage: A human-readable message about the result.\ntranscript: An array of transcript segments (each with text, start time, and duration).\ntranscript_text: The full transcript as a single plain text string.\nvideo_id: The YouTube video ID.\nvideo_url: The YouTube video URL.\nExample Usage\nSuppose you want to extract the English transcript from a YouTube video:\nvideo_url_or_id: https://www.youtube.com/watch?v=dQw4w9WgXcQ\nlanguage: en\nThe node will return:\nThe transcript as an array (with timing and text for each segment).\nThe full transcript as plain text.\nStatus and message fields for error handling.\nHow to Connect and Use in a Workflow\nAdd the YouTube node to your workflow.\nSet the required inputs (video URL/ID and language).\nConnect the output to downstream nodes (e.g., an LLM node for summarization, or an Output node to display the transcript).\nExample node reference in a prompt: If your YouTube node is action-0, you can reference the plain text transcript as {action-0.transcript_text} in downstream nodes to get the full text from the video.\nSummary Table\nYouTube video URL or ID (required)\nTranscript language code (required)\nArray of transcript segments\nFull transcript as plain text\nHuman-readable result message\nTip: If you want to process or summarize the transcript, connect the YouTube node’s output to an LLM node and reference it in your prompt.\nLast updated 3 months ago","markdown":"# Youtube | StackAI\n\nThe **YouTube Node** allows you to extract the transcript (captions) from a YouTube video, which is useful for summarization, analysis, or further AI processing.\n\n* * *\n\n### \n\nAvailable Actions\n\n#### \n\nExtract YouTube Transcript\n\nThis action retrieves the transcript (captions) from a specified YouTube video in your chosen language. It returns both a structured array of transcript segments and a plain text version.\n\n#### \n\nInput Parameters\n\n*   **video\\_url\\_or\\_id** (required): The YouTube video URL (e.g., `https://www.youtube.com/watch?v=dQw4w9WgXcQ`) or just the video ID (e.g., `dQw4w9WgXcQ`).\n    \n*   **language** (required): The language code for the transcript you want to extract (ISO 639-1 format, e.g., `en` for English, `es` for Spanish, etc.).\n    \n\nSupported languages include: en, es, de, fr, it, pt, ru, ja, zh, ar, hi, bn, ur, ko, nl, sv, no, da, fi, pl, el, tr, cs, hu, th, vi.\n\n#### \n\nOutput\n\n*   **status**: Indicates if the extraction was successful (\"success\") or failed (\"error\").\n    \n*   **message**: A human-readable message about the result.\n    \n*   **transcript**: An array of transcript segments (each with text, start time, and duration).\n    \n*   **transcript\\_text**: The full transcript as a single plain text string.\n    \n*   **video\\_id**: The YouTube video ID.\n    \n*   **video\\_url**: The YouTube video URL.\n    \n\n* * *\n\n### \n\nExample Usage\n\nSuppose you want to extract the English transcript from a YouTube video:\n\n*   **video\\_url\\_or\\_id**: `https://www.youtube.com/watch?v=dQw4w9WgXcQ`\n    \n*   **language**: `en`\n    \n\nThe node will return:\n\n*   The transcript as an array (with timing and text for each segment).\n    \n*   The full transcript as plain text.\n    \n*   Status and message fields for error handling.\n    \n\n* * *\n\n### \n\nHow to Connect and Use in a Workflow\n\n1.  **Add the YouTube node to your workflow.**\n    \n2.  **Set the required inputs** (video URL/ID and language).\n    \n3.  **Connect the output** to downstream nodes (e.g., an LLM node for summarization, or an Output node to display the transcript).\n    \n\n**Example node reference in a prompt:** If your YouTube node is `action-0`, you can reference the plain text transcript as `{action-0.transcript_text}` in downstream nodes to get the full text from the video.\n\n* * *\n\n### \n\nSummary Table\n\nYouTube video URL or ID (required)\n\nTranscript language code (required)\n\nArray of transcript segments\n\nFull transcript as plain text\n\nHuman-readable result message\n\n* * *\n\n**Tip:** If you want to process or summarize the transcript, connect the YouTube node’s output to an LLM node and reference it in your prompt.\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/typeform","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/typeform","loadedTime":"2025-10-17T18:29:49.538Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/typeform","title":"Typeform | StackAI","description":"Comprehensive guide to Typeform integration in StackAI, including available actions, input and output details, and practical usage examples.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Typeform | StackAI"},{"property":"og:description","content":"Comprehensive guide to Typeform integration in StackAI, including available actions, input and output details, and practical usage examples."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"date":"Fri, 17 Oct 2025 18:29:47 GMT","content-type":"text/html; charset=utf-8","content-encoding":"br","cf-ray":"9901dd09abd58157-SEA","cf-cache-status":"DYNAMIC","age":"1579","cache-control":"public, max-age=0, must-revalidate","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","referrer-policy":"no-referrer-when-downgrade","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"pdx1::iad1::bdlpl-1760725787173-f75ad34a9eee","server":"cloudflare","alt-svc":"h3=\":443\"; ma=86400","x-firefox-spdy":"h2"}},"screenshotUrl":"https://api.apify.com/v2/key-value-stores/3K2WBdQQFTu6EGDhJ/records/SCREENSHOT-docs-stack-ai-com-stack-ai-workflow-builder-apps-typeform-9483a3db.jpg","text":"Typeform | StackAI\nComprehensive guide to Typeform integration in StackAI, including available actions, input and output details, and practical usage examples.\nWhat is Typeform?\nTypeform is an online platform that allows you to create interactive forms, surveys, and quizzes. Integrating Typeform with StackAI enables you to automate workflows, collect responses, and manage form data seamlessly within your AI-powered processes.\nHow to use it?\nTo use Typeform in StackAI, connect your Typeform account using a valid connection ID. Once connected, you can trigger actions such as retrieving forms, collecting responses, or managing form data. Each action requires specific inputs and configurations, which you provide in the workflow builder.\nEstablishing A Connection\nClick “New Connection” and enter a name to identify it later.\nYou’ll be redirected to the Typeform login page.\nLog in to your Typeform account.\nAccept the required permissions. You’ll be redirected back to StackAI.\nIn the dropdown, select your newly created connection.\nClick “Test” to verify that the connection is healthy.\nAction Summary Table\nAction Name\nDescription\nInput\nretrieve_account_workspaces\nRetrieve all workspaces in your Typeform account\nAccount Id, Search, Page, Page Size\nRetrieve all forms in your Typeform account\nSearch, Page, Page Size, Workspace Id\nRetrieve a single form's details\nUpdate a form (partial update)\nUpdate a form (full update)\nretrieve_custom_form_messages\nRetrieve custom messages for a form\nUpdate custom messages for a form\nDelete responses from a form\nForm Id, Included Response Ids\nRetrieve responses for a form\nForm Id, Page Size, Since, Until, After, Before, Included Response Ids, Excluded Response Ids, Completed, Sort, Query, Fields, Answered Fields\nDownload all responses for a form as a file\nForm Id, Response Id, Field Id, Filename, Inline\nRetrieve all webhooks for a form\nDelete a webhook from a form\nRetrieve a single webhook's details\nretrieve_images_collection\nRetrieve all images in your Typeform account\nDelete an image from your Typeform account\nRetrieve a single image's details\nretrieve_background_by_size\nRetrieve a background image by size\nretrieve_choice_image_by_size\nRetrieve a choice image by size\nRetrieve an image by size\nRetrieve insights for a form\nRetrieve your own user details\nDelete responses for right to be forgotten (GDPR)\nRetrieve all themes in your Typeform account\nDelete a theme from your Typeform account\nRetrieve a single theme's details\nRetrieve a single workspace's details\nOutput\nStatus Code (integer)\nThis is the HTTP status code returned by the Typeform API after attempting to delete the form.\nCommon values:\n200: Success (form deleted)\n204: Success (no content, form deleted)\n404: Not found (form does not exist)\n401/403: Unauthorized/Forbidden (invalid credentials or permissions)\n500: Internal server error\nHeaders (dict)\nThis is a dictionary containing the HTTP response headers from the Typeform API.\nHeaders may include metadata such as:\nContent-Type: The format of the response (e.g., application/json)\nDate: The time the response was sent\nRate limit information: How many API calls you have left, etc.\nBody (object)\nThis is the main content of the response, usually in JSON format.\nFor a successful delete, the body may be empty or contain a confirmation message.\nFor errors, the body will typically include details such as:\nerror: A short error code or message\ndescription: A human-readable explanation of the error\nAdvanced Settings\nRetry on Failure: Enable retrying when the node execution fails\nFallback Branch: Create a separate branch that executes when this node fails, allowing you to handle errors gracefullyCreate a separate branch that executes when this node fails, allowing you to handle errors gracefully\nLast updated 2 months ago","markdown":"# Typeform | StackAI\n\nComprehensive guide to Typeform integration in StackAI, including available actions, input and output details, and practical usage examples.\n\n**What is Typeform?**\n\nTypeform is an online platform that allows you to create interactive forms, surveys, and quizzes. Integrating Typeform with StackAI enables you to automate workflows, collect responses, and manage form data seamlessly within your AI-powered processes.\n\n**How to use it?**\n\nTo use Typeform in StackAI, connect your Typeform account using a valid connection ID. Once connected, you can trigger actions such as retrieving forms, collecting responses, or managing form data. Each action requires specific inputs and configurations, which you provide in the workflow builder.\n\n**Establishing A Connection**\n\n1.  Click **“New Connection”** and enter a name to identify it later.\n    \n2.  You’ll be redirected to the Typeform login page.\n    \n3.  Log in to your Typeform account.\n    \n4.  Accept the required permissions. You’ll be redirected back to StackAI.\n    \n5.  In the dropdown, select your newly created connection.\n    \n6.  Click **“Test”** to verify that the connection is healthy.\n    \n\n**Action Summary Table**\n\nAction Name\n\nDescription\n\nInput\n\nretrieve\\_account\\_workspaces\n\nRetrieve all workspaces in your Typeform account\n\nAccount Id, Search, Page, Page Size\n\nRetrieve all forms in your Typeform account\n\nSearch, Page, Page Size, Workspace Id\n\nRetrieve a single form's details\n\nUpdate a form (partial update)\n\nUpdate a form (full update)\n\nretrieve\\_custom\\_form\\_messages\n\nRetrieve custom messages for a form\n\nUpdate custom messages for a form\n\nDelete responses from a form\n\nForm Id, Included Response Ids\n\nRetrieve responses for a form\n\nForm Id, Page Size, Since, Until, After, Before, Included Response Ids, Excluded Response Ids, Completed, Sort, Query, Fields, Answered Fields\n\nDownload all responses for a form as a file\n\nForm Id, Response Id, Field Id, Filename, Inline\n\nRetrieve all webhooks for a form\n\nDelete a webhook from a form\n\nRetrieve a single webhook's details\n\nretrieve\\_images\\_collection\n\nRetrieve all images in your Typeform account\n\nDelete an image from your Typeform account\n\nRetrieve a single image's details\n\nretrieve\\_background\\_by\\_size\n\nRetrieve a background image by size\n\nretrieve\\_choice\\_image\\_by\\_size\n\nRetrieve a choice image by size\n\nRetrieve an image by size\n\nRetrieve insights for a form\n\nRetrieve your own user details\n\nDelete responses for right to be forgotten (GDPR)\n\nRetrieve all themes in your Typeform account\n\nDelete a theme from your Typeform account\n\nRetrieve a single theme's details\n\nRetrieve a single workspace's details\n\n**Output**\n\n1.  Status Code (integer)\n    \n    *   This is the HTTP status code returned by the Typeform API after attempting to delete the form.\n        \n    *   Common values:\n        \n        *   200: Success (form deleted)\n            \n        *   204: Success (no content, form deleted)\n            \n        *   404: Not found (form does not exist)\n            \n        *   401/403: Unauthorized/Forbidden (invalid credentials or permissions)\n            \n        *   500: Internal server error\n            \n        \n    \n2.  Headers (dict)\n    \n    *   This is a dictionary containing the HTTP response headers from the Typeform API.\n        \n    *   Headers may include metadata such as:\n        \n        *   Content-Type: The format of the response (e.g., application/json)\n            \n        *   Date: The time the response was sent\n            \n        *   Rate limit information: How many API calls you have left, etc.\n            \n        \n    \n3.  Body (object)\n    \n    *   This is the main content of the response, usually in JSON format.\n        \n    *   For a successful delete, the body may be empty or contain a confirmation message.\n        \n    *   For errors, the body will typically include details such as:\n        \n        *   error: A short error code or message\n            \n        *   description: A human-readable explanation of the error\n            \n        \n    \n\n**Advanced Settings**\n\n*   Retry on Failure: Enable retrying when the node execution fails\n    \n*   Fallback Branch: Create a separate branch that executes when this node fails, allowing you to handle errors gracefullyCreate a separate branch that executes when this node fails, allowing you to handle errors gracefully\n    \n\nLast updated 2 months ago","debug":{"requestHandlerMode":"browser"}}
{"url":"https://docs.stack-ai.com/stack-ai/logic/if-else-node","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/logic/if-else-node","loadedTime":"2025-10-17T18:30:00.409Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/logic/if-else-node","title":"If/Else Node | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"If/Else Node | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1137","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dd5b29c2ff28-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:00 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::pzmgd-1760725800214-ffe2aa1c4d2d"}},"screenshotUrl":null,"text":"If/Else Node | StackAI\nThe If/Else Node is a logic node that lets you route the flow of your workflow based on conditions. It checks the output of a previous node (or nodes) and, depending on whether the condition is true or false, sends the data down different branches.\nHow It Works in Your Workflow\nCondition Setup\nIn your workflow, the If/Else node always takes an input from the left side. The input allows you to define the conditions. Each condition is then routed to its corresponding output according to the branching logic defined.\nThe available condition operators you can use in the If/Else node are:\nequals: Checks if the left variable is exactly equal to the right variable.\nnot equals: Checks if the left variable is not equal to the right variable.\ncontains: Checks if the left variable (usually a string or list) contains the right variable.\nnot contains: Checks if the left variable does not contain the right variable.\ngreater than: Checks if the left variable is greater than the right variable (for numbers).\ngreater than or equal: Checks if the left variable is greater than or equal to the right variable.\nless than: Checks if the left variable is less than the right variable.\nless than or equal: Checks if the left variable is less than or equal to the right variable.\nis empty: Checks if the left variable is empty (no value, empty string, or empty list).\nis not empty: Checks if the left variable is not empty.\nYou can combine multiple conditions using logical operators like and or or to create more complex branching logic.\nExample usage:\n{llm-0} contains \"DONE\" \n{in-0} equals \"yes\"\n{llm-1} is not empty\nAdding Branches\nAdd another branch by choosing \"+ Add IF/ELSE Branch\"\nTypical Use Cases\nQuality control: Only output results that meet a certain criteria.\nMulti-step reasoning: If the first LLM’s answer isn’t “final,” send it to another LLM for more processing.\nDynamic routing: Route user queries to different tools or models based on their content.\nKey Points\nThe If/Else node does not process or change the data itself; it only checks the condition and routes the data.\nYou can set up multiple conditions and even use \"elif\" branches for more complex logic.\nThe left and right variables can reference any previous node’s output.\nLast updated 2 months ago","markdown":"# If/Else Node | StackAI\n\nThe **If/Else Node** is a logic node that lets you route the flow of your workflow based on conditions. It checks the output of a previous node (or nodes) and, depending on whether the condition is true or false, sends the data down different branches.\n\n* * *\n\n### \n\nHow It Works in Your Workflow\n\n#### \n\n**Condition Setup**\n\nIn your workflow, the If/Else node always takes an input from the left side. The input allows you to define the conditions. Each condition is then routed to its corresponding output according to the branching logic defined.\n\n#### \n\nThe available condition operators you can use in the If/Else node are:\n\n*   **equals**: Checks if the left variable is exactly equal to the right variable.\n    \n*   **not equals**: Checks if the left variable is not equal to the right variable.\n    \n*   **contains**: Checks if the left variable (usually a string or list) contains the right variable.\n    \n*   **not contains**: Checks if the left variable does not contain the right variable.\n    \n*   **greater than**: Checks if the left variable is greater than the right variable (for numbers).\n    \n*   **greater than or equal**: Checks if the left variable is greater than or equal to the right variable.\n    \n*   **less than**: Checks if the left variable is less than the right variable.\n    \n*   **less than or equal**: Checks if the left variable is less than or equal to the right variable.\n    \n*   **is empty**: Checks if the left variable is empty (no value, empty string, or empty list).\n    \n*   **is not empty**: Checks if the left variable is not empty.\n    \n\nYou can combine multiple conditions using logical operators like **and** or **or** to create more complex branching logic.\n\n**Example usage:**\n\n*   `{llm-0} contains \"DONE\"`\n    \n*   `{in-0} equals \"yes\"`\n    \n*   `{llm-1} is not empty`\n    \n\n* * *\n\n### \n\nAdding Branches\n\nAdd another branch by choosing \"+ Add IF/ELSE Branch\"\n\n* * *\n\n### \n\n**Typical Use Cases**\n\n*   **Quality control:** Only output results that meet a certain criteria.\n    \n*   **Multi-step reasoning:** If the first LLM’s answer isn’t “final,” send it to another LLM for more processing.\n    \n*   **Dynamic routing:** Route user queries to different tools or models based on their content.\n    \n\n* * *\n\n### \n\n**Key Points**\n\n*   The If/Else node does not process or change the data itself; it only checks the condition and routes the data.\n    \n*   You can set up multiple conditions and even use \"elif\" branches for more complex logic.\n    \n*   The left and right variables can reference any previous node’s output.\n    \n\nLast updated 2 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/logic","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/logic","loadedTime":"2025-10-17T18:30:00.338Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/logic","title":"Logic | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Logic | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1798","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dd5aecbdd62c-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:00 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::8zlms-1760725800182-80a1d402df7d"}},"screenshotUrl":null,"text":"Logic | StackAI\nAI RoutingPython CodeIf/Else Node\nPreviousZendeskNextAI Routing\nWas this helpful?","markdown":"# Logic | StackAI\n\n[AI Routing](https://docs.stack-ai.com/stack-ai/logic/ai-routing)[Python Code](https://docs.stack-ai.com/stack-ai/logic/python-code)[If/Else Node](https://docs.stack-ai.com/stack-ai/logic/if-else-node)\n\n[PreviousZendesk](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/zendesk)[NextAI Routing](https://docs.stack-ai.com/stack-ai/logic/ai-routing)\n\nWas this helpful?","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/utils","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/utils","loadedTime":"2025-10-17T18:30:00.552Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/utils","title":"Utils | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Utils | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1797","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dd5be9041853-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:00 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::fvtkp-1760725800329-545081952aec"}},"screenshotUrl":null,"text":"Utils | StackAI\nCustom APIStackAI ProjectSticky NoteDefault MessageDelayShared MemoryDynamic Vector Store\nPreviousIf/Else NodeNextCustom API\nWas this helpful?","markdown":"# Utils | StackAI\n\n[Custom API](https://docs.stack-ai.com/stack-ai/utils/custom-api)[StackAI Project](https://docs.stack-ai.com/stack-ai/utils/stackai-project)[Sticky Note](https://docs.stack-ai.com/stack-ai/utils/sticky-note)[Default Message](https://docs.stack-ai.com/stack-ai/utils/default-message)[Delay](https://docs.stack-ai.com/stack-ai/utils/delay)[Shared Memory](https://docs.stack-ai.com/stack-ai/utils/shared-memory)[Dynamic Vector Store](https://docs.stack-ai.com/stack-ai/utils/dynamic-vector-store)\n\n[PreviousIf/Else Node](https://docs.stack-ai.com/stack-ai/logic/if-else-node)[NextCustom API](https://docs.stack-ai.com/stack-ai/utils/custom-api)\n\nWas this helpful?","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/zendesk","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/zendesk","loadedTime":"2025-10-17T18:30:00.605Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/zendesk","title":"Zendesk | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Zendesk | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1590","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dd5af995bacc-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:00 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::6rffr-1760725800216-ea47ef5b8199"}},"screenshotUrl":null,"text":"Zendesk | StackAI\nZendesk is a customer service platform designed to create better customer relationships, it provides businesses with a suite of tools that allow them to offer support, communicate with customers, and manage customer interactions efficiently.\nThe Zendesk Node enables seamless integration with your Zendesk account, specifically for automating the creation of tickets.\nA common use-case is using this node to hand off the customer support to a real human over at Zendesk.\nConfiguration\nThe Zendesk node requires you to set up the following:\nUser Email (Input) : the recepient of the email.\nSubject (Input) : the subject of the email.\nContents (Input) : the contents of the email.\nZendesk Domain (Config) : the Zendesk domain of the sender.\nZendesk Email (Config) : the sender of the email.\nZendesk API Key (Config) : the API key of the sender's Zendesk account.\nThe output is the created ticket's URL in Zendesk (e.g. https:// your_domain.zendesk.com/tickets/28)\nExample of usage\nIn this example, we built a workflow that demonstrates the node's usage.\nTo play around with it, go to the \"Support with Zendesk\" pre-built template.\nRetrieval of API\nTo get the API that will allow you to set up a Zendesk connection, you will access the following URL. (Zendesk API Settings)\nhttps://<your_domain>.zendesk.com/admin/apps-integrations/apis/zendesk-api/settings\nEnable the \"Token Access\" by clicking on the toggle.\nClick on \"Add API Token\".\nCopy-paste the value in the node's parameter field\nLast updated 3 months ago","markdown":"# Zendesk | StackAI\n\nZendesk is a customer service platform designed to create better customer relationships, it provides businesses with a suite of tools that allow them to offer support, communicate with customers, and manage customer interactions efficiently.\n\nThe **Zendesk Node** enables seamless integration with your Zendesk account, specifically for automating the creation of tickets.\n\nA common use-case is using this node to hand off the customer support to a real human over at Zendesk.\n\n### \n\nConfiguration\n\nThe Zendesk node requires you to set up the following:\n\n*   **User Email (Input)** : the recepient of the email.\n    \n*   **Subject (Input)** : the subject of the email.\n    \n*   **Contents (Input)** : the contents of the email.\n    \n*   **Zendesk Domain (Config)** : the Zendesk domain of the sender.\n    \n*   **Zendesk Email (Config)** : the sender of the email.\n    \n*   **Zendesk API Key (Config)** : the API key of the sender's Zendesk account.\n    \n\nThe output is the created ticket's URL in Zendesk (e.g. https:// your\\_domain.zendesk.com/tickets/28)\n\n### \n\nExample of usage\n\nIn this example, we built a workflow that demonstrates the node's usage.\n\nTo play around with it, go to the \"Support with Zendesk\" pre-built template.\n\n### \n\nRetrieval of API\n\nTo get the API that will allow you to set up a Zendesk connection, you will access the following URL. (Zendesk API Settings)\n\n```\nhttps://<your_domain>.zendesk.com/admin/apps-integrations/apis/zendesk-api/settings\n```\n\n1.  Enable the \"Token Access\" by clicking on the toggle.\n    \n2.  Click on \"Add API Token\".\n    \n3.  Copy-paste the value in the node's parameter field\n    \n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/logic/ai-routing","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/logic/ai-routing","loadedTime":"2025-10-17T18:30:00.686Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/logic/ai-routing","title":"AI Routing | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"AI Routing | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"0","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dd5afbc6396d-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:00 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"iad1::iad1::dczhl-1760725800190-54fb2b155e6c"}},"screenshotUrl":null,"text":"AI Routing | StackAI\nThe AI Routing Node in Stack AI is a powerful node designed to intelligently classify, categorize, and direct user input within your AI workflow. By leveraging advanced intent detection and categorization, the Routing node enables dynamic branching, ensuring that each user query is handled by the most relevant downstream process or AI model.\nHere we see an AI router that routes the user's input to do deep research using GPT-o3 if the user's query is asking for important insights, otherwise, the input is routed to a lightweight model (GPT-4o).\nKey Features of the Routing Node\nIntent Classification: Automatically detects the intent or topic of user input, such as general questions or company-specific inquiries.\nDynamic Workflow Branching: Routes input to different workflow branches based on detected categories, enabling personalized and context-aware responses.\nSeamless Integration: Easily connects with LLMs, knowledge bases, and other nodes for advanced AI automation.\nCustomizable Categories: Supports multiple, user-defined categories for granular control over workflow logic.\nDynamic Input: set the input query of the so that it’s easier to work with multiple inputs being passed to it\nHow the Routing Node Works\nInput Reception: The Routing node receives user input, typically from an Input node.\nIntent Detection: Using AI-powered classification (e.g., Azure AI), the node analyzes the input and assigns one or more categories. Example categories:\n[Default] User asks a general question.\nUser asks a question related to the company.\nBranching Logic: Based on the assigned categories, the workflow can trigger different downstream nodes, such as specialized LLMs or knowledge base searches.\nWorkflow Integration: The Routing node is typically placed after the Input node and before nodes like LLMs or knowledge bases, acting as a decision point in the workflow.\nExample Use Case\nSuppose you want your AI assistant to handle both general and company-specific questions differently:\nGeneral questions are routed to a general-purpose LLM.\nCompany-related questions are routed to a knowledge base search for more accurate, context-specific answers.\nThe Routing node makes this possible by categorizing each user query and directing it to the appropriate branch.\nBest Practices for Using the Routing Node\nDefine Clear Categories: Ensure your categories are distinct and cover all expected user intents.\nAlways Include a Default Category: This ensures that ambiguous or unexpected inputs are still handled gracefully (e.g., the user asks about other topics).\nTest with Real User Inputs: Validate that the Routing node assigns categories as expected for a variety of queries.\nConnect to Multiple Branches: Use the Routing node to trigger different LLMs, knowledge bases, or actions based on detected intent.\nInclude Downstream Inputs: Make sure all downstream inputs go through the AI Routing Node\nBenefits of the Routing Node in Stack AI\nProvides greater flexibility than a standard if-else node, as it excels at identifying user intent rather than just specific words. It's akin to having a Large Language Model (LLM) manage your workflow, determining the best routing for user queries.\nFrequently Asked Questions\nQ: Can I customize the categories in the Routing node? A: Yes! You can define as many categories as needed to match your workflow requirements.\nQ: What AI models does the Routing node use for classification? A: The Routing node uses an Azure OpenAI for intent detection and classification.\nQ: How do I connect the Routing node to other nodes? A: Simply draw edges from the Routing node to downstream nodes corresponding to each category in your workflow editor.\nConclusion\nThe Routing node is essential for building intelligent, context-aware, and scalable AI workflows in Stack AI. By classifying and directing user input, it ensures that every query is handled by the most appropriate process, enhancing both automation and user satisfaction.\nLast updated 2 months ago","markdown":"# AI Routing | StackAI\n\nThe **AI Routing Node** in Stack AI is a powerful node designed to intelligently classify, categorize, and direct user input within your AI workflow. By leveraging advanced intent detection and categorization, the Routing node enables dynamic branching, ensuring that each user query is handled by the most relevant downstream process or AI model.\n\nHere we see an AI router that routes the user's input to do deep research using GPT-o3 if the user's query is asking for important insights, otherwise, the input is routed to a lightweight model (GPT-4o).\n\n* * *\n\n### \n\nKey Features of the Routing Node\n\n*   **Intent Classification:** Automatically detects the intent or topic of user input, such as general questions or company-specific inquiries.\n    \n*   **Dynamic Workflow Branching:** Routes input to different workflow branches based on detected categories, enabling personalized and context-aware responses.\n    \n*   **Seamless Integration:** Easily connects with LLMs, knowledge bases, and other nodes for advanced AI automation.\n    \n*   **Customizable Categories:** Supports multiple, user-defined categories for granular control over workflow logic.\n    \n*   **Dynamic Input:** set the input query of the so that it’s easier to work with multiple inputs being passed to it\n    \n\n* * *\n\n### \n\nHow the Routing Node Works\n\n1.  **Input Reception:** The Routing node receives user input, typically from an Input node.\n    \n2.  **Intent Detection:** Using AI-powered classification (e.g., Azure AI), the node analyzes the input and assigns one or more categories. _Example categories:_\n    \n    *   `[Default] User asks a general question.`\n        \n    *   `User asks a question related to the company.`\n        \n    \n3.  **Branching Logic:** Based on the assigned categories, the workflow can trigger different downstream nodes, such as specialized LLMs or knowledge base searches.\n    \n4.  **Workflow Integration:** The Routing node is typically placed after the Input node and before nodes like LLMs or knowledge bases, acting as a decision point in the workflow.\n    \n\n* * *\n\n### \n\nExample Use Case\n\nSuppose you want your AI assistant to handle both general and company-specific questions differently:\n\n*   **General questions** are routed to a general-purpose LLM.\n    \n*   **Company-related questions** are routed to a knowledge base search for more accurate, context-specific answers.\n    \n\nThe Routing node makes this possible by categorizing each user query and directing it to the appropriate branch.\n\n* * *\n\n### \n\nBest Practices for Using the Routing Node\n\n*   **Define Clear Categories:** Ensure your categories are distinct and cover all expected user intents.\n    \n*   **Always Include a Default Category:** This ensures that ambiguous or unexpected inputs are still handled gracefully (e.g., the user asks about other topics).\n    \n*   **Test with Real User Inputs:** Validate that the Routing node assigns categories as expected for a variety of queries.\n    \n*   **Connect to Multiple Branches:** Use the Routing node to trigger different LLMs, knowledge bases, or actions based on detected intent.\n    \n*   **Include Downstream Inputs:** Make sure all downstream inputs go through the AI Routing Node\n    \n\n* * *\n\n### \n\nBenefits of the Routing Node in Stack AI\n\n*   Provides greater flexibility than a standard if-else node, as it excels at identifying user intent rather than just specific words. It's akin to having a Large Language Model (LLM) manage your workflow, determining the best routing for user queries.\n    \n\n* * *\n\n### \n\nFrequently Asked Questions\n\n**Q: Can I customize the categories in the Routing node?** A: Yes! You can define as many categories as needed to match your workflow requirements.\n\n**Q: What AI models does the Routing node use for classification?** A: The Routing node uses an Azure OpenAI for intent detection and classification.\n\n**Q: How do I connect the Routing node to other nodes?** A: Simply draw edges from the Routing node to downstream nodes corresponding to each category in your workflow editor.\n\n* * *\n\n### \n\nConclusion\n\nThe **Routing node** is essential for building intelligent, context-aware, and scalable AI workflows in Stack AI. By classifying and directing user input, it ensures that every query is handled by the most appropriate process, enhancing both automation and user satisfaction.\n\nLast updated 2 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/utils/custom-api","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/utils/custom-api","loadedTime":"2025-10-17T18:30:02.703Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/utils/custom-api","title":"Custom API | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Custom API | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"0","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dd638ce382c2-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:02 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"iad1::iad1::nv5zf-1760725801612-55642697e653"}},"screenshotUrl":null,"text":"Custom API | StackAI\nThe Custom API node in Stack AI allows you to connect your workflow to any external API endpoint. This powerful feature enables you to fetch, process, and utilize data from third-party services, internal APIs, or any web-accessible resource, making your AI workflows highly flexible and extensible.\nKey Features\nUniversal API Integration: Connect to any RESTful API using GET, POST, PUT, or DELETE methods.\nCustom Headers and Authentication: Add custom headers for authentication or content-type requirements.\nDynamic Payloads: Pass data from previous nodes (like user input or AI-generated content) directly into your API requests.\nSeamless Data Flow: Use API responses as inputs for downstream nodes, such as LLMs, Python code, or output nodes.\nHow to Configure the Custom API Node\n1. Add the Custom API Node to Your Workflow\nIn the Stack AI workflow builder, drag the Custom API node onto your canvas.\n2. Set the API Endpoint\nEnter the full URL of the API you want to connect to in the URL field (e.g., https://api.example.com/data).\n3. Choose the HTTP Method\nSelect the HTTP method you need: GET, POST, PUT, or DELETE.\n4. Configure Headers (Optional)\nAdd any required headers in JSON format. For example, to add an API key:\n{ \"Authorization\": \"Bearer YOUR_API_KEY\", \"Content-Type\": \"application/json\" }\n5. Set the Request Body or Query Parameters\nFor POST or PUT requests, the request body or query parameters will come from the previous node connected to it.\nFor GET requests, add query parameters directly to the URL or use the information from the previous node connected to it.\n6. Connect Upstream Nodes\nLink nodes like Input, Python, or LLM to the Custom API node to pass dynamic data into your API call.\n7. Use the API Response\nThe output of the Custom API node can be referenced in downstream nodes for further processing, summarization, or display.\nBest Practices for Using the Custom API Node\nTest Your API Calls: Use tools like Postman to verify your API endpoint and payload before integrating.\nHandle Authentication Securely: Store sensitive keys in environment variables or secure storage.\nUse Dynamic References: Leverage Stack AI’s node referencing (e.g., {in-0}) to make your API calls dynamic and context-aware.\nError Handling: Check the API response for errors and handle them gracefully in your workflow.\nFrequently Asked Questions\nQ: Can I use the Custom API node with authenticated APIs? A: Yes! Just add the required authentication headers in the headers field.\nQ: How do I pass data from previous nodes into my API request? A: Use curly braces with the node ID (e.g., {in-0} or {python-0}) in your request body or URL.\nQ: What happens to the API response? A: The response is available as the output of the Custom API node and can be used in any downstream node.\nConclusion\nThe Custom API node in Stack AI is your gateway to integrating any external data source or service into your AI workflows. By following the steps above, you can easily connect, fetch, and process data from any API, unlocking endless automation and AI-powered possibilities.\nLast updated 3 months ago","markdown":"# Custom API | StackAI\n\nThe **Custom API node** in Stack AI allows you to connect your workflow to any external API endpoint. This powerful feature enables you to fetch, process, and utilize data from third-party services, internal APIs, or any web-accessible resource, making your AI workflows highly flexible and extensible.\n\n* * *\n\n### \n\nKey Features\n\n*   **Universal API Integration:** Connect to any RESTful API using GET, POST, PUT, or DELETE methods.\n    \n*   **Custom Headers and Authentication:** Add custom headers for authentication or content-type requirements.\n    \n*   **Dynamic Payloads:** Pass data from previous nodes (like user input or AI-generated content) directly into your API requests.\n    \n*   **Seamless Data Flow:** Use API responses as inputs for downstream nodes, such as LLMs, Python code, or output nodes.\n    \n\n* * *\n\n### \n\nHow to Configure the Custom API Node\n\n#### \n\n1\\. Add the Custom API Node to Your Workflow\n\n*   In the Stack AI workflow builder, drag the **Custom API** node onto your canvas.\n    \n\n#### \n\n2\\. Set the API Endpoint\n\n*   Enter the full URL of the API you want to connect to in the **URL** field (e.g., `https://api.example.com/data`).\n    \n\n#### \n\n3\\. Choose the HTTP Method\n\n*   Select the HTTP method you need: **GET**, **POST**, **PUT**, or **DELETE**.\n    \n\n#### \n\n4\\. Configure Headers (Optional)\n\n*   Add any required headers in JSON format. For example, to add an API key:\n    \n    ```\n    {\n      \"Authorization\": \"Bearer YOUR_API_KEY\",\n      \"Content-Type\": \"application/json\"\n    }\n    ```\n    \n\n#### \n\n5\\. Set the Request Body or Query Parameters\n\n*   For **POST** or **PUT** requests, the request body or query parameters will come from the previous node connected to it.\n    \n*   For **GET** requests, add query parameters directly to the URL or use the information from the previous node connected to it.\n    \n\n#### \n\n6\\. Connect Upstream Nodes\n\n*   Link nodes like **Input**, **Python**, or **LLM** to the Custom API node to pass dynamic data into your API call.\n    \n\n#### \n\n7\\. Use the API Response\n\n*   The output of the Custom API node can be referenced in downstream nodes for further processing, summarization, or display.\n    \n\n* * *\n\n### \n\nBest Practices for Using the Custom API Node\n\n*   **Test Your API Calls:** Use tools like Postman to verify your API endpoint and payload before integrating.\n    \n*   **Handle Authentication Securely:** Store sensitive keys in environment variables or secure storage.\n    \n*   **Use Dynamic References:** Leverage Stack AI’s node referencing (e.g., `{in-0}`) to make your API calls dynamic and context-aware.\n    \n*   **Error Handling:** Check the API response for errors and handle them gracefully in your workflow.\n    \n\n* * *\n\n### \n\nFrequently Asked Questions\n\n**Q: Can I use the Custom API node with authenticated APIs?** A: Yes! Just add the required authentication headers in the headers field.\n\n**Q: How do I pass data from previous nodes into my API request?** A: Use curly braces with the node ID (e.g., `{in-0}` or `{python-0}`) in your request body or URL.\n\n**Q: What happens to the API response?** A: The response is available as the output of the Custom API node and can be used in any downstream node.\n\n* * *\n\n### \n\nConclusion\n\nThe **Custom API node** in Stack AI is your gateway to integrating any external data source or service into your AI workflows. By following the steps above, you can easily connect, fetch, and process data from any API, unlocking endless automation and AI-powered possibilities.\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/logic/python-code","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/logic/python-code","loadedTime":"2025-10-17T18:30:01.881Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/logic/python-code","title":"Python Code | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Python Code | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"0","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dd5b2814172b-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:01 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"iad1::iad1::9mcx9-1760725800278-2e6426f27180"}},"screenshotUrl":null,"text":"Python Code | StackAI\nThe Python Node in Stack AI lets you write and execute custom Python code as part of your workflow. It’s perfect for advanced data processing, custom logic, or integrating with APIs and libraries not natively supported by Stack AI. This node gives you the flexibility of Python right inside your automated workflow.\nKey Features\nCustom Python Execution: Write and run any Python code within your workflow.\nMultiple Inputs: Access results from any connected nodes as Python variables.\nPre-Imported Libraries: Common libraries like pandas, numpy, requests, and more are available by default—no need to import them manually.\nFlexible Output: The value you assign to the output variable (or return) becomes the node’s output, which can be used by downstream nodes.\nTemplates Support: You can use Template nodes to format and combine outputs from the Python node and other nodes, making your results more readable and structured.\nRun Code Independently: You can run the Python node by itself to test your code, without executing the entire workflow. This is useful for debugging and rapid iteration.\nHow the Python Node Works\nInput Variables\nEach connected node’s output is available as a variable in your Python code.\nThe variable name is the node ID with dashes replaced by underscores. For example, if you connect a node with ID llm-0, you can access its output as llm_0.\nOutput Handling\nThe value of the variable output (or the value returned by a return statement) is passed to downstream nodes.\nBest Practice: Use a return statement for clarity and reliability.\nPre-Imported Python Libraries\nYou do not need to import common libraries—they are already available. Do not write import statements in your code, as this may cause errors.\nAvailable libraries include:\nimport aiohttp\nimport asyncio\nimport base64\nimport concurrent.futures\nimport datetime\nfrom fuzzywuzzy import fuzz\nimport io\nimport json\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport pypdf2\nimport random\nimport re\nimport requests\nimport seaborn as sns\nimport sklearn\nfrom tabulate import tabulate\nimport tiktoken\nimport time\nimport typing\nimport weaviate\n'Unsafe' expressions\nDue to security purposes the below expressions are deemed 'unsafe' and to be avoided in the python node. If included, the user should expect the error Unsafe expression '[word]' detected in the code...\nUnsafe expressions:\n\"eval\"\n\"exec\"\n\"safe_eval\"\n\"safe_exec\"\n\"compile\"\n\"subprocess\"\nExample Usage\nSuppose you want to send a message to a hypothetical API endpoint (e.g., https://api.example.com/message) using user input from your input node (in-0). The Python node will:\nRead the user’s message from the input node.\nConstruct a JSON payload for the API.\nSend a POST request using requests.\nReturn the API’s response (as text or JSON).\nExample Python Node Code\n# Assume in_0 contains the user's message from the input node user_message = in_0 # Construct the request payload payload = { \"message\": user_message, \"sender\": \"StackAI Workflow\" } # Set the API endpoint URL url = \"https://api.example.com/message\" # Optionally, set headers (e.g., for JSON) headers = { \"Content-Type\": \"application/json\", \"Authorization\": \"Bearer YOUR_API_KEY\" # Remove if not needed } # Send the POST request response = requests.post(url, json=payload, headers=headers) # Check for success and return the result if response.status_code == 200: # If the API returns JSON, you can parse it: return response.json() else: # Return error details return f\"Error {response.status_code}: {response.text}\"\nHow This Works\nin_0: This variable contains the output from your input node (in-0). In Stack AI, you access it as in_0 (dashes replaced by underscores).\npayload: The body of the request, constructed using the user’s input.\nrequests.post: Sends the POST request to the API endpoint.\nheaders: Optional, but often needed for APIs (especially for JSON and authentication).\nresponse.json(): Parses the API’s JSON response and returns it to downstream nodes.\nError handling: If the request fails, the error code and message are returned.\nCustomization Tips\nChange the url to your actual API endpoint.\nAdjust the payload structure to match your API’s requirements.\nAdd or remove headers as needed (e.g., for authentication).\nYou can use any HTTP method (get, post, put, etc.) supported by requests.\nReal-World Use Cases\nSending user feedback to a backend service.\nCreating a new record in a database via a REST API.\nTriggering a webhook with dynamic data from your workflow.\nRunning the Python Node Independently\nYou can run the Python node by itself to test your code, without executing the entire workflow. This is especially useful for debugging or when you want to quickly check the output of your code before connecting it to other nodes.\nBest Practices\nNo Import Statements: All common libraries are pre-imported.\nUse Return Statements: Always use return to specify the output.\nVariable Naming: Use node IDs with dashes replaced by underscores to access inputs.\nDebugging: Test your code with sample inputs to ensure reliability.\nLeverage Templates: Use Template nodes to format and present your Python node’s output in a user-friendly way.\nFrequently Asked Questions\n1. Can I use external Python packages?\nOnly the pre-imported libraries are available. If you need a specific package, check if it’s already included.\n2. How do I access inputs from other nodes?\nConnect the desired node to your Python node. Its output will be available as a variable named after its node ID (dashes replaced by underscores). Text input from the node \"in-0\" will be available as a variable called in_0\n3. What happens if my code has an error?\nThe workflow will stop at the Python node, and you’ll see an error message in the node’s output.\n4. Can I test my Python code without running the whole workflow?\nYes! You can run the Python node independently to test and debug your code. Click Run Code at the top right. \nConclusion\nThe Python Node in Stack AI unlocks limitless customization for your AI workflows. Whether you need to process data, apply business logic, or integrate with external systems, the Python node gives you the flexibility and power of Python—right inside your automated workflow. Combine it with Template nodes for beautiful, structured output, and take advantage of the ability to run and test your code independently for a smooth development experience.","markdown":"# Python Code | StackAI\n\nThe **Python Node** in Stack AI lets you write and execute custom Python code as part of your workflow. It’s perfect for advanced data processing, custom logic, or integrating with APIs and libraries not natively supported by Stack AI. This node gives you the flexibility of Python right inside your automated workflow.\n\n* * *\n\n### \n\nKey Features\n\n*   **Custom Python Execution:** Write and run any Python code within your workflow.\n    \n*   **Multiple Inputs:** Access results from any connected nodes as Python variables.\n    \n*   **Pre-Imported Libraries:** Common libraries like pandas, numpy, requests, and more are available by default—no need to import them manually.\n    \n*   **Flexible Output:** The value you assign to the output variable (or return) becomes the node’s output, which can be used by downstream nodes.\n    \n*   **Templates Support:** You can use Template nodes to format and combine outputs from the Python node and other nodes, making your results more readable and structured.\n    \n*   **Run Code Independently:** You can run the Python node by itself to test your code, without executing the entire workflow. This is useful for debugging and rapid iteration.\n    \n\n* * *\n\n### \n\nHow the Python Node Works\n\n#### \n\nInput Variables\n\n*   Each connected node’s output is available as a variable in your Python code.\n    \n*   The variable name is the node ID with dashes replaced by underscores. For example, if you connect a node with ID `llm-0`, you can access its output as `llm_0`.\n    \n\n#### \n\nOutput Handling\n\n*   The value of the variable `output` (or the value returned by a `return` statement) is passed to downstream nodes.\n    \n*   **Best Practice:** Use a `return` statement for clarity and reliability.\n    \n\n* * *\n\n### \n\nPre-Imported Python Libraries\n\nYou do **not** need to import common libraries—they are already available. **Do not write import statements** in your code, as this may cause errors.\n\n**Available libraries include:**\n\n*   import aiohttp\n    \n*   import asyncio\n    \n*   import base64\n    \n*   import concurrent.futures\n    \n*   import datetime\n    \n*   from fuzzywuzzy import fuzz\n    \n*   import io\n    \n*   import json\n    \n*   import matplotlib.pyplot as plt\n    \n*   import numpy as np\n    \n*   import pandas as pd\n    \n*   import plotly.express as px\n    \n*   import plotly.graph\\_objects as go\n    \n*   import pypdf2\n    \n*   import random\n    \n*   import re\n    \n*   import requests\n    \n*   import seaborn as sns\n    \n*   import sklearn\n    \n*   from tabulate import tabulate\n    \n*   import tiktoken\n    \n*   import time\n    \n*   import typing\n    \n*   import weaviate\n    \n\n* * *\n\n### \n\n'Unsafe' expressions\n\nDue to security purposes the below expressions are deemed 'unsafe' and to be avoided in the python node. If included, the user should expect the error `Unsafe expression '[word]' detected in the code...`\n\n**Unsafe expressions:**\n\n*   \"eval\"\n    \n*   \"exec\"\n    \n*   \"safe\\_eval\"\n    \n*   \"safe\\_exec\"\n    \n*   \"compile\"\n    \n*   \"subprocess\"\n    \n\n* * *\n\n### \n\nExample Usage\n\nSuppose you want to send a message to a hypothetical API endpoint (e.g., [https://api.example.com/message](https://api.example.com/message)) using user input from your input node (`in-0`). The Python node will:\n\n1.  Read the user’s message from the input node.\n    \n2.  Construct a JSON payload for the API.\n    \n3.  Send a POST request using requests.\n    \n4.  Return the API’s response (as text or JSON).\n    \n\n* * *\n\n### \n\nExample Python Node Code\n\n```\n# Assume in_0 contains the user's message from the input node\nuser_message = in_0\n\n# Construct the request payload\npayload = {\n    \"message\": user_message,\n    \"sender\": \"StackAI Workflow\"\n}\n\n# Set the API endpoint URL\nurl = \"https://api.example.com/message\"\n\n# Optionally, set headers (e.g., for JSON)\nheaders = {\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": \"Bearer YOUR_API_KEY\"  # Remove if not needed\n}\n\n# Send the POST request\nresponse = requests.post(url, json=payload, headers=headers)\n\n# Check for success and return the result\nif response.status_code == 200:\n    # If the API returns JSON, you can parse it:\n    return response.json()\nelse:\n    # Return error details\n    return f\"Error {response.status_code}: {response.text}\"\n```\n\n### \n\nHow This Works\n\n*   **in\\_0**: This variable contains the output from your input node (`in-0`). In Stack AI, you access it as `in_0` (dashes replaced by underscores).\n    \n*   **payload**: The body of the request, constructed using the user’s input.\n    \n*   **requests.post**: Sends the POST request to the API endpoint.\n    \n*   **headers**: Optional, but often needed for APIs (especially for JSON and authentication).\n    \n*   **response.json()**: Parses the API’s JSON response and returns it to downstream nodes.\n    \n*   **Error handling**: If the request fails, the error code and message are returned.\n    \n\n### \n\nCustomization Tips\n\n*   Change the `url` to your actual API endpoint.\n    \n*   Adjust the `payload` structure to match your API’s requirements.\n    \n*   Add or remove headers as needed (e.g., for authentication).\n    \n*   You can use any HTTP method (`get`, `post`, `put`, etc.) supported by requests.\n    \n\n* * *\n\n### \n\nReal-World Use Cases\n\n*   Sending user feedback to a backend service.\n    \n*   Creating a new record in a database via a REST API.\n    \n*   Triggering a webhook with dynamic data from your workflow.\n    \n\n* * *\n\n### \n\nRunning the Python Node Independently\n\nYou can run the Python node by itself to test your code, without executing the entire workflow. This is especially useful for debugging or when you want to quickly check the output of your code before connecting it to other nodes.\n\n* * *\n\n### \n\nBest Practices\n\n*   **No Import Statements:** All common libraries are pre-imported.\n    \n*   **Use Return Statements:** Always use `return` to specify the output.\n    \n*   **Variable Naming:** Use node IDs with dashes replaced by underscores to access inputs.\n    \n*   **Debugging:** Test your code with sample inputs to ensure reliability.\n    \n*   **Leverage Templates:** Use Template nodes to format and present your Python node’s output in a user-friendly way.\n    \n\n* * *\n\n### \n\nFrequently Asked Questions\n\n#### \n\n1\\. Can I use external Python packages?\n\nOnly the pre-imported libraries are available. If you need a specific package, check if it’s already included.\n\n#### \n\n2\\. How do I access inputs from other nodes?\n\nConnect the desired node to your Python node. Its output will be available as a variable named after its node ID (dashes replaced by underscores). Text input from the node \"in-0\" will be available as a variable called `in_0`\n\n#### \n\n3\\. What happens if my code has an error?\n\nThe workflow will stop at the Python node, and you’ll see an error message in the node’s output.\n\n#### \n\n4\\. Can I test my Python code without running the whole workflow?\n\nYes! You can run the Python node independently to test and debug your code. Click Run Code at the top right.\n\n* * *\n\n### \n\nConclusion\n\nThe **Python Node** in Stack AI unlocks limitless customization for your AI workflows. Whether you need to process data, apply business logic, or integrate with external systems, the Python node gives you the flexibility and power of Python—right inside your automated workflow. Combine it with Template nodes for beautiful, structured output, and take advantage of the ability to run and test your code independently for a smooth development experience.\n\n* * *","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/utils/stackai-project","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/utils/stackai-project","loadedTime":"2025-10-17T18:30:03.896Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/utils/stackai-project","title":"StackAI Project | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"StackAI Project | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"0","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dd6c1aeb8797-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:03 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"iad1::iad1::dgdq2-1760725802935-72af6b25ef2e"}},"screenshotUrl":null,"text":"StackAI Project | StackAI\nThe Stack AI Project Node allows you to run (or \"call\") another Stack AI project from within your current workflow. This is useful for reusing logic, chaining projects, and modularizing complex workflows.\nWhen to Use:\nYou want to repeat the same logic across multiple projects. Create a project with the repeat logic, then import it in your other projects with a StackAI Project Node.\nYou want to chain projects together. Create a separate orchestration project and import all the projects you'd like to chain as StackAI Project Nodes.\nYou want to make a complex project more modular and easier to understand for other builders. Put each branch or section into a separate project and import them as StackAI Project Nodes.\nHow does it work?\nInputs:\nProject: You select which Stack AI Project you want to execute. This is required.\nInput Data: You provide the input(s) for the project. This is a list of strings. If you want to run the project multiple times (once for each item), you can enable Loop Mode. Make sure the inputs you select here match the inputs in the project you are importing.\nLoop Mode (optional): If enabled, the node will execute the selected project for each item in the input data list, returning a list of results. When turning this ON, encode this input as a JSON list: [\"input1\", \"input2\"]\nOutputs:\nResults: After execution, the node outputs the results from the called Stack AI Project. If Loop Mode is enabled, you get a list of results (one per input); otherwise, you get a single result. Important: the output(s) of your StackAI Project Node will be output as a JSON, this is because a project can have multiple outputs\nTypical Use Cases\nReusing a pre-built project (like a custom data processor or AI agent) in multiple workflows.\nChaining together multiple projects for advanced automation.\nRunning a project in bulk on a list of inputs (using Loop Mode).\nManaging the Output(s) of the StackAI Project Node\nIf you'd like to see the output of the StackAI Project instead of the JSON file, use the Template feature in the Output Node. This allows you to manage multiple outputs and control how they are displayed.\nWith projects that have multiple outputs, it's easy to choose which ones you would like to display and how you want to format them!\nLast updated 2 months ago","markdown":"# StackAI Project | StackAI\n\nThe **Stack AI Project Node** allows you to run (or \"call\") another Stack AI project from within your current workflow. This is useful for reusing logic, chaining projects, and modularizing complex workflows.\n\nWhen to Use:\n\n1.  You want to repeat the same logic across multiple projects. Create a project with the repeat logic, then import it in your other projects with a StackAI Project Node.\n    \n2.  You want to chain projects together. Create a separate orchestration project and import all the projects you'd like to chain as StackAI Project Nodes.\n    \n3.  You want to make a complex project more modular and easier to understand for other builders. Put each branch or section into a separate project and import them as StackAI Project Nodes.\n    \n\n#### \n\nHow does it work?\n\n*   **Inputs:**\n    \n    *   **Project**: You select which Stack AI Project you want to execute. This is required.\n        \n    *   **Input Data**: You provide the input(s) for the project. This is a list of strings. If you want to run the project multiple times (once for each item), you can enable Loop Mode. Make sure the inputs you select here match the inputs in the project you are importing.\n        \n    *   **Loop Mode** (optional): If enabled, the node will execute the selected project for each item in the input data list, returning a list of results. When turning this ON, encode this input as a JSON list: \\[\"input1\", \"input2\"\\]\n        \n    \n*   **Outputs:**\n    \n    *   **Results**: After execution, the node outputs the results from the called Stack AI Project. If Loop Mode is enabled, you get a list of results (one per input); otherwise, you get a single result. Important: the output(s) of your StackAI Project Node will be output as a JSON, this is because a project can have multiple outputs\n        \n    \n\n#### \n\nTypical Use Cases\n\n*   Reusing a pre-built project (like a custom data processor or AI agent) in multiple workflows.\n    \n*   Chaining together multiple projects for advanced automation.\n    \n*   Running a project in bulk on a list of inputs (using Loop Mode).\n    \n\n#### \n\nManaging the Output(s) of the StackAI Project Node\n\nIf you'd like to see the output of the StackAI Project instead of the JSON file, use the Template feature in the Output Node. This allows you to manage multiple outputs and control how they are displayed.\n\nWith projects that have multiple outputs, it's easy to choose which ones you would like to display and how you want to format them!\n\nLast updated 2 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/utils/delay","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/utils/delay","loadedTime":"2025-10-17T18:30:04.305Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/utils/delay","title":"Delay | StackAI","description":"Learn how to use the Delay node in StackAI workflows to pause execution for a set time.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Delay | StackAI"},{"property":"og:description","content":"Learn how to use the Delay node in StackAI workflows to pause execution for a set time."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"0","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dd6e09ed5794-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:03 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"iad1::iad1::vkrv8-1760725803300-0d554b56f7aa"}},"screenshotUrl":null,"text":"Delay | StackAI\nLearn how to use the Delay node in StackAI workflows to pause execution for a set time.\nWhat is Delay?\nThe Delay node in StackAI allows you to pause the execution of your workflow for a specified number of seconds. This is useful for scenarios where you need to wait before proceeding to the next step, such as rate-limiting, waiting for external processes, scheduled notifications or reminders, or simulating human-like interactions.\nHow to use it?\nPlace the Delay node between two nodes in your workflow where you want to introduce a pause.\nConfigure the number of seconds to delay.\nThe Delay node will hold the workflow for the specified duration before passing control to the next node.\nActions and Triggers\nThe Delay node acts as a passive step in the workflow and does not have active triggers or multiple actions. Its primary function is to introduce a time delay between nodes.\nSettings\nDelay (integer, required): The number of seconds to pause the workflow.\nExample: To wait for 10 seconds, set delay to 10.\nOutput\nNo output parameters.\nThe Delay node does not produce any data output. It simply allows the workflow to continue after the delay.\nExample Configuration\nExample Workflow\nCurrent Time node records the start time.\nDelay node pauses the workflow for 10 seconds.\nCurrent Time node records the end time.\nOutput node displays both times.\nThis setup helps you measure elapsed time or create time-based automation in your StackAI workflow.\nLast updated 3 months ago","markdown":"# Delay | StackAI\n\nLearn how to use the Delay node in StackAI workflows to pause execution for a set time.\n\n**What is Delay?**\n\nThe Delay node in StackAI allows you to pause the execution of your workflow for a specified number of seconds. This is useful for scenarios where you need to wait before proceeding to the next step, such as rate-limiting, waiting for external processes, scheduled notifications or reminders, or simulating human-like interactions.\n\n**How to use it?**\n\n*   Place the Delay node between two nodes in your workflow where you want to introduce a pause.\n    \n*   Configure the number of seconds to delay.\n    \n*   The Delay node will hold the workflow for the specified duration before passing control to the next node.\n    \n\n**Actions and Triggers**\n\nThe Delay node acts as a passive step in the workflow and does not have active triggers or multiple actions. Its primary function is to introduce a time delay between nodes.\n\n#### \n\nSettings\n\n*   **Delay** (integer, required): The number of seconds to pause the workflow.\n    \n    *   **Example:** To wait for 10 seconds, set `delay` to 10.\n        \n    \n\n#### \n\nOutput\n\n*   **No output parameters.**\n    \n    *   The Delay node does not produce any data output. It simply allows the workflow to continue after the delay.\n        \n    \n\n**Example Configuration**\n\n**Example Workflow**\n\n1.  **Current Time** node records the start time.\n    \n2.  **Delay** node pauses the workflow for 10 seconds.\n    \n3.  **Current Time** node records the end time.\n    \n4.  **Output** node displays both times.\n    \n\nThis setup helps you measure elapsed time or create time-based automation in your StackAI workflow.\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/utils/sticky-note","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/utils/sticky-note","loadedTime":"2025-10-17T18:30:04.643Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/utils/sticky-note","title":"Sticky Note | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Sticky Note | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"0","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dd6d4e9f07c4-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:04 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"cle1::iad1::l46dv-1760725803259-f9b0e83cd148"}},"screenshotUrl":null,"text":"Sticky Note | StackAI\nThe Sticky Note allows you to take notes in your workflow, leave explanations for other builders, and make the builder view easier to understand.\nYou can change the color of your sticky note as well as format your content using Markdown.\nLast updated 2 months ago","markdown":"# Sticky Note | StackAI\n\nThe Sticky Note allows you to take notes in your workflow, leave explanations for other builders, and make the builder view easier to understand.\n\nYou can change the color of your sticky note as well as format your content using Markdown.\n\nLast updated 2 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/utils/shared-memory","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/utils/shared-memory","loadedTime":"2025-10-17T18:30:05.899Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/utils/shared-memory","title":"Shared Memory | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Shared Memory | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"0","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dd777a530a13-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:05 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"iad1::iad1::rqnsv-1760725804803-9adbc5d2e4fc"}},"screenshotUrl":null,"text":"Shared Memory | StackAI\nThe Shared Memory Node is a special node designed to pass memory from one LLM (Large Language Model) node to another. Here’s how it works and what it does:\nPurpose\nThe Shared Memory node allows you to maintain conversational context or \"memory\" across multiple LLM nodes.\nIt is especially useful if you want to share the conversation history, user input, or other relevant context between different AI models or across different parts of your workflow.\nHow it works in your flow\nYou can choose how many of the past interactions it should pass. Be careful! Passing too many interactions may overwhelm the context window of the LLM you are passing to.\nChoose the LLM to pass from, you can choose from any of the LLMs in your current workflow. Any relevant context from previous steps or user inputs can be included in the LLM’s prompt, making the AI’s responses more coherent and context-aware.\nReference the Shared Memory node in your LLM so the memory is passed in.\nTypical Use Case\nIf your workflow involves multiple turns of conversation or needs to remember previous user inputs, the Shared Memory node ensures that the LLM has access to this history, improving the quality and relevance of its responses.\nLast updated 2 months ago","markdown":"# Shared Memory | StackAI\n\nThe **Shared Memory Node** is a special node designed to pass memory from one LLM (Large Language Model) node to another. Here’s how it works and what it does:\n\n#### \n\nPurpose\n\n*   The Shared Memory node allows you to maintain conversational context or \"memory\" across multiple LLM nodes.\n    \n*   It is especially useful if you want to share the conversation history, user input, or other relevant context between different AI models or across different parts of your workflow.\n    \n\n#### \n\nHow it works in your flow\n\n*   You can choose how many of the past interactions it should pass. Be careful! Passing too many interactions may overwhelm the context window of the LLM you are passing to.\n    \n*   Choose the LLM to pass from, you can choose from any of the LLMs in your current workflow. Any relevant context from previous steps or user inputs can be included in the LLM’s prompt, making the AI’s responses more coherent and context-aware.\n    \n*   Reference the Shared Memory node in your LLM so the memory is passed in.\n    \n\n#### \n\nTypical Use Case\n\n*   If your workflow involves multiple turns of conversation or needs to remember previous user inputs, the Shared Memory node ensures that the LLM has access to this history, improving the quality and relevance of its responses.\n    \n\nLast updated 2 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/azure-sql","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/azure-sql","loadedTime":"2025-10-17T18:30:10.304Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/azure-sql","title":"Azure SQL | StackAI","description":"Learn how to use the Azure SQL node to query your Azure SQL database with natural language or SQL, including required inputs, configurations, and output details.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Azure SQL | StackAI"},{"property":"og:description","content":"Learn how to use the Azure SQL node to query your Azure SQL database with natural language or SQL, including required inputs, configurations, and output details."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"109","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dd98fc451752-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:10 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::62n4m-1760725810142-68ac4bb50507"}},"screenshotUrl":null,"text":"Azure SQL | StackAI\nLearn how to use the Azure SQL node to query your Azure SQL database with natural language or SQL, including required inputs, configurations, and output details.\nThe Azure SQL Node is a workflow node that allows you to query an Azure SQL database using either plain English or SQL queries. This node is ideal for retrieving, analyzing, and interacting with your database data directly within your workflow, making data access seamless and user-friendly.\nHow to use it?\nTo use the Azure SQL node, you must provide two required inputs:\nSchema: Describe your database schema, including tables, columns, and data types.\nQuery: Enter your question or request in plain English or as a SQL statement.\nThe node will process your input, convert plain English queries to SQL if needed, execute the query, and return the results.\nExample of Usage\nSuppose you have a table called Sales with columns CustomerName, OrderAmount, and OrderDate.\nSchema (Required):\nTABLE Sales ( CustomerName TEXT, OrderAmount REAL, OrderDate DATE );\nQuery (Required):\nWhat is the total order amount for 2024?\nor\nSELECT SUM(OrderAmount) FROM Sales WHERE YEAR(OrderDate) = 2024;\nOutputs:\nQuery (Required): The SQL query that was executed (e.g., SELECT SUM(OrderAmount) FROM Sales WHERE YEAR(OrderDate) = 2024;)\nResults (Required): The results of the query (e.g., {\"SUM(OrderAmount)\": 150000})\nAvailable Actions\nQuery an Azure SQL database\nInputs:\nSchema (Required): The structure of your database (tables, columns, types, etc.).\nQuery (Required): Your question in plain English or a SQL statement.\nConfigurations: None required beyond the schema and query.\nOutputs:\nQuery: The SQL query that was executed.\nResults: The results returned from the database.\nLast updated 2 months ago","markdown":"# Azure SQL | StackAI\n\nLearn how to use the Azure SQL node to query your Azure SQL database with natural language or SQL, including required inputs, configurations, and output details.\n\nThe **Azure SQL Node** is a workflow node that allows you to query an Azure SQL database using either plain English or SQL queries. This node is ideal for retrieving, analyzing, and interacting with your database data directly within your workflow, making data access seamless and user-friendly.\n\n* * *\n\n**How to use it?**\n\nTo use the Azure SQL node, you must provide two required inputs:\n\n1.  **Schema**: Describe your database schema, including tables, columns, and data types.\n    \n2.  **Query**: Enter your question or request in plain English or as a SQL statement.\n    \n\nThe node will process your input, convert plain English queries to SQL if needed, execute the query, and return the results.\n\n* * *\n\n**Example of Usage**\n\nSuppose you have a table called `Sales` with columns `CustomerName`, `OrderAmount`, and `OrderDate`.\n\n*   **Schema (Required):**\n    \n    ```\n    TABLE Sales (\n      CustomerName TEXT,\n      OrderAmount REAL,\n      OrderDate DATE\n    );\n    ```\n    \n*   **Query (Required):**\n    \n    ```\n    What is the total order amount for 2024?\n    ```\n    \n    or\n    \n    ```\n    SELECT SUM(OrderAmount) FROM Sales WHERE YEAR(OrderDate) = 2024;\n    ```\n    \n\n**Outputs:**\n\n*   **Query (Required):** The SQL query that was executed (e.g., `SELECT SUM(OrderAmount) FROM Sales WHERE YEAR(OrderDate) = 2024;`)\n    \n*   **Results (Required):** The results of the query (e.g., `{\"SUM(OrderAmount)\": 150000}`)\n    \n\n* * *\n\n**Available Actions**\n\n*   **Query an Azure SQL database**\n    \n    *   **Inputs:**\n        \n        *   **Schema** (Required): The structure of your database (tables, columns, types, etc.).\n            \n        *   **Query** (Required): Your question in plain English or a SQL statement.\n            \n        \n    *   **Configurations:** None required beyond the schema and query.\n        \n    *   **Outputs:**\n        \n        *   **Query**: The SQL query that was executed.\n            \n        *   **Results**: The results returned from the database.\n            \n        \n    \n\nLast updated 2 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/utils/default-message","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/utils/default-message","loadedTime":"2025-10-17T18:30:06.530Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/utils/default-message","title":"Default Message | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Default Message | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"date":"Fri, 17 Oct 2025 18:30:05 GMT","content-type":"text/html; charset=utf-8","content-encoding":"br","cf-ray":"9901dd73dafb8157-SEA","cf-cache-status":"DYNAMIC","age":"0","cache-control":"public, max-age=0, must-revalidate","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","referrer-policy":"no-referrer-when-downgrade","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"pdx1::iad1::vxhmb-1760725804169-d1cccff34c69","server":"cloudflare","alt-svc":"h3=\":443\"; ma=86400","x-firefox-spdy":"h2"}},"screenshotUrl":"https://api.apify.com/v2/key-value-stores/3K2WBdQQFTu6EGDhJ/records/SCREENSHOT-docs-stack-ai-com-stack-ai-utils-default-message-23b16017.jpg","text":"Default Message | StackAI\nThe Default Message Node is a special utility node in Stack AI workflows.\nPurpose\nThe Default Message node is designed to always pass a preset, static message to downstream nodes in your workflow.\nIt does not process or transform any input; instead, it simply outputs the message you configure in its settings.\nIt is useful for providing fallback text, default instructions, or static context that you want to inject into your workflow regardless of user input.\nThe Default Message node is a simple way to inject a fixed message into your workflow, ensuring that downstream nodes always have a value to work with, even if no dynamic input is provided.\nLast updated 2 months ago","markdown":"# Default Message | StackAI\n\nThe **Default Message Node** is a special utility node in Stack AI workflows.\n\n#### \n\nPurpose\n\n*   The Default Message node is designed to always pass a preset, static message to downstream nodes in your workflow.\n    \n*   It does not process or transform any input; instead, it simply outputs the message you configure in its settings.\n    \n*   It is useful for providing fallback text, default instructions, or static context that you want to inject into your workflow regardless of user input.\n    \n\n#### \n\nThe Default Message node is a simple way to inject a fixed message into your workflow, ensuring that downstream nodes always have a value to work with, even if no dynamic input is provided.\n\nLast updated 2 months ago","debug":{"requestHandlerMode":"browser"}}
{"url":"https://docs.stack-ai.com/stack-ai/utils/dynamic-vector-store","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/utils/dynamic-vector-store","loadedTime":"2025-10-17T18:30:10.857Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/utils/dynamic-vector-store","title":"Dynamic Vector Store | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Dynamic Vector Store | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"0","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dd98dae87001-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:10 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"iad1::iad1::jw8nj-1760725810098-1ba02e90b48c"}},"screenshotUrl":null,"text":"Dynamic Vector Store | StackAI\nThe Dynamic Vector Store node in your workflow is a specialized component designed to store and manage document embeddings in memory, enabling efficient semantic search and retrieval. \nWhy use the Dynamic Vector Store?\nPurpose: The Dynamic Vector Store node takes documents (such as those uploaded via the Files node) and converts them into vector embeddings using the embedding model you specify.\nHow it works:\nWhen you upload or process documents, the node generates high-dimensional vector representations (embeddings) for each chunk of text.\nThese vectors are stored in memory, allowing for fast similarity search and retrieval based on user queries.\nWhen a user asks a question or submits a query, the node can compare the query’s embedding to the stored document embeddings to find the most relevant content.\nKey Properties\nembeddings: The embedding model used to convert text into vectors (here: \"text-embedding-3-large\").\nquery_len: The maximum length of the query that can be processed (here: 4500 tokens/characters).\nmulti_query: Indicates whether multiple queries can be processed at once (set to false in your config).\nTypical Use Cases\nSemantic Search:\nUsers can search for information in large document sets using natural language queries.\nThe node retrieves the most relevant document chunks based on semantic similarity, not just keyword matching.\nRetrieval-Augmented Generation (RAG):\nCombine with an LLM node to provide contextually relevant information from your documents to the AI model.\nThe LLM can use the retrieved content to generate more accurate and informed responses.\nKnowledge Management:\nStore and organize internal knowledge bases, manuals, or research papers for quick access and Q&A.\nPersonalized Recommendations:\nSuggest relevant documents, articles, or resources to users based on the similarity of their queries to stored content.\nDocument Clustering and Organization:\nGroup similar documents or text chunks together for easier navigation and analysis.\nSummary: The Dynamic Vector Store is a powerful tool for enabling advanced search, retrieval, and knowledge management capabilities in your AI workflows. It is especially useful when you need to work with large volumes of unstructured text and want to provide users with fast, relevant, and semantically meaningful results.","markdown":"# Dynamic Vector Store | StackAI\n\nThe **Dynamic Vector Store** node in your workflow is a specialized component designed to store and manage document embeddings in memory, enabling efficient semantic search and retrieval.\n\n* * *\n\n### \n\nWhy use the Dynamic Vector Store?\n\n*   **Purpose:** The Dynamic Vector Store node takes documents (such as those uploaded via the Files node) and converts them into vector embeddings using the embedding model you specify.\n    \n*   **How it works:**\n    \n    *   When you upload or process documents, the node generates high-dimensional vector representations (embeddings) for each chunk of text.\n        \n    *   These vectors are stored in memory, allowing for fast similarity search and retrieval based on user queries.\n        \n    *   When a user asks a question or submits a query, the node can compare the query’s embedding to the stored document embeddings to find the most relevant content.\n        \n    \n\n* * *\n\n### \n\nKey Properties\n\n*   **embeddings:** The embedding model used to convert text into vectors (here: \"text-embedding-3-large\").\n    \n*   **query\\_len:** The maximum length of the query that can be processed (here: 4500 tokens/characters).\n    \n*   **multi\\_query:** Indicates whether multiple queries can be processed at once (set to false in your config).\n    \n\n* * *\n\n### \n\nTypical Use Cases\n\n1.  **Semantic Search:**\n    \n    *   Users can search for information in large document sets using natural language queries.\n        \n    *   The node retrieves the most relevant document chunks based on semantic similarity, not just keyword matching.\n        \n    \n2.  **Retrieval-Augmented Generation (RAG):**\n    \n    *   Combine with an LLM node to provide contextually relevant information from your documents to the AI model.\n        \n    *   The LLM can use the retrieved content to generate more accurate and informed responses.\n        \n    \n3.  **Knowledge Management:**\n    \n    *   Store and organize internal knowledge bases, manuals, or research papers for quick access and Q&A.\n        \n    \n4.  **Personalized Recommendations:**\n    \n    *   Suggest relevant documents, articles, or resources to users based on the similarity of their queries to stored content.\n        \n    \n5.  **Document Clustering and Organization:**\n    \n    *   Group similar documents or text chunks together for easier navigation and analysis.\n        \n    \n\n* * *\n\n**Summary:** The Dynamic Vector Store is a powerful tool for enabling advanced search, retrieval, and knowledge management capabilities in your AI workflows. It is especially useful when you need to work with large volumes of unstructured text and want to provide users with fast, relevant, and semantically meaningful results.","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/bonus-features","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/bonus-features","loadedTime":"2025-10-17T18:30:10.353Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/bonus-features","title":"Bonus Features | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Bonus Features | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1807","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dd98ff9bf4e3-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:10 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::64l84-1760725810135-42a6cf6e4192"}},"screenshotUrl":null,"text":"Bonus Features | StackAI\nShare WorkflowSkip a NodeReplace a Node\nPreviousDynamic Vector StoreNextShare Workflow\nWas this helpful?","markdown":"# Bonus Features | StackAI\n\n[Share Workflow](https://docs.stack-ai.com/stack-ai/bonus-features/share-workflow)[Skip a Node](https://docs.stack-ai.com/stack-ai/bonus-features/skip-a-node)[Replace a Node](https://docs.stack-ai.com/stack-ai/bonus-features/replace-a-node)\n\n[PreviousDynamic Vector Store](https://docs.stack-ai.com/stack-ai/utils/dynamic-vector-store)[NextShare Workflow](https://docs.stack-ai.com/stack-ai/bonus-features/share-workflow)\n\nWas this helpful?","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/asana","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/asana","loadedTime":"2025-10-17T18:30:10.502Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/asana","title":"Asana | StackAI","description":"Master Asana integration in StackAI: discover top actions, required inputs, configurations, and outputs with clear examples for seamless workflow automation.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Asana | StackAI"},{"property":"og:description","content":"Master Asana integration in StackAI: discover top actions, required inputs, configurations, and outputs with clear examples for seamless workflow automation."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"110","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dd98fc9cd6ff-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:10 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"cle1::iad1::5jvxt-1760725810159-aa2c7e3a3946"}},"screenshotUrl":null,"text":"Asana | StackAI\nMaster Asana integration in StackAI: discover top actions, required inputs, configurations, and outputs with clear examples for seamless workflow automation.\nThe Asana Node in StackAI is a powerful integration that allows you to automate and manage tasks, projects, and team collaboration directly from your AI workflows. With Asana actions, you can create, update, retrieve, and list tasks and projects, streamlining your project management processes.\nHow to use it?\nTo use Asana in your StackAI workflow:\nAdd the Asana node to your workflow.\nSelect the desired action (e.g., Create Task, Update Task).\nFill in the required input fields and configurations, including your Asana connection ID.\nConnect the node to other workflow components as needed.\nRun the workflow to automate your Asana operations.\nExample of Usage\nSuppose you want to automatically create a new Asana task when a form is submitted:\nAdd an Input node to collect form data.\nAdd an Asana node and select the \"Create Task\" action.\nMap the form fields to the Asana task inputs (e.g., task name, notes).\nProvide your Asana connection ID in the configuration.\nConnect the nodes and execute the workflow.\nMost Commonly Used Asana Actions\nBelow are the most frequently used Asana actions in StackAI, with detailed input, configuration, and output requirements.\n1. Create Task\nDescription: Create a new task in a specified Asana project or workspace.\nInputs:\nname (string, required): The name/title of the task. Example: \"Design Homepage\"\nnotes (string, optional): Additional details or description for the task. Example: \"Create initial wireframes and upload to Figma.\"\nassignee (string, optional): The user ID or email to assign the task to. Example: \"[email protected]\"\nprojects (array of strings, optional): List of project IDs to add the task to. Example: [\"1234567890\"]\ndue_on (string, optional): Due date in YYYY-MM-DD format. Example: \"2025-07-10\"\nConfigurations:\nconnection_id (string, required): Your Asana connection ID.\nOutputs:\ntask_id (string, required): The unique ID of the created task.\ntask_url (string, required): Direct URL to the new task in Asana.\nstatus (string, required): Status of the operation (e.g., \"success\").\n2. Update Task\nDescription: Update details of an existing Asana task.\nInputs:\ntask_id (string, required): The ID of the task to update.\nname (string, optional): New name for the task.\nnotes (string, optional): Updated notes.\ncompleted (boolean, optional): Mark the task as completed or not.\nConfigurations:\nconnection_id (string, required): Your Asana connection ID.\nOutputs:\ntask_id (string, required): The ID of the updated task.\nstatus (string, required): Status of the operation.\n3. Get Task\nDescription: Retrieve details of a specific Asana task.\nInputs:\ntask_id (string, required): The ID of the task to retrieve.\nConfigurations:\nconnection_id (string, required): Your Asana connection ID.\nOutputs:\ntask (object, required): Full details of the task, including name, notes, assignee, status, etc.\n4. Create Project\nDescription: Create a new project in Asana.\nInputs:\nname (string, required): Name of the project.\nteam (string, optional): Team ID to associate the project with.\nnotes (string, optional): Project description.\nConfigurations:\nconnection_id (string, required): Your Asana connection ID.\nOutputs:\nproject_id (string, required): The unique ID of the created project.\nproject_url (string, required): Direct URL to the new project.\n5. List Projects\nDescription: List all projects in a workspace or team.\nInputs:\nworkspace (string, optional): Workspace ID to filter projects.\nteam (string, optional): Team ID to filter projects.\nConfigurations:\nconnection_id (string, required): Your Asana connection ID.\nOutputs:\nprojects (array, required): List of project objects.\n6. Create Comment\nDescription: Add a comment to a specific Asana task.\nInputs:\ntask_id (string, required): The ID of the task to comment on.\ntext (string, required): The comment text.\nConfigurations:\nconnection_id (string, required): Your Asana connection ID.\nOutputs:\ncomment_id (string, required): The unique ID of the created comment.\nstatus (string, required): Status of the operation.\n7. List Tasks\nDescription: Retrieve a list of tasks from a project, section, or workspace.\nInputs:\nproject (string, optional): Project ID to filter tasks.\nsection (string, optional): Section ID to filter tasks.\nworkspace (string, optional): Workspace ID to filter tasks.\nConfigurations:\nconnection_id (string, required): Your Asana connection ID.\nOutputs:\ntasks (array, required): List of task objects.\nLast updated 2 months ago","markdown":"# Asana | StackAI\n\nMaster Asana integration in StackAI: discover top actions, required inputs, configurations, and outputs with clear examples for seamless workflow automation.\n\nThe **Asana Node** in StackAI is a powerful integration that allows you to automate and manage tasks, projects, and team collaboration directly from your AI workflows. With Asana actions, you can create, update, retrieve, and list tasks and projects, streamlining your project management processes.\n\n* * *\n\n**How to use it?**\n\nTo use Asana in your StackAI workflow:\n\n1.  Add the Asana node to your workflow.\n    \n2.  Select the desired action (e.g., Create Task, Update Task).\n    \n3.  Fill in the required input fields and configurations, including your Asana connection ID.\n    \n4.  Connect the node to other workflow components as needed.\n    \n5.  Run the workflow to automate your Asana operations.\n    \n\n* * *\n\n**Example of Usage**\n\nSuppose you want to automatically create a new Asana task when a form is submitted:\n\n*   Add an Input node to collect form data.\n    \n*   Add an Asana node and select the \"Create Task\" action.\n    \n*   Map the form fields to the Asana task inputs (e.g., task name, notes).\n    \n*   Provide your Asana connection ID in the configuration.\n    \n*   Connect the nodes and execute the workflow.\n    \n\n* * *\n\n**Most Commonly Used Asana Actions**\n\nBelow are the most frequently used Asana actions in StackAI, with detailed input, configuration, and output requirements.\n\n* * *\n\n#### \n\n1\\. Create Task\n\n**Description:** Create a new task in a specified Asana project or workspace.\n\n**Inputs:**\n\n*   **name** (string, required): The name/title of the task. _Example:_ `\"Design Homepage\"`\n    \n*   **notes** (string, optional): Additional details or description for the task. _Example:_ `\"Create initial wireframes and upload to Figma.\"`\n    \n*   **assignee** (string, optional): The user ID or email to assign the task to. _Example:_ `\"[[email protected]](https://docs.stack-ai.com/cdn-cgi/l/email-protection)\"`\n    \n*   **projects** (array of strings, optional): List of project IDs to add the task to. _Example:_ `[\"1234567890\"]`\n    \n*   **due\\_on** (string, optional): Due date in `YYYY-MM-DD` format. _Example:_ `\"2025-07-10\"`\n    \n\n**Configurations:**\n\n*   **connection\\_id** (string, required): Your Asana connection ID.\n    \n\n**Outputs:**\n\n*   **task\\_id** (string, required): The unique ID of the created task.\n    \n*   **task\\_url** (string, required): Direct URL to the new task in Asana.\n    \n*   **status** (string, required): Status of the operation (e.g., `\"success\"`).\n    \n\n* * *\n\n#### \n\n2\\. Update Task\n\n**Description:** Update details of an existing Asana task.\n\n**Inputs:**\n\n*   **task\\_id** (string, required): The ID of the task to update.\n    \n*   **name** (string, optional): New name for the task.\n    \n*   **notes** (string, optional): Updated notes.\n    \n*   **completed** (boolean, optional): Mark the task as completed or not.\n    \n\n**Configurations:**\n\n*   **connection\\_id** (string, required): Your Asana connection ID.\n    \n\n**Outputs:**\n\n*   **task\\_id** (string, required): The ID of the updated task.\n    \n*   **status** (string, required): Status of the operation.\n    \n\n* * *\n\n#### \n\n3\\. Get Task\n\n**Description:** Retrieve details of a specific Asana task.\n\n**Inputs:**\n\n*   **task\\_id** (string, required): The ID of the task to retrieve.\n    \n\n**Configurations:**\n\n*   **connection\\_id** (string, required): Your Asana connection ID.\n    \n\n**Outputs:**\n\n*   **task** (object, required): Full details of the task, including name, notes, assignee, status, etc.\n    \n\n* * *\n\n#### \n\n4\\. Create Project\n\n**Description:** Create a new project in Asana.\n\n**Inputs:**\n\n*   **name** (string, required): Name of the project.\n    \n*   **team** (string, optional): Team ID to associate the project with.\n    \n*   **notes** (string, optional): Project description.\n    \n\n**Configurations:**\n\n*   **connection\\_id** (string, required): Your Asana connection ID.\n    \n\n**Outputs:**\n\n*   **project\\_id** (string, required): The unique ID of the created project.\n    \n*   **project\\_url** (string, required): Direct URL to the new project.\n    \n\n* * *\n\n#### \n\n5\\. List Projects\n\n**Description:** List all projects in a workspace or team.\n\n**Inputs:**\n\n*   **workspace** (string, optional): Workspace ID to filter projects.\n    \n*   **team** (string, optional): Team ID to filter projects.\n    \n\n**Configurations:**\n\n*   **connection\\_id** (string, required): Your Asana connection ID.\n    \n\n**Outputs:**\n\n*   **projects** (array, required): List of project objects.\n    \n\n* * *\n\n#### \n\n6\\. Create Comment\n\n**Description:** Add a comment to a specific Asana task.\n\n**Inputs:**\n\n*   **task\\_id** (string, required): The ID of the task to comment on.\n    \n*   **text** (string, required): The comment text.\n    \n\n**Configurations:**\n\n*   **connection\\_id** (string, required): Your Asana connection ID.\n    \n\n**Outputs:**\n\n*   **comment\\_id** (string, required): The unique ID of the created comment.\n    \n*   **status** (string, required): Status of the operation.\n    \n\n* * *\n\n#### \n\n7\\. List Tasks\n\n**Description:** Retrieve a list of tasks from a project, section, or workspace.\n\n**Inputs:**\n\n*   **project** (string, optional): Project ID to filter tasks.\n    \n*   **section** (string, optional): Section ID to filter tasks.\n    \n*   **workspace** (string, optional): Workspace ID to filter tasks.\n    \n\n**Configurations:**\n\n*   **connection\\_id** (string, required): Your Asana connection ID.\n    \n\n**Outputs:**\n\n*   **tasks** (array, required): List of task objects.\n    \n\n* * *\n\nLast updated 2 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/bigquery","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/bigquery","loadedTime":"2025-10-17T18:30:11.021Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/bigquery","title":"BigQuery | StackAI","description":"Comprehensive guide to the BigQuery node in StackAI: actions, inputs, configurations, outputs, and usage examples for seamless Google BigQuery integration.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"BigQuery | StackAI"},{"property":"og:description","content":"Comprehensive guide to the BigQuery node in StackAI: actions, inputs, configurations, outputs, and usage examples for seamless Google BigQuery integration."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"110","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dd9c4a0d062e-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:10 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::6vbkw-1760725810683-b258d0c17dde"}},"screenshotUrl":null,"text":"BigQuery | StackAI\nComprehensive guide to the BigQuery node in StackAI: actions, inputs, configurations, outputs, and usage examples for seamless Google BigQuery integration.\nWhat is BigQuery?\nBigQuery is a fully managed, serverless data warehouse by Google Cloud that enables super-fast SQL queries using the processing power of Google's infrastructure. In StackAI workflows, the BigQuery node allows you to connect, query, and interact with your Google BigQuery datasets directly from your automated flows.\nHow to Use the BigQuery Node\nThe BigQuery node in StackAI is designed to execute SQL queries on your Google BigQuery database. It can be used to retrieve, analyze, and process large datasets as part of your workflow automation. You can connect this node to other nodes to automate data-driven tasks, reporting, or trigger downstream actions based on query results.\nExample of Usage\nSuppose you want to retrieve sales data for the last month from your BigQuery database and use it in a report. You would configure the BigQuery node with your SQL query, connect your Google Cloud credentials, and pass the results to a reporting or output node.\nAvailable Actions for BigQuery\n1. Database Query (BigQuery)\nDescription: Run a SQL query against your Google BigQuery database and retrieve the results for use in your workflow.\nInputs\nInput Name\nDescription\nRequired\nExample\nThe SQL query to execute on your BigQuery database.\nSELECT * FROM sales WHERE date > '2025-06-01'\nOptional parameters for parameterized queries.\nShowing 1-2 of 2 items\nConfigurations\nConfiguration Name\nDescription\nRequired\nExample\nThe ID of your Google BigQuery connection (credentials).\nThe Google Cloud project ID where your BigQuery dataset resides.\nThe BigQuery dataset ID to query.\nThe location of your BigQuery dataset (e.g., ,US,, ,EU,).\nShowing 1-4 of 4 items\nOutputs\nOutput Name\nDescription\nRequired\nExample\nThe rows returned by your SQL query, as a list of records.\n[{\"date\": \"2025-06-01\", \"total\": 1000}, ...]\nThe number of rows returned by the query.\nThe schema of the returned data (column names and types).\n[{\"name\": \"date\", \"type\": \"DATE\"}, ...]\nShowing 1-3 of 3 items\nExample Configuration\n{ \"action_id\": \"database_query_bigquery\", \"action_configurations\": { \"connection_id\": \"bq-connection-12345\", \"project_id\": \"my-gcp-project\", \"dataset_id\": \"sales_data\", \"location\": \"US\" }, \"action_input_parameters\": { \"query\": \"SELECT * FROM sales WHERE date > '2025-06-01'\", \"parameters\": {} } }\nLast updated 3 months ago","markdown":"# BigQuery | StackAI\n\nComprehensive guide to the BigQuery node in StackAI: actions, inputs, configurations, outputs, and usage examples for seamless Google BigQuery integration.\n\n## \n\nWhat is BigQuery?\n\n**BigQuery** is a fully managed, serverless data warehouse by Google Cloud that enables super-fast SQL queries using the processing power of Google's infrastructure. In StackAI workflows, the BigQuery node allows you to connect, query, and interact with your Google BigQuery datasets directly from your automated flows.\n\n* * *\n\n## \n\nHow to Use the BigQuery Node\n\nThe BigQuery node in StackAI is designed to execute SQL queries on your Google BigQuery database. It can be used to retrieve, analyze, and process large datasets as part of your workflow automation. You can connect this node to other nodes to automate data-driven tasks, reporting, or trigger downstream actions based on query results.\n\n* * *\n\n## \n\nExample of Usage\n\nSuppose you want to retrieve sales data for the last month from your BigQuery database and use it in a report. You would configure the BigQuery node with your SQL query, connect your Google Cloud credentials, and pass the results to a reporting or output node.\n\n* * *\n\n## \n\nAvailable Actions for BigQuery\n\n### \n\n1\\. Database Query (BigQuery)\n\n**Description:** Run a SQL query against your Google BigQuery database and retrieve the results for use in your workflow.\n\n#### \n\nInputs\n\nInput Name\n\nDescription\n\nRequired\n\nExample\n\nThe SQL query to execute on your BigQuery database.\n\nSELECT \\* FROM sales WHERE date > '2025-06-01'\n\nOptional parameters for parameterized queries.\n\nShowing 1-2 of 2 items\n\n#### \n\nConfigurations\n\nConfiguration Name\n\nDescription\n\nRequired\n\nExample\n\nThe ID of your Google BigQuery connection (credentials).\n\nThe Google Cloud project ID where your BigQuery dataset resides.\n\nThe BigQuery dataset ID to query.\n\nThe location of your BigQuery dataset (e.g., ,US,, ,EU,).\n\nShowing 1-4 of 4 items\n\n#### \n\nOutputs\n\nOutput Name\n\nDescription\n\nRequired\n\nExample\n\nThe rows returned by your SQL query, as a list of records.\n\n\\[{\"date\": \"2025-06-01\", \"total\": 1000}, ...\\]\n\nThe number of rows returned by the query.\n\nThe schema of the returned data (column names and types).\n\n\\[{\"name\": \"date\", \"type\": \"DATE\"}, ...\\]\n\nShowing 1-3 of 3 items\n\n* * *\n\n## \n\nExample Configuration\n\n```\n{\n  \"action_id\": \"database_query_bigquery\",\n  \"action_configurations\": {\n    \"connection_id\": \"bq-connection-12345\",\n    \"project_id\": \"my-gcp-project\",\n    \"dataset_id\": \"sales_data\",\n    \"location\": \"US\"\n  },\n  \"action_input_parameters\": {\n    \"query\": \"SELECT * FROM sales WHERE date > '2025-06-01'\",\n    \"parameters\": {}\n  }\n}\n```\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/box","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/box","loadedTime":"2025-10-17T18:30:13.787Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/box","title":"Box | StackAI","description":"Comprehensive guide to the Box integration in StackAI: discover key actions, input/output details, and best practices for automating file and folder management.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Box | StackAI"},{"property":"og:description","content":"Comprehensive guide to the Box integration in StackAI: discover key actions, input/output details, and best practices for automating file and folder management."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"941","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901ddad19f9ec03-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:13 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::c9dh4-1760725813328-50a963541383"}},"screenshotUrl":null,"text":"Box | StackAI\nComprehensive guide to the Box integration in StackAI: discover key actions, input/output details, and best practices for automating file and folder management.\nWhat is Box?\nBox is a leading cloud content management and file sharing service for businesses. The Box integration in StackAI allows you to automate, manage, and interact with your Box files, folders, metadata, and user permissions directly within your workflows. This enables seamless collaboration, secure file storage, and efficient document handling without leaving the StackAI platform.\nHow to use it?\nTo use the Box integration in StackAI, add the Box node to your workflow. You can then select from a wide range of actions to interact with your Box account, such as uploading files, managing folders, sharing documents, and handling metadata. Each action can be configured with specific inputs and settings to match your automation needs.\nExample of Usage\nScenario: Automatically upload a file to a specific Box folder when a new document is generated in your workflow.\nAdd the Box node to your StackAI workflow.\nSelect the \"Upload File\" action.\nConfigure the required inputs:\nfile (Required): The file to upload (e.g., from a previous node).\nparent_folder_id (Required): The ID of the Box folder where the file will be uploaded.\nOptionally, set configurations such as connection ID for authentication.\nUse the output (uploaded file details) in downstream nodes for further processing or notifications.\nMost Commonly Used Actions in Box\nBelow are the most frequently used Box actions in StackAI, along with their input, configuration, and output details:\n1. Upload File\nDescription: Uploads a file to a specified folder in your Box account.\nInputs:\nfile (Required): The file object or path to upload.\nparent_folder_id (Required): The ID of the destination folder in Box.\nname (Optional): The name for the uploaded file.\nConfigurations:\nconnection_id (Required): Your Box connection for authentication.\nOutputs:\nid: The unique ID of the uploaded file.\nname: The name of the uploaded file.\ncreated_at: Timestamp of file creation.\nmodified_at: Timestamp of last modification.\nsize: File size in bytes.\nExample:\n{ \"file\": \"{doc-0}\", \"parent_folder_id\": \"123456789\", \"name\": \"report.pdf\" }\n2. Download File\nDescription: Downloads a file from Box using its file ID.\nInputs:\nfile_id (Required): The ID of the file to download.\nConfigurations:\nconnection_id (Required): Your Box connection for authentication.\nOutputs:\nfile_content: The binary content of the downloaded file.\nExample:\n{ \"file_id\": \"987654321\" }\n3. Create Folder\nDescription: Creates a new folder in a specified parent folder.\nInputs:\nname (Required): The name of the new folder.\nparent_folder_id (Required): The ID of the parent folder.\nConfigurations:\nconnection_id (Required): Your Box connection for authentication.\nOutputs:\nid: The unique ID of the new folder.\nname: The name of the new folder.\nExample:\n{ \"name\": \"Project Files\", \"parent_folder_id\": \"123456789\" }\n4. List Folder Items\nDescription: Lists all items (files and folders) within a specified folder.\nInputs:\nfolder_id (Required): The ID of the folder to list items from.\nConfigurations:\nconnection_id (Required): Your Box connection for authentication.\nOutputs:\nentries: Array of items (files/folders) in the folder.\ntotal_count: Total number of items.\nExample:\n{ \"folder_id\": \"123456789\" }\nDescription: Generates a shared link for a file or folder.\nInputs:\nfile_id or folder_id (Required): The ID of the file or folder to share.\naccess (Optional): Access level (e.g., \"open\", \"company\", \"collaborators\").\nConfigurations:\nconnection_id (Required): Your Box connection for authentication.\nOutputs:\nshared_link: The generated URL for sharing.\nExample:\n{ \"file_id\": \"987654321\", \"access\": \"open\" }\nLast updated 3 months ago","markdown":"# Box | StackAI\n\nComprehensive guide to the Box integration in StackAI: discover key actions, input/output details, and best practices for automating file and folder management.\n\n## \n\nWhat is Box?\n\nBox is a leading cloud content management and file sharing service for businesses. The Box integration in StackAI allows you to automate, manage, and interact with your Box files, folders, metadata, and user permissions directly within your workflows. This enables seamless collaboration, secure file storage, and efficient document handling without leaving the StackAI platform.\n\n* * *\n\n## \n\nHow to use it?\n\nTo use the Box integration in StackAI, add the Box node to your workflow. You can then select from a wide range of actions to interact with your Box account, such as uploading files, managing folders, sharing documents, and handling metadata. Each action can be configured with specific inputs and settings to match your automation needs.\n\n* * *\n\n## \n\nExample of Usage\n\n**Scenario:** Automatically upload a file to a specific Box folder when a new document is generated in your workflow.\n\n1.  Add the Box node to your StackAI workflow.\n    \n2.  Select the \"Upload File\" action.\n    \n3.  Configure the required inputs:\n    \n    *   **file** (Required): The file to upload (e.g., from a previous node).\n        \n    *   **parent\\_folder\\_id** (Required): The ID of the Box folder where the file will be uploaded.\n        \n    \n4.  Optionally, set configurations such as connection ID for authentication.\n    \n5.  Use the output (uploaded file details) in downstream nodes for further processing or notifications.\n    \n\n* * *\n\n## \n\nMost Commonly Used Actions in Box\n\nBelow are the most frequently used Box actions in StackAI, along with their input, configuration, and output details:\n\n* * *\n\n### \n\n1\\. Upload File\n\n**Description:** Uploads a file to a specified folder in your Box account.\n\n**Inputs:**\n\n*   **file** (Required): The file object or path to upload.\n    \n*   **parent\\_folder\\_id** (Required): The ID of the destination folder in Box.\n    \n*   **name** (Optional): The name for the uploaded file.\n    \n\n**Configurations:**\n\n*   **connection\\_id** (Required): Your Box connection for authentication.\n    \n\n**Outputs:**\n\n*   **id**: The unique ID of the uploaded file.\n    \n*   **name**: The name of the uploaded file.\n    \n*   **created\\_at**: Timestamp of file creation.\n    \n*   **modified\\_at**: Timestamp of last modification.\n    \n*   **size**: File size in bytes.\n    \n\n**Example:**\n\n```\n{\n  \"file\": \"{doc-0}\",\n  \"parent_folder_id\": \"123456789\",\n  \"name\": \"report.pdf\"\n}\n```\n\n* * *\n\n### \n\n2\\. Download File\n\n**Description:** Downloads a file from Box using its file ID.\n\n**Inputs:**\n\n*   **file\\_id** (Required): The ID of the file to download.\n    \n\n**Configurations:**\n\n*   **connection\\_id** (Required): Your Box connection for authentication.\n    \n\n**Outputs:**\n\n*   **file\\_content**: The binary content of the downloaded file.\n    \n\n**Example:**\n\n```\n{\n  \"file_id\": \"987654321\"\n}\n```\n\n* * *\n\n### \n\n3\\. Create Folder\n\n**Description:** Creates a new folder in a specified parent folder.\n\n**Inputs:**\n\n*   **name** (Required): The name of the new folder.\n    \n*   **parent\\_folder\\_id** (Required): The ID of the parent folder.\n    \n\n**Configurations:**\n\n*   **connection\\_id** (Required): Your Box connection for authentication.\n    \n\n**Outputs:**\n\n*   **id**: The unique ID of the new folder.\n    \n*   **name**: The name of the new folder.\n    \n\n**Example:**\n\n```\n{\n  \"name\": \"Project Files\",\n  \"parent_folder_id\": \"123456789\"\n}\n```\n\n* * *\n\n### \n\n4\\. List Folder Items\n\n**Description:** Lists all items (files and folders) within a specified folder.\n\n**Inputs:**\n\n*   **folder\\_id** (Required): The ID of the folder to list items from.\n    \n\n**Configurations:**\n\n*   **connection\\_id** (Required): Your Box connection for authentication.\n    \n\n**Outputs:**\n\n*   **entries**: Array of items (files/folders) in the folder.\n    \n*   **total\\_count**: Total number of items.\n    \n\n**Example:**\n\n```\n{\n  \"folder_id\": \"123456789\"\n}\n```\n\n* * *\n\n**Description:** Generates a shared link for a file or folder.\n\n**Inputs:**\n\n*   **file\\_id** or **folder\\_id** (Required): The ID of the file or folder to share.\n    \n*   **access** (Optional): Access level (e.g., \"open\", \"company\", \"collaborators\").\n    \n\n**Configurations:**\n\n*   **connection\\_id** (Required): Your Box connection for authentication.\n    \n\n**Outputs:**\n\n*   **shared\\_link**: The generated URL for sharing.\n    \n\n**Example:**\n\n```\n{\n  \"file_id\": \"987654321\",\n  \"access\": \"open\"\n}\n```\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/crunchbase","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/crunchbase","loadedTime":"2025-10-17T18:30:14.783Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/crunchbase","title":"Crunchbase | StackAI","description":"Discover how to use the Crunchbase node in StackAI to search for company and investment data, including required inputs, configurations, and output examples.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Crunchbase | StackAI"},{"property":"og:description","content":"Discover how to use the Crunchbase node in StackAI to search for company and investment data, including required inputs, configurations, and output examples."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"107","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901ddb4af0a81ca-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:14 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::hvwls-1760725814581-476dcc1353f9"}},"screenshotUrl":null,"text":"Crunchbase | StackAI\nDiscover how to use the Crunchbase node in StackAI to search for company and investment data, including required inputs, configurations, and output examples.\nWhat is Crunchbase?\nThe Crunchbase node in StackAI allows you to access and search company and investment data directly from Crunchbase. This integration is ideal for workflows that require up-to-date business intelligence, company profiles, or investment research.\nHow to use it?\nTo use the Crunchbase node, simply add it to your StackAI workflow and configure the search parameters. You can specify your search query, the number of results you want, and the country to focus your search. The node will return structured results with company or investment information.\nExample of Usage\nSuppose you want to find information about \"OpenAI\" in the United States and retrieve the top 5 results:\nQuery: \"OpenAI\" (required)\nTop K: 5 (optional, default is 10)\nCountry: \"US\" (optional, default is \"US\")\nThe node will return a list of results, each containing a title and a text summary.\nAvailable Actions\n1. Crunchbase Search\nDescription: Searches Crunchbase for companies, investments, or related data based on your query.\nInputs\nName\nDescription\nRequired\nExample Value\nConfigurations\nName\nDescription\nRequired\nDefault\nExample Value\nThe number of results to return\nCountry Options: AR, AU, AT, BE, BR, CA, CL, CN, CO, CZ, DK, FI, FR, DE, HK, IN, ID, IT, JP, KR, MY, MX, NL, NZ, NO, PH, PL, PT, RU, SA, SG, ZA, ES, SE, CH, TW, TH, TR, GB, US\nOutputs\nName\nDescription\nRequired\nExample Value\nThe query that was used to search Crunchbase\nThe results of the Crunchbase search\nEach result object contains:\nTitle (required): The title of the Crunchbase result (e.g., \"OpenAI, Inc.\")\nText (required): The text content or summary of the result (e.g., \"OpenAI is an AI research and deployment company...\")\nExample Output\n{ \"query\": \"OpenAI\", \"search_results\": [ { \"title\": \"OpenAI, Inc.\", \"text\": \"OpenAI is an AI research and deployment company based in San Francisco, CA...\" }, { \"title\": \"OpenAI LP\", \"text\": \"OpenAI LP operates as a limited partnership for AI research and development...\" } // ...more results ] }\nLast updated 3 months ago","markdown":"# Crunchbase | StackAI\n\nDiscover how to use the Crunchbase node in StackAI to search for company and investment data, including required inputs, configurations, and output examples.\n\n**What is Crunchbase?**\n\nThe Crunchbase node in StackAI allows you to access and search company and investment data directly from Crunchbase. This integration is ideal for workflows that require up-to-date business intelligence, company profiles, or investment research.\n\n* * *\n\n**How to use it?**\n\nTo use the Crunchbase node, simply add it to your StackAI workflow and configure the search parameters. You can specify your search query, the number of results you want, and the country to focus your search. The node will return structured results with company or investment information.\n\n* * *\n\n**Example of Usage**\n\nSuppose you want to find information about \"OpenAI\" in the United States and retrieve the top 5 results:\n\n*   **Query:** \"OpenAI\" (required)\n    \n*   **Top K:** 5 (optional, default is 10)\n    \n*   **Country:** \"US\" (optional, default is \"US\")\n    \n\nThe node will return a list of results, each containing a title and a text summary.\n\n* * *\n\n**Available Actions**\n\n#### \n\n1\\. Crunchbase Search\n\n**Description:** Searches Crunchbase for companies, investments, or related data based on your query.\n\n**Inputs**\n\nName\n\nDescription\n\nRequired\n\nExample Value\n\n**Configurations**\n\nName\n\nDescription\n\nRequired\n\nDefault\n\nExample Value\n\nThe number of results to return\n\n*   **Country Options:** AR, AU, AT, BE, BR, CA, CL, CN, CO, CZ, DK, FI, FR, DE, HK, IN, ID, IT, JP, KR, MY, MX, NL, NZ, NO, PH, PL, PT, RU, SA, SG, ZA, ES, SE, CH, TW, TH, TR, GB, US\n    \n\n**Outputs**\n\nName\n\nDescription\n\nRequired\n\nExample Value\n\nThe query that was used to search Crunchbase\n\nThe results of the Crunchbase search\n\nEach result object contains:\n\n*   **Title** (required): The title of the Crunchbase result (e.g., \"OpenAI, Inc.\")\n    \n*   **Text** (required): The text content or summary of the result (e.g., \"OpenAI is an AI research and deployment company...\")\n    \n\n* * *\n\n**Example Output**\n\n```\n{\n  \"query\": \"OpenAI\",\n  \"search_results\": [\n    {\n      \"title\": \"OpenAI, Inc.\",\n      \"text\": \"OpenAI is an AI research and deployment company based in San Francisco, CA...\"\n    },\n    {\n      \"title\": \"OpenAI LP\",\n      \"text\": \"OpenAI LP operates as a limited partnership for AI research and development...\"\n    }\n    // ...more results\n  ]\n}\n```\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/coda","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/coda","loadedTime":"2025-10-17T18:30:14.734Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/coda","title":"Coda | StackAI","description":"Comprehensive guide to the Coda node in StackAI: discover top actions, input/output details, and practical usage examples for seamless Coda automation.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Coda | StackAI"},{"property":"og:description","content":"Comprehensive guide to the Coda node in StackAI: discover top actions, input/output details, and practical usage examples for seamless Coda automation."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"107","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901ddb49be9d705-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:14 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::ql5w6-1760725814546-eff0917db92a"}},"screenshotUrl":null,"text":"Coda | StackAI\nComprehensive guide to the Coda node in StackAI: discover top actions, input/output details, and practical usage examples for seamless Coda automation.\nWhat is the Coda Node?\nThe Coda node in StackAI enables seamless integration with Coda, allowing you to automate document management, data updates, and workflow actions directly within your StackAI flows. With this node, you can create, update, and manage Coda docs, pages, tables, and rows, streamlining your business processes and boosting productivity.\nHow to Use the Coda Node?\nTo use the Coda node, simply add it to your StackAI workflow and select the desired action. Connect your Coda account using a valid connection ID, then configure the required inputs and settings for your chosen action. The node will execute the action and return the results, which can be used in downstream nodes for further automation.\nExample of Usage\nSuppose you want to add a new row to a Coda table whenever a new lead is captured. You would use the \"Upsert Rows\" action, provide the required Doc ID, Table ID, and row data, and connect the output to your reporting or notification nodes.\nMost Commonly Used Actions in the Coda Node\nBelow are the most popular and useful Coda actions available in StackAI, along with detailed input, configuration, and output explanations:\n1. List Docs\nDescription: Retrieve a list of all Coda docs accessible to your account.\nConfigurations:\nconnection_id (Required): Your Coda connection ID.\nOutputs:\ndocs: Array of document objects, each containing doc ID, name, and other metadata.\nExample:\n{ \"action_configurations\": { \"connection_id\": \"<your-coda-connection-id>\" }, \"action_input_parameters\": {} }\n2. Create Doc\nDescription: Create a new Coda document.\nInputs:\ntitle (Required): The name of the new document.\nConfigurations:\nconnection_id (Required): Your Coda connection ID.\nOutputs:\ndoc_id: The unique ID of the created document.\nname: The name of the document.\nExample:\n{ \"action_configurations\": { \"connection_id\": \"<your-coda-connection-id>\" }, \"action_input_parameters\": { \"title\": \"Project Plan\" } }\n3. List Tables\nDescription: List all tables in a specified Coda doc.\nInputs:\ndoc_id (Required): The ID of the Coda document.\nConfigurations:\nconnection_id (Required): Your Coda connection ID.\nOutputs:\ntables: Array of table objects with table IDs and names.\nExample:\n{ \"action_configurations\": { \"connection_id\": \"<your-coda-connection-id>\" }, \"action_input_parameters\": { \"doc_id\": \"abc123\" } }\n4. Upsert Rows\nDescription: Add or update rows in a Coda table.\nInputs:\ndoc_id (Required): The ID of the Coda document.\ntable_id (Required): The ID of the table within the document.\nrows (Required): Array of row objects to insert or update.\nConfigurations:\nconnection_id (Required): Your Coda connection ID.\nOutputs:\nrow_ids: Array of IDs for the upserted rows.\nExample:\n{ \"action_configurations\": { \"connection_id\": \"<your-coda-connection-id>\" }, \"action_input_parameters\": { \"doc_id\": \"abc123\", \"table_id\": \"table456\", \"rows\": [{ \"Name\": \"John Doe\", \"Email\": \"[email protected]\" }] } }\n5. Get Row\nDescription: Retrieve a specific row from a Coda table.\nInputs:\ndoc_id (Required): The ID of the Coda document.\ntable_id (Required): The ID of the table.\nrow_id (Required): The ID of the row to retrieve.\nConfigurations:\nconnection_id (Required): Your Coda connection ID.\nOutputs:\nrow: Object containing the row data.\nExample:\n{ \"action_configurations\": { \"connection_id\": \"<your-coda-connection-id>\" }, \"action_input_parameters\": { \"doc_id\": \"abc123\", \"table_id\": \"table456\", \"row_id\": \"row789\" } }\nLast updated 3 months ago","markdown":"# Coda | StackAI\n\nComprehensive guide to the Coda node in StackAI: discover top actions, input/output details, and practical usage examples for seamless Coda automation.\n\n**What is the Coda Node?**\n\nThe Coda node in StackAI enables seamless integration with Coda, allowing you to automate document management, data updates, and workflow actions directly within your StackAI flows. With this node, you can create, update, and manage Coda docs, pages, tables, and rows, streamlining your business processes and boosting productivity.\n\n* * *\n\n**How to Use the Coda Node?**\n\nTo use the Coda node, simply add it to your StackAI workflow and select the desired action. Connect your Coda account using a valid connection ID, then configure the required inputs and settings for your chosen action. The node will execute the action and return the results, which can be used in downstream nodes for further automation.\n\n* * *\n\n**Example of Usage**\n\nSuppose you want to add a new row to a Coda table whenever a new lead is captured. You would use the \"Upsert Rows\" action, provide the required Doc ID, Table ID, and row data, and connect the output to your reporting or notification nodes.\n\n* * *\n\n**Most Commonly Used Actions in the Coda Node**\n\nBelow are the most popular and useful Coda actions available in StackAI, along with detailed input, configuration, and output explanations:\n\n* * *\n\n#### \n\n1\\. List Docs\n\n**Description:** Retrieve a list of all Coda docs accessible to your account.\n\n*   **Configurations:**\n    \n    *   **connection\\_id** (Required): Your Coda connection ID.\n        \n    \n*   **Outputs:**\n    \n    *   **docs**: Array of document objects, each containing doc ID, name, and other metadata.\n        \n    \n\n**Example:**\n\n```\n{\n  \"action_configurations\": { \"connection_id\": \"<your-coda-connection-id>\" },\n  \"action_input_parameters\": {}\n}\n```\n\n* * *\n\n#### \n\n2\\. Create Doc\n\n**Description:** Create a new Coda document.\n\n*   **Inputs:**\n    \n    *   **title** (Required): The name of the new document.\n        \n    \n*   **Configurations:**\n    \n    *   **connection\\_id** (Required): Your Coda connection ID.\n        \n    \n*   **Outputs:**\n    \n    *   **doc\\_id**: The unique ID of the created document.\n        \n    *   **name**: The name of the document.\n        \n    \n\n**Example:**\n\n```\n{\n  \"action_configurations\": { \"connection_id\": \"<your-coda-connection-id>\" },\n  \"action_input_parameters\": { \"title\": \"Project Plan\" }\n}\n```\n\n* * *\n\n#### \n\n3\\. List Tables\n\n**Description:** List all tables in a specified Coda doc.\n\n*   **Inputs:**\n    \n    *   **doc\\_id** (Required): The ID of the Coda document.\n        \n    \n*   **Configurations:**\n    \n    *   **connection\\_id** (Required): Your Coda connection ID.\n        \n    \n*   **Outputs:**\n    \n    *   **tables**: Array of table objects with table IDs and names.\n        \n    \n\n**Example:**\n\n```\n{\n  \"action_configurations\": { \"connection_id\": \"<your-coda-connection-id>\" },\n  \"action_input_parameters\": { \"doc_id\": \"abc123\" }\n}\n```\n\n* * *\n\n#### \n\n4\\. Upsert Rows\n\n**Description:** Add or update rows in a Coda table.\n\n*   **Inputs:**\n    \n    *   **doc\\_id** (Required): The ID of the Coda document.\n        \n    *   **table\\_id** (Required): The ID of the table within the document.\n        \n    *   **rows** (Required): Array of row objects to insert or update.\n        \n    \n*   **Configurations:**\n    \n    *   **connection\\_id** (Required): Your Coda connection ID.\n        \n    \n*   **Outputs:**\n    \n    *   **row\\_ids**: Array of IDs for the upserted rows.\n        \n    \n\n**Example:**\n\n```\n{\n  \"action_configurations\": { \"connection_id\": \"<your-coda-connection-id>\" },\n  \"action_input_parameters\": {\n    \"doc_id\": \"abc123\",\n    \"table_id\": \"table456\",\n    \"rows\": [{ \"Name\": \"John Doe\", \"Email\": \"[email protected]\" }]\n  }\n}\n```\n\n* * *\n\n#### \n\n5\\. Get Row\n\n**Description:** Retrieve a specific row from a Coda table.\n\n*   **Inputs:**\n    \n    *   **doc\\_id** (Required): The ID of the Coda document.\n        \n    *   **table\\_id** (Required): The ID of the table.\n        \n    *   **row\\_id** (Required): The ID of the row to retrieve.\n        \n    \n*   **Configurations:**\n    \n    *   **connection\\_id** (Required): Your Coda connection ID.\n        \n    \n*   **Outputs:**\n    \n    *   **row**: Object containing the row data.\n        \n    \n\n**Example:**\n\n```\n{\n  \"action_configurations\": { \"connection_id\": \"<your-coda-connection-id>\" },\n  \"action_input_parameters\": {\n    \"doc_id\": \"abc123\",\n    \"table_id\": \"table456\",\n    \"row_id\": \"row789\"\n  }\n}\n```\n\n* * *\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/clickup","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/clickup","loadedTime":"2025-10-17T18:30:14.866Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/clickup","title":"Clickup | StackAI","description":"Comprehensive guide to the Clickup node in StackAI: discover top actions, input/output details, and practical usage examples for seamless Clickup automation.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Clickup | StackAI"},{"property":"og:description","content":"Comprehensive guide to the Clickup node in StackAI: discover top actions, input/output details, and practical usage examples for seamless Clickup automation."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"107","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901ddb49e81ae7d-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:14 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::25smf-1760725814539-9867bb78db7c"}},"screenshotUrl":null,"text":"Clickup | StackAI\nComprehensive guide to the Clickup node in StackAI: discover top actions, input/output details, and practical usage examples for seamless Clickup automation.\nWhat is Clickup?\nThe Clickup node in StackAI enables seamless integration with your Clickup workspace, allowing you to automate project management tasks such as creating tasks, updating lists, managing comments, and more. This node connects StackAI workflows directly to Clickup, streamlining your productivity and collaboration.\nHow to use it?\nTo use the Clickup node, add it to your StackAI workflow and select the desired action. Configure the required inputs and connection settings, referencing other nodes as needed. You can automate task creation, update project details, manage comments, and more, all within your workflow.\nExample of Usage\nSuppose you want to automatically create a new task in Clickup when a form is submitted. Connect the form input node to the Clickup node, select the \"Create Task\" action, and map the form fields to the required Clickup task fields. When the workflow runs, a new task will be created in your Clickup workspace with the provided details.\nMost Commonly Used Actions in Clickup\nBelow are the most popular and practical Clickup actions available in StackAI, along with their input, configuration, and output details:\n1. Create Task\nDescription: Automatically create a new task in a specified Clickup list.\nInputs:\nlist_id (Required): The ID of the Clickup list where the task will be created.\nname (Required): The name/title of the task.\ndescription (Optional): Detailed description of the task.\nassignees (Optional): Array of user IDs to assign the task to.\nstatus (Optional): The status of the task (e.g., \"to do\", \"in progress\").\npriority (Optional): Priority level (1-4).\ndue_date (Optional): Due date in timestamp format.\nConfigurations:\nconnection_id (Required): Your Clickup connection ID for authentication.\nOutputs:\ntask_id: The unique ID of the created task.\ntask_url: Direct URL to the new task.\nstatus: Confirmation of task creation.\nExample:\n{ \"action_input_parameters\": { \"list_id\": \"123456\", \"name\": \"Review Project Proposal\", \"description\": \"Review the new project proposal submitted by the team.\", \"assignees\": [\"78910\"], \"status\": \"to do\", \"priority\": 2 }, \"action_configurations\": { \"connection_id\": \"<your_clickup_connection_id>\" } }\n2. Update Task\nDescription: Update details of an existing task in Clickup.\nInputs:\ntask_id (Required): The ID of the task to update.\nname (Optional): New name/title for the task.\ndescription (Optional): Updated description.\nstatus (Optional): New status.\npriority (Optional): Updated priority.\nassignees (Optional): Updated list of assignees.\nConfigurations:\nconnection_id (Required): Your Clickup connection ID.\nOutputs:\ntask_id: The ID of the updated task.\nstatus: Confirmation of update.\nExample:\n{ \"action_input_parameters\": { \"task_id\": \"654321\", \"status\": \"in progress\" }, \"action_configurations\": { \"connection_id\": \"<your_clickup_connection_id>\" } }\n3. Get Task\nDescription: Retrieve details of a specific task from Clickup.\nInputs:\ntask_id (Required): The ID of the task to retrieve.\nConfigurations:\nconnection_id (Required): Your Clickup connection ID.\nOutputs:\ntask: Full details of the task (name, description, status, assignees, etc.).\nExample:\n{ \"action_input_parameters\": { \"task_id\": \"654321\" }, \"action_configurations\": { \"connection_id\": \"<your_clickup_connection_id>\" } }\n4. Create Task Comment\nDescription: Add a comment to a specific task in Clickup.\nInputs:\ntask_id (Required): The ID of the task to comment on.\ncomment_text (Required): The content of the comment.\nConfigurations:\nconnection_id (Required): Your Clickup connection ID.\nOutputs:\ncomment_id: The ID of the created comment.\nstatus: Confirmation of comment creation.\nExample:\n{ \"action_input_parameters\": { \"task_id\": \"654321\", \"comment_text\": \"Please review the latest updates.\" }, \"action_configurations\": { \"connection_id\": \"<your_clickup_connection_id>\" } }\n5. Get Lists\nDescription: Retrieve all lists within a specified Clickup folder or space.\nInputs:\nfolder_id (Optional): The ID of the folder to retrieve lists from.\nspace_id (Optional): The ID of the space to retrieve lists from.\nConfigurations:\nconnection_id (Required): Your Clickup connection ID.\nOutputs:\nlists: Array of lists with details (list_id, name, status, etc.).\nExample:\n{ \"action_input_parameters\": { \"space_id\": \"987654\" }, \"action_configurations\": { \"connection_id\": \"<your_clickup_connection_id>\" } }\nLast updated 3 months ago","markdown":"# Clickup | StackAI\n\nComprehensive guide to the Clickup node in StackAI: discover top actions, input/output details, and practical usage examples for seamless Clickup automation.\n\n**What is Clickup?**\n\nThe Clickup node in StackAI enables seamless integration with your Clickup workspace, allowing you to automate project management tasks such as creating tasks, updating lists, managing comments, and more. This node connects StackAI workflows directly to Clickup, streamlining your productivity and collaboration.\n\n* * *\n\n**How to use it?**\n\nTo use the Clickup node, add it to your StackAI workflow and select the desired action. Configure the required inputs and connection settings, referencing other nodes as needed. You can automate task creation, update project details, manage comments, and more, all within your workflow.\n\n* * *\n\n**Example of Usage**\n\nSuppose you want to automatically create a new task in Clickup when a form is submitted. Connect the form input node to the Clickup node, select the \"Create Task\" action, and map the form fields to the required Clickup task fields. When the workflow runs, a new task will be created in your Clickup workspace with the provided details.\n\n* * *\n\n**Most Commonly Used Actions in Clickup**\n\nBelow are the most popular and practical Clickup actions available in StackAI, along with their input, configuration, and output details:\n\n* * *\n\n#### \n\n1\\. Create Task\n\n**Description:** Automatically create a new task in a specified Clickup list.\n\n**Inputs:**\n\n*   **list\\_id** (Required): The ID of the Clickup list where the task will be created.\n    \n*   **name** (Required): The name/title of the task.\n    \n*   **description** (Optional): Detailed description of the task.\n    \n*   **assignees** (Optional): Array of user IDs to assign the task to.\n    \n*   **status** (Optional): The status of the task (e.g., \"to do\", \"in progress\").\n    \n*   **priority** (Optional): Priority level (1-4).\n    \n*   **due\\_date** (Optional): Due date in timestamp format.\n    \n\n**Configurations:**\n\n*   **connection\\_id** (Required): Your Clickup connection ID for authentication.\n    \n\n**Outputs:**\n\n*   **task\\_id**: The unique ID of the created task.\n    \n*   **task\\_url**: Direct URL to the new task.\n    \n*   **status**: Confirmation of task creation.\n    \n\n**Example:**\n\n```\n{\n  \"action_input_parameters\": {\n    \"list_id\": \"123456\",\n    \"name\": \"Review Project Proposal\",\n    \"description\": \"Review the new project proposal submitted by the team.\",\n    \"assignees\": [\"78910\"],\n    \"status\": \"to do\",\n    \"priority\": 2\n  },\n  \"action_configurations\": {\n    \"connection_id\": \"<your_clickup_connection_id>\"\n  }\n}\n```\n\n* * *\n\n#### \n\n2\\. Update Task\n\n**Description:** Update details of an existing task in Clickup.\n\n**Inputs:**\n\n*   **task\\_id** (Required): The ID of the task to update.\n    \n*   **name** (Optional): New name/title for the task.\n    \n*   **description** (Optional): Updated description.\n    \n*   **status** (Optional): New status.\n    \n*   **priority** (Optional): Updated priority.\n    \n*   **assignees** (Optional): Updated list of assignees.\n    \n\n**Configurations:**\n\n*   **connection\\_id** (Required): Your Clickup connection ID.\n    \n\n**Outputs:**\n\n*   **task\\_id**: The ID of the updated task.\n    \n*   **status**: Confirmation of update.\n    \n\n**Example:**\n\n```\n{\n  \"action_input_parameters\": {\n    \"task_id\": \"654321\",\n    \"status\": \"in progress\"\n  },\n  \"action_configurations\": {\n    \"connection_id\": \"<your_clickup_connection_id>\"\n  }\n}\n```\n\n* * *\n\n#### \n\n3\\. Get Task\n\n**Description:** Retrieve details of a specific task from Clickup.\n\n**Inputs:**\n\n*   **task\\_id** (Required): The ID of the task to retrieve.\n    \n\n**Configurations:**\n\n*   **connection\\_id** (Required): Your Clickup connection ID.\n    \n\n**Outputs:**\n\n*   **task**: Full details of the task (name, description, status, assignees, etc.).\n    \n\n**Example:**\n\n```\n{\n  \"action_input_parameters\": {\n    \"task_id\": \"654321\"\n  },\n  \"action_configurations\": {\n    \"connection_id\": \"<your_clickup_connection_id>\"\n  }\n}\n```\n\n* * *\n\n#### \n\n4\\. Create Task Comment\n\n**Description:** Add a comment to a specific task in Clickup.\n\n**Inputs:**\n\n*   **task\\_id** (Required): The ID of the task to comment on.\n    \n*   **comment\\_text** (Required): The content of the comment.\n    \n\n**Configurations:**\n\n*   **connection\\_id** (Required): Your Clickup connection ID.\n    \n\n**Outputs:**\n\n*   **comment\\_id**: The ID of the created comment.\n    \n*   **status**: Confirmation of comment creation.\n    \n\n**Example:**\n\n```\n{\n  \"action_input_parameters\": {\n    \"task_id\": \"654321\",\n    \"comment_text\": \"Please review the latest updates.\"\n  },\n  \"action_configurations\": {\n    \"connection_id\": \"<your_clickup_connection_id>\"\n  }\n}\n```\n\n* * *\n\n#### \n\n5\\. Get Lists\n\n**Description:** Retrieve all lists within a specified Clickup folder or space.\n\n**Inputs:**\n\n*   **folder\\_id** (Optional): The ID of the folder to retrieve lists from.\n    \n*   **space\\_id** (Optional): The ID of the space to retrieve lists from.\n    \n\n**Configurations:**\n\n*   **connection\\_id** (Required): Your Clickup connection ID.\n    \n\n**Outputs:**\n\n*   **lists**: Array of lists with details (list\\_id, name, status, etc.).\n    \n\n**Example:**\n\n```\n{\n  \"action_input_parameters\": {\n    \"space_id\": \"987654\"\n  },\n  \"action_configurations\": {\n    \"connection_id\": \"<your_clickup_connection_id>\"\n  }\n}\n```\n\n* * *\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/databricks","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/databricks","loadedTime":"2025-10-17T18:30:14.962Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/databricks","title":"Databricks | StackAI","description":"Learn how to use the Databricks node in StackAI to run analytics and machine learning queries. See required inputs, configurations, and output examples.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Databricks | StackAI"},{"property":"og:description","content":"Learn how to use the Databricks node in StackAI to run analytics and machine learning queries. See required inputs, configurations, and output examples."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"107","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901ddb4acd97f82-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:14 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::2bkfz-1760725814572-21106cf93769"}},"screenshotUrl":null,"text":"Databricks | StackAI\nLearn how to use the Databricks node in StackAI to run analytics and machine learning queries. See required inputs, configurations, and output examples.\nWhat is Databricks?\nThe Databricks node in StackAI allows you to query a Databricks workspace for data analytics and machine learning. It translates plain English or SQL queries into actionable database operations, returning both the executed SQL and the results.\nHow to make a Databricks Connection?\nLogin to Databricks, the Workspace URL is illustrated below:\nIn this example dbc-003abf48-15.cloud.databricks.com is the Workspace URL \nTo get your Personal Access Token:\nClick on your Profile in the upper right\nThen click on Settings\nUnder Users, click on Developer\nThen in this menu, click on Manage\nHow to use it?\nAdd the Databricks node to your StackAI workflow.\nProvide the required database schema and your query (in plain English or SQL).\nConnect the node to downstream nodes to process or display the results.\nExample of Usage\nSuppose you want to find the total revenue for 2024 from your sales table:\nSchema Example:\nTABLE Sales (OrderID INT, Customer STRING, Revenue DOUBLE, Year INT);\nQuery Example:\nWhat is the total revenue for the year 2024?\nAvailable Actions\n1. Query a Databricks Workspace\nDescription: Run analytics or machine learning queries on your Databricks database using natural language or SQL.\nInputs\nSchema (sql_schema)\nType: Array of strings (textarea)\nRequired: Yes\nDescription: The database schema, including tables, columns, and types.\nExample:\nTABLE Sales (OrderID INT, Customer STRING, Revenue DOUBLE, Year INT);\nQuery (query)\nType: String\nRequired: Yes\nDescription: The question or command you want to run, in plain English or SQL.\nExample:\nWhat is the total revenue for the year 2024?\nConfigurations\nNo additional configurations are required for this action.\nOutputs\nQuery (sql_query)\nType: String\nRequired: Yes\nDescription: The SQL query that was executed.\nExample:\nSELECT SUM(Revenue) FROM Sales WHERE Year = 2024;\nResults (results)\nType: Array of objects\nRequired: Yes\nDescription: The results returned from the Databricks query.\nExample:\n[ { \"SUM(Revenue)\": 1250000 } ]\nSummary Table\nField\nType\nRequired\nDescription\nExample\nDatabase schema (tables, columns, types, etc.)\nTABLE Sales (OrderID INT, Revenue DOUBLE);\nQuery in plain English or SQL\nWhat is the total revenue for 2024?\nThe SQL query that was executed\nSELECT SUM(Revenue) FROM Sales WHERE ...\nResults of the Databricks query\n[{ \"SUM(Revenue)\": 1250000 }]\nBest Practices\nAlways provide a clear and complete schema for accurate query translation.\nUse natural language for ease, or SQL for precision.\nReview the returned SQL to ensure it matches your intent.\nUse the Databricks node in StackAI to seamlessly integrate advanced analytics and machine learning queries into your automated workflows.","markdown":"# Databricks | StackAI\n\nLearn how to use the Databricks node in StackAI to run analytics and machine learning queries. See required inputs, configurations, and output examples.\n\n**What is Databricks?**\n\nThe Databricks node in StackAI allows you to query a Databricks workspace for data analytics and machine learning. It translates plain English or SQL queries into actionable database operations, returning both the executed SQL and the results.\n\n* * *\n\n**How to make a Databricks Connection?**\n\n*   Login to Databricks, the Workspace URL is illustrated below:\n    \n    *   In this example `dbc-003abf48-15.cloud.databricks.com` is the Workspace URL\n        \n    \n*   To get your Personal Access Token:\n    \n    1.  Click on your Profile in the upper right\n        \n    2.  Then click on Settings\n        \n    \n*   Under Users, click on Developer\n    \n*   Then in this menu, click on Manage\n    \n\n* * *\n\n**How to use it?**\n\n1.  Add the Databricks node to your StackAI workflow.\n    \n2.  Provide the required database schema and your query (in plain English or SQL).\n    \n3.  Connect the node to downstream nodes to process or display the results.\n    \n\n* * *\n\n**Example of Usage**\n\nSuppose you want to find the total revenue for 2024 from your sales table:\n\n*   **Schema Example:**\n    \n    ```\n    TABLE Sales (OrderID INT, Customer STRING, Revenue DOUBLE, Year INT);\n    ```\n    \n*   **Query Example:**\n    \n    ```\n    What is the total revenue for the year 2024?\n    ```\n    \n\n* * *\n\n**Available Actions**\n\n#### \n\n1\\. Query a Databricks Workspace\n\n**Description:** Run analytics or machine learning queries on your Databricks database using natural language or SQL.\n\n**Inputs**\n\n*   **Schema (sql\\_schema)**\n    \n    *   **Type:** Array of strings (textarea)\n        \n    *   **Required:** Yes\n        \n    *   **Description:** The database schema, including tables, columns, and types.\n        \n    *   **Example:**\n        \n        ```\n        TABLE Sales (OrderID INT, Customer STRING, Revenue DOUBLE, Year INT);\n        ```\n        \n    \n*   **Query (query)**\n    \n    *   **Type:** String\n        \n    *   **Required:** Yes\n        \n    *   **Description:** The question or command you want to run, in plain English or SQL.\n        \n    *   **Example:**\n        \n        ```\n        What is the total revenue for the year 2024?\n        ```\n        \n    \n\n**Configurations**\n\n*   No additional configurations are required for this action.\n    \n\n**Outputs**\n\n*   **Query (sql\\_query)**\n    \n    *   **Type:** String\n        \n    *   **Required:** Yes\n        \n    *   **Description:** The SQL query that was executed.\n        \n    *   **Example:**\n        \n        ```\n        SELECT SUM(Revenue) FROM Sales WHERE Year = 2024;\n        ```\n        \n    \n*   **Results (results)**\n    \n    *   **Type:** Array of objects\n        \n    *   **Required:** Yes\n        \n    *   **Description:** The results returned from the Databricks query.\n        \n    *   **Example:**\n        \n        ```\n        [\n          { \"SUM(Revenue)\": 1250000 }\n        ]\n        ```\n        \n    \n\n* * *\n\n**Summary Table**\n\nField\n\nType\n\nRequired\n\nDescription\n\nExample\n\nDatabase schema (tables, columns, types, etc.)\n\nTABLE Sales (OrderID INT, Revenue DOUBLE);\n\nQuery in plain English or SQL\n\nWhat is the total revenue for 2024?\n\nThe SQL query that was executed\n\nSELECT SUM(Revenue) FROM Sales WHERE ...\n\nResults of the Databricks query\n\n\\[{ \"SUM(Revenue)\": 1250000 }\\]\n\n* * *\n\n**Best Practices**\n\n*   Always provide a clear and complete schema for accurate query translation.\n    \n*   Use natural language for ease, or SQL for precision.\n    \n*   Review the returned SQL to ensure it matches your intent.\n    \n\n* * *\n\nUse the Databricks node in StackAI to seamlessly integrate advanced analytics and machine learning queries into your automated workflows.","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/e2b","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/e2b","loadedTime":"2025-10-17T18:30:15.276Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/e2b","title":"E2B | StackAI","description":"Learn how to use the E2B node in StackAI to execute code in a secure, sandboxed environment. Discover available actions, input/output details, and best practices.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"E2B | StackAI"},{"property":"og:description","content":"Learn how to use the E2B node in StackAI to execute code in a secure, sandboxed environment. Discover available actions, input/output details, and best practices."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"96","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901ddb7eaeb34a5-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:15 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::zpr9d-1760725815061-1d24fe762a06"}},"screenshotUrl":null,"text":"E2B | StackAI\nLearn how to use the E2B node in StackAI to execute code in a secure, sandboxed environment. Discover available actions, input/output details, and best practices.\nWhat is E2B?\nThe E2B node in StackAI allows you to execute code in a secure, sandboxed environment. This is ideal for running scripts, automating tasks, or processing data without exposing your main system to risk. E2B is designed for flexibility, supporting a wide range of coding and automation scenarios.\nHow to Use the E2B Node\nTo use the E2B node, add it to your StackAI workflow and configure it to execute your desired code. You can pass inputs from other nodes, specify code to run, and retrieve outputs for further processing. E2B is especially useful for custom logic, data transformation, or integrating with APIs not natively supported by StackAI.\nExample of Usage\nSuppose you want to process user input, run a Python script, and return the result:\nAdd an Input node to collect user data.\nConnect the Input node to the E2B node.\nIn the E2B node, specify the code you want to execute, referencing the input as needed.\nConnect the E2B node to an Output node to display the result.\nAvailable Actions for E2B\nBelow are the most commonly used actions for the E2B node:\n1. Run Code (run_code_e2b)\nDescription: Executes custom code in a sandboxed environment and returns the output.\nInputs\nName\nDescription\nRequired\nExample\nThe code to execute (string)\nProgramming language (string)\nInput variables (object/dictionary)\nShowing 1-3 of 3 items\nConfigurations\nName\nDescription\nRequired\nExample\nConnection ID for E2B (if required)\nShowing 1-1 of 1 items\nOutputs\nName\nDescription\nRequired\nExample\nOutput of the executed code\nError message (if execution fails)\nShowing 1-3 of 3 items\nExample\nInput:\n{ \"code\": \"return x + y\", \"language\": \"python\", \"inputs\": {\"x\": 5, \"y\": 10} }\nOutput:\n{ \"result\": 15, \"logs\": \"\", \"error\": null }\nBest Practices\nAlways validate your code before running to avoid errors.\nUse input variables to make your code reusable and dynamic.\nCheck the output and error fields to handle execution results gracefully.\nFor sensitive or resource-intensive tasks, ensure your code is optimized and secure.\nSummary\nThe E2B node in StackAI is a powerful tool for executing custom code securely within your workflows. By leveraging its flexible input and output options, you can automate complex tasks, process data, and extend StackAI’s capabilities to fit your unique needs.\nLast updated 3 months ago","markdown":"# E2B | StackAI\n\nLearn how to use the E2B node in StackAI to execute code in a secure, sandboxed environment. Discover available actions, input/output details, and best practices.\n\n## \n\nWhat is E2B?\n\nThe E2B node in StackAI allows you to execute code in a secure, sandboxed environment. This is ideal for running scripts, automating tasks, or processing data without exposing your main system to risk. E2B is designed for flexibility, supporting a wide range of coding and automation scenarios.\n\n* * *\n\n## \n\nHow to Use the E2B Node\n\nTo use the E2B node, add it to your StackAI workflow and configure it to execute your desired code. You can pass inputs from other nodes, specify code to run, and retrieve outputs for further processing. E2B is especially useful for custom logic, data transformation, or integrating with APIs not natively supported by StackAI.\n\n* * *\n\n## \n\nExample of Usage\n\nSuppose you want to process user input, run a Python script, and return the result:\n\n1.  Add an Input node to collect user data.\n    \n2.  Connect the Input node to the E2B node.\n    \n3.  In the E2B node, specify the code you want to execute, referencing the input as needed.\n    \n4.  Connect the E2B node to an Output node to display the result.\n    \n\n* * *\n\n## \n\nAvailable Actions for E2B\n\nBelow are the most commonly used actions for the E2B node:\n\n### \n\n1\\. Run Code (run\\_code\\_e2b)\n\n**Description:** Executes custom code in a sandboxed environment and returns the output.\n\n#### \n\nInputs\n\nName\n\nDescription\n\nRequired\n\nExample\n\nThe code to execute (string)\n\nProgramming language (string)\n\nInput variables (object/dictionary)\n\nShowing 1-3 of 3 items\n\n#### \n\nConfigurations\n\nName\n\nDescription\n\nRequired\n\nExample\n\nConnection ID for E2B (if required)\n\nShowing 1-1 of 1 items\n\n#### \n\nOutputs\n\nName\n\nDescription\n\nRequired\n\nExample\n\nOutput of the executed code\n\nError message (if execution fails)\n\nShowing 1-3 of 3 items\n\n**Example**\n\n**Input:**\n\n```\n{\n  \"code\": \"return x + y\",\n  \"language\": \"python\",\n  \"inputs\": {\"x\": 5, \"y\": 10}\n}\n```\n\n**Output:**\n\n```\n{\n  \"result\": 15,\n  \"logs\": \"\",\n  \"error\": null\n}\n```\n\n* * *\n\n## \n\nBest Practices\n\n*   Always validate your code before running to avoid errors.\n    \n*   Use input variables to make your code reusable and dynamic.\n    \n*   Check the output and error fields to handle execution results gracefully.\n    \n*   For sensitive or resource-intensive tasks, ensure your code is optimized and secure.\n    \n\n* * *\n\n## \n\nSummary\n\nThe E2B node in StackAI is a powerful tool for executing custom code securely within your workflows. By leveraging its flexible input and output options, you can automate complex tasks, process data, and extend StackAI’s capabilities to fit your unique needs.\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/excel","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/excel","loadedTime":"2025-10-17T18:30:16.205Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/excel","title":"Excel | StackAI","description":"Comprehensive guide to the Excel node in StackAI: Learn how to automate spreadsheet tasks, write data, and integrate Excel with your workflows.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Excel | StackAI"},{"property":"og:description","content":"Comprehensive guide to the Excel node in StackAI: Learn how to automate spreadsheet tasks, write data, and integrate Excel with your workflows."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"74","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901ddbdfb35d705-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:16 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::qtkmj-1760725816022-17b6851774d3"}},"screenshotUrl":null,"text":"Excel | StackAI\nComprehensive guide to the Excel node in StackAI: Learn how to automate spreadsheet tasks, write data, and integrate Excel with your workflows.\nHow to Use the Excel Node\nTo use the Excel node, simply add it to your StackAI workflow and configure it to perform actions such as writing data to a spreadsheet. You can connect it to other nodes (like LLMs, input nodes, or data sources) to automate the flow of information into your Excel files. The node supports secure authentication via connection IDs, ensuring your data remains protected.\nExample of Usage\nSuppose you want to automatically log survey responses from a form into an Excel spreadsheet stored in SharePoint. You can connect the input node (collecting responses) to the Excel node, which then writes each new entry into the designated spreadsheet, eliminating manual data entry.\nAvailable Actions for the Excel Node\nBelow are the most commonly used actions for the Excel node in StackAI:\n1. Write to Sheet\nDescription: Automatically writes data to a specified Excel sheet in SharePoint.\nInputs\nThe unique ID of the Excel spreadsheet\nThe name of the sheet/tab to write to\nThe data to write (array of objects/rows)\nThe cell range to write data (e.g., A1:D10)\nShowing 1-4 of 4 items\nExample Input:\n{ \"spreadsheet_id\": \"abc123\", \"sheet_name\": \"Responses\", \"data\": [ {\"Name\": \"John Doe\", \"Email\": \"[email protected]\", \"Score\": 95} ], \"range\": \"A2:C2\" }\nConfigurations\nThe connection ID for SharePoint/Excel\nShowing 1-1 of 1 items\nExample Configuration:\n{ \"connection_id\": \"your-connection-id-here\" }\nOutputs\nBoolean indicating if the write was successful\nThe range that was updated\nError message if the operation failed\nShowing 1-3 of 3 items\nExample Output:\n{ \"success\": true, \"updated_range\": \"A2:C2\" }\nBest Practices\nAlways ensure your connection ID is valid and has the necessary permissions to access the target Excel file.\nValidate your data structure before writing to avoid errors.\nUse dynamic node references (e.g., {in-0}) to automate data flow from other nodes.\nSummary\nThe Excel node in StackAI is a powerful tool for automating spreadsheet operations in SharePoint. By leveraging its write capabilities, you can streamline data management, reduce manual work, and enhance collaboration across your team.","markdown":"# Excel | StackAI\n\nComprehensive guide to the Excel node in StackAI: Learn how to automate spreadsheet tasks, write data, and integrate Excel with your workflows.\n\n## \n\nHow to Use the Excel Node\n\nTo use the Excel node, simply add it to your StackAI workflow and configure it to perform actions such as writing data to a spreadsheet. You can connect it to other nodes (like LLMs, input nodes, or data sources) to automate the flow of information into your Excel files. The node supports secure authentication via connection IDs, ensuring your data remains protected.\n\n* * *\n\n## \n\nExample of Usage\n\nSuppose you want to automatically log survey responses from a form into an Excel spreadsheet stored in SharePoint. You can connect the input node (collecting responses) to the Excel node, which then writes each new entry into the designated spreadsheet, eliminating manual data entry.\n\n* * *\n\n## \n\nAvailable Actions for the Excel Node\n\nBelow are the most commonly used actions for the Excel node in StackAI:\n\n### \n\n1\\. Write to Sheet\n\n**Description:** Automatically writes data to a specified Excel sheet in SharePoint.\n\n#### \n\nInputs\n\nThe unique ID of the Excel spreadsheet\n\nThe name of the sheet/tab to write to\n\nThe data to write (array of objects/rows)\n\nThe cell range to write data (e.g., A1:D10)\n\nShowing 1-4 of 4 items\n\n**Example Input:**\n\n```\n{\n  \"spreadsheet_id\": \"abc123\",\n  \"sheet_name\": \"Responses\",\n  \"data\": [\n    {\"Name\": \"John Doe\", \"Email\": \"[email protected]\", \"Score\": 95}\n  ],\n  \"range\": \"A2:C2\"\n}\n```\n\n#### \n\nConfigurations\n\nThe connection ID for SharePoint/Excel\n\nShowing 1-1 of 1 items\n\n**Example Configuration:**\n\n```\n{\n  \"connection_id\": \"your-connection-id-here\"\n}\n```\n\n#### \n\nOutputs\n\nBoolean indicating if the write was successful\n\nThe range that was updated\n\nError message if the operation failed\n\nShowing 1-3 of 3 items\n\n**Example Output:**\n\n```\n{\n  \"success\": true,\n  \"updated_range\": \"A2:C2\"\n}\n```\n\n* * *\n\n## \n\nBest Practices\n\n*   Always ensure your connection ID is valid and has the necessary permissions to access the target Excel file.\n    \n*   Validate your data structure before writing to avoid errors.\n    \n*   Use dynamic node references (e.g., {in-0}) to automate data flow from other nodes.\n    \n\n* * *\n\n## \n\nSummary\n\nThe Excel node in StackAI is a powerful tool for automating spreadsheet operations in SharePoint. By leveraging its write capabilities, you can streamline data management, reduce manual work, and enhance collaboration across your team.","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/firecrawl","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/firecrawl","loadedTime":"2025-10-17T18:30:18.112Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/firecrawl","title":"Firecrawl | StackAI","description":"Comprehensive guide to the Firecrawl node in StackAI: discover its most common actions, input requirements, configurations, and output examples for seamless web data extraction.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Firecrawl | StackAI"},{"property":"og:description","content":"Comprehensive guide to the Firecrawl node in StackAI: discover its most common actions, input requirements, configurations, and output examples for seamless web data extraction."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"76","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901ddc6281ed88a-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:17 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::5zwdl-1760725817338-af72fd4caa69"}},"screenshotUrl":null,"text":"Firecrawl | StackAI\nComprehensive guide to the Firecrawl node in StackAI: discover its most common actions, input requirements, configurations, and output examples for seamless web data extraction.\nWhat is Firecrawl?\nFirecrawl is a powerful integration within StackAI that enables automated web data extraction, web scraping, and content retrieval from websites. It is designed to help users gather structured or unstructured data from web pages, making it ideal for research, monitoring, and automation workflows.\nHow to use it?\nTo use the Firecrawl node in StackAI, simply add the node to your workflow and select the desired action. Configure the required inputs and settings based on your use case. Firecrawl supports a variety of actions, from scraping a single URL to crawling entire websites or searching for specific content. Connect the node to downstream nodes to process or analyze the extracted data.\nExample of Usage\nSuppose you want to extract the main content from a specific web page. You would use the \"Scrape from URL\" action, provide the target URL as input, and receive the extracted text and metadata as output. This data can then be used for further analysis, summarization, or storage.\nFirecrawl: Most Common Actions\nBelow are the most commonly used Firecrawl actions in StackAI, along with detailed explanations, input requirements, configurations, and output examples.\n1. Scrape from URL\nDescription: Extracts the main content, metadata, and structure from a single web page.\nInputs:\nurl (Required): The full URL of the web page to scrape. Example: \"https://example.com/article\"\nConfigurations:\nNone required for basic usage.\nOutputs:\ncontent (Always returned): The main text content of the page.\nmetadata (Always returned): Information such as title, description, and author.\nstructure (Optional): Structured representation of the page (e.g., headings, sections).\nExample:\n{ \"content\": \"This is the main article text...\", \"metadata\": { \"title\": \"Example Article\", \"description\": \"A sample article for demonstration.\", \"author\": \"Jane Doe\" }, \"structure\": { \"headings\": [\"Introduction\", \"Main Content\", \"Conclusion\"] } }\n2. Web Scrape\nDescription: Performs advanced scraping with options for custom selectors, extracting specific elements or data points from a web page.\nInputs:\nurl (Required): The target web page URL.\nselectors (Optional): CSS selectors or XPath expressions to target specific elements. Example: [\".article-title\", \".author-name\"]\nConfigurations:\nNone required for basic usage.\nOutputs:\nresults (Always returned): An array of extracted elements or data points.\nExample:\n{ \"results\": [ {\"selector\": \".article-title\", \"value\": \"Example Article\"}, {\"selector\": \".author-name\", \"value\": \"Jane Doe\"} ] }\n3. Batch Scrape\nDescription: Scrapes multiple URLs in a single request, ideal for bulk data extraction.\nInputs:\nurls (Required): An array of URLs to scrape. Example: [\"https://site1.com\", \"https://site2.com\"]\nConfigurations:\nNone required for basic usage.\nOutputs:\nresults (Always returned): An array of objects, each containing the content and metadata for a URL.\nExample:\n{ \"results\": [ { \"url\": \"https://site1.com\", \"content\": \"Content from site 1...\", \"metadata\": {\"title\": \"Site 1\"} }, { \"url\": \"https://site2.com\", \"content\": \"Content from site 2...\", \"metadata\": {\"title\": \"Site 2\"} } ] }\n4. Crawl Website\nDescription: Automatically crawls a website, following links to extract content from multiple pages.\nInputs:\nstart_url (Required): The starting URL for the crawl.\nmax_depth (Optional): How many link levels deep to crawl (default is 1). Example: 2\nConfigurations:\nNone required for basic usage.\nOutputs:\npages (Always returned): An array of page objects, each with content and metadata.\nExample:\n{ \"pages\": [ { \"url\": \"https://example.com/page1\", \"content\": \"Page 1 content...\", \"metadata\": {\"title\": \"Page 1\"} }, { \"url\": \"https://example.com/page2\", \"content\": \"Page 2 content...\", \"metadata\": {\"title\": \"Page 2\"} } ] }\n5. Search\nDescription: Searches a website or a set of pages for specific keywords or patterns.\nInputs:\nurl (Required): The base URL to search.\nquery (Required): The keyword or pattern to search for. Example: \"AI automation\"\nConfigurations:\nNone required for basic usage.\nOutputs:\nmatches (Always returned): An array of search results with context.\nExample:\n{ \"matches\": [ { \"url\": \"https://example.com/page1\", \"snippet\": \"AI automation is transforming industries...\" } ] }\nSummary Table: Firecrawl Actions\nAction\nRequired Inputs\nConfigurations\nOutputs\ncontent, metadata, structure\nstart_url, max_depth(opt.)\nLast updated 3 months ago","markdown":"# Firecrawl | StackAI\n\nComprehensive guide to the Firecrawl node in StackAI: discover its most common actions, input requirements, configurations, and output examples for seamless web data extraction.\n\n**What is Firecrawl?**\n\nFirecrawl is a powerful integration within StackAI that enables automated web data extraction, web scraping, and content retrieval from websites. It is designed to help users gather structured or unstructured data from web pages, making it ideal for research, monitoring, and automation workflows.\n\n* * *\n\n**How to use it?**\n\nTo use the Firecrawl node in StackAI, simply add the node to your workflow and select the desired action. Configure the required inputs and settings based on your use case. Firecrawl supports a variety of actions, from scraping a single URL to crawling entire websites or searching for specific content. Connect the node to downstream nodes to process or analyze the extracted data.\n\n* * *\n\n**Example of Usage**\n\nSuppose you want to extract the main content from a specific web page. You would use the \"Scrape from URL\" action, provide the target URL as input, and receive the extracted text and metadata as output. This data can then be used for further analysis, summarization, or storage.\n\n* * *\n\n**Firecrawl: Most Common Actions**\n\nBelow are the most commonly used Firecrawl actions in StackAI, along with detailed explanations, input requirements, configurations, and output examples.\n\n* * *\n\n#### \n\n1\\. Scrape from URL\n\n**Description:** Extracts the main content, metadata, and structure from a single web page.\n\n**Inputs:**\n\n*   **url** (Required): The full URL of the web page to scrape. _Example:_ `\"https://example.com/article\"`\n    \n\n**Configurations:**\n\n*   None required for basic usage.\n    \n\n**Outputs:**\n\n*   **content** (Always returned): The main text content of the page.\n    \n*   **metadata** (Always returned): Information such as title, description, and author.\n    \n*   **structure** (Optional): Structured representation of the page (e.g., headings, sections).\n    \n\n**Example:**\n\n```\n{\n  \"content\": \"This is the main article text...\",\n  \"metadata\": {\n    \"title\": \"Example Article\",\n    \"description\": \"A sample article for demonstration.\",\n    \"author\": \"Jane Doe\"\n  },\n  \"structure\": {\n    \"headings\": [\"Introduction\", \"Main Content\", \"Conclusion\"]\n  }\n}\n```\n\n* * *\n\n#### \n\n2\\. Web Scrape\n\n**Description:** Performs advanced scraping with options for custom selectors, extracting specific elements or data points from a web page.\n\n**Inputs:**\n\n*   **url** (Required): The target web page URL.\n    \n*   **selectors** (Optional): CSS selectors or XPath expressions to target specific elements. _Example:_ `[\".article-title\", \".author-name\"]`\n    \n\n**Configurations:**\n\n*   None required for basic usage.\n    \n\n**Outputs:**\n\n*   **results** (Always returned): An array of extracted elements or data points.\n    \n\n**Example:**\n\n```\n{\n  \"results\": [\n    {\"selector\": \".article-title\", \"value\": \"Example Article\"},\n    {\"selector\": \".author-name\", \"value\": \"Jane Doe\"}\n  ]\n}\n```\n\n* * *\n\n#### \n\n3\\. Batch Scrape\n\n**Description:** Scrapes multiple URLs in a single request, ideal for bulk data extraction.\n\n**Inputs:**\n\n*   **urls** (Required): An array of URLs to scrape. _Example:_ `[\"https://site1.com\", \"https://site2.com\"]`\n    \n\n**Configurations:**\n\n*   None required for basic usage.\n    \n\n**Outputs:**\n\n*   **results** (Always returned): An array of objects, each containing the content and metadata for a URL.\n    \n\n**Example:**\n\n```\n{\n  \"results\": [\n    {\n      \"url\": \"https://site1.com\",\n      \"content\": \"Content from site 1...\",\n      \"metadata\": {\"title\": \"Site 1\"}\n    },\n    {\n      \"url\": \"https://site2.com\",\n      \"content\": \"Content from site 2...\",\n      \"metadata\": {\"title\": \"Site 2\"}\n    }\n  ]\n}\n```\n\n* * *\n\n#### \n\n4\\. Crawl Website\n\n**Description:** Automatically crawls a website, following links to extract content from multiple pages.\n\n**Inputs:**\n\n*   **start\\_url** (Required): The starting URL for the crawl.\n    \n*   **max\\_depth** (Optional): How many link levels deep to crawl (default is 1). _Example:_ `2`\n    \n\n**Configurations:**\n\n*   None required for basic usage.\n    \n\n**Outputs:**\n\n*   **pages** (Always returned): An array of page objects, each with content and metadata.\n    \n\n**Example:**\n\n```\n{\n  \"pages\": [\n    {\n      \"url\": \"https://example.com/page1\",\n      \"content\": \"Page 1 content...\",\n      \"metadata\": {\"title\": \"Page 1\"}\n    },\n    {\n      \"url\": \"https://example.com/page2\",\n      \"content\": \"Page 2 content...\",\n      \"metadata\": {\"title\": \"Page 2\"}\n    }\n  ]\n}\n```\n\n* * *\n\n#### \n\n5\\. Search\n\n**Description:** Searches a website or a set of pages for specific keywords or patterns.\n\n**Inputs:**\n\n*   **url** (Required): The base URL to search.\n    \n*   **query** (Required): The keyword or pattern to search for. _Example:_ `\"AI automation\"`\n    \n\n**Configurations:**\n\n*   None required for basic usage.\n    \n\n**Outputs:**\n\n*   **matches** (Always returned): An array of search results with context.\n    \n\n**Example:**\n\n```\n{\n  \"matches\": [\n    {\n      \"url\": \"https://example.com/page1\",\n      \"snippet\": \"AI automation is transforming industries...\"\n    }\n  ]\n}\n```\n\n* * *\n\n**Summary Table: Firecrawl Actions**\n\nAction\n\nRequired Inputs\n\nConfigurations\n\nOutputs\n\ncontent, metadata, structure\n\nstart\\_url, max\\_depth(opt.)\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/gdocs","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/gdocs","loadedTime":"2025-10-17T18:30:18.394Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/gdocs","title":"GDocs | StackAI","description":"Learn how to automate Google Docs creation in StackAI: create new documents, set file names, add content, and organize in folders with easy integration.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"GDocs | StackAI"},{"property":"og:description","content":"Learn how to automate Google Docs creation in StackAI: create new documents, set file names, add content, and organize in folders with easy integration."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"77","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901ddcb181f1972-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:18 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::ph5ck-1760725818135-4608f30f0c95"}},"screenshotUrl":null,"text":"GDocs | StackAI\nLearn how to automate Google Docs creation in StackAI: create new documents, set file names, add content, and organize in folders with easy integration.\nGDocs in StackAI allows you to automate the creation of Google Docs directly from your workflow. The GDocs Node integration streamlines document generation, making it easy to create, organize, and access Google Docs using dynamic data and AI-powered content.\nHow to use it?\nTo use the GDocs node, connect it in your StackAI workflow where you want to generate a new Google Doc. You can specify the document’s name, content (in Markdown), and optionally the folder where it should be stored in your Google Drive. The node will output the document’s unique ID and a direct link to open it.\nExample of Usage\nSuppose you want to generate a project report automatically after processing some data. You can use the GDocs node to create a new document titled \"Project Report\" with the body content generated by an LLM node, and save it in a specific Google Drive folder.\nAvailable Actions\n1. Create Google Doc\nDescription: Creates a new Google Doc with specified content and file name, optionally placing it in a chosen Google Drive folder.\nInputs:\nFile Name (Required):\nType: String\nDescription: Name of the Word document to create.\nExample: \"Project Report\"\nContent (Required):\nType: String (Markdown)\nDescription: Document body text in Markdown format.\nExample: \"## Executive Summary\\nThis report covers...\"\nFolder ID (Optional):\nType: String\nDescription: Google Drive folder ID where the file will be created. Leave blank to create in My Drive.\nExample: \"1A2B3C4D5E6F\"\nConfigurations: No additional configurations are required for this action.\nOutputs:\nFile ID (Required):\nType: String\nDescription: Unique identifier of the created Google Doc.\nExample: \"1x2y3z4w5v6u\"\nFile URL (Required):\nType: String\nDescription: URL to open the document in Google Drive.\nExample: \"https://docs.google.com/document/d/1x2y3z4w5v6u/edit\"\nExample Workflow Step\nSet up an LLM node to generate a summary.\nConnect the LLM output to the GDocs node’s Content input.\nSet File Name to \"Weekly Summary\".\n(Optional) Provide a Folder ID to organize the document.\nThe GDocs node will output a File ID and a File URL for immediate access.\nSummary Table\nInput Name\nRequired\nType\nDescription\nExample\nDocument body in Markdown\n\"## Executive Summary...\"\nGoogle Drive folder ID (optional)\nOutput Name\nRequired\nType\nDescription\nExample\nUnique identifier of the created Google Doc\nURL to open the document in Google Drive\n\",https://docs.google.com/,...\"\nNote: To use this node, ensure your StackAI workspace is connected to Google Drive with the necessary permissions. Use the Folder ID to organize documents as needed, or leave it blank to save in your main Drive.\nLast updated 2 months ago","markdown":"# GDocs | StackAI\n\nLearn how to automate Google Docs creation in StackAI: create new documents, set file names, add content, and organize in folders with easy integration.\n\nGDocs in StackAI allows you to automate the creation of Google Docs directly from your workflow. The **GDocs Node** integration streamlines document generation, making it easy to create, organize, and access Google Docs using dynamic data and AI-powered content.\n\n* * *\n\n**How to use it?**\n\nTo use the GDocs node, connect it in your StackAI workflow where you want to generate a new Google Doc. You can specify the document’s name, content (in Markdown), and optionally the folder where it should be stored in your Google Drive. The node will output the document’s unique ID and a direct link to open it.\n\n* * *\n\n**Example of Usage**\n\nSuppose you want to generate a project report automatically after processing some data. You can use the GDocs node to create a new document titled \"Project Report\" with the body content generated by an LLM node, and save it in a specific Google Drive folder.\n\n* * *\n\n**Available Actions**\n\n#### \n\n1\\. Create Google Doc\n\n**Description:** Creates a new Google Doc with specified content and file name, optionally placing it in a chosen Google Drive folder.\n\n**Inputs:**\n\n*   **File Name** (Required):\n    \n    *   Type: String\n        \n    *   Description: Name of the Word document to create.\n        \n    *   Example: `\"Project Report\"`\n        \n    \n*   **Content** (Required):\n    \n    *   Type: String (Markdown)\n        \n    *   Description: Document body text in Markdown format.\n        \n    *   Example: `\"## Executive Summary\\nThis report covers...\"`\n        \n    \n*   **Folder ID** (Optional):\n    \n    *   Type: String\n        \n    *   Description: Google Drive folder ID where the file will be created. Leave blank to create in My Drive.\n        \n    *   Example: `\"1A2B3C4D5E6F\"`\n        \n    \n\n**Configurations:** No additional configurations are required for this action.\n\n**Outputs:**\n\n*   **File ID** (Required):\n    \n    *   Type: String\n        \n    *   Description: Unique identifier of the created Google Doc.\n        \n    *   Example: `\"1x2y3z4w5v6u\"`\n        \n    \n*   **File URL** (Required):\n    \n    *   Type: String\n        \n    *   Description: URL to open the document in Google Drive.\n        \n    *   Example: `\"https://docs.google.com/document/d/1x2y3z4w5v6u/edit\"`\n        \n    \n\n* * *\n\n**Example Workflow Step**\n\n*   Set up an LLM node to generate a summary.\n    \n*   Connect the LLM output to the GDocs node’s Content input.\n    \n*   Set File Name to \"Weekly Summary\".\n    \n*   (Optional) Provide a Folder ID to organize the document.\n    \n*   The GDocs node will output a File ID and a File URL for immediate access.\n    \n\n* * *\n\n**Summary Table**\n\nInput Name\n\nRequired\n\nType\n\nDescription\n\nExample\n\nDocument body in Markdown\n\n\"## Executive Summary...\"\n\nGoogle Drive folder ID (optional)\n\nOutput Name\n\nRequired\n\nType\n\nDescription\n\nExample\n\nUnique identifier of the created Google Doc\n\nURL to open the document in Google Drive\n\n\",https://docs.google.com/,...\"\n\n* * *\n\n**Note:** To use this node, ensure your StackAI workspace is connected to Google Drive with the necessary permissions. Use the Folder ID to organize documents as needed, or leave it blank to save in your main Drive.\n\nLast updated 2 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/fred","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/fred","loadedTime":"2025-10-17T18:30:18.691Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/fred","title":"Fred | StackAI","description":"Learn how to use the Fred node in StackAI workflows. Discover key actions, input requirements, configurations, and output examples for seamless economic data integration.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Fred | StackAI"},{"property":"og:description","content":"Learn how to use the Fred node in StackAI workflows. Discover key actions, input requirements, configurations, and output examples for seamless economic data integration."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"77","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901ddcc5c1d9682-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:18 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::5tp4q-1760725818325-d1e672b26190"}},"screenshotUrl":null,"text":"Fred | StackAI\nLearn how to use the Fred node in StackAI workflows. Discover key actions, input requirements, configurations, and output examples for seamless economic data integration.\nThe Fred Node is a powerful integration node in StackAI that connects your workflow to the Federal Reserve Economic Data (FRED) API. This enables you to access, search, and retrieve a wide range of economic data, including categories, series, releases, and tags, directly within your automated processes.\nHow to use it?\nTo use the Fred node, simply add it to your StackAI workflow and select the desired action. Each action allows you to interact with different aspects of the FRED database, such as fetching economic series, searching for categories, or retrieving release information. Configure the required inputs and parameters for each action to tailor the data retrieval to your needs.\nExample of Usage\nSuppose you want to retrieve a list of economic data series for a specific category. You would select the \"Get Category Series\" action, provide the required category ID, and optionally set filters like limit or order. The node will output a structured list of series matching your criteria.\nAvailable Actions in Fred\nBelow are the most commonly used actions in the Fred integration, along with their input, configuration, and output details:\n1. Get Category\nDescription: Retrieve information about a specific FRED category.\nInputs:\ncategory_id (Required): The unique ID of the FRED category.\nConfigurations:\nNone required.\nOutputs:\nCategory details (Required): Returns the category’s ID, name, parent ID, and notes.\nExample: Retrieve details for category_id \"125\".\n2. Get Category Children\nDescription: List all subcategories under a specific FRED category.\nInputs:\ncategory_id (Required): The unique ID of the parent category.\nConfigurations:\nNone required.\nOutputs:\nList of child categories (Required): Each with ID, name, and parent ID.\nExample: List children for category_id \"125\".\n3. Get Category Series\nDescription: Retrieve all economic data series within a specific category.\nInputs:\ncategory_id (Required): The unique ID of the category.\nlimit (Optional): Maximum number of series to return.\norder_by (Optional): Field to order results by (e.g., \"popularity\").\nsort_order (Optional): \"asc\" or \"desc\".\nConfigurations:\nNone required.\nOutputs:\nList of series (Required): Each with ID, title, frequency, units, and more.\nExample: Get up to 10 series in category_id \"125\", ordered by popularity.\n4. Get Releases\nDescription: Retrieve a list of all FRED data releases.\nInputs:\nlimit (Optional): Maximum number of releases to return.\norder_by (Optional): Field to order results by.\nsort_order (Optional): \"asc\" or \"desc\".\nConfigurations:\nNone required.\nOutputs:\nList of releases (Required): Each with ID, name, and release dates.\nExample: Get the 5 most recent releases.\n5. Get Release Info\nDescription: Retrieve detailed information about a specific FRED release.\nInputs:\nrelease_id (Required): The unique ID of the release.\nConfigurations:\nNone required.\nOutputs:\nRelease details (Required): Includes name, press release, and notes.\nExample: Get info for release_id \"53\".\n6. Get Release Series\nDescription: List all data series associated with a specific release.\nInputs:\nrelease_id (Required): The unique ID of the release.\nlimit (Optional): Maximum number of series to return.\nConfigurations:\nNone required.\nOutputs:\nList of series (Required): Each with ID, title, and frequency.\nExample: Get up to 10 series for release_id \"53\".\n7. Get Release Dates\nDescription: Retrieve all release dates for a specific FRED release.\nInputs:\nrelease_id (Required): The unique ID of the release.\nConfigurations:\nNone required.\nOutputs:\nList of release dates (Required): Each with a date and status.\nExample: Get all dates for release_id \"53\".\n8. Get Category Tags\nDescription: List all tags associated with a specific FRED category.\nInputs:\ncategory_id (Required): The unique ID of the category.\nConfigurations:\nNone required.\nOutputs:\nList of tags (Required): Each with name, group ID, and notes.\nExample: Get tags for category_id \"125\".\n9. Get Releases Sources\nDescription: List all sources for a specific FRED release.\nInputs:\nrelease_id (Required): The unique ID of the release.\nConfigurations:\nNone required.\nOutputs:\nList of sources (Required): Each with ID and name.\nExample: Get sources for release_id \"53\".\n10. Get Release Tables\nDescription: Retrieve all tables associated with a specific FRED release.\nInputs:\nrelease_id (Required): The unique ID of the release.\nConfigurations:\nNone required.\nOutputs:\nList of tables (Required): Each with ID, name, and description.\nExample: Get tables for release_id \"53\".\nSummary\nThe Fred node in StackAI provides seamless access to economic data from the FRED database. By configuring the appropriate action and supplying the required inputs, you can automate the retrieval and analysis of economic indicators, categories, releases, and more within your workflows.\nLast updated 2 months ago","markdown":"# Fred | StackAI\n\nLearn how to use the Fred node in StackAI workflows. Discover key actions, input requirements, configurations, and output examples for seamless economic data integration.\n\nThe **Fred Node** is a powerful integration node in StackAI that connects your workflow to the Federal Reserve Economic Data (FRED) API. This enables you to access, search, and retrieve a wide range of economic data, including categories, series, releases, and tags, directly within your automated processes.\n\n* * *\n\n**How to use it?**\n\nTo use the Fred node, simply add it to your StackAI workflow and select the desired action. Each action allows you to interact with different aspects of the FRED database, such as fetching economic series, searching for categories, or retrieving release information. Configure the required inputs and parameters for each action to tailor the data retrieval to your needs.\n\n* * *\n\n**Example of Usage**\n\nSuppose you want to retrieve a list of economic data series for a specific category. You would select the \"Get Category Series\" action, provide the required category ID, and optionally set filters like limit or order. The node will output a structured list of series matching your criteria.\n\n* * *\n\n**Available Actions in Fred**\n\nBelow are the most commonly used actions in the Fred integration, along with their input, configuration, and output details:\n\n* * *\n\n#### \n\n1\\. Get Category\n\n**Description:** Retrieve information about a specific FRED category.\n\n**Inputs:**\n\n*   category\\_id (Required): The unique ID of the FRED category.\n    \n\n**Configurations:**\n\n*   None required.\n    \n\n**Outputs:**\n\n*   Category details (Required): Returns the category’s ID, name, parent ID, and notes.\n    \n\n**Example:** Retrieve details for category\\_id \"125\".\n\n* * *\n\n#### \n\n2\\. Get Category Children\n\n**Description:** List all subcategories under a specific FRED category.\n\n**Inputs:**\n\n*   category\\_id (Required): The unique ID of the parent category.\n    \n\n**Configurations:**\n\n*   None required.\n    \n\n**Outputs:**\n\n*   List of child categories (Required): Each with ID, name, and parent ID.\n    \n\n**Example:** List children for category\\_id \"125\".\n\n* * *\n\n#### \n\n3\\. Get Category Series\n\n**Description:** Retrieve all economic data series within a specific category.\n\n**Inputs:**\n\n*   category\\_id (Required): The unique ID of the category.\n    \n*   limit (Optional): Maximum number of series to return.\n    \n*   order\\_by (Optional): Field to order results by (e.g., \"popularity\").\n    \n*   sort\\_order (Optional): \"asc\" or \"desc\".\n    \n\n**Configurations:**\n\n*   None required.\n    \n\n**Outputs:**\n\n*   List of series (Required): Each with ID, title, frequency, units, and more.\n    \n\n**Example:** Get up to 10 series in category\\_id \"125\", ordered by popularity.\n\n* * *\n\n#### \n\n4\\. Get Releases\n\n**Description:** Retrieve a list of all FRED data releases.\n\n**Inputs:**\n\n*   limit (Optional): Maximum number of releases to return.\n    \n*   order\\_by (Optional): Field to order results by.\n    \n*   sort\\_order (Optional): \"asc\" or \"desc\".\n    \n\n**Configurations:**\n\n*   None required.\n    \n\n**Outputs:**\n\n*   List of releases (Required): Each with ID, name, and release dates.\n    \n\n**Example:** Get the 5 most recent releases.\n\n* * *\n\n#### \n\n5\\. Get Release Info\n\n**Description:** Retrieve detailed information about a specific FRED release.\n\n**Inputs:**\n\n*   release\\_id (Required): The unique ID of the release.\n    \n\n**Configurations:**\n\n*   None required.\n    \n\n**Outputs:**\n\n*   Release details (Required): Includes name, press release, and notes.\n    \n\n**Example:** Get info for release\\_id \"53\".\n\n* * *\n\n#### \n\n6\\. Get Release Series\n\n**Description:** List all data series associated with a specific release.\n\n**Inputs:**\n\n*   release\\_id (Required): The unique ID of the release.\n    \n*   limit (Optional): Maximum number of series to return.\n    \n\n**Configurations:**\n\n*   None required.\n    \n\n**Outputs:**\n\n*   List of series (Required): Each with ID, title, and frequency.\n    \n\n**Example:** Get up to 10 series for release\\_id \"53\".\n\n* * *\n\n#### \n\n7\\. Get Release Dates\n\n**Description:** Retrieve all release dates for a specific FRED release.\n\n**Inputs:**\n\n*   release\\_id (Required): The unique ID of the release.\n    \n\n**Configurations:**\n\n*   None required.\n    \n\n**Outputs:**\n\n*   List of release dates (Required): Each with a date and status.\n    \n\n**Example:** Get all dates for release\\_id \"53\".\n\n* * *\n\n#### \n\n8\\. Get Category Tags\n\n**Description:** List all tags associated with a specific FRED category.\n\n**Inputs:**\n\n*   category\\_id (Required): The unique ID of the category.\n    \n\n**Configurations:**\n\n*   None required.\n    \n\n**Outputs:**\n\n*   List of tags (Required): Each with name, group ID, and notes.\n    \n\n**Example:** Get tags for category\\_id \"125\".\n\n* * *\n\n#### \n\n9\\. Get Releases Sources\n\n**Description:** List all sources for a specific FRED release.\n\n**Inputs:**\n\n*   release\\_id (Required): The unique ID of the release.\n    \n\n**Configurations:**\n\n*   None required.\n    \n\n**Outputs:**\n\n*   List of sources (Required): Each with ID and name.\n    \n\n**Example:** Get sources for release\\_id \"53\".\n\n* * *\n\n#### \n\n10\\. Get Release Tables\n\n**Description:** Retrieve all tables associated with a specific FRED release.\n\n**Inputs:**\n\n*   release\\_id (Required): The unique ID of the release.\n    \n\n**Configurations:**\n\n*   None required.\n    \n\n**Outputs:**\n\n*   List of tables (Required): Each with ID, name, and description.\n    \n\n**Example:** Get tables for release\\_id \"53\".\n\n* * *\n\n**Summary**\n\nThe Fred node in StackAI provides seamless access to economic data from the FRED database. By configuring the appropriate action and supplying the required inputs, you can automate the retrieval and analysis of economic indicators, categories, releases, and more within your workflows.\n\nLast updated 2 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/gmail","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/gmail","loadedTime":"2025-10-17T18:30:18.920Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/gmail","title":"Gmail | StackAI","description":"Comprehensive guide to using the Gmail node in StackAI workflows, including available actions, required inputs, configurations, and output examples.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Gmail | StackAI"},{"property":"og:description","content":"Comprehensive guide to using the Gmail node in StackAI workflows, including available actions, required inputs, configurations, and output examples."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"75","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901ddcda87157f1-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:18 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::jpgv7-1760725818580-e205402a4ccd"}},"screenshotUrl":null,"text":"Gmail | StackAI\nComprehensive guide to using the Gmail node in StackAI workflows, including available actions, required inputs, configurations, and output examples.\nThe Gmail Node in StackAI enables you to automate sending and managing emails directly through your Gmail account. This integration streamlines communication tasks, allowing you to trigger email actions within your automated workflows.\nHow to use it?\nTo use the Gmail node, connect your Gmail account using a valid connection ID. Choose the desired action (such as sending an email), provide the required input fields, and configure any optional settings. The node will execute the action and return the relevant output, which can be used in downstream workflow steps.\nExample of Usage\nSuppose you want to automatically send a notification email when a new lead is added to your CRM. You can set up a workflow where the Gmail node is triggered with the lead’s details, and an email is sent to your sales team.\nAvailable Actions\nBelow are the most commonly used actions for the Gmail node in StackAI:\n1. Send Email\nDescription: Send an email from your connected Gmail account to one or more recipients.\nInputs:\nsubject (Required): The subject line of the email. Example: \"subject\": \"Welcome to Our Service\"\nbody (Required): The main content of the email. Example: \"body\": \"Thank you for signing up!\"\ncc (Optional): Email addresses to be copied on the email. Example: \"cc\": \"[email protected]\"\nbcc (Optional): Email addresses to be blind-copied on the email. Example: \"bcc\": \"[email protected]\"\nattachments (Optional): List of file paths or file objects to attach. Example: \"attachments\": [\"/path/to/file.pdf\"]\nConfigurations:\nconnection_id (Required): The ID of your Gmail connection. Example: \"connection_id\": \"5a56b86a-c7d3-4e6a-af3f-0969d00ff9f8\"\nOutputs:\nmessage_id (Always returned): The unique ID of the sent email. Example: \"message_id\": \"17c8b2e5e8b2c1a2\"\nstatus (Always returned): The status of the email send operation. Example: \"status\": \"sent\"\n2. Search Emails\nDescription: Search for emails in your Gmail account using specific criteria.\nInputs:\nquery (Required): The search query string (Gmail search syntax). Example: \"query\": \"from:[email protected] is:unread\"\nmax_results (Optional): Maximum number of emails to return. Example: \"max_results\": 10\nConfigurations:\nconnection_id (Required): The ID of your Gmail connection.\nOutputs:\nemails (Always returned): A list of email objects matching the search criteria. Example:\n\"emails\": [ { \"subject\": \"Meeting Reminder\", \"from\": \"[email protected]\", \"date\": \"2025-07-07T10:00:00Z\", \"snippet\": \"Don't forget our meeting at 2pm.\" } ]\n3. (Optional) Additional Actions\nOther actions may be available, such as managing labels or retrieving email details. For most workflow automations, \"Send Email\" and \"Search Emails\" are the primary actions used.\nBest Practices\nAlways use a valid Gmail connection ID from your available connections.\nEnsure all required fields are provided for each action.\nUse dynamic references (e.g., from previous nodes) to personalize email content or search queries.\nAttachments should be properly formatted and accessible by the workflow.\nSummary Table\nAction\nRequired Inputs\nOptional Inputs\nRequired Configurations\nOutputs\nUse the Gmail node in StackAI to automate your email workflows, streamline communication, and enhance productivity with seamless Gmail integration.\nLast updated 2 months ago","markdown":"# Gmail | StackAI\n\nComprehensive guide to using the Gmail node in StackAI workflows, including available actions, required inputs, configurations, and output examples.\n\nThe **Gmail Node** in StackAI enables you to automate sending and managing emails directly through your Gmail account. This integration streamlines communication tasks, allowing you to trigger email actions within your automated workflows.\n\n* * *\n\n**How to use it?**\n\nTo use the Gmail node, connect your Gmail account using a valid connection ID. Choose the desired action (such as sending an email), provide the required input fields, and configure any optional settings. The node will execute the action and return the relevant output, which can be used in downstream workflow steps.\n\n* * *\n\n**Example of Usage**\n\nSuppose you want to automatically send a notification email when a new lead is added to your CRM. You can set up a workflow where the Gmail node is triggered with the lead’s details, and an email is sent to your sales team.\n\n* * *\n\n**Available Actions**\n\nBelow are the most commonly used actions for the Gmail node in StackAI:\n\n* * *\n\n#### \n\n1\\. Send Email\n\n**Description:** Send an email from your connected Gmail account to one or more recipients.\n\n**Inputs:**\n\n*   **subject** (Required): The subject line of the email. _Example:_ `\"subject\": \"Welcome to Our Service\"`\n    \n*   **body** (Required): The main content of the email. _Example:_ `\"body\": \"Thank you for signing up!\"`\n    \n*   **cc** (Optional): Email addresses to be copied on the email. _Example:_ `\"cc\": \"[[email protected]](https://docs.stack-ai.com/cdn-cgi/l/email-protection)\"`\n    \n*   **bcc** (Optional): Email addresses to be blind-copied on the email. _Example:_ `\"bcc\": \"[[email protected]](https://docs.stack-ai.com/cdn-cgi/l/email-protection)\"`\n    \n*   **attachments** (Optional): List of file paths or file objects to attach. _Example:_ `\"attachments\": [\"/path/to/file.pdf\"]`\n    \n\n**Configurations:**\n\n*   **connection\\_id** (Required): The ID of your Gmail connection. _Example:_ `\"connection_id\": \"5a56b86a-c7d3-4e6a-af3f-0969d00ff9f8\"`\n    \n\n**Outputs:**\n\n*   **message\\_id** (Always returned): The unique ID of the sent email. _Example:_ `\"message_id\": \"17c8b2e5e8b2c1a2\"`\n    \n*   **status** (Always returned): The status of the email send operation. _Example:_ `\"status\": \"sent\"`\n    \n\n* * *\n\n#### \n\n2\\. Search Emails\n\n**Description:** Search for emails in your Gmail account using specific criteria.\n\n**Inputs:**\n\n*   **query** (Required): The search query string (Gmail search syntax). _Example:_ `\"query\": \"from:[[email protected]](https://docs.stack-ai.com/cdn-cgi/l/email-protection) is:unread\"`\n    \n*   **max\\_results** (Optional): Maximum number of emails to return. _Example:_ `\"max_results\": 10`\n    \n\n**Configurations:**\n\n*   **connection\\_id** (Required): The ID of your Gmail connection.\n    \n\n**Outputs:**\n\n*   **emails** (Always returned): A list of email objects matching the search criteria. _Example:_\n    \n    ```\n    \"emails\": [\n      {\n        \"subject\": \"Meeting Reminder\",\n        \"from\": \"[email protected]\",\n        \"date\": \"2025-07-07T10:00:00Z\",\n        \"snippet\": \"Don't forget our meeting at 2pm.\"\n      }\n    ]\n    ```\n    \n\n* * *\n\n#### \n\n3\\. (Optional) Additional Actions\n\nOther actions may be available, such as managing labels or retrieving email details. For most workflow automations, \"Send Email\" and \"Search Emails\" are the primary actions used.\n\n* * *\n\n**Best Practices**\n\n*   Always use a valid Gmail connection ID from your available connections.\n    \n*   Ensure all required fields are provided for each action.\n    \n*   Use dynamic references (e.g., from previous nodes) to personalize email content or search queries.\n    \n*   Attachments should be properly formatted and accessible by the workflow.\n    \n\n* * *\n\n**Summary Table**\n\nAction\n\nRequired Inputs\n\nOptional Inputs\n\nRequired Configurations\n\nOutputs\n\n* * *\n\nUse the Gmail node in StackAI to automate your email workflows, streamline communication, and enhance productivity with seamless Gmail integration.\n\nLast updated 2 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/github","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/github","loadedTime":"2025-10-17T18:30:18.823Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/github","title":"Github | StackAI","description":"Comprehensive guide to the Github node in StackAI workflows, including key actions, input requirements, configurations, and output examples.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Github | StackAI"},{"property":"og:description","content":"Comprehensive guide to the Github node in StackAI workflows, including key actions, input requirements, configurations, and output examples."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"76","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901ddcdab3bd670-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:18 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::gz6bl-1760725818551-ad0fb5b2a341"}},"screenshotUrl":null,"text":"Github | StackAI\nComprehensive guide to the Github node in StackAI workflows, including key actions, input requirements, configurations, and output examples.\nThe Github Node in StackAI enables seamless integration with Github, allowing you to automate, query, and manage repositories, workflows, and project data directly within your workflow. This node connects your StackAI automation to Github’s powerful API, making it easy to interact with repositories, pull requests, workflows, and more.\nHow to Use It?\nTo use the Github node, add it to your StackAI workflow and select the desired action. Connect your Github account using a valid connection ID if required. Configure the action by providing the necessary input parameters and configurations. The node will execute the selected action and return the output, which can be used in downstream nodes.\nExample of Usage\nSuppose you want to list all branches in a repository. You would select the \"List Branches\" action, provide the repository owner and name as required inputs, and the node will return a list of branches.\nCommonly Used Actions in the Github Node\nBelow are some of the most commonly used Github actions available in StackAI workflows. For each action, you’ll find a description, required inputs, configurations, and example outputs.\n1. List Branches\nDescription: Retrieve a list of branches for a specified Github repository.\nInputs:\nowner (Required): The username or organization name that owns the repository. Example: \"octocat\"\nrepo (Required): The name of the repository. Example: \"Hello-World\"\nConfigurations:\nconnection_id (Required): The Github connection ID for authentication.\nOutputs:\nbranches (Required): An array of branch objects, each containing branch name and commit details.\nExample: Input:\n{ \"owner\": \"octocat\", \"repo\": \"Hello-World\" }\nOutput:\n{ \"branches\": [ { \"name\": \"main\", \"commit\": { \"sha\": \"abc123\", ... } }, { \"name\": \"dev\", \"commit\": { \"sha\": \"def456\", ... } } ] }\n2. List Commits\nDescription: Fetch a list of commits from a repository.\nInputs:\nowner (Required): Repository owner.\nrepo (Required): Repository name.\nsha (Optional): SHA or branch to start listing commits from.\nConfigurations:\nconnection_id (Required): Github connection ID.\nOutputs:\ncommits (Required): Array of commit objects with details like SHA, author, and message.\nExample: Input:\n{ \"owner\": \"octocat\", \"repo\": \"Hello-World\" }\nOutput:\n{ \"commits\": [ { \"sha\": \"abc123\", \"commit\": { \"message\": \"Initial commit\", ... } }, { \"sha\": \"def456\", \"commit\": { \"message\": \"Update README\", ... } } ] }\n3. List Pull Requests\nDescription: Retrieve all pull requests for a repository.\nInputs:\nowner (Required): Repository owner.\nrepo (Required): Repository name.\nstate (Optional): Filter by state (open, closed, all).\nConfigurations:\nconnection_id (Required): Github connection ID.\nOutputs:\npull_requests (Required): Array of pull request objects with title, state, and author.\nExample: Input:\n{ \"owner\": \"octocat\", \"repo\": \"Hello-World\", \"state\": \"open\" }\nOutput:\n{ \"pull_requests\": [ { \"number\": 1, \"title\": \"Add new feature\", \"state\": \"open\", ... } ] }\n4. Get Repository Details\nDescription: Fetch metadata and details about a specific repository.\nInputs:\nowner (Required): Repository owner.\nrepo (Required): Repository name.\nConfigurations:\nconnection_id (Required): Github connection ID.\nOutputs:\nrepository (Required): Object containing repository details such as description, stars, forks, and more.\nExample: Input:\n{ \"owner\": \"octocat\", \"repo\": \"Hello-World\" }\nOutput:\n{ \"repository\": { \"name\": \"Hello-World\", \"description\": \"This is your first repository\", \"stargazers_count\": 42, \"forks_count\": 10, ... } }\n5. List Releases\nDescription: Get a list of releases published in a repository.\nInputs:\nowner (Required): Repository owner.\nrepo (Required): Repository name.\nConfigurations:\nconnection_id (Required): Github connection ID.\nOutputs:\nreleases (Required): Array of release objects with tag name, release notes, and published date.\nExample: Input:\n{ \"owner\": \"octocat\", \"repo\": \"Hello-World\" }\nOutput:\n{ \"releases\": [ { \"tag_name\": \"v1.0.0\", \"name\": \"First Release\", ... } ] }\nBest Practices:\nAlways provide the required owner, repo, and connection_id for all actions.\nUse the output of the Github node as input for downstream nodes, such as LLMs or output nodes, to automate reporting or notifications.\nFor advanced use cases, chain multiple Github actions to build complex automations.\nSummary\nThe Github node in StackAI empowers you to automate and manage Github repositories, branches, commits, pull requests, and more. By configuring the right action and providing the necessary inputs, you can streamline your development workflows and integrate Github data into your automation pipelines.\nLast updated 2 months ago","markdown":"# Github | StackAI\n\nComprehensive guide to the Github node in StackAI workflows, including key actions, input requirements, configurations, and output examples.\n\nThe **Github Node** in StackAI enables seamless integration with Github, allowing you to automate, query, and manage repositories, workflows, and project data directly within your workflow. This node connects your StackAI automation to Github’s powerful API, making it easy to interact with repositories, pull requests, workflows, and more.\n\n* * *\n\n**How to Use It?**\n\nTo use the Github node, add it to your StackAI workflow and select the desired action. Connect your Github account using a valid connection ID if required. Configure the action by providing the necessary input parameters and configurations. The node will execute the selected action and return the output, which can be used in downstream nodes.\n\n* * *\n\n**Example of Usage**\n\nSuppose you want to list all branches in a repository. You would select the \"List Branches\" action, provide the repository owner and name as required inputs, and the node will return a list of branches.\n\n* * *\n\n**Commonly Used Actions in the Github Node**\n\nBelow are some of the most commonly used Github actions available in StackAI workflows. For each action, you’ll find a description, required inputs, configurations, and example outputs.\n\n* * *\n\n#### \n\n1\\. List Branches\n\n**Description:** Retrieve a list of branches for a specified Github repository.\n\n**Inputs:**\n\n*   `owner` (Required): The username or organization name that owns the repository. _Example:_ `_\"octocat\"_`\n    \n*   `repo` (Required): The name of the repository. _Example:_ `_\"Hello-World\"_`\n    \n\n**Configurations:**\n\n*   `connection_id` (Required): The Github connection ID for authentication.\n    \n\n**Outputs:**\n\n*   `branches` (Required): An array of branch objects, each containing branch name and commit details.\n    \n\n**Example:** _Input:_\n\n```\n{\n  \"owner\": \"octocat\",\n  \"repo\": \"Hello-World\"\n}\n```\n\n_Output:_\n\n```\n{\n  \"branches\": [\n    { \"name\": \"main\", \"commit\": { \"sha\": \"abc123\", ... } },\n    { \"name\": \"dev\", \"commit\": { \"sha\": \"def456\", ... } }\n  ]\n}\n```\n\n* * *\n\n#### \n\n2\\. List Commits\n\n**Description:** Fetch a list of commits from a repository.\n\n**Inputs:**\n\n*   `owner` (Required): Repository owner.\n    \n*   `repo` (Required): Repository name.\n    \n*   `sha` (Optional): SHA or branch to start listing commits from.\n    \n\n**Configurations:**\n\n*   `connection_id` (Required): Github connection ID.\n    \n\n**Outputs:**\n\n*   `commits` (Required): Array of commit objects with details like SHA, author, and message.\n    \n\n**Example:** _Input:_\n\n```\n{\n  \"owner\": \"octocat\",\n  \"repo\": \"Hello-World\"\n}\n```\n\n_Output:_\n\n```\n{\n  \"commits\": [\n    { \"sha\": \"abc123\", \"commit\": { \"message\": \"Initial commit\", ... } },\n    { \"sha\": \"def456\", \"commit\": { \"message\": \"Update README\", ... } }\n  ]\n}\n```\n\n* * *\n\n#### \n\n3\\. List Pull Requests\n\n**Description:** Retrieve all pull requests for a repository.\n\n**Inputs:**\n\n*   `owner` (Required): Repository owner.\n    \n*   `repo` (Required): Repository name.\n    \n*   `state` (Optional): Filter by state (`open`, `closed`, `all`).\n    \n\n**Configurations:**\n\n*   `connection_id` (Required): Github connection ID.\n    \n\n**Outputs:**\n\n*   `pull_requests` (Required): Array of pull request objects with title, state, and author.\n    \n\n**Example:** _Input:_\n\n```\n{\n  \"owner\": \"octocat\",\n  \"repo\": \"Hello-World\",\n  \"state\": \"open\"\n}\n```\n\n_Output:_\n\n```\n{\n  \"pull_requests\": [\n    { \"number\": 1, \"title\": \"Add new feature\", \"state\": \"open\", ... }\n  ]\n}\n```\n\n* * *\n\n#### \n\n4\\. Get Repository Details\n\n**Description:** Fetch metadata and details about a specific repository.\n\n**Inputs:**\n\n*   `owner` (Required): Repository owner.\n    \n*   `repo` (Required): Repository name.\n    \n\n**Configurations:**\n\n*   `connection_id` (Required): Github connection ID.\n    \n\n**Outputs:**\n\n*   `repository` (Required): Object containing repository details such as description, stars, forks, and more.\n    \n\n**Example:** _Input:_\n\n```\n{\n  \"owner\": \"octocat\",\n  \"repo\": \"Hello-World\"\n}\n```\n\n_Output:_\n\n```\n{\n  \"repository\": {\n    \"name\": \"Hello-World\",\n    \"description\": \"This is your first repository\",\n    \"stargazers_count\": 42,\n    \"forks_count\": 10,\n    ...\n  }\n}\n```\n\n* * *\n\n#### \n\n5\\. List Releases\n\n**Description:** Get a list of releases published in a repository.\n\n**Inputs:**\n\n*   `owner` (Required): Repository owner.\n    \n*   `repo` (Required): Repository name.\n    \n\n**Configurations:**\n\n*   `connection_id` (Required): Github connection ID.\n    \n\n**Outputs:**\n\n*   `releases` (Required): Array of release objects with tag name, release notes, and published date.\n    \n\n**Example:** _Input:_\n\n```\n{\n  \"owner\": \"octocat\",\n  \"repo\": \"Hello-World\"\n}\n```\n\n_Output:_\n\n```\n{\n  \"releases\": [\n    { \"tag_name\": \"v1.0.0\", \"name\": \"First Release\", ... }\n  ]\n}\n```\n\n* * *\n\n**Best Practices:**\n\n*   Always provide the required `owner`, `repo`, and `connection_id` for all actions.\n    \n*   Use the output of the Github node as input for downstream nodes, such as LLMs or output nodes, to automate reporting or notifications.\n    \n*   For advanced use cases, chain multiple Github actions to build complex automations.\n    \n\n* * *\n\n**Summary**\n\nThe Github node in StackAI empowers you to automate and manage Github repositories, branches, commits, pull requests, and more. By configuring the right action and providing the necessary inputs, you can streamline your development workflows and integrate Github data into your automation pipelines.\n\nLast updated 2 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/exa-ai","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/exa-ai","loadedTime":"2025-10-17T18:30:18.939Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/exa-ai","title":"Exa AI | StackAI","description":"Comprehensive guide to the Exa AI node in StackAI: Learn how to use Exa AI for internet-scale search, including action details, input/output parameters, and practical examples.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Exa AI | StackAI"},{"property":"og:description","content":"Comprehensive guide to the Exa AI node in StackAI: Learn how to use Exa AI for internet-scale search, including action details, input/output parameters, and practical examples."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"date":"Fri, 17 Oct 2025 18:30:16 GMT","content-type":"text/html; charset=utf-8","content-encoding":"br","cf-ray":"9901ddc16c808157-SEA","cf-cache-status":"DYNAMIC","age":"75","cache-control":"public, max-age=0, must-revalidate","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","referrer-policy":"no-referrer-when-downgrade","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"pdx1::iad1::hb2wx-1760725816580-6e78d2ddd2b5","server":"cloudflare","alt-svc":"h3=\":443\"; ma=86400","x-firefox-spdy":"h2"}},"screenshotUrl":"https://api.apify.com/v2/key-value-stores/3K2WBdQQFTu6EGDhJ/records/SCREENSHOT-docs-stack-ai-com-stack-ai-workflow-builder-apps-exa-ai-626855a7.jpg","text":"Exa AI | StackAI\nComprehensive guide to the Exa AI node in StackAI: Learn how to use Exa AI for internet-scale search, including action details, input/output parameters, and practical examples.\nWhat is Exa AI?\nExa AI is a powerful node in StackAI that enables users to perform advanced, internet-scale searches using both embeddings-based and traditional search methods. It allows you to query a wide variety of sources, retrieve relevant results, and integrate real-time web data into your AI workflows.\nHow to use it?\nTo use the Exa AI node in StackAI, simply add the node to your workflow and select the desired action. Configure the required input parameters to define your search query and any additional options. The node will return structured search results that can be used in downstream nodes for further processing, analysis, or display.\nExample of Usage\nSuppose you want to perform a web search for the latest AI research papers. You would select the \"Web Search\" action, provide your query (e.g., \"latest AI research papers\"), and configure any optional parameters such as the number of results. The node will return a list of relevant web pages, including titles, URLs, and summaries.\nAvailable Actions in Exa AI\nBelow are the most commonly used actions available in the Exa AI node:\n1. Web Search\nDescription: Performs a real-time web search using advanced algorithms to retrieve the most relevant results from the internet.\nInputs:\nquery (string, required): The search term or question you want to look up.\nExample: \"latest AI research papers\"\nnum_results (integer, optional): Number of search results to return.\nExample: 5\nConfigurations: No additional configurations are required for this action.\nOutputs:\nresults (array, required): List of search results, each containing:\ntitle (string): Title of the web page.\nurl (string): Direct link to the web page.\nsnippet (string): Short summary or excerpt from the page.\nExample:\n{ \"results\": [ { \"title\": \"Recent Advances in AI Research\", \"url\": \"https://example.com/ai-research\", \"snippet\": \"This article discusses the latest breakthroughs in artificial intelligence...\" } ] }\n2. Deep Research\nDescription: Conducts an in-depth search and analysis on a given topic, aggregating information from multiple sources for comprehensive insights.\nInputs:\nquery (string, required): The topic or question for deep research.\nExample: \"impact of AI on healthcare\"\nnum_results (integer, optional): Number of sources to aggregate.\nExample: 3\nConfigurations: No additional configurations are required.\nOutputs:\nsummary (string, required): A synthesized summary of findings.\nsources (array, required): List of source URLs and brief descriptions.\nExample:\n{ \"summary\": \"AI is transforming healthcare by improving diagnostics, patient care, and operational efficiency...\", \"sources\": [ { \"url\": \"https://example.com/ai-healthcare\", \"description\": \"Overview of AI applications in healthcare.\" } ] }\n3. Find Similar\nDescription: Finds web pages or documents similar to a provided URL or text snippet.\nInputs:\nurl (string, required): The URL of the reference page.\nnum_results (integer, optional): Number of similar results to return.\nExample: 5\nConfigurations: No additional configurations are required.\nOutputs:\nsimilar_results (array, required): List of similar web pages with titles, URLs, and similarity scores.\nExample:\n{ \"similar_results\": [ { \"title\": \"Understanding AI\", \"url\": \"https://example.com/understanding-ai\", \"score\": 0.92 } ] }\n4. Get Contents\nDescription: Retrieves the full content of a web page or document from a given URL.\nInputs:\nurl (string, required): The URL of the page to extract content from.\nConfigurations: No additional configurations are required.\nOutputs:\ncontent (string, required): The extracted text content of the page.\nExample:\n{ \"content\": \"Artificial intelligence (AI) is a rapidly evolving field...\" }\n5. Answer\nDescription: Provides a direct answer to a question by searching and synthesizing information from the web.\nInputs:\nquestion (string, required): The question you want answered.\nExample: \"What is generative AI?\"\nConfigurations: No additional configurations are required.\nOutputs:\nanswer (string, required): The synthesized answer.\nsources (array, required): List of source URLs used to generate the answer.\nExample:\n{ \"answer\": \"Generative AI refers to artificial intelligence systems that can create new content...\", \"sources\": [ \"https://example.com/generative-ai\" ] }\nBest Practices for Using Exa AI in StackAI\nAlways provide clear and specific queries for the best results.\nUse the \"num_results\" parameter to control the amount of data returned.\nIntegrate Exa AI outputs with downstream nodes for advanced processing, such as summarization or visualization.\nReview the sources and content for accuracy, especially when using results in critical applications.\nSummary\nThe Exa AI node in StackAI is a versatile tool for integrating real-time, internet-scale search and research capabilities into your workflows. By leveraging its powerful actions, you can access, analyze, and utilize web data efficiently and effectively.\nLast updated 3 months ago","markdown":"# Exa AI | StackAI\n\nComprehensive guide to the Exa AI node in StackAI: Learn how to use Exa AI for internet-scale search, including action details, input/output parameters, and practical examples.\n\n**What is Exa AI?**\n\nExa AI is a powerful node in StackAI that enables users to perform advanced, internet-scale searches using both embeddings-based and traditional search methods. It allows you to query a wide variety of sources, retrieve relevant results, and integrate real-time web data into your AI workflows.\n\n* * *\n\n**How to use it?**\n\nTo use the Exa AI node in StackAI, simply add the node to your workflow and select the desired action. Configure the required input parameters to define your search query and any additional options. The node will return structured search results that can be used in downstream nodes for further processing, analysis, or display.\n\n* * *\n\n**Example of Usage**\n\nSuppose you want to perform a web search for the latest AI research papers. You would select the \"Web Search\" action, provide your query (e.g., \"latest AI research papers\"), and configure any optional parameters such as the number of results. The node will return a list of relevant web pages, including titles, URLs, and summaries.\n\n* * *\n\n**Available Actions in Exa AI**\n\nBelow are the most commonly used actions available in the Exa AI node:\n\n* * *\n\n#### \n\n1\\. Web Search\n\n**Description:** Performs a real-time web search using advanced algorithms to retrieve the most relevant results from the internet.\n\n**Inputs:**\n\n*   **query** (string, required): The search term or question you want to look up.\n    \n    *   Example: \"latest AI research papers\"\n        \n    \n*   **num\\_results** (integer, optional): Number of search results to return.\n    \n    *   Example: 5\n        \n    \n\n**Configurations:** No additional configurations are required for this action.\n\n**Outputs:**\n\n*   **results** (array, required): List of search results, each containing:\n    \n    *   **title** (string): Title of the web page.\n        \n    *   **url** (string): Direct link to the web page.\n        \n    *   **snippet** (string): Short summary or excerpt from the page.\n        \n    \n\n**Example:**\n\n```\n{\n  \"results\": [\n    {\n      \"title\": \"Recent Advances in AI Research\",\n      \"url\": \"https://example.com/ai-research\",\n      \"snippet\": \"This article discusses the latest breakthroughs in artificial intelligence...\"\n    }\n  ]\n}\n```\n\n* * *\n\n#### \n\n2\\. Deep Research\n\n**Description:** Conducts an in-depth search and analysis on a given topic, aggregating information from multiple sources for comprehensive insights.\n\n**Inputs:**\n\n*   **query** (string, required): The topic or question for deep research.\n    \n    *   Example: \"impact of AI on healthcare\"\n        \n    \n*   **num\\_results** (integer, optional): Number of sources to aggregate.\n    \n    *   Example: 3\n        \n    \n\n**Configurations:** No additional configurations are required.\n\n**Outputs:**\n\n*   **summary** (string, required): A synthesized summary of findings.\n    \n*   **sources** (array, required): List of source URLs and brief descriptions.\n    \n\n**Example:**\n\n```\n{\n  \"summary\": \"AI is transforming healthcare by improving diagnostics, patient care, and operational efficiency...\",\n  \"sources\": [\n    {\n      \"url\": \"https://example.com/ai-healthcare\",\n      \"description\": \"Overview of AI applications in healthcare.\"\n    }\n  ]\n}\n```\n\n* * *\n\n#### \n\n3\\. Find Similar\n\n**Description:** Finds web pages or documents similar to a provided URL or text snippet.\n\n**Inputs:**\n\n*   **url** (string, required): The URL of the reference page.\n    \n*   **num\\_results** (integer, optional): Number of similar results to return.\n    \n    *   Example: 5\n        \n    \n\n**Configurations:** No additional configurations are required.\n\n**Outputs:**\n\n*   **similar\\_results** (array, required): List of similar web pages with titles, URLs, and similarity scores.\n    \n\n**Example:**\n\n```\n{\n  \"similar_results\": [\n    {\n      \"title\": \"Understanding AI\",\n      \"url\": \"https://example.com/understanding-ai\",\n      \"score\": 0.92\n    }\n  ]\n}\n```\n\n* * *\n\n#### \n\n4\\. Get Contents\n\n**Description:** Retrieves the full content of a web page or document from a given URL.\n\n**Inputs:**\n\n*   **url** (string, required): The URL of the page to extract content from.\n    \n\n**Configurations:** No additional configurations are required.\n\n**Outputs:**\n\n*   **content** (string, required): The extracted text content of the page.\n    \n\n**Example:**\n\n```\n{\n  \"content\": \"Artificial intelligence (AI) is a rapidly evolving field...\"\n}\n```\n\n* * *\n\n#### \n\n5\\. Answer\n\n**Description:** Provides a direct answer to a question by searching and synthesizing information from the web.\n\n**Inputs:**\n\n*   **question** (string, required): The question you want answered.\n    \n    *   Example: \"What is generative AI?\"\n        \n    \n\n**Configurations:** No additional configurations are required.\n\n**Outputs:**\n\n*   **answer** (string, required): The synthesized answer.\n    \n*   **sources** (array, required): List of source URLs used to generate the answer.\n    \n\n**Example:**\n\n```\n{\n  \"answer\": \"Generative AI refers to artificial intelligence systems that can create new content...\",\n  \"sources\": [\n    \"https://example.com/generative-ai\"\n  ]\n}\n```\n\n* * *\n\n**Best Practices for Using Exa AI in StackAI**\n\n*   Always provide clear and specific queries for the best results.\n    \n*   Use the \"num\\_results\" parameter to control the amount of data returned.\n    \n*   Integrate Exa AI outputs with downstream nodes for advanced processing, such as summarization or visualization.\n    \n*   Review the sources and content for accuracy, especially when using results in critical applications.\n    \n\n* * *\n\n**Summary**\n\nThe Exa AI node in StackAI is a versatile tool for integrating real-time, internet-scale search and research capabilities into your workflows. By leveraging its powerful actions, you can access, analyze, and utilize web data efficiently and effectively.\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"browser"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/gsheets","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/gsheets","loadedTime":"2025-10-17T18:30:23.785Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/gsheets","title":"GSheets | StackAI","description":"Learn how to automate writing data to Google Sheets using the GSheets node in StackAI. Step-by-step guide with input, configuration, and output details.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"GSheets | StackAI"},{"property":"og:description","content":"Learn how to automate writing data to Google Sheets using the GSheets node in StackAI. Step-by-step guide with input, configuration, and output details."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"80","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dded3e535728-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:23 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::8st7q-1760725823599-e19656ff1d2e"}},"screenshotUrl":null,"text":"GSheets | StackAI\nLearn how to automate writing data to Google Sheets using the GSheets node in StackAI. Step-by-step guide with input, configuration, and output details.\nWhat is GSheets?\nGSheets is a StackAI integration node that allows you to write data directly to Google Sheets. This node is ideal for automating data entry, updating records, or logging information in your spreadsheets as part of your workflow.\nHow to use it?\nTo use the GSheets node, you need to configure it with the required spreadsheet and sheet details, and provide the data you want to write. The node will then append or update the specified Google Sheet with your data and return the status of the operation.\nExample of Usage\nSuppose you want to log new user signups into a Google Sheet. You can connect the GSheets node in your StackAI workflow, configure it with your target spreadsheet and sheet, and pass the signup data as input.\nAvailable Actions\n1. Write to Google Sheet\nDescription: Appends or updates data in a specified Google Sheet.\nInputs\nSpreadsheet (spreadsheet_id)\nRequired: Yes\nType: Select\nDescription: Select the Google Sheet to write to.\nSheet (sheet_name)\nRequired: Yes\nType: String\nDescription: Specify the sheet/tab within the spreadsheet.\nData (data)\nRequired: Yes\nType: Textarea\nDescription: The data to write. Can be a JSON object (preferred for structured data) or plain text.\nExample Input:\n{ \"spreadsheet_id\": \"1A2B3C4D5E6F7G8H9I0J\", \"sheet_name\": \"Signups\", \"data\": { \"Name\": \"Jane Doe\", \"Email\": \"[email protected]\", \"Signup Date\": \"2025-07-07\" } }\nConfigurations\nNo additional configurations are required beyond the inputs above.\nOutputs\nStatus (status)\nRequired: Yes\nType: String\nDescription: Indicates if the operation was successful (e.g., \"success\" or \"failure\").\nUpdated Range (updated_range)\nRequired: Yes\nType: String\nDescription: The cell range in the sheet that was updated (e.g., \"Signups!A2:C2\").\nMessage (message)\nRequired: Yes\nType: String\nDescription: A message describing the outcome of the operation.\nExample Output:\n{ \"status\": \"success\", \"updated_range\": \"Signups!A2:C2\", \"message\": \"Data written successfully.\" }\nSummary Table\nInput Name\nRequired\nType\nDescription\nSheet/tab within the spreadsheet\nData to write (JSON or plain text)\nOutput Name\nRequired\nType\nDescription\nThe updated cell range in the spreadsheet\nMessage about the operation\nBest Practices\nAlways use structured JSON for the data input for best results.\nEnsure you have the correct permissions to access and write to the selected Google Sheet.\nUse clear sheet and spreadsheet names to avoid confusion in multi-sheet documents.\nAutomate your data workflows with the GSheets node in StackAI for seamless Google Sheets integration.\nLast updated 3 months ago","markdown":"# GSheets | StackAI\n\nLearn how to automate writing data to Google Sheets using the GSheets node in StackAI. Step-by-step guide with input, configuration, and output details.\n\n**What is GSheets?**\n\nGSheets is a StackAI integration node that allows you to write data directly to Google Sheets. This node is ideal for automating data entry, updating records, or logging information in your spreadsheets as part of your workflow.\n\n* * *\n\n**How to use it?**\n\nTo use the GSheets node, you need to configure it with the required spreadsheet and sheet details, and provide the data you want to write. The node will then append or update the specified Google Sheet with your data and return the status of the operation.\n\n* * *\n\n**Example of Usage**\n\nSuppose you want to log new user signups into a Google Sheet. You can connect the GSheets node in your StackAI workflow, configure it with your target spreadsheet and sheet, and pass the signup data as input.\n\n* * *\n\n**Available Actions**\n\n#### \n\n1\\. Write to Google Sheet\n\n**Description:** Appends or updates data in a specified Google Sheet.\n\n**Inputs**\n\n*   **Spreadsheet (spreadsheet\\_id)**\n    \n    *   _Required_: Yes\n        \n    *   _Type_: Select\n        \n    *   _Description_: Select the Google Sheet to write to.\n        \n    \n*   **Sheet (sheet\\_name)**\n    \n    *   _Required_: Yes\n        \n    *   _Type_: String\n        \n    *   _Description_: Specify the sheet/tab within the spreadsheet.\n        \n    \n*   **Data (data)**\n    \n    *   _Required_: Yes\n        \n    *   _Type_: Textarea\n        \n    *   _Description_: The data to write. Can be a JSON object (preferred for structured data) or plain text.\n        \n    \n\n**Example Input:**\n\n```\n{\n  \"spreadsheet_id\": \"1A2B3C4D5E6F7G8H9I0J\",\n  \"sheet_name\": \"Signups\",\n  \"data\": {\n    \"Name\": \"Jane Doe\",\n    \"Email\": \"[email protected]\",\n    \"Signup Date\": \"2025-07-07\"\n  }\n}\n```\n\n**Configurations**\n\n*   No additional configurations are required beyond the inputs above.\n    \n\n**Outputs**\n\n*   **Status (status)**\n    \n    *   _Required_: Yes\n        \n    *   _Type_: String\n        \n    *   _Description_: Indicates if the operation was successful (e.g., \"success\" or \"failure\").\n        \n    \n*   **Updated Range (updated\\_range)**\n    \n    *   _Required_: Yes\n        \n    *   _Type_: String\n        \n    *   _Description_: The cell range in the sheet that was updated (e.g., \"Signups!A2:C2\").\n        \n    \n*   **Message (message)**\n    \n    *   _Required_: Yes\n        \n    *   _Type_: String\n        \n    *   _Description_: A message describing the outcome of the operation.\n        \n    \n\n**Example Output:**\n\n```\n{\n  \"status\": \"success\",\n  \"updated_range\": \"Signups!A2:C2\",\n  \"message\": \"Data written successfully.\"\n}\n```\n\n* * *\n\n**Summary Table**\n\nInput Name\n\nRequired\n\nType\n\nDescription\n\nSheet/tab within the spreadsheet\n\nData to write (JSON or plain text)\n\nOutput Name\n\nRequired\n\nType\n\nDescription\n\nThe updated cell range in the spreadsheet\n\nMessage about the operation\n\n* * *\n\n**Best Practices**\n\n*   Always use structured JSON for the data input for best results.\n    \n*   Ensure you have the correct permissions to access and write to the selected Google Sheet.\n    \n*   Use clear sheet and spreadsheet names to avoid confusion in multi-sheet documents.\n    \n\n* * *\n\n**Automate your data workflows with the GSheets node in StackAI for seamless Google Sheets integration.**\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/hightouch","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/hightouch","loadedTime":"2025-10-17T18:30:23.903Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/hightouch","title":"Hightouch | StackAI","description":"Comprehensive guide to the Hightouch node in StackAI, including top actions, input and output details, and practical usage examples.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Hightouch | StackAI"},{"property":"og:description","content":"Comprehensive guide to the Hightouch node in StackAI, including top actions, input and output details, and practical usage examples."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"81","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dded2e9b081b-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:23 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::gnjgr-1760725823596-7bac1b0dc906"}},"screenshotUrl":null,"text":"Hightouch | StackAI\nComprehensive guide to the Hightouch node in StackAI, including top actions, input and output details, and practical usage examples.\nWhat is Hightouch?\nHightouch is a powerful integration node in StackAI that enables seamless data synchronization between your data warehouse and various business applications. With Hightouch, you can automate workflows, trigger actions, and keep your business tools up-to-date with the latest data.\nHow to use it?\nTo use the Hightouch node in StackAI, add it to your workflow and select the desired action. Configure the required inputs and connection settings, then connect it to other nodes to automate data-driven processes. Hightouch supports a variety of actions, allowing you to query sources and destinations, and orchestrate data syncs.\nExample of Usage\nSuppose you want to list all available sources in your Hightouch account. You would add the Hightouch node, select the \"List Source\" action, provide your connection ID, and connect the output to a display or processing node.\nAvailable Actions in Hightouch\nBelow are the most commonly used Hightouch actions in StackAI:\n1. List Source\nDescription: Retrieves a list of all data sources connected to your Hightouch account.\nInputs:\nNone required.\nConfigurations:\nconnection_id (Required): The unique identifier for your Hightouch connection.\nOutputs:\nsources (Required): An array of source objects, each containing details such as source name, type, and status.\nExample:\n{ \"action_configurations\": { \"connection_id\": \"<your-hightouch-connection-id>\" } }\n2. List Destination\nDescription: Fetches all destinations configured in your Hightouch account.\nInputs:\nNone required.\nConfigurations:\nconnection_id (Required): The unique identifier for your Hightouch connection.\nOutputs:\ndestinations (Required): An array of destination objects, each with properties like destination name, type, and status.\nExample:\n{ \"action_configurations\": { \"connection_id\": \"<your-hightouch-connection-id>\" } }\nHow to Use These Actions in StackAI\nAdd the Hightouch Node: Drag the Hightouch node into your workflow.\nSelect an Action: Choose \"List Source\" or \"List Destination\" based on your needs.\nConfigure the Node: Enter your Hightouch connection ID in the configuration.\nConnect to Other Nodes: Use the output in downstream nodes for further processing or display.\nExample Workflow\nAdd Hightouch node → Select \"List Source\" → Set connection_id → Connect output to a Template or Output node to display the list of sources.\nSummary Table\nAction\nRequired Inputs\nRequired Configurations\nOutputs\nUse the Hightouch node in StackAI to automate and streamline your data operations, ensuring your business tools always have the most up-to-date information.\nLast updated 3 months ago","markdown":"# Hightouch | StackAI\n\nComprehensive guide to the Hightouch node in StackAI, including top actions, input and output details, and practical usage examples.\n\n**What is Hightouch?**\n\nHightouch is a powerful integration node in StackAI that enables seamless data synchronization between your data warehouse and various business applications. With Hightouch, you can automate workflows, trigger actions, and keep your business tools up-to-date with the latest data.\n\n**How to use it?**\n\nTo use the Hightouch node in StackAI, add it to your workflow and select the desired action. Configure the required inputs and connection settings, then connect it to other nodes to automate data-driven processes. Hightouch supports a variety of actions, allowing you to query sources and destinations, and orchestrate data syncs.\n\n**Example of Usage**\n\nSuppose you want to list all available sources in your Hightouch account. You would add the Hightouch node, select the \"List Source\" action, provide your connection ID, and connect the output to a display or processing node.\n\n* * *\n\n**Available Actions in Hightouch**\n\nBelow are the most commonly used Hightouch actions in StackAI:\n\n* * *\n\n#### \n\n1\\. List Source\n\n**Description:** Retrieves a list of all data sources connected to your Hightouch account.\n\n**Inputs:**\n\n*   None required.\n    \n\n**Configurations:**\n\n*   `connection_id` (Required): The unique identifier for your Hightouch connection.\n    \n\n**Outputs:**\n\n*   `sources` (Required): An array of source objects, each containing details such as source name, type, and status.\n    \n\n**Example:**\n\n```\n{\n  \"action_configurations\": {\n    \"connection_id\": \"<your-hightouch-connection-id>\"\n  }\n}\n```\n\n* * *\n\n#### \n\n2\\. List Destination\n\n**Description:** Fetches all destinations configured in your Hightouch account.\n\n**Inputs:**\n\n*   None required.\n    \n\n**Configurations:**\n\n*   `connection_id` (Required): The unique identifier for your Hightouch connection.\n    \n\n**Outputs:**\n\n*   `destinations` (Required): An array of destination objects, each with properties like destination name, type, and status.\n    \n\n**Example:**\n\n```\n{\n  \"action_configurations\": {\n    \"connection_id\": \"<your-hightouch-connection-id>\"\n  }\n}\n```\n\n* * *\n\n**How to Use These Actions in StackAI**\n\n1.  **Add the Hightouch Node:** Drag the Hightouch node into your workflow.\n    \n2.  **Select an Action:** Choose \"List Source\" or \"List Destination\" based on your needs.\n    \n3.  **Configure the Node:** Enter your Hightouch connection ID in the configuration.\n    \n4.  **Connect to Other Nodes:** Use the output in downstream nodes for further processing or display.\n    \n\n* * *\n\n**Example Workflow**\n\n*   Add Hightouch node → Select \"List Source\" → Set `connection_id` → Connect output to a Template or Output node to display the list of sources.\n    \n\n* * *\n\n**Summary Table**\n\nAction\n\nRequired Inputs\n\nRequired Configurations\n\nOutputs\n\n* * *\n\nUse the Hightouch node in StackAI to automate and streamline your data operations, ensuring your business tools always have the most up-to-date information.\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/hubspot","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/hubspot","loadedTime":"2025-10-17T18:30:24.011Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/hubspot","title":"HubSpot | StackAI","description":"Comprehensive guide to using the HubSpot node in StackAI workflows, including key actions, input requirements, configurations, and output examples.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"HubSpot | StackAI"},{"property":"og:description","content":"Comprehensive guide to using the HubSpot node in StackAI workflows, including key actions, input requirements, configurations, and output examples."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"79","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dded480cd664-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:23 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::zf6jd-1760725823608-16d4f04452f6"}},"screenshotUrl":null,"text":"HubSpot | StackAI\nComprehensive guide to using the HubSpot node in StackAI workflows, including key actions, input requirements, configurations, and output examples.\nWhat is HubSpot?\nThe HubSpot node in StackAI enables seamless integration with HubSpot CRM, allowing you to automate, query, and manage your sales, marketing, and customer data directly within your workflow. This node connects to HubSpot’s powerful CRM features, making it easy to retrieve, create, or update contacts, deals, pipelines, and more.\nHow to use it?\nTo use the HubSpot node, add it to your StackAI workflow and select the desired action. Each action corresponds to a specific HubSpot operation, such as searching for deals, retrieving contact information, or creating new records. Configure the required inputs and connection settings, then connect the node to other workflow components to automate your business processes.\nExample of Usage\nSuppose you want to search for deals in your HubSpot CRM based on specific criteria. You would select the \"Search Deals\" action, provide the necessary search parameters, and connect the output to a reporting or notification node.\nMost Commonly Used Actions in HubSpot\nBelow are the most frequently used actions available in the HubSpot node, along with their input, configuration, and output details:\n1. Search Deals\nDescription: Retrieve a list of deals from HubSpot CRM based on search criteria.\nInputs:\nfilters (Required): Array of filter objects specifying search conditions (e.g., propertyName, operator, value).\nsorts (Optional): Array of property names to sort results.\nlimit (Optional): Maximum number of results to return.\nafter (Optional): Pagination cursor for additional results.\nConfigurations:\nconnection_id (Required): Your HubSpot connection ID.\nOutputs:\nresults: Array of deal objects matching the search criteria.\ntotal: Total number of deals found.\nExample:\n{ \"filters\": [ { \"propertyName\": \"dealstage\", \"operator\": \"EQ\", \"value\": \"appointmentscheduled\" } ], \"limit\": 5 }\n2. Get Full Deal Data\nDescription: Retrieve detailed information for a specific deal.\nInputs:\ndeal_id (Required): The unique ID of the deal.\nConfigurations:\nconnection_id (Required): Your HubSpot connection ID.\nOutputs:\ndeal: Full deal object with all properties.\nExample:\n{ \"deal_id\": \"123456789\" }\n3. Get Contact with History\nDescription: Retrieve a contact’s details along with their historical changes.\nInputs:\ncontact_id (Required): The unique ID of the contact.\nConfigurations:\nconnection_id (Required): Your HubSpot connection ID.\nOutputs:\ncontact: Contact object with history.\nExample:\n{ \"contact_id\": \"987654321\" }\n4. Create Deal\nDescription: Create a new deal in HubSpot CRM.\nInputs:\nproperties (Required): Object containing deal properties (e.g., dealname, amount, pipeline, dealstage).\nConfigurations:\nconnection_id (Required): Your HubSpot connection ID.\nOutputs:\ndeal: The newly created deal object.\nExample:\n{ \"properties\": { \"dealname\": \"New Enterprise Deal\", \"amount\": \"50000\", \"pipeline\": \"default\", \"dealstage\": \"appointmentscheduled\" } }\n5. Create Contact\nDescription: Add a new contact to HubSpot CRM.\nInputs:\nproperties (Required): Object containing contact properties (e.g., email, firstname, lastname).\nConfigurations:\nconnection_id (Required): Your HubSpot connection ID.\nOutputs:\ncontact: The newly created contact object.\nExample:\n{ \"properties\": { \"email\": \"[email protected]\", \"firstname\": \"Jane\", \"lastname\": \"Doe\" } }\n6. Get Pipeline\nDescription: Retrieve information about a specific pipeline.\nInputs:\npipeline_id (Required): The unique ID of the pipeline.\nConfigurations:\nconnection_id (Required): Your HubSpot connection ID.\nOutputs:\npipeline: Pipeline object with details.\nExample:\n{ \"pipeline_id\": \"default\" }\n7. List Pipelines\nDescription: List all pipelines in your HubSpot account.\nInputs: None.\nConfigurations:\nconnection_id (Required): Your HubSpot connection ID.\nOutputs:\npipelines: Array of pipeline objects.\nSummary Table\nAction\nRequired Inputs\nRequired Configurations\nOutputs\nShowing 1-7 of 7 items\nBest Practices\nAlways provide the required connection_id to authenticate with your HubSpot account.\nEnsure all required input fields are filled to avoid errors.\nUse the outputs to connect to downstream nodes for further automation, such as notifications, reporting, or data enrichment.\nExample of Usage\nTo automatically add a new contact when a user submits a form, use the \"Create Contact\" action, map the form fields to the required properties, and connect the output to a notification or CRM update node.\nThis guide helps you leverage the HubSpot node in StackAI to automate and streamline your CRM workflows efficiently.\nLast updated 3 months ago","markdown":"# HubSpot | StackAI\n\nComprehensive guide to using the HubSpot node in StackAI workflows, including key actions, input requirements, configurations, and output examples.\n\n**What is HubSpot?**\n\nThe HubSpot node in StackAI enables seamless integration with HubSpot CRM, allowing you to automate, query, and manage your sales, marketing, and customer data directly within your workflow. This node connects to HubSpot’s powerful CRM features, making it easy to retrieve, create, or update contacts, deals, pipelines, and more.\n\n* * *\n\n**How to use it?**\n\nTo use the HubSpot node, add it to your StackAI workflow and select the desired action. Each action corresponds to a specific HubSpot operation, such as searching for deals, retrieving contact information, or creating new records. Configure the required inputs and connection settings, then connect the node to other workflow components to automate your business processes.\n\n* * *\n\n**Example of Usage**\n\nSuppose you want to search for deals in your HubSpot CRM based on specific criteria. You would select the \"Search Deals\" action, provide the necessary search parameters, and connect the output to a reporting or notification node.\n\n* * *\n\n**Most Commonly Used Actions in HubSpot**\n\nBelow are the most frequently used actions available in the HubSpot node, along with their input, configuration, and output details:\n\n* * *\n\n#### \n\n1\\. Search Deals\n\n**Description:** Retrieve a list of deals from HubSpot CRM based on search criteria.\n\n*   **Inputs:**\n    \n    *   `filters` (Required): Array of filter objects specifying search conditions (e.g., propertyName, operator, value).\n        \n    *   `sorts` (Optional): Array of property names to sort results.\n        \n    *   `limit` (Optional): Maximum number of results to return.\n        \n    *   `after` (Optional): Pagination cursor for additional results.\n        \n    \n*   **Configurations:**\n    \n    *   `connection_id` (Required): Your HubSpot connection ID.\n        \n    \n*   **Outputs:**\n    \n    *   `results`: Array of deal objects matching the search criteria.\n        \n    *   `total`: Total number of deals found.\n        \n    \n\n**Example:**\n\n```\n{\n  \"filters\": [\n    { \"propertyName\": \"dealstage\", \"operator\": \"EQ\", \"value\": \"appointmentscheduled\" }\n  ],\n  \"limit\": 5\n}\n```\n\n* * *\n\n#### \n\n2\\. Get Full Deal Data\n\n**Description:** Retrieve detailed information for a specific deal.\n\n*   **Inputs:**\n    \n    *   `deal_id` (Required): The unique ID of the deal.\n        \n    \n*   **Configurations:**\n    \n    *   `connection_id` (Required): Your HubSpot connection ID.\n        \n    \n*   **Outputs:**\n    \n    *   `deal`: Full deal object with all properties.\n        \n    \n\n**Example:**\n\n```\n{\n  \"deal_id\": \"123456789\"\n}\n```\n\n* * *\n\n#### \n\n3\\. Get Contact with History\n\n**Description:** Retrieve a contact’s details along with their historical changes.\n\n*   **Inputs:**\n    \n    *   `contact_id` (Required): The unique ID of the contact.\n        \n    \n*   **Configurations:**\n    \n    *   `connection_id` (Required): Your HubSpot connection ID.\n        \n    \n*   **Outputs:**\n    \n    *   `contact`: Contact object with history.\n        \n    \n\n**Example:**\n\n```\n{\n  \"contact_id\": \"987654321\"\n}\n```\n\n* * *\n\n#### \n\n4\\. Create Deal\n\n**Description:** Create a new deal in HubSpot CRM.\n\n*   **Inputs:**\n    \n    *   `properties` (Required): Object containing deal properties (e.g., dealname, amount, pipeline, dealstage).\n        \n    \n*   **Configurations:**\n    \n    *   `connection_id` (Required): Your HubSpot connection ID.\n        \n    \n*   **Outputs:**\n    \n    *   `deal`: The newly created deal object.\n        \n    \n\n**Example:**\n\n```\n{\n  \"properties\": {\n    \"dealname\": \"New Enterprise Deal\",\n    \"amount\": \"50000\",\n    \"pipeline\": \"default\",\n    \"dealstage\": \"appointmentscheduled\"\n  }\n}\n```\n\n* * *\n\n#### \n\n5\\. Create Contact\n\n**Description:** Add a new contact to HubSpot CRM.\n\n*   **Inputs:**\n    \n    *   `properties` (Required): Object containing contact properties (e.g., email, firstname, lastname).\n        \n    \n*   **Configurations:**\n    \n    *   `connection_id` (Required): Your HubSpot connection ID.\n        \n    \n*   **Outputs:**\n    \n    *   `contact`: The newly created contact object.\n        \n    \n\n**Example:**\n\n```\n{\n  \"properties\": {\n    \"email\": \"[email protected]\",\n    \"firstname\": \"Jane\",\n    \"lastname\": \"Doe\"\n  }\n}\n```\n\n* * *\n\n#### \n\n6\\. Get Pipeline\n\n**Description:** Retrieve information about a specific pipeline.\n\n*   **Inputs:**\n    \n    *   `pipeline_id` (Required): The unique ID of the pipeline.\n        \n    \n*   **Configurations:**\n    \n    *   `connection_id` (Required): Your HubSpot connection ID.\n        \n    \n*   **Outputs:**\n    \n    *   `pipeline`: Pipeline object with details.\n        \n    \n\n**Example:**\n\n```\n{\n  \"pipeline_id\": \"default\"\n}\n```\n\n* * *\n\n#### \n\n7\\. List Pipelines\n\n**Description:** List all pipelines in your HubSpot account.\n\n*   **Inputs:** None.\n    \n*   **Configurations:**\n    \n    *   `connection_id` (Required): Your HubSpot connection ID.\n        \n    \n*   **Outputs:**\n    \n    *   `pipelines`: Array of pipeline objects.\n        \n    \n\n* * *\n\n**Summary Table**\n\nAction\n\nRequired Inputs\n\nRequired Configurations\n\nOutputs\n\nShowing 1-7 of 7 items\n\n* * *\n\n**Best Practices**\n\n*   Always provide the required `connection_id` to authenticate with your HubSpot account.\n    \n*   Ensure all required input fields are filled to avoid errors.\n    \n*   Use the outputs to connect to downstream nodes for further automation, such as notifications, reporting, or data enrichment.\n    \n\n* * *\n\n**Example of Usage**\n\nTo automatically add a new contact when a user submits a form, use the \"Create Contact\" action, map the form fields to the required properties, and connect the output to a notification or CRM update node.\n\n* * *\n\nThis guide helps you leverage the HubSpot node in StackAI to automate and streamline your CRM workflows efficiently.\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/knowledge-base","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/knowledge-base","loadedTime":"2025-10-17T18:30:24.201Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/knowledge-base","title":"Knowledge Base | StackAI","description":"Learn how to use the Knowledge Base node in StackAI to search and retrieve information from your indexed documents, including input, configuration, and output details.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Knowledge Base | StackAI"},{"property":"og:description","content":"Learn how to use the Knowledge Base node in StackAI to search and retrieve information from your indexed documents, including input, configuration, and output details."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"79","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dded7fc41fee-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:23 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"cle1::iad1::84l6z-1760725823664-5996c37eada2"}},"screenshotUrl":null,"text":"Knowledge Base | StackAI\nLearn how to use the Knowledge Base node in StackAI to search and retrieve information from your indexed documents, including input, configuration, and output details.\nThe Knowledge Base Node in StackAI allows you to search and retrieve information from your indexed documents. It is designed to help AI workflows access relevant content from your organization's knowledge repositories, making it easy to build intelligent document search, retrieval-augmented generation (RAG), and automated Q&A solutions.\nHow to use it?\nTo use the Knowledge Base node, connect it within your StackAI workflow where you want to enable document search or retrieval. The node can be configured to search specific knowledge bases, filter results, and control the number and type of results returned. It is typically used in conjunction with LLM nodes to provide context-aware answers or summaries based on your indexed content.\nExample of Usage\nSuppose you want to build a chatbot that answers user questions using your company’s internal documentation. You would add the Knowledge Base node to your workflow, configure it to search your indexed documents, and connect its output to an LLM node. When a user asks a question, the Knowledge Base node retrieves relevant document snippets, which the LLM then uses to generate a precise answer.\nAvailable Actions\nBelow are the most commonly used actions for the Knowledge Base node:\n1. Search Knowledge Base\nDescription: Searches your indexed knowledge base for relevant documents or content based on a query.\nInputs:\nquery (Required): The search string or question to look up in your knowledge base.\nknowledge_base_id (Required): The unique identifier of the knowledge base to search.\nfilters (Optional): Metadata or tag filters to narrow down the search results.\ntop_k (Optional): The maximum number of results to return (default is 10).\nadvanced_rag (Optional): Boolean to enable advanced retrieval-augmented generation features.\nConfigurations:\nconnection_id (Required if your knowledge base requires authentication): The connection ID for accessing the knowledge base provider.\nOutputs:\nresults (Required): An array of relevant document snippets or content chunks.\nmetadata (Optional): Additional information about each result, such as source, date, or tags.\nExample:\nInput:\nquery: \"What is the company’s refund policy?\"\nknowledge_base_id: \"630eed87-31bf-4e64-9399-a1d298ca8a45\"\ntop_k: 5\nOutput:\nresults:\n\"Our refund policy allows returns within 30 days of purchase...\"\n\"Refunds are processed within 5 business days after approval...\"\nHow to Use in a Workflow\nAdd the Knowledge Base node to your StackAI workflow.\nSet the required inputs, such as the query and knowledge base ID.\n(Optional) Add filters or adjust the number of results.\nConnect the output to an LLM node or Output node to display or process the retrieved information.\nBest Practices\nAlways specify the correct knowledge base ID to ensure accurate search results.\nUse filters to refine results for more targeted answers.\nCombine with LLM nodes for context-aware, natural language responses.\nSummary\nThe Knowledge Base node is a powerful tool in StackAI for searching and retrieving information from your indexed documents. By configuring its inputs and outputs, you can build intelligent workflows that leverage your organization’s knowledge for automation, support, and more.\nLast updated 2 months ago","markdown":"# Knowledge Base | StackAI\n\nLearn how to use the Knowledge Base node in StackAI to search and retrieve information from your indexed documents, including input, configuration, and output details.\n\nThe **Knowledge Base Node** in StackAI allows you to search and retrieve information from your indexed documents. It is designed to help AI workflows access relevant content from your organization's knowledge repositories, making it easy to build intelligent document search, retrieval-augmented generation (RAG), and automated Q&A solutions.\n\n* * *\n\n**How to use it?**\n\nTo use the Knowledge Base node, connect it within your StackAI workflow where you want to enable document search or retrieval. The node can be configured to search specific knowledge bases, filter results, and control the number and type of results returned. It is typically used in conjunction with LLM nodes to provide context-aware answers or summaries based on your indexed content.\n\n* * *\n\n**Example of Usage**\n\nSuppose you want to build a chatbot that answers user questions using your company’s internal documentation. You would add the Knowledge Base node to your workflow, configure it to search your indexed documents, and connect its output to an LLM node. When a user asks a question, the Knowledge Base node retrieves relevant document snippets, which the LLM then uses to generate a precise answer.\n\n* * *\n\n**Available Actions**\n\nBelow are the most commonly used actions for the Knowledge Base node:\n\n#### \n\n1\\. Search Knowledge Base\n\n**Description:** Searches your indexed knowledge base for relevant documents or content based on a query.\n\n**Inputs:**\n\n*   **query** (Required): The search string or question to look up in your knowledge base.\n    \n*   **knowledge\\_base\\_id** (Required): The unique identifier of the knowledge base to search.\n    \n*   **filters** (Optional): Metadata or tag filters to narrow down the search results.\n    \n*   **top\\_k** (Optional): The maximum number of results to return (default is 10).\n    \n*   **advanced\\_rag** (Optional): Boolean to enable advanced retrieval-augmented generation features.\n    \n\n**Configurations:**\n\n*   **connection\\_id** (Required if your knowledge base requires authentication): The connection ID for accessing the knowledge base provider.\n    \n\n**Outputs:**\n\n*   **results** (Required): An array of relevant document snippets or content chunks.\n    \n*   **metadata** (Optional): Additional information about each result, such as source, date, or tags.\n    \n\n**Example:**\n\n*   **Input:**\n    \n    *   query: \"What is the company’s refund policy?\"\n        \n    *   knowledge\\_base\\_id: \"630eed87-31bf-4e64-9399-a1d298ca8a45\"\n        \n    *   top\\_k: 5\n        \n    \n*   **Output:**\n    \n    *   results:\n        \n        *   \"Our refund policy allows returns within 30 days of purchase...\"\n            \n        *   \"Refunds are processed within 5 business days after approval...\"\n            \n        \n    \n\n* * *\n\n**How to Use in a Workflow**\n\n1.  Add the Knowledge Base node to your StackAI workflow.\n    \n2.  Set the required inputs, such as the query and knowledge base ID.\n    \n3.  (Optional) Add filters or adjust the number of results.\n    \n4.  Connect the output to an LLM node or Output node to display or process the retrieved information.\n    \n\n* * *\n\n**Best Practices**\n\n*   Always specify the correct knowledge base ID to ensure accurate search results.\n    \n*   Use filters to refine results for more targeted answers.\n    \n*   Combine with LLM nodes for context-aware, natural language responses.\n    \n\n* * *\n\n**Summary**\n\nThe Knowledge Base node is a powerful tool in StackAI for searching and retrieving information from your indexed documents. By configuring its inputs and outputs, you can build intelligent workflows that leverage your organization’s knowledge for automation, support, and more.\n\nLast updated 2 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/hyperbrowser","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/hyperbrowser","loadedTime":"2025-10-17T18:30:24.107Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/hyperbrowser","title":"HyperBrowser | StackAI","description":"Learn how to automate browser tasks with the HyperBrowser node in StackAI. Discover available actions, required inputs, configurations, and output details.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"HyperBrowser | StackAI"},{"property":"og:description","content":"Learn how to automate browser tasks with the HyperBrowser node in StackAI. Discover available actions, required inputs, configurations, and output details."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"79","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dded2e97ee0d-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:23 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::w4vzm-1760725823596-399cbe430557"}},"screenshotUrl":null,"text":"HyperBrowser | StackAI\nLearn how to automate browser tasks with the HyperBrowser node in StackAI. Discover available actions, required inputs, configurations, and output details.\nHyperBrowser is a StackAI integration that enables you to automate and control browser-based tasks programmatically. It is ideal for scenarios such as web automation, scraping, testing, and simulating user interactions on websites.\nHow to use HyperBrowser\nFirst, create a connection to HyperBrowser if you are using it for the first time. You must have a HyperBrowser account. \nIn HyperBrowser, select Settings and then select API Keys. Create a new key and copy/paste the key into the new connection window in your StackAI workflow. Your connection will now be saved and can be reused across different workflows. \nThere are two ways to include HyperBrowser in your workflow:\nAs a tool: Allow your LLM to decide when a query necessitates searching the web. Click on your LLM, and choose \"Add Tool\". Select HyperBrowser. Make sure to reference this tool in your prompt for best results.\nAs a node: Enforce Hyperbrowser usage every run. To set up HyperBrowser as a Node, make sure to reference all the Hyperbrowser actions in your LLM prompt.\nYou can monitor the job status and retrieve results or errors upon completion.\nAvailable Actions\n1. Use Browser\nAutomate a browser session to perform a specific task.\nInputs\nTask (Required)\nDescription: The task to perform in the browser (e.g., \"Log in to example.com and scrape the dashboard data\").\nExample:\nLog in to https://example.com with username 'user' and password 'pass', then extract the text from the dashboard.\nSession ID (Optional)\nDescription: The ID of an existing browser session to use.\nMax Failures (Optional, default: 1)\nDescription: The maximum number of failures allowed before stopping the browser.\nMax Steps (Optional, default: 25)\nDescription: The maximum number of steps to allow before stopping the browser.\nKeep Browser Open (Optional, default: false)\nDescription: Whether to keep the browser open after the task is completed.\nConfigurations\nAll configuration options are provided as part of the input parameters above. No additional required configurations.\nOutputs\nJob ID (Required)\nDescription: The unique identifier for the browser automation job.\nLive URL (Required)\nDescription: The URL to view the live browser session.\nExample:\n\"https://hyperbrowser.live/session/job_456def\"\nStatus (Required)\nDescription: The current status of the job. Possible values: pending, running, completed, failed, stopped.\nFinal Result (Optional)\nDescription: The final result or output of the browser task.\nExample:\n\"Dashboard data: { ... }\"\nError (Optional)\nDescription: Error message if the task failed.\nExample:\n\"Login failed: Invalid credentials\"\nSession Stopped (Optional, default: false)\nDescription: Indicates if the browser session was stopped after completion.\nSummary Table\nInput Name\nRequired\nDescription\nExample\nThe browser task to perform\n\"Log in and scrape dashboard\"\nUse an existing browser session\nMax failures before stopping (default: 1)\nMax steps before stopping (default: 25)\nKeep browser open after task (default: false)\nOutput Name\nRequired\nDescription\nExample\nURL to view live browser session\n\",https://hyperbrowser.live/session/job_456def,\"\nJob status (,pending,, ,running,, etc.)\n\"Dashboard data: { ... }\"\n\"Login failed: Invalid credentials\"\nWas the session stopped after completion?\nBest Practices\nAlways provide a clear and specific task description.\nUse session management for multi-step or persistent workflows.\nMonitor the job status and handle errors gracefully in your workflow.\nHyperBrowser in StackAI empowers you to automate and control browser tasks efficiently, making it a powerful tool for web automation and data extraction.\nLast updated 3 months ago","markdown":"# HyperBrowser | StackAI\n\nLearn how to automate browser tasks with the HyperBrowser node in StackAI. Discover available actions, required inputs, configurations, and output details.\n\nHyperBrowser is a StackAI integration that enables you to automate and control browser-based tasks programmatically. It is ideal for scenarios such as web automation, scraping, testing, and simulating user interactions on websites.\n\n* * *\n\n#### \n\n**How to use HyperBrowser**\n\nFirst, create a connection to HyperBrowser if you are using it for the first time. You must have a HyperBrowser account.\n\nIn HyperBrowser, select **Settings** and then select **API Keys.** Create a new key and copy/paste the key into the new connection window in your StackAI workflow. Your connection will now be saved and can be reused across different workflows.\n\nThere are two ways to include HyperBrowser in your workflow:\n\n1.  As a tool: Allow your LLM to decide when a query necessitates searching the web. Click on your LLM, and choose \"Add Tool\". Select HyperBrowser. Make sure to reference this tool in your prompt for [best results](https://docs.stack-ai.com/stack-ai/best-practices/prompt-engineering).\n    \n2.  As a node: Enforce Hyperbrowser usage every run. To set up HyperBrowser as a Node, make sure to reference all the Hyperbrowser actions in your LLM prompt.\n    \n\nYou can monitor the job status and retrieve results or errors upon completion.\n\n* * *\n\n**Available Actions**\n\n#### \n\n1\\. Use Browser\n\nAutomate a browser session to perform a specific task.\n\n**Inputs**\n\n*   **Task** (Required)\n    \n    *   Description: The task to perform in the browser (e.g., \"Log in to example.com and scrape the dashboard data\").\n        \n    *   Example:\n        \n        ```\n        Log in to https://example.com with username 'user' and password 'pass', then extract the text from the dashboard.\n        ```\n        \n    \n*   **Session ID** (Optional)\n    \n    *   Description: The ID of an existing browser session to use.\n        \n    \n*   **Max Failures** (Optional, default: 1)\n    \n    *   Description: The maximum number of failures allowed before stopping the browser.\n        \n    \n*   **Max Steps** (Optional, default: 25)\n    \n    *   Description: The maximum number of steps to allow before stopping the browser.\n        \n    \n*   **Keep Browser Open** (Optional, default: false)\n    \n    *   Description: Whether to keep the browser open after the task is completed.\n        \n    \n\n**Configurations**\n\nAll configuration options are provided as part of the input parameters above. No additional required configurations.\n\n**Outputs**\n\n*   **Job ID** (Required)\n    \n    *   Description: The unique identifier for the browser automation job.\n        \n    \n*   **Live URL** (Required)\n    \n    *   Description: The URL to view the live browser session.\n        \n    *   Example:\n        \n        ```\n        \"https://hyperbrowser.live/session/job_456def\"\n        ```\n        \n    \n*   **Status** (Required)\n    \n    *   Description: The current status of the job. Possible values: `pending`, `running`, `completed`, `failed`, `stopped`.\n        \n    \n*   **Final Result** (Optional)\n    \n    *   Description: The final result or output of the browser task.\n        \n    *   Example:\n        \n        ```\n        \"Dashboard data: { ... }\"\n        ```\n        \n    \n*   **Error** (Optional)\n    \n    *   Description: Error message if the task failed.\n        \n    *   Example:\n        \n        ```\n        \"Login failed: Invalid credentials\"\n        ```\n        \n    \n*   **Session Stopped** (Optional, default: false)\n    \n    *   Description: Indicates if the browser session was stopped after completion.\n        \n    \n\n* * *\n\n**Summary Table**\n\nInput Name\n\nRequired\n\nDescription\n\nExample\n\nThe browser task to perform\n\n\"Log in and scrape dashboard\"\n\nUse an existing browser session\n\nMax failures before stopping (default: 1)\n\nMax steps before stopping (default: 25)\n\nKeep browser open after task (default: false)\n\nOutput Name\n\nRequired\n\nDescription\n\nExample\n\nURL to view live browser session\n\n\",https://hyperbrowser.live/session/job\\_456def,\"\n\nJob status (,pending,, ,running,, etc.)\n\n\"Dashboard data: { ... }\"\n\n\"Login failed: Invalid credentials\"\n\nWas the session stopped after completion?\n\n* * *\n\n**Best Practices**\n\n*   Always provide a clear and specific task description.\n    \n*   Use session management for multi-step or persistent workflows.\n    \n*   Monitor the job status and handle errors gracefully in your workflow.\n    \n\n* * *\n\nHyperBrowser in StackAI empowers you to automate and control browser tasks efficiently, making it a powerful tool for web automation and data extraction.\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/jira","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/jira","loadedTime":"2025-10-17T18:30:24.321Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/jira","title":"Jira | StackAI","description":"Comprehensive guide to using the Jira node in StackAI workflows, including top actions, input requirements, configurations, and output details.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Jira | StackAI"},{"property":"og:description","content":"Comprehensive guide to using the Jira node in StackAI workflows, including top actions, input requirements, configurations, and output details."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"79","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dded3caf05fa-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:23 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::dqg8c-1760725823643-74fac928d788"}},"screenshotUrl":null,"text":"Jira | StackAI\nComprehensive guide to using the Jira node in StackAI workflows, including top actions, input requirements, configurations, and output details.\nWhat is Jira?\nJira is a powerful project management tool designed for issue and ticket tracking. The Jira node in StackAI allows you to automate the creation of Jira issues directly from your workflow, streamlining project management and team collaboration.\nEstablishing A Connection\nClick 'Create Connection' and give it a name you’ll recognize later (e.g., Sam's Connection).\nYou’ll be redirected to the Atlassian website — sign in using your existing Jira account.\nAccept the requested permissions.\nOnce redirected back to StackAI, open the dropdown menu under 'Select Connection' and select your newly created connection.\nClick the 'Test' button to verify the connection status is Healthy.\nAction Summary Table\nAction\nDescriprion\nInputs\nOutputs\nAutomatically create a new issue (ticket) in your Jira project.\nProject ID, Issue Type ID, Summary, Description, Assignee ID, Parent Key, Priority ID, Labels, Due Date, Component, Custom Fields\nIssue Key, Issue ID, Issue URL, Summary, Status, Message\nAdd one or more file attachments to a Jira issue\nJira Issue ID or Key, File Path\nIssue ID or Key, Issue, Message\nAdd a comment to an existing Jira issue.\nJira Comment ID, Jira Issue URL, Message\nCreate a link between two Jira issues with an optional comment\nOutward Issue Id Or Key, Inward Issue Id Or Key, Link Type, Comment Text\nOutward Jira Issue, Inward Jira Issue, Jira Link Type, Operation Message\nRetrieve details of a specific Jira issue.\nIssue ID or Key, Fields, Expand, Update History, Custom Field IDs, Include All Custom Fields\nRetrieve comments for a Jira issue\nJira Issue ID or Key, Start At, Max Results, Order By, Expand\nIssue ID or Key, Comments\nGet a specific Jira project by its ID or key\nProject ID or Key, Expand\nProject ID, Project Key, Project Name, Project Category, Project Description, Project Lead, Project Issue Types, Project URL, Project Keys\nRetrieve a list of all Jira projects accessible to your account.\nStart At, Max Results, Order By, Query, Type Key, Status, Expand\nTotal Projects, Start At, Max Results, Is Last, Projects\nModify details of an existing Jira issue.\nIssue ID or Key, Summary, Description, Labels Add, Labels Remove, Assignee, Priority, Custom Fields, Notify Users, Return Issue\nInput Breakdowns\nAssignee (ID) (string)\nDescription: Account ID of the user to assign the issue to. Use null or an empty string to unassign.\nWhere to find it: In Jira Cloud, the Account ID is a unique identifier for each user. You can usually find it by:\nGoing to the user's profile in Jira (the URL will contain the accountId parameter).\nUsing the Jira API to list users, which will return their accountId.\nSometimes, when assigning users in the Jira UI, you can inspect the network requests to see the accountId.\nExample: 5b10a2844c20165700ede21g\nComment Text (string) \nDescription: The text content of the comment that will be added to the Jira issue.\nExample: Linking this issue to track its dependency on the target issue\nComponent (IDs) (string)\nDescription: Components are sub-sections or parts of a Jira project. They are used to group issues within a project into smaller parts, such as features, teams, modules, or functional areas. Each component has a unique component ID within the project.\nWhere to find it: In the Jira UI\nGo to your Jira project.\nIn the left sidebar, look for \"Project settings\" (or \"Settings\").\nClick on \"Components.\"\nHere, you will see a list of all components for the project, along with their names and IDs (the ID is often visible in the URL when you click on a component, or you can get it via the API).\nExample: [\"10001\", \"10003\"]\nCustom Field IDs (string)\nDescription: A comma-separated list of specific custom field IDs to extract from the Jira issue. Only these fields will be included in the custom_fields response. \nWhere to find it: You can find custom field IDs in your Jira instance by navigating to Jira Administration > Issues > Custom Fields. The field ID is usually shown in the URL when you edit a custom field (e.g., .../customfields/customfield_12345). You can also use the Jira REST API to list all custom fields and their IDs.\nExample: customfield_18165, customfield_12345\nCustom Fields (string)\nDescription: A JSON object containing custom field key-value pairs i.e. additional fields that your organization has configured to capture information beyond the standard fields (like summary, description, priority, etc.). These fields can be of various types (text, number, date, dropdown, user picker, etc.) and are used to tailor Jira issues to your team's specific needs.\nExample: \n\"custom_fields\": { \"customfield_10010\": \"Affects all users in Europe\", \"customfield_10011\": \"High\" }\nDescription (string)\nDescription: A detailed description of the issue (supports Atlassian Document Format)\nExample: Steps to reproduce the bug: 1. Log in to the app. 2. Click on the dashboard. 3. Observe the error message. Expected: Dashboard loads successfully. Actual: Error 500 is shown.\nDue Date (string)\nDescription: Allows you to specify the deadline for the issue in the format YYYY-MM-DD. This field is optional—if provided, it sets when the issue should be completed; if left blank, no due date will be assigned.\nExample: 2025-08-15\nExpand (string)\nDescription: The expand parameter allows you to request additional information in the response. \nExample: renderedBody\nFields (string)\nDescription: The fields parameter lets you specify which fields to include in the response when retrieving a Jira issue. You can use it to limit the output to only the fields you care about (like summary, status, or custom fields), or use special keywords to include all or only navigable fields.\nExample: summary,comment\nFile Path (string)\nDescription: The file path parameter specifies the location of the file you want to attach to a Jira issue. It must be a valid path to the file on your system or accessible storage.\nExample: /Users/alex/Documents/screenshot.png\nInclude All Custom Fields (boolean)\nDescription: Whether to include all custom fields for exploration (WARNING: creates very long output).\nInward Issue Id Or Key (string) \nDescription: This parameter specifies the ID or key of the target (inward) Jira issue that you want to link to. It identifies the issue that will be on the receiving end of the link relationship.\nWhere to find it: You can find the issue key or ID in the Jira issue’s URL or at the top of the issue page. For more details, search for \"Jira issue key\" or see Atlassian’s documentation on Finding an issue key in Jira.\nExample: PROJ-123, 10002\nIssue ID (string)\nDescription: The Issue Id parameter specifies the unique identifier of the Jira issue where you want to add a comment. This is required to ensure the comment is attached to the correct issue.\nWhere to find it: You can find the Issue Id in the Jira issue’s URL (e.g., the part like \"PROJ-123\" in https://yourcompany.atlassian.net/browse/PROJ-123) or at the top of the issue page. It is also sometimes referred to as the \"issue key.\"\nExample: PROJ-123\nIssue Type ID (string)\nDescription: Specifies what kind of issue you are creating in Jira. Common issue types include \"Bug\", \"Task\", \"Story\", \"Epic\", etc. Each type has its own workflow, fields, and purpose within your Jira project.\nWhere to Find It:\nJira Web Interface:\nGo to your Jira project.\nClick “Create” to open the new issue dialog.\nIn the “Issue Type” dropdown, you’ll see the available types (e.g., Bug, Task, Story).\nLabels (Add/Remove) (string)\nDescription: Labels are keywords or tags you can attach to a Jira issue to help categorize, filter, and search for related issues. They are optional and can be used for custom organization or reporting.\nWhere to find it: In the Jira issue creation or edit screen, there is a \"Labels\" field where you can add one or more labels. You can also see existing labels on the issue view page, usually near the bottom or in the details section. \nExample: customer-request, backend, sprint-12\nLink Type (string)\nDescription: Specifies the relationship between two Jira issues, such as whether one issue blocks another, duplicates it, or is simply related. This determines how the issues are visually and logically connected in Jira.\nWhere to find it: In Jira, when you manually link issues, you select the link type from a dropdown menu in the \"Link\" dialog (e.g., \"Blocks\", \"Relates to\", \"Duplicate\"). You can see available link types in your Jira instance by starting to link an issue or by asking your Jira admin for the configured link types.\nExample: Blocks, Relates to, Duplicate\nMax Results (number) \nDescription: The \"max results\" parameter controls the maximum number of comments to return per request when retrieving comments for a Jira issue.\nExample: 10, 50\nNotify Users (boolean)\nDescription: Whether to send email notifications about the update.\nOrder By (string)\nDescription: The \"Order By\" parameter determines the sort order of the returned comments, such as by creation date in ascending or descending order.\nExample: \ncreated - no sorting\n-created - descending order by creation date\n+created - ascending order by creation date\nOutward Issue Id Or Key (string)\nDescription: This is the ID or key of the source Jira issue from which the link originates (the \"outward\" issue in the relationship). It identifies the issue that will be linked to another issue.\nWhere to find it: You can find the issue key or ID in the Jira web interface—it's usually displayed at the top of the issue page (e.g., \"PROJ-123\"). You can also copy it from the issue's URL or from search results in Jira.\nExample: PROJ-123\nParent Key (string)\nDescription: specify the key of a parent issue when you are creating a subtask in Jira.\nIt links the new subtask to an existing parent issue (like a Story, Task, or Bug).\nFor regular issues (not subtasks), you should leave this field blank.\nWhere to find it:\nThe parent key is the unique identifier of the parent issue, visible in Jira as the issue key (e.g., PROJ-123).\nYou can find it in the Jira issue list, in the issue’s URL, or at the top of the issue detail page.\nExample: ENG-456\nPriority (ID) (string)\nDescription: used to set the priority level of the Jira issue you are creating (such as \"High\", \"Medium\", \"Low\", etc.). The value must be the ID of the priority, not its name or label.\nWhere to find the priority ID:\nIn Jira, go to Issues → Priorities (admin section).\nEach priority (like \"High\", \"Medium\", \"Low\") has a unique ID (e.g., \"1\", \"2\", \"3\", or sometimes a UUID).\nYou can also get the priority ID using the Jira API or by inspecting the page URL when editing a priority.\nExample: 1\nProject ID (string)\nDescription: A unique identifier for a Jira project. \nWhere to Find It:\nJira Web Interface:\nGo to your Jira dashboard.\nClick on \"Projects\" in the top menu and select your project.\nThe project key is usually shown in the project’s URL and in the project header (e.g., \"ABC\" in \"ABC-123\").\nThe project id (a numeric value) is not always visible in the UI, but the project key (a short code like \"ABC\") is commonly used and accepted in most API calls and integrations.\nJira URL Example:\nIf your project’s issues look like: https://yourcompany.atlassian.net/browse/ABC-123 Then \"ABC\" is the project key.\nStatus (string)\nDescription: The status input parameter allows you to filter Jira projects by their status. You can specify one or more statuses (comma-separated) such as live, archived, or deleted (for projects in the recycle bin). By default, only live projects are returned.\nExample: To list only archived projects, set status to archived.\nType Key (string)\nDescription: The \"type key\" parameter lets you filter Jira projects by their type. You can specify one or more types (comma-separated), such as business, service_desk, or software, to only return projects of those types.\nExample: To list only software projects software .\nQuery (string)\nDescription: The query parameter allows you to filter Jira projects by a search string. It returns projects whose key or name matches the provided text (case insensitive), making it easy to find specific projects by name or key.\nExample: To find all projects with \"marketing\" in their name or key, set query to marketing .\nReturn Issue (boolean)\nDescription: Whether to return the full updated issue in the response.\nStart At (number)\nDescription: The index of the first comment to return (pagination).\nExample: 10\nSummary (string)\nDescription: A concise summary or title for the Jira issue\nExample: Add dark mode support to dashboard\nUpdate History (boolean)\nDescription: Whether to update the user's recently viewed project list.\nBest Practices:\nAlways use the correct connection ID for your Jira account.\nEnsure required fields are provided for each action.\nUse outputs to connect Jira actions to downstream workflow nodes for further automation.\nAdvanced Settings\nRetry on Failure: Enable retrying when the node execution fails\nFallback Branch: Create a separate branch that executes when this node fails, allowing you to handle errors gracefullyCreate a separate branch that executes when this node fails, allowing you to handle errors gracefully\nLast updated 2 months ago","markdown":"# Jira | StackAI\n\nComprehensive guide to using the Jira node in StackAI workflows, including top actions, input requirements, configurations, and output details.\n\n**What is Jira?**\n\nJira is a powerful project management tool designed for issue and ticket tracking. The Jira node in StackAI allows you to automate the creation of Jira issues directly from your workflow, streamlining project management and team collaboration.\n\n* * *\n\n**Establishing A Connection**\n\n1.  Click **'Create Connection'** and give it a name you’ll recognize later (e.g., _Sam's Connection_).\n    \n2.  You’ll be redirected to the Atlassian website — sign in using your existing Jira account.\n    \n3.  Accept the requested permissions.\n    \n4.  Once redirected back to StackAI, open the dropdown menu under 'Select Connection' and select your newly created connection.\n    \n5.  Click the **'Test'** button to verify the connection status is _Healthy_.\n    \n\n* * *\n\n**Action Summary Table**\n\nAction\n\nDescriprion\n\nInputs\n\nOutputs\n\nAutomatically create a new issue (ticket) in your Jira project.\n\nProject ID, Issue Type ID, Summary, Description, Assignee ID, Parent Key, Priority ID, Labels, Due Date, Component, Custom Fields\n\nIssue Key, Issue ID, Issue URL, Summary, Status, Message\n\nAdd one or more file attachments to a Jira issue\n\nJira Issue ID or Key, File Path\n\nIssue ID or Key, Issue, Message\n\nAdd a comment to an existing Jira issue.\n\nJira Comment ID, Jira Issue URL, Message\n\nCreate a link between two Jira issues with an optional comment\n\nOutward Issue Id Or Key, Inward Issue Id Or Key, Link Type, Comment Text\n\nOutward Jira Issue, Inward Jira Issue, Jira Link Type, Operation Message\n\nRetrieve details of a specific Jira issue.\n\nIssue ID or Key, Fields, Expand, Update History, Custom Field IDs, Include All Custom Fields\n\nRetrieve comments for a Jira issue\n\nJira Issue ID or Key, Start At, Max Results, Order By, Expand\n\nIssue ID or Key, Comments\n\nGet a specific Jira project by its ID or key\n\nProject ID or Key, Expand\n\nProject ID, Project Key, Project Name, Project Category, Project Description, Project Lead, Project Issue Types, Project URL, Project Keys\n\nRetrieve a list of all Jira projects accessible to your account.\n\nStart At, Max Results, Order By, Query, Type Key, Status, Expand\n\nTotal Projects, Start At, Max Results, Is Last, Projects\n\nModify details of an existing Jira issue.\n\nIssue ID or Key, Summary, Description, Labels Add, Labels Remove, Assignee, Priority, Custom Fields, Notify Users, Return Issue\n\n**Input Breakdowns**\n\n*   **Assignee (ID)** (string)\n    \n    *   Description: Account ID of the user to assign the issue to. Use null or an empty string to unassign.\n        \n    *   Where to find it: In Jira Cloud, the Account ID is a unique identifier for each user. You can usually find it by:\n        \n        1.  Going to the user's profile in Jira (the URL will contain the accountId parameter).\n            \n        2.  Using the Jira API to list users, which will return their accountId.\n            \n        3.  Sometimes, when assigning users in the Jira UI, you can inspect the network requests to see the accountId.\n            \n        \n    *   Example: `5b10a2844c20165700ede21g`\n        \n    \n*   **Comment Text** (string)\n    \n    *   Description: The text content of the comment that will be added to the Jira issue.\n        \n    *   Example: `Linking this issue to track its dependency on the target issue`\n        \n    \n*   **Component (IDs)** (string)\n    \n    *   Description: Components are sub-sections or parts of a Jira project. They are used to group issues within a project into smaller parts, such as features, teams, modules, or functional areas. Each component has a unique component ID within the project.\n        \n    *   Where to find it: In the Jira UI\n        \n        *   Go to your Jira project.\n            \n        *   In the left sidebar, look for \"Project settings\" (or \"Settings\").\n            \n        *   Click on \"Components.\"\n            \n        *   Here, you will see a list of all components for the project, along with their names and IDs (the ID is often visible in the URL when you click on a component, or you can get it via the API).\n            \n        \n    *   Example: `[\"10001\", \"10003\"]`\n        \n    \n*   **Custom Field IDs** (string)\n    \n    *   Description: A comma-separated list of specific custom field IDs to extract from the Jira issue. Only these fields will be included in the custom\\_fields response.\n        \n    *   Where to find it: You can find custom field IDs in your Jira instance by navigating to Jira Administration > Issues > Custom Fields. The field ID is usually shown in the URL when you edit a custom field (e.g., .../customfields/customfield\\_12345). You can also use the Jira REST API to list all custom fields and their IDs.\n        \n    *   Example: `customfield_18165, customfield_12345`\n        \n    \n*   **Custom Fields** (string)\n    \n    *   Description: A JSON object containing custom field key-value pairs i.e. additional fields that your organization has configured to capture information beyond the standard fields (like summary, description, priority, etc.). These fields can be of various types (text, number, date, dropdown, user picker, etc.) and are used to tailor Jira issues to your team's specific needs.\n        \n    *   Example:\n        \n        ```\n        \"custom_fields\": {\n          \"customfield_10010\": \"Affects all users in Europe\",\n          \"customfield_10011\": \"High\"\n        }\n        ```\n        \n    \n*   **Description** (string)\n    \n    *   Description: A detailed description of the issue (supports Atlassian Document Format)\n        \n    *   Example: `Steps to reproduce the bug: 1. Log in to the app. 2. Click on the dashboard. 3. Observe the error message. Expected: Dashboard loads successfully. Actual: Error 500 is shown.`\n        \n    \n*   **Due Date** (string)\n    \n    *   Description: Allows you to specify the deadline for the issue in the format YYYY-MM-DD. This field is optional—if provided, it sets when the issue should be completed; if left blank, no due date will be assigned.\n        \n    *   Example: `2025-08-15`\n        \n    \n*   **Expand** (string)\n    \n    *   Description: The expand parameter allows you to request additional information in the response.\n        \n    *   Example: `renderedBody`\n        \n    \n*   **Fields** (string)\n    \n    *   Description: The fields parameter lets you specify which fields to include in the response when retrieving a Jira issue. You can use it to limit the output to only the fields you care about (like summary, status, or custom fields), or use special keywords to include all or only navigable fields.\n        \n    \n    *   Example: `summary,comment`\n        \n    \n*   **File Path** (string)\n    \n    *   Description: The file path parameter specifies the location of the file you want to attach to a Jira issue. It must be a valid path to the file on your system or accessible storage.\n        \n    \n    *   Example: `/Users/alex/Documents/screenshot.png`\n        \n    \n*   **Include All Custom Fields** (boolean)\n    \n    *   Description: Whether to include all custom fields for exploration (WARNING: creates very long output).\n        \n    \n*   **Inward Issue Id Or Key** (string)\n    \n    *   Description: This parameter specifies the ID or key of the target (inward) Jira issue that you want to link to. It identifies the issue that will be on the receiving end of the link relationship.\n        \n    *   Where to find it: You can find the issue key or ID in the Jira issue’s URL or at the top of the issue page. For more details, search for \"Jira issue key\" or see Atlassian’s documentation on [Finding an issue key in Jira](https://support.atlassian.com/jira-software-cloud/docs/what-is-an-issue-key/).\n        \n    *   Example: `PROJ-123`, `10002`\n        \n    \n*   **Issue ID** (string)\n    \n    *   Description: The Issue Id parameter specifies the unique identifier of the Jira issue where you want to add a comment. This is required to ensure the comment is attached to the correct issue.\n        \n    *   Where to find it: You can find the Issue Id in the Jira issue’s URL (e.g., the part like \"PROJ-123\" in [https://yourcompany.atlassian.net/browse/PROJ-123](https://yourcompany.atlassian.net/browse/PROJ-123)) or at the top of the issue page. It is also sometimes referred to as the \"issue key.\"\n        \n    *   Example: `PROJ-123`\n        \n    \n*   **Issue Type ID** (string)\n    \n    *   Description: Specifies what kind of issue you are creating in Jira. Common issue types include \"Bug\", \"Task\", \"Story\", \"Epic\", etc. Each type has its own workflow, fields, and purpose within your Jira project.\n        \n    *   Where to Find It:\n        \n        *   **Jira Web Interface:**\n            \n            1.  Go to your Jira project.\n                \n            2.  Click “Create” to open the new issue dialog.\n                \n            3.  In the “Issue Type” dropdown, you’ll see the available types (e.g., Bug, Task, Story).\n                \n            \n        \n    \n*   **Labels (Add/Remove)** (string)\n    \n    *   Description: Labels are keywords or tags you can attach to a Jira issue to help categorize, filter, and search for related issues. They are optional and can be used for custom organization or reporting.\n        \n    *   Where to find it: In the Jira issue creation or edit screen, there is a \"Labels\" field where you can add one or more labels. You can also see existing labels on the issue view page, usually near the bottom or in the details section.\n        \n    *   Example: `customer-request, backend, sprint-12`\n        \n    \n*   **Link Type** (string)\n    \n    *   Description: Specifies the relationship between two Jira issues, such as whether one issue blocks another, duplicates it, or is simply related. This determines how the issues are visually and logically connected in Jira.\n        \n    *   Where to find it: In Jira, when you manually link issues, you select the link type from a dropdown menu in the \"Link\" dialog (e.g., \"Blocks\", \"Relates to\", \"Duplicate\"). You can see available link types in your Jira instance by starting to link an issue or by asking your Jira admin for the configured link types.\n        \n    *   Example: `Blocks`, `Relates to`, `Duplicate`\n        \n    \n*   **Max Results** (number)\n    \n    *   Description: The \"max results\" parameter controls the maximum number of comments to return per request when retrieving comments for a Jira issue.\n        \n    *   Example: `10`, `50`\n        \n    \n*   **Notify Users** (boolean)\n    \n    *   Description: Whether to send email notifications about the update.\n        \n    \n*   **Order By** (string)\n    \n    *   Description: The \"Order By\" parameter determines the sort order of the returned comments, such as by creation date in ascending or descending order.\n        \n    *   Example:\n        \n        *   `created` - no sorting\n            \n        *   `-created` - descending order by creation date\n            \n        *   `+created` - ascending order by creation date\n            \n        \n    \n*   **Outward Issue Id Or Key** (string)\n    \n    *   Description: This is the ID or key of the source Jira issue from which the link originates (the \"outward\" issue in the relationship). It identifies the issue that will be linked to another issue.\n        \n    *   Where to find it: You can find the issue key or ID in the Jira web interface—it's usually displayed at the top of the issue page (e.g., \"PROJ-123\"). You can also copy it from the issue's URL or from search results in Jira.\n        \n    *   Example: `PROJ-123`\n        \n    \n*   **Parent Key** (string)\n    \n    *   Description: specify the key of a parent issue when you are creating a subtask in Jira.\n        \n        *   It links the new subtask to an existing parent issue (like a Story, Task, or Bug).\n            \n        *   For regular issues (not subtasks), you should leave this field blank.\n            \n        \n    *   #### \n        \n        Where to find it:\n        \n        *   The parent key is the unique identifier of the parent issue, visible in Jira as the issue key (e.g., `PROJ-123`).\n            \n        *   You can find it in the Jira issue list, in the issue’s URL, or at the top of the issue detail page.\n            \n        \n    *   Example: `ENG-456`\n        \n    \n*   **Priority (ID)** (string)\n    \n    *   Description: used to set the priority level of the Jira issue you are creating (such as \"High\", \"Medium\", \"Low\", etc.). The value must be the **ID** of the priority, not its name or label.\n        \n    *   Where to find the priority ID:\n        \n        *   In Jira, go to **Issues** → **Priorities** (admin section).\n            \n        *   Each priority (like \"High\", \"Medium\", \"Low\") has a unique ID (e.g., \"1\", \"2\", \"3\", or sometimes a UUID).\n            \n        *   You can also get the priority ID using the Jira API or by inspecting the page URL when editing a priority.\n            \n        \n    *   Example: `1`\n        \n    \n*   **Project ID** (string)\n    \n    *   Description: A unique identifier for a Jira project.\n        \n    *   Where to Find It:\n        \n        *   **Jira Web Interface:**\n            \n            1.  Go to your Jira dashboard.\n                \n            2.  Click on \"Projects\" in the top menu and select your project.\n                \n            3.  The project key is usually shown in the project’s URL and in the project header (e.g., \"ABC\" in \"ABC-123\").\n                \n            4.  The **project id** (a numeric value) is not always visible in the UI, but the **project key** (a short code like \"ABC\") is commonly used and accepted in most API calls and integrations.\n                \n            \n        *   **Jira URL Example:**\n            \n            *   If your project’s issues look like: `https://yourcompany.atlassian.net/browse/ABC-123` Then **\"ABC\"** is the project key.\n                \n            \n        \n    \n*   **Status** (string)\n    \n    *   Description: The status input parameter allows you to filter Jira projects by their status. You can specify one or more statuses (comma-separated) such as live, archived, or deleted (for projects in the recycle bin). By default, only live projects are returned.\n        \n    *   Example: To list only archived projects, set status to `archived`.\n        \n    \n*   **Type Key** (string)\n    \n    *   Description: The \"type key\" parameter lets you filter Jira projects by their type. You can specify one or more types (comma-separated), such as business, service\\_desk, or software, to only return projects of those types.\n        \n    *   Example: To list only software projects `software` .\n        \n    \n*   **Query** (string)\n    \n    *   Description: The query parameter allows you to filter Jira projects by a search string. It returns projects whose key or name matches the provided text (case insensitive), making it easy to find specific projects by name or key.\n        \n    *   Example: To find all projects with \"marketing\" in their name or key, set query to `marketing` .\n        \n    \n*   **Return Issue** (boolean)\n    \n    *   Description: Whether to return the full updated issue in the response.\n        \n    \n*   **Start At** (number)\n    \n    *   Description: The index of the first comment to return (pagination).\n        \n    *   Example: `10`\n        \n    \n*   **Summary** (string)\n    \n    *   Description: A concise summary or title for the Jira issue\n        \n    *   Example: `Add dark mode support to dashboard`\n        \n    \n*   **Update History** (boolean)\n    \n    *   Description: Whether to update the user's recently viewed project list.\n        \n    \n\n* * *\n\n**Best Practices:**\n\n*   Always use the correct connection ID for your Jira account.\n    \n*   Ensure required fields are provided for each action.\n    \n*   Use outputs to connect Jira actions to downstream workflow nodes for further automation.\n    \n\n* * *\n\n**Advanced Settings**\n\n*   Retry on Failure: Enable retrying when the node execution fails\n    \n*   Fallback Branch: Create a separate branch that executes when this node fails, allowing you to handle errors gracefullyCreate a separate branch that executes when this node fails, allowing you to handle errors gracefully\n    \n\nLast updated 2 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/linkedin","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/linkedin","loadedTime":"2025-10-17T18:30:26.836Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/linkedin","title":"LinkedIn | StackAI","description":"Comprehensive guide to the LinkedIn node in StackAI workflows, including available actions, input requirements, configurations, and output details.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"LinkedIn | StackAI"},{"property":"og:description","content":"Comprehensive guide to the LinkedIn node in StackAI workflows, including available actions, input requirements, configurations, and output details."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"81","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901ddfe7d8e5b3b-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:26 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::r6ptl-1760725826369-77c0b15c8f62"}},"screenshotUrl":null,"text":"LinkedIn | StackAI\nComprehensive guide to the LinkedIn node in StackAI workflows, including available actions, input requirements, configurations, and output details.\nThe LinkedIn Node in StackAI enables seamless integration with LinkedIn, the leading professional networking platform. This node allows you to automate LinkedIn-related tasks, such as searching for profiles, extracting professional data, and more, directly within your workflow/\nExample of Usage\nSuppose you want to search for professionals in a specific industry and extract their public profile data. You would use the LinkedIn node, select the \"Search\" action, provide the search keywords as input, and configure any optional filters. The output will be a list of matching LinkedIn profiles with relevant details.\nAvailable Actions\n1. LinkedIn Search\nDescription: Search for professionals, companies, or jobs on LinkedIn based on keywords and filters.\nInputs:\nKeywords (Required): The search terms to find relevant profiles or companies. Example: \"Data Scientist San Francisco\"\nFilters (Optional): Additional filters such as location, industry, or company size. Example: {\"location\": \"San Francisco\", \"industry\": \"Technology\"}\nConfigurations:\nQuery Filter: which fields of the JSON to include in the output\nTop K: how many results to return\nLinkedInSearchType: search generally, or for jobs, companies, or content\nCountryCode: the country to search in\nOutputs:\nResults (Always Provided): A list of LinkedIn profiles, companies, or jobs matching the search criteria. Example:\n[ { \"name\": \"Jane Doe\", \"title\": \"Senior Data Scientist\", \"company\": \"TechCorp\", \"location\": \"San Francisco\" }, ... ]\nLast updated 3 months ago","markdown":"# LinkedIn | StackAI\n\nComprehensive guide to the LinkedIn node in StackAI workflows, including available actions, input requirements, configurations, and output details.\n\nThe **LinkedIn Node** in StackAI enables seamless integration with LinkedIn, the leading professional networking platform. This node allows you to automate LinkedIn-related tasks, such as searching for profiles, extracting professional data, and more, directly within your workflow/\n\n* * *\n\n**Example of Usage**\n\nSuppose you want to search for professionals in a specific industry and extract their public profile data. You would use the LinkedIn node, select the \"Search\" action, provide the search keywords as input, and configure any optional filters. The output will be a list of matching LinkedIn profiles with relevant details.\n\n* * *\n\n**Available Actions**\n\n#### \n\n1\\. LinkedIn Search\n\n**Description:** Search for professionals, companies, or jobs on LinkedIn based on keywords and filters.\n\n**Inputs:**\n\n*   **Keywords** (Required): The search terms to find relevant profiles or companies. _Example:_ `\"Data Scientist San Francisco\"`\n    \n*   **Filters** (Optional): Additional filters such as location, industry, or company size. _Example:_ `{\"location\": \"San Francisco\", \"industry\": \"Technology\"}`\n    \n\n**Configurations:**\n\n*   **Query Filter:** which fields of the JSON to include in the output\n    \n*   **Top K:** how many results to return\n    \n*   **LinkedInSearchType:** search generally, or for jobs, companies, or content\n    \n*   **CountryCode:** the country to search in\n    \n\n**Outputs:**\n\n*   **Results** (Always Provided): A list of LinkedIn profiles, companies, or jobs matching the search criteria. _Example:_\n    \n    ```\n    [\n      {\n        \"name\": \"Jane Doe\",\n        \"title\": \"Senior Data Scientist\",\n        \"company\": \"TechCorp\",\n        \"location\": \"San Francisco\"\n      },\n      ...\n    ]\n    ```\n    \n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/inputs/audio-input-node","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/inputs/audio-input-node","loadedTime":"2025-10-17T18:30:26.929Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/inputs/audio-input-node","title":"Audio Input Node | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Audio Input Node | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"42","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901ddff385c6e25-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:26 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::rr477-1760725826496-81be0c40fde5"}},"screenshotUrl":null,"text":"Audio Input Node | StackAI\nThe Audio Node allows you to upload or record an audio clip as input. The audio is converted to text (using an audio-to-text LLM) and passed to your model.\nProviders\nThe Audio Node enables you to choose from two providers that will transcribe your audio:\ndeepgram: Uses Deepgram's API for audio transcription. Supports multiple models and submodels.\nwhisper-1: Uses OpenAI's Whisper v1 model. Does not support model or submodel selection (uses a default configuration).\nModel\nAvailable only when using the deepgram provider. Defines the main model used for transcription.\nnova: Legacy model, fast and lightweight.\nnova-2: Latest generation with improved accuracy and speed.\nenhanced: Optimized for high-quality audio and complex content.\nbase: Baseline transcription model with balanced performance.\nThis field is disabled for whisper-1.\nSubmodel\nFurther refines transcription behavior. Available only with deepgram.\ngeneral: Default submodel for general-purpose transcription.\nOther submodels exist depending on Deepgram's model.\nThis field is disabled for whisper-1.\nAudio Node Settings\nIf you're using your own audio-to-text model, here you can add your own API key to use it.\nHow to use it\nAdd an Audio to Text node to your flow.\nConnect the Audio to Text node to an LLM node.\nMention the Audio to Text node in the LLM node by pressing \"/\" and selecting the Audio to Text node.\nAdd an Output node to your flow.\nConnect the Output node to the LLM node.\nExpose the Audio to Text node to your users\nGo to the Export tab.\nEnable the audio node in the Inputs section.\nPress Save Interface to save your changes.\nYour users should now see an upload button in the interface.\nLast updated 3 months ago","markdown":"# Audio Input Node | StackAI\n\nThe **Audio Node** allows you to upload or record an audio clip as input. The audio is converted to text (using an audio-to-text LLM) and passed to your model.\n\n#### \n\n**Providers**\n\nThe Audio Node enables you to choose from two providers that will transcribe your audio:\n\n*   `deepgram`: Uses Deepgram's API for audio transcription. Supports multiple models and submodels.\n    \n*   `whisper-1`: Uses OpenAI's Whisper v1 model. Does not support model or submodel selection (uses a default configuration).\n    \n\n#### \n\n**Model**\n\nAvailable only when using the `deepgram` provider. Defines the main model used for transcription.\n\n*   `nova`: Legacy model, fast and lightweight.\n    \n*   `nova-2`: Latest generation with improved accuracy and speed.\n    \n*   `enhanced`: Optimized for high-quality audio and complex content.\n    \n*   `base`: Baseline transcription model with balanced performance.\n    \n\nThis field is disabled for `whisper-1`.\n\n#### \n\n**Submodel**\n\nFurther refines transcription behavior. Available only with `deepgram`.\n\n*   `general`: Default submodel for general-purpose transcription.\n    \n*   _Other submodels exist depending on Deepgram's model._\n    \n\nThis field is disabled for `whisper-1`.\n\n### \n\nAudio Node Settings\n\nIf you're using your own audio-to-text model, here you can add your own API key to use it.\n\n### \n\nHow to use it\n\n1.  Add an Audio to Text node to your flow.\n    \n2.  Connect the Audio to Text node to an LLM node.\n    \n3.  Mention the Audio to Text node in the LLM node by pressing **\"/\"** and selecting the Audio to Text node.\n    \n4.  Add an Output node to your flow.\n    \n5.  Connect the Output node to the LLM node.\n    \n\n### \n\nExpose the Audio to Text node to your users\n\n1.  Go to the **Export** tab.\n    \n2.  Enable the audio node in the **Inputs** section.\n    \n3.  Press **Save Interface** to save your changes.\n    \n4.  Your users should now see an upload button in the interface.\n    \n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/inputs/image-input-node","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/inputs/image-input-node","loadedTime":"2025-10-17T18:30:26.997Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/inputs/image-input-node","title":"Image Input Node | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Image Input Node | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"41","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901ddff1d3ce5f3-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:26 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"cle1::iad1::v4ld8-1760725826486-5cc7838ce549"}},"screenshotUrl":null,"text":"Image Input Node | StackAI\nThe Image Input node allows you to analyze and process images using advanced AI vision models. It can describe image content, extract information, answer questions about images, and perform various computer vision tasks by processing images from uploaded files.\nTo use the image node, upload a file or multiple files and connect the node to your input.\nOCR\nOCR is OFF by default. Turn it ON to first transform the image to text before passing to the model. A model of your choice will transform the image to text, based on a prompt you provide.\nAvailable Models\nSelect the AI vision model to use for image analysis\ngpt-4o: Fastest option\ngpt-4.1: Balanced option offering good performance with faster processing\nflux-kontext-pro: Advanced model for detailed image understanding and complex analysis\nOCR prompt: Describe what you want the AI to do with the image\nBe specific about what information you need extracted\nExamples: \"Describe the content of this image in detail\", \"Count the number of people in this photo\", \"What text is visible in this image?\"\nOutputs\nThe Image Input node provides processed information based on your prompt and the selected model's analysis of the image.\nCommon Use Cases\nContent Moderation: Automatically detect inappropriate or unsafe content in images\nProduct Cataloging: Extract product details, descriptions, and features from product photos\nDocument Processing: Extract text and data from scanned documents, receipts, or forms\nQuality Control: Analyze product images for defects or compliance issues\nSocial Media Management: Generate captions and descriptions for social media posts\nAccessibility: Create alt text descriptions for web images\nInventory Management: Count items or identify products in warehouse photos\nMedical Imaging: Analyze medical images for preliminary screening (with appropriate oversight)\nReal Estate: Generate property descriptions from listing photos\nEducation: Create study materials by analyzing diagrams, charts, or textbook images\nPrompt Examples\nGeneral Description: \"Describe everything you see in this image in detail\"\nText Extraction: \"Extract all visible text from this image and format it as plain text\"\nObject Counting: \"Count how many [specific objects] are visible in this image\"\nColor Analysis: \"What are the dominant colors in this image?\"\nScene Understanding: \"What is the setting or location shown in this image?\"\nSafety Assessment: \"Identify any potential safety hazards visible in this workplace image\"\nProduct Information: \"List all the product features and specifications visible on this packaging\"\nBest Practices\nImage Quality: Use high-resolution, clear images for better analysis results\nSpecific Prompts: Be precise about what information you need from the image\nModel Selection: Choose the appropriate model based on complexity requirements\nURL Accessibility: Ensure image URLs are publicly accessible and don't require authentication\nFile Formats: Use standard image formats (JPG, PNG) for best compatibility\nPrivacy Considerations: Be mindful of privacy when processing images containing personal information\nTroubleshooting\nImage Not Loading: Verify the image URL is correct and publicly accessible\nPoor Analysis Results: Try using a more detailed or specific prompt\nModel Errors: Switch to a different model if you encounter processing issues\nSlow Processing: Consider using o3-mini for faster results on simple tasks\nFormat Issues: Ensure your image is in a supported format and not corrupted\nLast updated 3 months ago","markdown":"# Image Input Node | StackAI\n\nThe Image Input node allows you to analyze and process images using advanced AI vision models. It can describe image content, extract information, answer questions about images, and perform various computer vision tasks by processing images from uploaded files.\n\nTo use the image node, upload a file or multiple files and connect the node to your input.\n\n### \n\nOCR\n\nOCR is OFF by default. Turn it ON to first transform the image to text before passing to the model. A model of your choice will transform the image to text, based on a prompt you provide.\n\n**Available Models**\n\nSelect the AI vision model to use for image analysis\n\n*   **gpt-4o**: Fastest option\n    \n*   **gpt-4.1**: Balanced option offering good performance with faster processing\n    \n*   **flux-kontext-pro:** Advanced model for detailed image understanding and complex analysis\n    \n\n**OCR prompt**: Describe what you want the AI to do with the image\n\n*   Be specific about what information you need extracted\n    \n*   Examples: \"Describe the content of this image in detail\", \"Count the number of people in this photo\", \"What text is visible in this image?\"\n    \n\n### \n\nOutputs\n\nThe Image Input node provides processed information based on your prompt and the selected model's analysis of the image.\n\n### \n\nCommon Use Cases\n\n*   **Content Moderation**: Automatically detect inappropriate or unsafe content in images\n    \n*   **Product Cataloging**: Extract product details, descriptions, and features from product photos\n    \n*   **Document Processing**: Extract text and data from scanned documents, receipts, or forms\n    \n*   **Quality Control**: Analyze product images for defects or compliance issues\n    \n*   **Social Media Management**: Generate captions and descriptions for social media posts\n    \n*   **Accessibility**: Create alt text descriptions for web images\n    \n*   **Inventory Management**: Count items or identify products in warehouse photos\n    \n*   **Medical Imaging**: Analyze medical images for preliminary screening (with appropriate oversight)\n    \n*   **Real Estate**: Generate property descriptions from listing photos\n    \n*   **Education**: Create study materials by analyzing diagrams, charts, or textbook images\n    \n\n### \n\nPrompt Examples\n\n*   **General Description**: \"Describe everything you see in this image in detail\"\n    \n*   **Text Extraction**: \"Extract all visible text from this image and format it as plain text\"\n    \n*   **Object Counting**: \"Count how many \\[specific objects\\] are visible in this image\"\n    \n*   **Color Analysis**: \"What are the dominant colors in this image?\"\n    \n*   **Scene Understanding**: \"What is the setting or location shown in this image?\"\n    \n*   **Safety Assessment**: \"Identify any potential safety hazards visible in this workplace image\"\n    \n*   **Product Information**: \"List all the product features and specifications visible on this packaging\"\n    \n\n### \n\nBest Practices\n\n*   **Image Quality**: Use high-resolution, clear images for better analysis results\n    \n*   **Specific Prompts**: Be precise about what information you need from the image\n    \n*   **Model Selection**: Choose the appropriate model based on complexity requirements\n    \n*   **URL Accessibility**: Ensure image URLs are publicly accessible and don't require authentication\n    \n*   **File Formats**: Use standard image formats (JPG, PNG) for best compatibility\n    \n*   **Privacy Considerations**: Be mindful of privacy when processing images containing personal information\n    \n\n### \n\nTroubleshooting\n\n*   **Image Not Loading**: Verify the image URL is correct and publicly accessible\n    \n*   **Poor Analysis Results**: Try using a more detailed or specific prompt\n    \n*   **Model Errors**: Switch to a different model if you encounter processing issues\n    \n*   **Slow Processing**: Consider using o3-mini for faster results on simple tasks\n    \n*   **Format Issues**: Ensure your image is in a supported format and not corrupted\n    \n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/outputs/output-node","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/outputs/output-node","loadedTime":"2025-10-17T18:30:27.522Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/outputs/output-node","title":"Output Node | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Output Node | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"0","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901de0289e24ba9-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:27 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"iad1::iad1::tj8cn-1760725827027-04e9ec3806f7"}},"screenshotUrl":null,"text":"Output Node | StackAI\nWhat is an Output Node?\nAn Output node displays the results generated by other nodes in your workflow. It acts as the final delivery point in your data pipeline, where outputs from processing nodes (like LLMs or data processors) are shown to your users.\nThe Output node is typically connected to nodes that generate textual or structured responses, such as:\nLLM nodes (to display answers or messages).\nKnowledge Base nodes (to show retrieved documents or summaries).\nKey benefits of the Output node:\nProvides a clear way to present results to end-users.\nEnables visibility into the results of data transformations or AI completions.\nSupports dynamic interfaces when exposed via the Export tab.\nHow to expose Outputs externally?\nTo allow users to see the Output node results:\nGo to the Export tab.\nEnable the Output node in the Outputs section under Fields.\nClick Save Interface.\nThe Output node’s results will now appear in your external interface when the workflow is triggered.\nWhat to expose in the Output node?\nWith the Output node, you will be able to plot the result coming out of any other node.\nHere are a few quick facts:\nMarkdown: The output node uses Markdown to format the text. You can use it to add links, imgs, headings, and more.\nLength: While output can have any length, you should be mindful that LLM prompts have a limit on how many words they can result.\nIntermediate Outputs: Use intermediate Output nodes to debug your workflow: for example, connect it to a vector store to see what chunks of text are returned.\nLast updated 3 months ago","markdown":"# Output Node | StackAI\n\n### \n\nWhat is an Output Node?\n\nAn Output node displays the results generated by other nodes in your workflow. It acts as the final delivery point in your data pipeline, where outputs from processing nodes (like LLMs or data processors) are shown to your users.\n\nThe Output node is typically connected to nodes that generate textual or structured responses, such as:\n\n1.  **LLM nodes** (to display answers or messages).\n    \n2.  **Knowledge Base nodes** (to show retrieved documents or summaries).\n    \n\nKey benefits of the Output node:\n\n*   Provides a clear way to present results to end-users.\n    \n*   Enables visibility into the results of data transformations or AI completions.\n    \n*   Supports dynamic interfaces when exposed via the **Export** tab.\n    \n\n### \n\nHow to expose Outputs externally?\n\nTo allow users to see the Output node results:\n\n1.  Go to the **Export** tab.\n    \n2.  Enable the Output node in the **Outputs** section under **Fields**.\n    \n3.  Click **Save Interface**.\n    \n4.  The Output node’s results will now appear in your external interface when the workflow is triggered.\n    \n\n### \n\nWhat to expose in the Output node?\n\nWith the Output node, you will be able to plot the result coming out of any other node.\n\nHere are a few quick facts:\n\n*   **Markdown:** The output node uses Markdown to format the text. You can use it to add links, imgs, headings, and more.\n    \n*   **Length:** While output can have any length, you should be mindful that LLM prompts have a limit on how many words they can result.\n    \n*   **Intermediate Outputs:** Use intermediate Output nodes to debug your workflow: for example, connect it to a vector store to see what chunks of text are returned.\n    \n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/outputs","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/outputs","loadedTime":"2025-10-17T18:30:27.201Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/outputs","title":"Outputs | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Outputs | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1827","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901de02696bd46a-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:27 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::74g7p-1760725826982-fc692174b70d"}},"screenshotUrl":null,"text":"Outputs | StackAI\nOutput NodeImage NodeAction NodeAudio Node\nPreviousImage Input NodeNextOutput Node\nWas this helpful?","markdown":"# Outputs | StackAI\n\n[Output Node](https://docs.stack-ai.com/stack-ai/workflow-builder/outputs/output-node)[Image Node](https://docs.stack-ai.com/stack-ai/workflow-builder/outputs/image-node)[Action Node](https://docs.stack-ai.com/stack-ai/workflow-builder/outputs/action-node)[Audio Node](https://docs.stack-ai.com/stack-ai/workflow-builder/outputs/audio-node)\n\n[PreviousImage Input Node](https://docs.stack-ai.com/stack-ai/workflow-builder/inputs/image-input-node)[NextOutput Node](https://docs.stack-ai.com/stack-ai/workflow-builder/outputs/output-node)\n\nWas this helpful?","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/outputs/image-node","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/outputs/image-node","loadedTime":"2025-10-17T18:30:28.072Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/outputs/image-node","title":"Image Node | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Image Node | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"0","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901de036c84d650-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:28 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"iad1::iad1::4pxxn-1760725827148-0c051e9944a2"}},"screenshotUrl":null,"text":"Image Node | StackAI\nWhat is an Image Node?\nThe Image node allows you to generate visual content from text prompts using AI image generation models such as OpenAI’s DALL·E 3 or Stable Diffusion.\nUse this node to turn descriptions into visuals. Ideal for creative tools, content generation, or enhancing user engagement with dynamic imagery.\nCommon applications include:\nIllustrating chatbot responses\nCreating product mockups or concept art\nGenerating visual assets on-the-fly for user interfaces\nHow to use it?\nTo use the Image node:\nInput: Accepts a text string (prompt), often from a user or LLM node.\nOutput: Returns a generated image that can be previewed or used downstream.\nThe model processes the prompt and returns a generated image in the specified size and style.\nSettings\nConfiguration Options\nModel: Choose between available image generation models:\nOpenAI DALL·E 3\nStable Diffusion 3.5\nImage size: Select the resolution for the generated image:\n1024×1024 (square)\n1024×1792 (portrait)\n1792×1024 (landscape)\nAPI Key: (Optional) Provide your own key to use a custom instance or higher tier of the selected model.\nBy adjusting the model and size, you can tailor visual outputs to match your product’s design or artistic needs.\nHow to expose Images externally?\nTo allow users to see the generated images:\nGo to the Export tab.\nEnable the Image node in the Outputs section under Fields.\nClick Save Interface.\nThe image result will now be rendered in your external interface when the flow is triggered.","markdown":"# Image Node | StackAI\n\n### \n\nWhat is an Image Node?\n\nThe Image node allows you to generate visual content from text prompts using AI image generation models such as OpenAI’s DALL·E 3 or Stable Diffusion.\n\nUse this node to turn descriptions into visuals. Ideal for creative tools, content generation, or enhancing user engagement with dynamic imagery.\n\nCommon applications include:\n\n*   Illustrating chatbot responses\n    \n*   Creating product mockups or concept art\n    \n*   Generating visual assets on-the-fly for user interfaces\n    \n\n### \n\nHow to use it?\n\nTo use the Image node:\n\n*   **Input:** Accepts a text string (prompt), often from a user or LLM node.\n    \n*   **Output:** Returns a generated image that can be previewed or used downstream.\n    \n\nThe model processes the prompt and returns a generated image in the specified size and style.\n\n### \n\nSettings\n\n#### \n\nConfiguration Options\n\n*   **Model:** Choose between available image generation models:\n    \n    *   `OpenAI DALL·E 3`\n        \n    *   `Stable Diffusion 3.5`\n        \n    \n*   **Image size:** Select the resolution for the generated image:\n    \n    *   `1024×1024` (square)\n        \n    *   `1024×1792` (portrait)\n        \n    *   `1792×1024` (landscape)\n        \n    \n*   **API Key:** (Optional) Provide your own key to use a custom instance or higher tier of the selected model.\n    \n\nBy adjusting the model and size, you can tailor visual outputs to match your product’s design or artistic needs.\n\n### \n\nHow to expose Images externally?\n\nTo allow users to see the generated images:\n\n1.  Go to the **Export** tab.\n    \n2.  Enable the Image node in the **Outputs** section under **Fields**.\n    \n3.  Click **Save Interface**.\n    \n4.  The image result will now be rendered in your external interface when the flow is triggered.","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/outputs/audio-node","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/outputs/audio-node","loadedTime":"2025-10-17T18:30:29.490Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/outputs/audio-node","title":"Audio Node | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Audio Node | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"0","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901de0b99ed9bb5-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:29 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"iad1::iad1::s6qsf-1760725828473-dd2c9d332124"}},"screenshotUrl":null,"text":"Audio Node | StackAI\nWhat is an Audio Node?\nThe Audio node lets you generate audio from text using high-quality voice synthesis models. It's ideal for turning responses from LLMs or static text into spoken audio.\nThis node is commonly used in voice interfaces, accessibility workflows, or any experience where you want to deliver output via sound.\nIt supports popular text-to-speech engines and customizable voices to match your tone and use case.\nKey capabilities include:\nSupports multilingual audio synthesis.\nChoose from multiple voice models and accents.\nPlay back audio directly in the interface with Test Output.\nOptionally use your own API key to connect with external TTS providers.\nHow to use it?\nTo use the Audio node:\nInput: Accepts a text string (e.g., from an LLM or Input node).\nOutput: Returns a playable audio file that can be previewed that can be previewed.\nAfter receiving text input, the Audio node displays a Test Output section with a play button, allowing you to listen to the generated audio.\nSettings\nConfiguration Options\nModel: Choose the TTS engine, such as eleven_multilingual_v2.\nVoice: Select from available voice profiles (e.g., Sarah, Chris).\nAPI Key: Optional field for providing your own TTS provider credentials.\nHow to expose Audio externally?\nTo make audio results available in your external interface:\nGo to the Export tab.\nEnable the Audio node in the Outputs section under Fields.\nClick Save Interface.\nWhen triggered, users will be able to hear the generated audio directly in the interface.","markdown":"# Audio Node | StackAI\n\n### \n\nWhat is an Audio Node?\n\nThe Audio node lets you generate audio from text using high-quality voice synthesis models. It's ideal for turning responses from LLMs or static text into spoken audio.\n\nThis node is commonly used in voice interfaces, accessibility workflows, or any experience where you want to deliver output via sound.\n\nIt supports popular text-to-speech engines and customizable voices to match your tone and use case.\n\nKey capabilities include:\n\n*   Supports multilingual audio synthesis.\n    \n*   Choose from multiple voice models and accents.\n    \n*   Play back audio directly in the interface with **Test Output**.\n    \n*   Optionally use your own API key to connect with external TTS providers.\n    \n\n### \n\nHow to use it?\n\nTo use the Audio node:\n\n*   **Input:** Accepts a text string (e.g., from an LLM or Input node).\n    \n*   **Output:** Returns a playable audio file that can be previewed that can be previewed.\n    \n\nAfter receiving text input, the Audio node displays a **Test Output** section with a play button, allowing you to listen to the generated audio.\n\n### \n\nSettings\n\n#### \n\nConfiguration Options\n\n*   **Model:** Choose the TTS engine, such as `eleven_multilingual_v2`.\n    \n*   **Voice:** Select from available voice profiles (e.g., Sarah, Chris).\n    \n*   **API Key:** Optional field for providing your own TTS provider credentials.\n    \n\n### \n\nHow to expose Audio externally?\n\nTo make audio results available in your external interface:\n\n1.  Go to the **Export** tab.\n    \n2.  Enable the Audio node in the **Outputs** section under **Fields**.\n    \n3.  Click **Save Interface**.\n    \n4.  When triggered, users will be able to hear the generated audio directly in the interface.","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/knowledge-bases","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/knowledge-bases","loadedTime":"2025-10-17T18:30:29.811Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/knowledge-bases","title":"Knowledge Bases | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Knowledge Bases | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1827","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901de0f5ec75008-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:29 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::jpgv7-1760725829046-44ddf4282559"}},"screenshotUrl":null,"text":"Knowledge Bases | StackAI\nHow to Use Knowledge BasesKnowledge Base NodesCreating a Knowledge BaseNode Specific Features\nPreviousAudio NodeNextHow to Use Knowledge Bases\nWas this helpful?","markdown":"# Knowledge Bases | StackAI\n\n[How to Use Knowledge Bases](https://docs.stack-ai.com/stack-ai/workflow-builder/knowledge-bases/how-to-use-knowledge-bases)[Knowledge Base Nodes](https://docs.stack-ai.com/stack-ai/workflow-builder/knowledge-bases/knowledge-base-nodes)[Creating a Knowledge Base](https://docs.stack-ai.com/stack-ai/workflow-builder/knowledge-bases/creating-a-knowledge-base)[Node Specific Features](https://docs.stack-ai.com/stack-ai/workflow-builder/knowledge-bases/node-specific-features)\n\n[PreviousAudio Node](https://docs.stack-ai.com/stack-ai/workflow-builder/outputs/audio-node)[NextHow to Use Knowledge Bases](https://docs.stack-ai.com/stack-ai/workflow-builder/knowledge-bases/how-to-use-knowledge-bases)\n\nWas this helpful?","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/knowledge-bases/how-to-use-knowledge-bases","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/knowledge-bases/how-to-use-knowledge-bases","loadedTime":"2025-10-17T18:30:30.115Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/knowledge-bases/how-to-use-knowledge-bases","title":"How to Use Knowledge Bases | StackAI","description":"What is a knowledge base and how to set up a knowledge base from the workflow builder or for your organization.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"How to Use Knowledge Bases | StackAI"},{"property":"og:description","content":"What is a knowledge base and how to set up a knowledge base from the workflow builder or for your organization."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"0","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901de11dc8f4d20-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:29 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"iad1::iad1::74g7p-1760725829458-280acbf3976d"}},"screenshotUrl":null,"text":"How to Use Knowledge Bases\nWhat is a knowledge base and how to set up a knowledge base from the workflow builder or for your organization.\nWhat is a Knowledge Base?\nA knowledge base is a centralized repository of information, documents, or data that can be searched and referenced to answer questions, solve problems, or provide context.\nStackAI enables users to leverage a powerful and flexible RAG (Retrieval-Augmented Generation) system through a simple drag-and-drop interface. By connecting directly to their knowledge base, users can effortlessly incorporate contextual search capabilities. \nTo use a Knowledge Base in your project, drag and drop a Knowledge Base Node or select the Knowledge Base tool in your LLM. Knowledge Bases can be created and managed in the Knowledge Base Dashboard, or you can create one on the fly in your Knowledge Base Node.\nThe standalone Knowledge Base Node requires an input to function—usually a standard text input. This input serves as the query that the Knowledge Base uses to fetch relevant context. If there are multiple inputs connected, you can specify which one to use in the Knowledge Base settings.\nIf no input is connected or specified in the Knowledge Base Node, it will not return a result.\nThe Knowledge Base Node\nThe Knowledge Base node acts like a search engine over files, allowing LLMs to retrieve the precise context needed to perform any given task effectively. Indexing and storage in vector databases happen automatically, without any action from the user. Syncing also occurs automatically, if enabled, so that new files or changes are added to the knowledge base.\nUnlike other platforms, StackAI enables users to leverage a powerful and flexible RAG (Retrieval-Augmented Generation) system through a simple drag-and-drop interface. By connecting directly to their knowledge base, users can effortlessly incorporate contextual search capabilities. The Knowledge Base node acts like a search engine over files, allowing LLMs to retrieve the precise context needed to perform any given task effectively. Indexing and storage in vector databases happen without any action from the user. Syncing occurs automatically if enabled, so that new files or changes are added to the knowledge base.\nImport Knowledge From Any Source\nStackAI allows you to create a knowledge base from uploaded documents, tables, Dropbox, Google Drive, Sharepoint, and many more! File metadata from platforms like SharePoint is also imported to enhance information retrieval, resulting in a 27% increase in accuracy for financial applications.\nAdvanced search controls within the knowledge base, designed with the right level of abstraction to ensure ease of use for end users.\nCitations are clearly displayed in the user interface to enable response auditing. Users can view the original source file and the exact information chunks utilized by the LLM. Superscript references within the response allow users to easily trace and verify the underlying data.","markdown":"# How to Use Knowledge Bases\n\nWhat is a knowledge base and how to set up a knowledge base from the workflow builder or for your organization.\n\n### \n\nWhat is a Knowledge Base?\n\nA **knowledge base** is a centralized repository of information, documents, or data that can be searched and referenced to answer questions, solve problems, or provide context.\n\nStackAI enables users to leverage a powerful and flexible RAG (Retrieval-Augmented Generation) system through a simple drag-and-drop interface. By connecting directly to their knowledge base, users can effortlessly incorporate contextual search capabilities.\n\nTo use a Knowledge Base in your project, drag and drop a Knowledge Base Node or select the Knowledge Base tool in your LLM. Knowledge Bases can be created and managed in the Knowledge Base Dashboard, or you can create one on the fly in your Knowledge Base Node.\n\nThe standalone Knowledge Base Node requires an input to function—usually a standard text input. This input serves as the query that the Knowledge Base uses to fetch relevant context. If there are multiple inputs connected, you can specify which one to use in the Knowledge Base settings.\n\n**If no input is connected or specified in the Knowledge Base Node, it will not return a result.**\n\n### \n\nThe Knowledge Base Node\n\nThe Knowledge Base node acts like a search engine over files, allowing LLMs to retrieve the precise context needed to perform any given task effectively. Indexing and storage in vector databases happen automatically, without any action from the user. Syncing also occurs automatically, if enabled, so that new files or changes are added to the knowledge base.\n\nUnlike other platforms, StackAI enables users to leverage a powerful and flexible RAG (Retrieval-Augmented Generation) system through a simple drag-and-drop interface. By connecting directly to their knowledge base, users can effortlessly incorporate contextual search capabilities. The Knowledge Base node acts like a search engine over files, allowing LLMs to retrieve the precise context needed to perform any given task effectively. Indexing and storage in vector databases happen without any action from the user. Syncing occurs automatically if enabled, so that new files or changes are added to the knowledge base.\n\n### \n\nImport Knowledge From Any Source\n\nStackAI allows you to create a knowledge base from uploaded documents, tables, Dropbox, Google Drive, Sharepoint, and many more! File metadata from platforms like SharePoint is also imported to enhance information retrieval, resulting in a 27% increase in accuracy for financial applications.\n\nAdvanced search controls within the knowledge base, designed with the right level of abstraction to ensure ease of use for end users.\n\nCitations are clearly displayed in the user interface to enable response auditing. Users can view the original source file and the exact information chunks utilized by the LLM. Superscript references within the response allow users to easily trace and verify the underlying data.","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/llms","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/llms","loadedTime":"2025-10-17T18:30:30.729Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/llms","title":"LLMs | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"LLMs | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1829","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901de180e2dd657-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:30 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::6vxbv-1760725830442-5bc548e78744"}},"screenshotUrl":null,"text":"LLMs | StackAI\nLLM NodeHow to Improve LLM PerformanceLLMs Hosted on Azure & AWS BedrockLLM Provider GovernanceLocal LLM\nPreviousNode Specific FeaturesNextLLM Node\nWas this helpful?","markdown":"# LLMs | StackAI\n\n[LLM Node](https://docs.stack-ai.com/stack-ai/workflow-builder/llms/llm-node)[How to Improve LLM Performance](https://docs.stack-ai.com/stack-ai/workflow-builder/llms/how-to-improve-llm-performance)[LLMs Hosted on Azure & AWS Bedrock](https://docs.stack-ai.com/stack-ai/workflow-builder/llms/llms-hosted-on-azure-and-aws-bedrock)[LLM Provider Governance](https://docs.stack-ai.com/stack-ai/workflow-builder/llms/llm-provider-governance)[Local LLM](https://docs.stack-ai.com/stack-ai/workflow-builder/llms/local-llm)\n\n[PreviousNode Specific Features](https://docs.stack-ai.com/stack-ai/workflow-builder/knowledge-bases/node-specific-features)[NextLLM Node](https://docs.stack-ai.com/stack-ai/workflow-builder/llms/llm-node)\n\nWas this helpful?","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/knowledge-bases/creating-a-knowledge-base","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/knowledge-bases/creating-a-knowledge-base","loadedTime":"2025-10-17T18:30:30.940Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/knowledge-bases/creating-a-knowledge-base","title":"Creating a Knowledge Base | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Creating a Knowledge Base | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"0","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901de16ffe0e76c-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:30 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"iad1::iad1::9mcx9-1760725830279-3648c5738cc1"}},"screenshotUrl":null,"text":"Creating a Knowledge Base | StackAI\nThe Knowledge Base Dashboard\nIt's easy to create a Knowledge Base on the fly with the KB Node, but the Knowledge Base Dashboard will be your centralized space to create, manage, and share knowledge bases. It enables you to upload files, import data from external connections, customize upload settings, and manage access permissions. This guide will walk you through the main features.\nYour First Knowledge Base\nThe Knowledge Base Dashboard allows you to create and manage your first knowledge base seamlessly. After creating a knowledge base, you can:\nAdd Files: Upload files directly by dragging and dropping or selecting files manually.\nOrganize Content: Group related files for easy navigation.\nEdit Descriptions: Add or modify descriptions to reflect the purpose of the knowledge base.\nUpload Files\nThe most straightforward way to create a knowledge base is by uploading files.\nExample File Types:\nWord Documents: .doc, .docx\nPDF Files: .pdf\nPowerPoint Presentations: .ppt, .pptx\nExcel Spreadsheets: .xls, .xlsx\nImport from Connection\nEasily import files from external connections such as Dropbox, Google Drive, Notion, and SharePoint. Follow these steps:\nNavigate to Import from Connection in the dashboard.\nSelect the external connection (e.g., Dropbox).\nBrowse and pick the files or folders you want to import.\nClick Import selected files to transfer them to your knowledge base.\nBe aware that the more files you import, the longer it will take to process them.\nAuto-Sync Files\nIf you are importing from a connection, you may want your files to automatically sync with your connection so that if a file is updated, it is also updated in your StackAI Knowledge Base. \nTo do this, first go to the Knowledge Base Dashboard, then go to the knowledge base you want to sync. Toggle ON auto-sync. Here you can also re-sync the files by clicking \"Sync Files.\" This is useful if you have added a new file and you would like it to be reflected you StackAI KB immediately.\nAdvanced: Upload Settings\nCustomize how files are processed and indexed in your knowledge base using Upload Settings:\nChunking Algorithm: Choose where and how files are broken down for indexing (e.g., sentence-based chunking). Sentence-based chunking is more granular; files are broken down into sentence chunks. \nChunk Length: Define the maximum size of each chunk in characters. \nChunk Overlap: Specify how much content should overlap between chunks. Some overlap can improve retrieval, as it avoids fragmentation.\nOCR (Optical Character Recognition): Enable extracting text from images.\nAdvanced Data Extraction: Activate for enhanced processing of complex files.\nEmbedding Model: Select the AI model for embedding and indexing files.\nExample:\nChunking Algorithm: Sentence-based\nChunk Length: 2,500 characters\nEmbedding Model: text-embedding-3-large\nSuccessfully Synced Files\nWhen uploading files to a knowledge base, the dashboard displays a status bar indicating progress. Once completed, a confirmation message appears: \"Successfully synced [X] files.\"\nRole-Based Access Control (RBAC)\nControl who can view, edit, or manage your knowledge bases with RBAC. You can assign roles and permissions to individuals or groups:\nAdmin: Full control over the knowledge base, including editing and sharing.\nViewer: Read-only access.\nGroups: Share with predefined groups for streamlined collaboration.\nExample:\nGroup Viewer: group1\nConclusion\nThe Knowledge Base Dashboard simplifies the process of creating and managing knowledge bases, whether for personal use or organizational collaboration. From file uploads and import options to advanced settings and access controls, this tool provides all the features needed to maintain an efficient and accessible repository of information.\nFor further assistance, refer to the Help & More section in the sidebar or contact your administrator.\nLast updated 2 months ago","markdown":"# Creating a Knowledge Base | StackAI\n\n### \n\nThe Knowledge Base Dashboard\n\nIt's easy to create a Knowledge Base on the fly with the KB Node, but the **Knowledge Base Dashboard** will be your centralized space to create, manage, and share knowledge bases. It enables you to upload files, import data from external connections, customize upload settings, and manage access permissions. This guide will walk you through the main features.\n\n* * *\n\n### \n\nYour First Knowledge Base\n\nThe **Knowledge Base Dashboard** allows you to create and manage your first knowledge base seamlessly. After creating a knowledge base, you can:\n\n1.  **Add Files**: Upload files directly by dragging and dropping or selecting files manually.\n    \n2.  **Organize Content**: Group related files for easy navigation.\n    \n3.  **Edit Descriptions**: Add or modify descriptions to reflect the purpose of the knowledge base.\n    \n\n* * *\n\n### \n\nUpload Files\n\nThe most straightforward way to create a knowledge base is by uploading files.\n\n#### \n\nExample File Types:\n\n*   **Word Documents**: `.doc`, `.docx`\n    \n*   **PDF Files**: `.pdf`\n    \n*   **PowerPoint Presentations**: `.ppt`, `.pptx`\n    \n*   **Excel Spreadsheets**: `.xls`, `.xlsx`\n    \n\n* * *\n\n### \n\nImport from Connection\n\nEasily import files from external connections such as **Dropbox**, **Google Drive**, **Notion**, and **SharePoint**. Follow these steps:\n\n1.  Navigate to **Import from Connection** in the dashboard.\n    \n2.  Select the external connection (e.g., Dropbox).\n    \n3.  Browse and pick the files or folders you want to import.\n    \n4.  Click **Import selected files** to transfer them to your knowledge base.\n    \n\nBe aware that the more files you import, the longer it will take to process them.\n\n* * *\n\n### \n\nAuto-Sync Files\n\nIf you are importing from a connection, you may want your files to automatically sync with your connection so that if a file is updated, it is also updated in your StackAI Knowledge Base.\n\nTo do this, first go to the Knowledge Base Dashboard, then go to the knowledge base you want to sync. Toggle ON auto-sync. Here you can also re-sync the files by clicking \"Sync Files.\" This is useful if you have added a new file and you would like it to be reflected you StackAI KB immediately.\n\n* * *\n\n### \n\nAdvanced: Upload Settings\n\nCustomize how files are processed and indexed in your knowledge base using **Upload Settings**:\n\n1.  **Chunking Algorithm**: Choose where and how files are broken down for indexing (e.g., sentence-based chunking). Sentence-based chunking is more granular; files are broken down into sentence chunks.\n    \n2.  **Chunk Length**: Define the maximum size of each chunk in characters.\n    \n3.  **Chunk Overlap**: Specify how much content should overlap between chunks. Some overlap can improve retrieval, as it avoids fragmentation.\n    \n4.  **OCR (Optical Character Recognition)**: Enable extracting text from images.\n    \n5.  **Advanced Data Extraction**: Activate for enhanced processing of complex files.\n    \n6.  **Embedding Model**: Select the AI model for embedding and indexing files.\n    \n\n#### \n\nExample:\n\n*   Chunking Algorithm: Sentence-based\n    \n*   Chunk Length: 2,500 characters\n    \n*   Embedding Model: `text-embedding-3-large`\n    \n\n* * *\n\n### \n\nSuccessfully Synced Files\n\nWhen uploading files to a knowledge base, the dashboard displays a status bar indicating progress. Once completed, a confirmation message appears: **\"Successfully synced \\[X\\] files.\"**\n\n* * *\n\n### \n\nRole-Based Access Control (RBAC)\n\nControl who can view, edit, or manage your knowledge bases with **RBAC**. You can assign roles and permissions to individuals or groups:\n\n1.  **Admin**: Full control over the knowledge base, including editing and sharing.\n    \n2.  **Viewer**: Read-only access.\n    \n3.  **Groups**: Share with predefined groups for streamlined collaboration.\n    \n\n#### \n\nExample:\n\n*   Group Viewer: `group1`\n    \n\n* * *\n\n### \n\nConclusion\n\nThe Knowledge Base Dashboard simplifies the process of creating and managing knowledge bases, whether for personal use or organizational collaboration. From file uploads and import options to advanced settings and access controls, this tool provides all the features needed to maintain an efficient and accessible repository of information.\n\nFor further assistance, refer to the **Help & More** section in the sidebar or contact your administrator.\n\nLast updated 2 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/knowledge-bases/node-specific-features","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/knowledge-bases/node-specific-features","loadedTime":"2025-10-17T18:30:31.225Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/knowledge-bases/node-specific-features","title":"Node Specific Features | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Node Specific Features | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"0","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901de179c7b82ab-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:31 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"iad1::iad1::6bcjj-1760725830392-a5157d947667"}},"screenshotUrl":null,"text":"Node Specific Features | StackAI\nData Node\nWhen you create a Data node, you will see a button to upload data to the Vector Store API. You can find the API documentation here. \nGoogle Drive Node\nAuthenticate through Google to give your project access to your Google Drive. Your end users will be able to ask an LLM questions based on the files you've uploaded.\nSharepoint Node\nThe Sharepoint Node allows you to index two types of media: documents stored in Sharepoint and Sharepoint News, where everything on the page is indexed. \nTo authenticate to your Sharepoint organization account, you must follow these steps:\nGo to App Registrations in Azure: visit your Azure Portal and go to \"App Registrations\" here.\nCreate App: Click on \"New Registration\". Add a name to your app and select \"Accounts in this organizational directory only (Default Directory only - Single tenant)\".\nGet Client ID and Tenant ID: get your client and tenant id from the \"Essentials\" section. You will find them under \"Application (client) ID\" and \"Directory (tenant) ID \".\nCreate a client secret: Navigate to \"Certificates & Secrets\" then click on \"New client secret\". Give an expiration date to your secret. Finally, you will find the client secret in the \"Value\" field of the secret.\nAdd Scopes: Naviate to \"App Permissions\" and then click on \"Add a permission\". Click on \"Microsoft Graph\" and select \"Application Permissions\". Then select the following scopes: Sites.ReadAll, Files.ReadAll, BrowserSiteLists.Read.All. Then click on \"Add Permissions\". Finally click on \"Grant Admin Consent for Default Directory\".\nNow you can proceed to add your node in Stack AI add add the value of your client_id, client_secret, tenant_id, site_id, and folder path.\nTable Node\nUse a Table Node to create a Knowledge Base from a .csv file. StackAI creates a SQL database with your .csv file and performs semantic search, all under the hood. A generative model decides which search result--SQL or semantic search--is more informative, giving you powerful search over tables.\nWebsites Node\nThe Website Node allows you to create a Knowledge Base from a website URL. The URLs that you upload are then indexed and stored in a vector data base - don't worry, we do this for you in the background! This process is done once, so that you can later query this knowledge base and only retrieve the pieces of information that are more related to your query. It's the most efficient way to manage a long list of URLs, without having to index them everytime you run the workflow (i.e., embeddings are generated only once, when you upload the URLs).\nJira Node\nThe Jira Node allows you to create a knowledge base from Jira projects. To use this node, first establish a connection to Jira, see how to do so here. You will be able to select which projects to include in your knowledge base and perform RAG over those projects.\nLast updated 2 months ago","markdown":"# Node Specific Features | StackAI\n\n### \n\nData Node\n\nWhen you create a Data node, you will see a button to upload data to the Vector Store API. You can find the API documentation [here](https://www.stack-ai.com/docs/api-reference/knowledge-base/upload-data).\n\n### \n\nGoogle Drive Node\n\nAuthenticate through Google to give your project access to your Google Drive. Your end users will be able to ask an LLM questions based on the files you've uploaded.\n\n### \n\nSharepoint Node\n\nThe Sharepoint Node allows you to index two types of media: documents stored in Sharepoint and Sharepoint News, where everything on the page is indexed.\n\nTo authenticate to your Sharepoint organization account, you must follow these steps:\n\n*   **Go to App Registrations in Azure**: visit your Azure Portal and go to \"App Registrations\" [here](https://portal.azure.com/#view/Microsoft_AAD_RegisteredApps/ApplicationsListBlade).\n    \n*   **Create App**: Click on \"New Registration\". Add a name to your app and select \"Accounts in this organizational directory only (Default Directory only - Single tenant)\".\n    \n*   **Get Client ID and Tenant ID**: get your client and tenant id from the \"Essentials\" section. You will find them under \"Application (client) ID\" and \"Directory (tenant) ID \".\n    \n*   **Create a client secret**: Navigate to \"Certificates & Secrets\" then click on \"New client secret\". Give an expiration date to your secret. Finally, you will find the client secret in the \"Value\" field of the secret.\n    \n*   **Add Scopes**: Naviate to \"App Permissions\" and then click on \"Add a permission\". Click on \"Microsoft Graph\" and select \"Application Permissions\". Then select the following scopes: Sites.ReadAll, Files.ReadAll, BrowserSiteLists.Read.All. Then click on \"Add Permissions\". Finally click on \"Grant Admin Consent for Default Directory\".\n    \n\nNow you can proceed to add your node in Stack AI add add the value of your client\\_id, client\\_secret, tenant\\_id, site\\_id, and folder path.\n\n### \n\nTable Node\n\nUse a Table Node to create a Knowledge Base from a .csv file. StackAI creates a SQL database with your .csv file and performs semantic search, all under the hood. A generative model decides which search result--SQL or semantic search--is more informative, giving you powerful search over tables.\n\n### \n\nWebsites Node\n\nThe Website Node allows you to create a Knowledge Base from a website URL. The URLs that you upload are then indexed and stored in a vector data base - don't worry, we do this for you in the background! This process is done once, so that you can later query this knowledge base and only retrieve the pieces of information that are more related to your query. It's the most efficient way to manage a long list of URLs, without having to index them everytime you run the workflow (i.e., embeddings are generated only once, when you upload the URLs).\n\n### \n\nJira Node\n\nThe Jira Node allows you to create a knowledge base from Jira projects. To use this node, first establish a connection to Jira, see how to do so [here](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/jira). You will be able to select which projects to include in your knowledge base and perform RAG over those projects.\n\nLast updated 2 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/outputs/action-node","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/outputs/action-node","loadedTime":"2025-10-17T18:30:30.616Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/outputs/action-node","title":"Action Node | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Action Node | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"date":"Fri, 17 Oct 2025 18:30:28 GMT","content-type":"text/html; charset=utf-8","content-encoding":"br","cf-ray":"9901de06b8b98157-SEA","cf-cache-status":"DYNAMIC","age":"0","cache-control":"public, max-age=0, must-revalidate","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","referrer-policy":"no-referrer-when-downgrade","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"pdx1::iad1::ndnqf-1760725827665-5fcd326d945e","server":"cloudflare","alt-svc":"h3=\":443\"; ma=86400","x-firefox-spdy":"h2"}},"screenshotUrl":"https://api.apify.com/v2/key-value-stores/3K2WBdQQFTu6EGDhJ/records/SCREENSHOT-docs-stack-ai-com-stack-ai-workflow-builder-outputs-action-node-6f47d40e.jpg","text":"Action Node | StackAI\nWhat is an Action Node?\nAn Action node allows your workflow to interact with external systems. You can use it to send data to other apps, update databases, trigger web searches, or automate other tasks across services.\nThis node is typically used after collecting and processing data through Input or LLM nodes.\nCommon uses include:\nSending rows to Airtable or Excel\nUpdating documents in Notion or MongoDB\nQuerying or writing to PostgreSQL\nTriggering a Web Search and retrieving results\nSending Emails using Gmail or Outlook\nThese nodes help turn your workflows into automated agents that don’t just compute — they also take action.\nHow to use the Action node\nTo use the Action node:\nClick the node.\nIn the right panel, search and select an action from the desired node.\nDepending on the Action selected:\nInput: Requires structured data (usually JSON or plain text) from a previous node.\nOutput: Sends data to an external service. The result can optionally be passed to an Output node or another processing node like an LLM.\nNot all actions produce user-facing output. Some simply perform the task in the background — such as logging, sending an email, or updating a database.","markdown":"# Action Node | StackAI\n\n### \n\nWhat is an Action Node?\n\nAn Action node allows your workflow to interact with external systems. You can use it to send data to other apps, update databases, trigger web searches, or automate other tasks across services.\n\nThis node is typically used after collecting and processing data through Input or LLM nodes.\n\nCommon uses include:\n\n*   Sending rows to **Airtable** or **Excel**\n    \n*   Updating documents in **Notion** or **MongoDB**\n    \n*   Querying or writing to **PostgreSQL**\n    \n*   Triggering a **Web Search** and retrieving results\n    \n*   Sending Emails using **Gmail** or **Outlook**\n    \n\nThese nodes help turn your workflows into automated agents that don’t just compute — they also take action.\n\n### \n\nHow to use the Action node\n\nTo use the Action node:\n\n1.  Click the node.\n    \n2.  In the right panel, search and select an action from the desired node.\n    \n\nDepending on the Action selected:\n\n*   **Input:** Requires structured data (usually JSON or plain text) from a previous node.\n    \n*   **Output:** Sends data to an external service. The result can optionally be passed to an Output node or another processing node like an LLM.\n    \n\nNot all actions produce user-facing output. Some simply perform the task in the background — such as logging, sending an email, or updating a database.","debug":{"requestHandlerMode":"browser"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/llms/llm-node/main-settings","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/llms/llm-node/main-settings","loadedTime":"2025-10-17T18:30:36.440Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/llms/llm-node/main-settings","title":"Main Settings | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Main Settings | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"0","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901de3a4e52819f-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:36 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"iad1::iad1::hf7bn-1760725835940-995e00a3ca69"}},"screenshotUrl":null,"text":"Main Settings | StackAI\nAdd Memory\nAdd memory to your LLMs in Stack AI. Improve user interaction by enabling models to remember previous conversations and provide more context-aware responses.\nLLMs do not hold an internal state, and many applications require tracking previous interactions with the LLM as part of the interface (e.g. chatbots). To this end, you can add memory to an LLM node under the Stack AI tool by clicking on the gear icon of the LLM node.\nSome quick facts:\nAll the LLM memory is encrypted end-to-end in the Stack AI database.\nThis data can be self-hosted under the Stack AI enterprise plan.\nThe LLM memory is user-dependent and an instance of the LLM memory.\nOnce the deployed as an API, you can specify the user_id for the LLM memory for each user (see Deployer Guide ).\nBy default, the “Sliding Window Input” memory is selected when a new LLM node is added to the flow.\nWe offer three types of memory modalities:\nSliding Window\nStores all LLM prompts and completions.\nThis strategy may consume many tokens as the LLM prompts can often occupy thousands of tokens.\nLoads a window of the previous prompts and completions as part of the LLM conversation memory, up to the number of messages in the window.\nIn non-chat models (e.g. Davinci), the memory is added as part of the prompt as a list of messages at the end of the prompt.\nSliding Window with Input\nStores one LLM input parameter (e.g. in-0) and all LLM completions, without storing the entire prompt from each turn. \nThis strategy is more token efficient and aligned with many applications (e.g. when only the user message from input is relevant)\nLoads a window of the previous inputs and completions as part of the LLM conversation memory, up-to the number of messages in the window. In non-chat models (e.g. davinci-003-text), the memory is added as part of the prompt as a list of messages at the end.\nVectorDB\nStores all of the inputs and outputs to the LLM in a Vector Database and retrieves the most relevant messages to use as LLM memory.\nThis is especially useful if you expect some of the information to be needed at a later time but not in a sequential manner.\nAllows the LLM to access older, contextually relevant interactions without the constraint of a fixed window size.\nSliding Window\nThe sliding window allows you to set the number of turns you would like to be included in your context.\nInput Id\nIf you chose to have 'Sliding Window with Input' saved in memory, then you can also select the id of the input that you would like to be held in context. All other inputs will not be stored in context.\nCitations\nTurn on citations to allow the AI to provide citations (references) for the information it generates, especially when it uses external sources or uploaded documents.\nResponse Format\nText is the default response format. You can also choose to have the AI return a response formatted as a JSON object\nResponse Format\nWhen to Use?\nThe default option. Best for most conversational, summary, or narrative outputs.\nUseful when you want structured data for further processing, such as extracting specific fields, integrating with APIs, or using the output in downstream nodes that expect JSON.\nWhen you want to specify an exact JSON schema for the output so the AI outputs data in a very specific format for integration, automation, or validation.\nJSON Object with Schema\nTo have an LLM output a JSON object according to a provided schema, you must provide the schema in the following format. JSON schemas not formatted according to this specification may throw an error. \n\"strict\": true if you want to enforce exactly this output schema\n\"description\": a description of your schema\n\"schema\": the actual schema of your ouput\n\"type\": set to \"object\" if you would like to return a JSON object\n\"properties\": the outputs you would like to return, include each outputs type, and an informative description for the LLM\n{ \"strict\": true, \"name\": \"weather-schema\", \"description\": \"Schema for a weather API request\", \"schema\": { \"type\": \"object\", \"properties\": { \"location\": { \"type\": \"string\", \"description\": \"The location to get the weather for\" }, \"unit\": { \"type\": \"string\", \"description\": \"The unit to return the temperature in\", \"enum\": [\"F\", \"C\"] } }, \"additionalProperties\": false, \"required\": [\"location\", \"unit\"] } }\nLast updated 3 months ago","markdown":"# Main Settings | StackAI\n\n### \n\nAdd Memory\n\nAdd memory to your LLMs in Stack AI. Improve user interaction by enabling models to remember previous conversations and provide more context-aware responses.\n\nLLMs do not hold an internal state, and many applications require tracking previous interactions with the LLM as part of the interface (e.g. chatbots). To this end, you can add memory to an LLM node under the Stack AI tool by clicking on the gear icon of the LLM node.\n\nSome quick facts:\n\n*   All the LLM memory is encrypted end-to-end in the Stack AI database.\n    \n*   This data can be self-hosted under the Stack AI enterprise plan.\n    \n*   The LLM memory is user-dependent and an instance of the LLM memory.\n    \n*   Once the deployed as an API, you can specify the user\\_id for the LLM memory for each user (see Deployer Guide ).\n    \n*   By default, the “Sliding Window Input” memory is selected when a new LLM node is added to the flow.\n    \n\nWe offer three types of memory modalities:\n\n*   **Sliding Window**\n    \n    *   Stores all LLM prompts and completions.\n        \n    *   This strategy may consume many tokens as the LLM prompts can often occupy thousands of tokens.\n        \n    *   Loads a window of the previous prompts and completions as part of the LLM conversation memory, up to the number of messages in the window.\n        \n    *   In non-chat models (e.g. Davinci), the memory is added as part of the prompt as a list of messages at the end of the prompt.\n        \n    \n*   **Sliding Window with Input**\n    \n    *   Stores one LLM input parameter (e.g. in-0) and all LLM completions, without storing the entire prompt from each turn.\n        \n    *   This strategy is more token efficient and aligned with many applications (e.g. when only the user message from input is relevant)\n        \n    *   Loads a window of the previous inputs and completions as part of the LLM conversation memory, up-to the number of messages in the window. In non-chat models (e.g. davinci-003-text), the memory is added as part of the prompt as a list of messages at the end.\n        \n    \n*   **VectorDB**\n    \n    *   Stores all of the inputs and outputs to the LLM in a Vector Database and retrieves the most relevant messages to use as LLM memory.\n        \n    *   This is especially useful if you expect some of the information to be needed at a later time but not in a sequential manner.\n        \n    *   Allows the LLM to access older, contextually relevant interactions without the constraint of a fixed window size.\n        \n    \n\n#### \n\nSliding Window\n\nThe sliding window allows you to set the number of turns you would like to be included in your context.\n\n#### \n\nInput Id\n\nIf you chose to have 'Sliding Window with Input' saved in memory, then you can also select the id of the input that you would like to be held in context. All other inputs will not be stored in context.\n\n### \n\nCitations\n\nTurn on citations to allow the AI to provide citations (references) for the information it generates, especially when it uses external sources or uploaded documents.\n\n### \n\nResponse Format\n\nText is the default response format. You can also choose to have the AI return a response formatted as a JSON object\n\nResponse Format\n\nWhen to Use?\n\nThe default option. Best for most conversational, summary, or narrative outputs.\n\nUseful when you want structured data for further processing, such as extracting specific fields, integrating with APIs, or using the output in downstream nodes that expect JSON.\n\nWhen you want to specify an exact JSON schema for the output so the AI outputs data in a very specific format for integration, automation, or validation.\n\n### \n\nJSON Object with Schema\n\nTo have an LLM output a JSON object according to a provided schema, you must provide the schema in the following format. JSON schemas not formatted according to this specification may throw an error.\n\n*   \"strict\": true if you want to enforce exactly this output schema\n    \n*   \"description\": a description of your schema\n    \n*   \"schema\": the actual schema of your ouput\n    \n    *   \"type\": set to \"object\" if you would like to return a JSON object\n        \n    *   \"properties\": the outputs you would like to return, include each outputs type, and an informative description for the LLM\n        \n    \n\n```\n{\n    \"strict\": true,\n    \"name\": \"weather-schema\",\n    \"description\": \"Schema for a weather API request\",\n    \"schema\": {\n        \"type\": \"object\",\n        \"properties\": {\n            \"location\": {\n                \"type\": \"string\",\n                \"description\": \"The location to get the weather for\"\n            },\n            \"unit\": {\n                \"type\": \"string\",\n                \"description\": \"The unit to return the temperature in\",\n                \"enum\": [\"F\", \"C\"]\n            }\n        },\n        \"additionalProperties\": false,\n        \"required\": [\"location\", \"unit\"]\n    }\n}\n```\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/llms/llm-node/prompting","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/llms/llm-node/prompting","loadedTime":"2025-10-17T18:30:36.591Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/llms/llm-node/prompting","title":"Prompting | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Prompting | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"0","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901de3a1d775935-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:36 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"iad1::iad1::q2xgb-1760725835903-c969b2a16bbd"}},"screenshotUrl":null,"text":"Prompting | StackAI\nIn the Prompting section of the LLM Node, you will see two sections: Instructions, and Prompt.\nSystem Prompt\nThe system prompt sets the overall behavior, tone, and role of the AI assistant for the entire conversation. It acts as a set of instructions or context that the model should always keep in mind when generating responses. This message is passed into the model's context each time you interact with it, so the model with always \"remember\" what you say here. It's important to keep this part as short and informative as you can. Put only the most important information into this section. It’s best used for setting rules, style, or persona (e.g., “You are a helpful tutor. Always explain things simply.”).\nUser Prompt\nThe user prompt is the main message or question that the LLM will answer. It can include direct user input, references to other nodes, or additional context. This is the main content the LLM will respond to, after considering the system prompt.\nInclude placeholders in your user prompt if you'd like to import output from other nodes (e.g., user input). You can do this by typing backslash and then selecting the node whose output you'd like to include. \nIf you need help with your prompt, try our Magic Wand tool on the bottom right of the prompt box.\nTo learn more about prompting best practices, go here.\nLast updated 2 months ago","markdown":"# Prompting | StackAI\n\nIn the Prompting section of the LLM Node, you will see two sections: Instructions, and Prompt.\n\n### \n\nSystem Prompt\n\nThe system prompt sets the overall behavior, tone, and role of the AI assistant for the entire conversation. It acts as a set of instructions or context that the model should always keep in mind when generating responses. This message is passed into the model's context each time you interact with it, so the model with always \"remember\" what you say here. It's important to keep this part as short and informative as you can. Put only the most important information into this section. It’s best used for setting rules, style, or persona (e.g., “You are a helpful tutor. Always explain things simply.”).\n\n### \n\nUser Prompt\n\nThe user prompt is the main message or question that the LLM will answer. It can include direct user input, references to other nodes, or additional context. This is the main content the LLM will respond to, after considering the system prompt.\n\nInclude placeholders in your user prompt if you'd like to import output from other nodes (e.g., user input). You can do this by typing backslash and then selecting the node whose output you'd like to include.\n\n* * *\n\nIf you need help with your prompt, try our Magic Wand tool on the bottom right of the prompt box.\n\nTo learn more about prompting best practices, go [here](https://docs.stack-ai.com/stack-ai/best-practices/prompt-engineering).\n\nLast updated 2 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/llms/llm-node","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/llms/llm-node","loadedTime":"2025-10-17T18:30:36.648Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/llms/llm-node","title":"LLM Node | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"LLM Node | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"0","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901de3a3904e5f4-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:36 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"iad1::iad1::rrqcc-1760725835909-50e3d54d4b7e"}},"screenshotUrl":null,"text":"LLM Node | StackAI\nA LLM Node is the heartbeat (or heartbeats!) or your project. StackAI is provider-agnostic, just choose your favorite provider and select the model you'd like to use in your project. If you change your mind and want to try a different provider or model, just make your selection in the dropdown menu.\nTo see an up to date list of our available providers and models, visit our LLM Leaderboard here.\nLast updated 3 months ago","markdown":"# LLM Node | StackAI\n\nA LLM Node is the heartbeat (or heartbeats!) or your project. StackAI is provider-agnostic, just choose your favorite provider and select the model you'd like to use in your project. If you change your mind and want to try a different provider or model, just make your selection in the dropdown menu.\n\nTo see an up to date list of our available providers and models, visit our [LLM Leaderboard here.](https://www.stack-ai.com/llm-leaderboard)\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/llms/llm-node/tools","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/llms/llm-node/tools","loadedTime":"2025-10-17T18:30:36.540Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/llms/llm-node/tools","title":"Tools | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Tools | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"0","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901de3a2a9da177-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:36 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"iad1::iad1::8frwd-1760725835955-c202ee94fcfa"}},"screenshotUrl":null,"text":"Tools | StackAI\nAdd tools directly to your LLM Node to let the LLM decide when to use them. The LLM intelligently determines when and how to call these tools based on the context of the conversation and user inputs. Unlike an outside node, whose input is always passed in to the LLM, a tool is integrated into the LLM itself. This approach works best when:\nYou don't need the tool to be accessed at every query, it's okay for the LLM to autonomously decide when to use the tool.\nYou would like the LLM to have access to multiple tools at once. \nLLMs with Tools\nOnly certain models are able to handle tools. If you don't see the option for tool calling in your LLM Node, it means that model is not built to handle tool calls.\nTool Provider\nBefore using a tool, it's important to understand how tools are organized in Stack AI. Tools are grouped under \"Providers\" - these are the main services or systems that contain related functionality. Think of a Provider as a container for multiple related tools.\nFor example:\nSalesforce (Provider)\nCreate Lead (Tool)\nUpdate Contact (Tool)\nSearch Records (Tool)\nThis organization makes it easy to find and use related tools. Additionally, providers share authentication headers and common access methods, allowing tools within the same provider to seamlessly utilize the same authentication and connection details when performing their actions.\nHow It Works\nThe LLM analyzes the user's request or query to understand what action needs to be taken\nIt identifies which tool (API endpoint) is most appropriate for fulfilling that request\nIt automatically constructs the API request by filling in:\nQuery parameters\nBody parameters\nPath parameters\nHeaders\nAny other required request data\nTools vs. Separate Node\nWhen should you use a tool and when should you use a separate node? This depends on what you want to accomplish. If you want to enforce using the app at every invocation, then use an outside node--the LLM will have to use the app every time. If you only want the app to be used when necessary and you want the LLM to decide--use a tool! \nTools are also a great choice if you want the LLM to have options. For example, if you want it to search LinkedIn, the Web, and your own knowledge base, you can add those tools to the same LLM and it may use one, two, or all of the options to answer your query. \nOn the other hand, if you want to make sure that a search is carried out across LinkedIn, the Web, and your KB--then its better to have three separate nodes delivering their output to the LLM. In this case, be careful! Concatenating inputs could exceed you chosen model's context window. \nPrompt Optimization with Tools\nIf you'd like to reference the tool directly in your user prompt, type @ and then select the tool.\nWhen using custom tools with an LLM node, it's important to provide clear prompting to help the LLM understand how and when to use your tools effectively:\nDescribe the Tool's Purpose: Include a clear description of what the tool does and when it should be used in your system prompt. For example: \"Use the addPet tool to add a new pet to the store database.\"\nProvide Usage Examples: Give examples of proper tool usage in your prompts to demonstrate the expected input/output patterns. For example: \"addPet(name='Max', category='dog', status='available')\"\nSet Clear Instructions: Specify any requirements or constraints for using the tool in your prompts. For example: \"When using addPet, ensure all required fields (name, category, status) are provided.\"\nHandle Errors: Include guidance on how to handle potential errors or edge cases when using the tool. For example: \"If addPet returns an error, verify the input data and try again with corrected values.\"\nExample system prompt:\nWhen the user wants to include a new pet, follow these steps: 1. Ask for the name of the pet 2. Use the listPets tool to check if the name already exists. If it does, ask the user for a different name that is not in the list. 3. If the pet name is unique, collect all required information for addPet. 3.1. If any information is missing, ask the user for it. 4. Use the addPet tool to create the new pet entry 5. Use the getPetById tool to retrieve the newly created pet 6. Provide a summary confirming the successful pet addition with the key details\nCustom Tools\nCustom Tools enable AI agents to execute custom actions by integrating with your API systems and services. When you define API endpoints in your custom tools, each endpoint becomes a distinct tool that the LLM can utilize. \nA custom tool represents a specific API endpoint and its functionality. Each tool has several key components:\nName: A unique identifier for the tool that can be referenced in LLM prompts. For example, if you name a tool addPet, you would reference it as \"addPet\" when instructing the LLM to use it.\nDescription: A clear explanation of what the tool does. This helps the LLM understand when and how to use the tool appropriately.\nPath: The API endpoint path that the tool will call (e.g., /api/v1/pets)\nMethod: The HTTP method to use (GET, POST, PUT, DELETE, etc.)\nWhen the LLM needs to create a new pet, it can reference the addPet tool by name and provide the necessary parameters based on the tool's description and requirements.\nCreate a Custom Tool\nCustom tools are defined through API services, allowing you to integrate external functionality into your LLM. When you create a custom tool, you'll describe your API endpoints and their capabilities. \nEach API endpoint becomes a distinct tool that represents a specific action or operation in your system. The LLM will automatically understand how to use these endpoints and fill in the required parameters (like body and query parameters) based on the context and user input.\nFor example, if you have an e-commerce API:\nThe /products endpoint becomes a tool for retrieving product information, where the LLM can fill search parameters\nThe /orders/create endpoint becomes a tool for placing new orders, with the LLM providing order details in the request body\nThe /inventory/update endpoint becomes a tool for managing stock levels, where the LLM determines the updated quantities\nThis approach lets you transform your existing APIs into reusable tools that can be easily incorporated into any LLM, making your external services and systems accessible to AI agents. The LLM handles the complexity of constructing proper API requests by intelligently filling parameters based on the conversation context. Custom tools help you build more maintainable and scalable flows by promoting code reuse and modular design.\nTo create a custom tool:\nNavigate to an LLM Node that supports Tools (like GPT-4 or Claude)\nClick the \"Tools\" button in the Tools section\nSelect the \"Custom tools\" tab where your custom tools will appear. Click the \"Add Custom Tool\" button.\nThis will open the custom tool creation interface where you can define your tool's functionality.\nAdding Tool Information\nTo create a custom tool, you need to include:\nTool Provider Name: Give your tool provider a descriptive name that represents the service or system\nOpenAPI Schema: Provide the OpenAPI specification that defines your API endpoints. The schema must include:\nServer URLs for the API endpoints\nComplete endpoint definitions with:\nImportant! Clear descriptions explaining what each endpoint does and its purpose to help the LLM understand how to use them correctly\nHTTP methods (GET, POST, PUT, etc.)\nPath parameters\nQuery parameters for GET requests\nDetailed request body schemas for POST/PUT requests\nResponse schemas\nRequired headers specific to endpoints\nCommon Headers (Optional): Define headers that should be applied across all endpoints, such as:\nAuthentication headers (e.g. API keys)\nCustom headers required by your API\nEach API endpoint defined in your OpenAPI schema will be automatically transformed into an individual tool that you can use in your LLMs. Taking time to properly configure these settings will make your tools more user-friendly and reliable.\nYour custom tool will now appear in the tools panel and can be used in any LLM!\nLast updated 2 months ago","markdown":"# Tools | StackAI\n\nAdd tools directly to your LLM Node to let the LLM decide when to use them. The LLM intelligently determines when and how to call these tools based on the context of the conversation and user inputs. Unlike an outside node, whose input is always passed in to the LLM, a tool is integrated into the LLM itself. This approach works best when:\n\n*   You don't need the tool to be accessed at every query, it's okay for the LLM to autonomously decide when to use the tool.\n    \n*   You would like the LLM to have access to multiple tools at once.\n    \n\n### \n\nLLMs with Tools\n\nOnly certain models are able to handle tools. If you don't see the option for tool calling in your LLM Node, it means that model is not built to handle tool calls.\n\n### \n\nTool Provider\n\nBefore using a tool, it's important to understand how tools are organized in Stack AI. Tools are grouped under \"Providers\" - these are the main services or systems that contain related functionality. Think of a Provider as a container for multiple related tools.\n\nFor example:\n\n*   Salesforce (Provider)\n    \n    *   Create Lead (Tool)\n        \n    *   Update Contact (Tool)\n        \n    *   Search Records (Tool)\n        \n    \n\nThis organization makes it easy to find and use related tools. Additionally, providers share authentication headers and common access methods, allowing tools within the same provider to seamlessly utilize the same authentication and connection details when performing their actions.\n\n### \n\nHow It Works\n\n*   The LLM analyzes the user's request or query to understand what action needs to be taken\n    \n*   It identifies which tool (API endpoint) is most appropriate for fulfilling that request\n    \n*   It automatically constructs the API request by filling in:\n    \n    *   Query parameters\n        \n    *   Body parameters\n        \n    *   Path parameters\n        \n    *   Headers\n        \n    *   Any other required request data\n        \n    \n\n### \n\nTools vs. Separate Node\n\nWhen should you use a tool and when should you use a separate node? This depends on what you want to accomplish. If you want to enforce using the app at every invocation, then use an outside node--the LLM will have to use the app every time. If you only want the app to be used when necessary and you want the LLM to decide--use a tool!\n\nTools are also a great choice if you want the LLM to have options. For example, if you want it to search LinkedIn, the Web, and your own knowledge base, you can add those tools to the same LLM and it may use one, two, or all of the options to answer your query.\n\nOn the other hand, if you want to make sure that a search is carried out across LinkedIn, the Web, and your KB--then its better to have three separate nodes delivering their output to the LLM. In this case, be careful! Concatenating inputs could exceed you chosen model's context window.\n\n### \n\nPrompt Optimization with Tools\n\nIf you'd like to reference the tool directly in your user prompt, type @ and then select the tool.\n\nWhen using custom tools with an LLM node, it's important to provide clear prompting to help the LLM understand how and when to use your tools effectively:\n\n1.  **Describe the Tool's Purpose**: Include a clear description of what the tool does and when it should be used in your system prompt. For example: \"Use the addPet tool to add a new pet to the store database.\"\n    \n2.  **Provide Usage Examples**: Give examples of proper tool usage in your prompts to demonstrate the expected input/output patterns. For example: \"addPet(name='Max', category='dog', status='available')\"\n    \n3.  **Set Clear Instructions**: Specify any requirements or constraints for using the tool in your prompts. For example: \"When using addPet, ensure all required fields (name, category, status) are provided.\"\n    \n4.  **Handle Errors**: Include guidance on how to handle potential errors or edge cases when using the tool. For example: \"If addPet returns an error, verify the input data and try again with corrected values.\"\n    \n\nExample system prompt:\n\n```\nWhen the user wants to include a new pet, follow these steps:\n\n1. Ask for the name of the pet\n2. Use the listPets tool to check if the name already exists. If it does, ask the user for a different name that is not in the list.\n3. If the pet name is unique, collect all required information for addPet.\n   3.1. If any information is missing, ask the user for it.\n4. Use the addPet tool to create the new pet entry\n5. Use the getPetById tool to retrieve the newly created pet\n6. Provide a summary confirming the successful pet addition with the key details\n```\n\n### \n\nCustom Tools\n\nCustom Tools enable AI agents to execute custom actions by integrating with your API systems and services. When you define API endpoints in your custom tools, each endpoint becomes a distinct tool that the LLM can utilize.\n\nA custom tool represents a specific API endpoint and its functionality. Each tool has several key components:\n\n*   **Name**: A unique identifier for the tool that can be referenced in LLM prompts. For example, if you name a tool `addPet`, you would reference it as \"addPet\" when instructing the LLM to use it.\n    \n*   **Description**: A clear explanation of what the tool does. This helps the LLM understand when and how to use the tool appropriately.\n    \n*   **Path**: The API endpoint path that the tool will call (e.g., `/api/v1/pets`)\n    \n*   **Method**: The HTTP method to use (GET, POST, PUT, DELETE, etc.)\n    \n\nWhen the LLM needs to create a new pet, it can reference the `addPet` tool by name and provide the necessary parameters based on the tool's description and requirements.\n\n### \n\nCreate a Custom Tool\n\nCustom tools are defined through API services, allowing you to integrate external functionality into your LLM. When you create a custom tool, you'll describe your API endpoints and their capabilities.\n\nEach API endpoint becomes a distinct tool that represents a specific action or operation in your system. The LLM will automatically understand how to use these endpoints and fill in the required parameters (like body and query parameters) based on the context and user input.\n\nFor example, if you have an e-commerce API:\n\n*   The `/products` endpoint becomes a tool for retrieving product information, where the LLM can fill search parameters\n    \n*   The `/orders/create` endpoint becomes a tool for placing new orders, with the LLM providing order details in the request body\n    \n*   The `/inventory/update` endpoint becomes a tool for managing stock levels, where the LLM determines the updated quantities\n    \n\nThis approach lets you transform your existing APIs into reusable tools that can be easily incorporated into any LLM, making your external services and systems accessible to AI agents. The LLM handles the complexity of constructing proper API requests by intelligently filling parameters based on the conversation context. Custom tools help you build more maintainable and scalable flows by promoting code reuse and modular design.\n\n**To create a custom tool:**\n\n1.  Navigate to an LLM Node that supports Tools (like GPT-4 or Claude)\n    \n2.  Click the \"Tools\" button in the Tools section\n    \n3.  Select the \"Custom tools\" tab where your custom tools will appear. Click the \"Add Custom Tool\" button.\n    \n\nThis will open the custom tool creation interface where you can define your tool's functionality.\n\n### \n\nAdding Tool Information\n\nTo create a custom tool, you need to include:\n\n1.  **Tool Provider Name**: Give your tool provider a descriptive name that represents the service or system\n    \n2.  **OpenAPI Schema**: Provide the OpenAPI specification that defines your API endpoints. The schema must include:\n    \n    *   Server URLs for the API endpoints\n        \n    *   Complete endpoint definitions with:\n        \n        *   Important! Clear descriptions explaining what each endpoint does and its purpose to help the LLM understand how to use them correctly\n            \n        *   HTTP methods (GET, POST, PUT, etc.)\n            \n        *   Path parameters\n            \n        *   Query parameters for GET requests\n            \n        *   Detailed request body schemas for POST/PUT requests\n            \n        *   Response schemas\n            \n        *   Required headers specific to endpoints\n            \n        \n    \n3.  **Common Headers** (Optional): Define headers that should be applied across all endpoints, such as:\n    \n    *   Authentication headers (e.g. API keys)\n        \n    *   Custom headers required by your API\n        \n    \n\nEach API endpoint defined in your OpenAPI schema will be automatically transformed into an individual tool that you can use in your LLMs. Taking time to properly configure these settings will make your tools more user-friendly and reliable.\n\nYour custom tool will now appear in the tools panel and can be used in any LLM!\n\nLast updated 2 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/llms/llm-node/advanced-settings","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/llms/llm-node/advanced-settings","loadedTime":"2025-10-17T18:30:36.721Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/llms/llm-node/advanced-settings","title":"Advanced Settings | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Advanced Settings | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"0","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901de3a496013c9-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:36 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"iad1::iad1::kw4g2-1760725835928-d6d31a3a8d89"}},"screenshotUrl":null,"text":"Advanced Settings | StackAI\nStream Data\nDefault - ON. When ON, output from the LLM is shown word-by-word, as it is produced. If you'd prefer the output to appear all at once when the LLM is done thinking, turn this feature OFF.\nSafe Context Window\nDefault - OFF. When ON, context will be automatically reduced to the model's maximum context size. If OFF, you will get an error message if your context gets too big. Be careful--turning this on means you might unexpectedly lose meaningful context without a warning!\nCharts\nTo maintain consistency, chart generation is now handled exclusively by the dedicated StackAI analysis tool.\nData & Time\nDefault - ON. When ON, the LLM will be aware of the current date & time.\nGuardrails\nDefault - OFF. Turn ON guardrails to screen for toxic content, legal advice, or suicidal thoughts.\nPII Compliance\nDefault - OFF. Turn ON PII Compliance in order to hide certain types of PII from the LLM if entered by a user.\nTemperature\nDefault - 0. Increase temperature in order to increase randomness in the output, making the model less deterministic. \nMax Output Length\nDefault - 3000. Increasing this slider will allow the model to give more verbose answers.\nRetry on Failure\nDefault - OFF. Turn ON to enable retrying when execution of a node fails. This can help make your project more robust\nLLM Fallback Mode\nDefault - OFF. Turn ON to make your project more robust to model failure. This allows you to select a backup model and provider to use in case something goes wrong.\nFallback Branch\nDefault - OFF. When turned ON, you can specify a different flow to follow in case this LLM node's execution fails.","markdown":"# Advanced Settings | StackAI\n\n#### \n\nStream Data\n\nDefault - ON. When ON, output from the LLM is shown word-by-word, as it is produced. If you'd prefer the output to appear all at once when the LLM is done thinking, turn this feature OFF.\n\n#### \n\nSafe Context Window\n\nDefault - OFF. When ON, context will be automatically reduced to the model's maximum context size. If OFF, you will get an error message if your context gets too big. Be careful--turning this on means you might unexpectedly lose meaningful context without a warning!\n\n#### \n\nCharts\n\nTo maintain consistency, chart generation is now handled exclusively by the dedicated StackAI [analysis tool](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/stackai#id-1.-analysis-tool).\n\n#### \n\nData & Time\n\nDefault - ON. When ON, the LLM will be aware of the current date & time.\n\n#### \n\nGuardrails\n\nDefault - OFF. Turn ON guardrails to screen for toxic content, legal advice, or suicidal thoughts.\n\n#### \n\nPII Compliance\n\nDefault - OFF. Turn ON PII Compliance in order to hide certain types of PII from the LLM if entered by a user.\n\n#### \n\nTemperature\n\nDefault - 0. Increase temperature in order to increase randomness in the output, making the model less deterministic.\n\n#### \n\nMax Output Length\n\nDefault - 3000. Increasing this slider will allow the model to give more verbose answers.\n\n#### \n\nRetry on Failure\n\nDefault - OFF. Turn ON to enable retrying when execution of a node fails. This can help make your project more robust\n\n#### \n\nLLM Fallback Mode\n\nDefault - OFF. Turn ON to make your project more robust to model failure. This allows you to select a backup model and provider to use in case something goes wrong.\n\n#### \n\nFallback Branch\n\nDefault - OFF. When turned ON, you can specify a different flow to follow in case this LLM node's execution fails.","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/llms/how-to-improve-llm-performance","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/llms/how-to-improve-llm-performance","loadedTime":"2025-10-17T18:30:37.156Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/llms/how-to-improve-llm-performance","title":"How to Improve LLM Performance | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"How to Improve LLM Performance | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"0","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901de3a1fe3c97c-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:37 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"iad1::iad1::xplpf-1760725835888-b9c6229997b3"}},"screenshotUrl":null,"text":"How to Improve LLM Performance\nThis guide offers various strategies and techniques to improve the performance of your Language Model (LLM). You can experiment with these methods individually or in combination to achieve better results for your specific needs. Some strategies include:\n1. Write Clear Instructions\nEnsure that your instructions are concise and clear. If the outputs are too lengthy, request brief responses. If you need expert-level writing, specify that. Minimizing guesswork for the LLM increases the likelihood of receiving the desired output. Consider the following:\nInclude specific details in your query for more relevant answers.\nInstruct the model to adopt a specific persona.\nUse delimiters to indicate distinct parts of the input.\nSpecify the steps required to complete a task.\nProvide examples.\nSpecify the desired length of the output.\nRefer to the Evaluation Description of available LLMs.\n2. Provide Reference Text\nTo reduce the generation of fake answers, particularly on obscure topics, or to include citations and URLs, provide reference text that can assist the LLM. Here's what you can do:\nInstruct the model to answer using reference text.\nInstruct the model to answer with citations from reference text.\nRefer to Offline Data Loaders.\n3. Break Down Complex Tasks into Simpler Subtasks\nComplex tasks tend to have higher error rates. To enhance performance, break down complex tasks into simpler subtasks. You can:\nUse intent classification to identify the most relevant instructions for a user query.\nFor dialogue applications with long conversations, summarize or filter previous dialogue.\nSummarize long documents piecewise and construct a full summary recursively.\nRefer to the Description of available LLMs.\n4. Allow LLMs Time to \"Think\"\nLLMs may make more reasoning errors when rushed. Asking for a chain of reasoning before a response can help them reason their way to correct answers. Consider:\nInstructing the model to work out its solution before rushing to a conclusion.\nUsing an inner monologue or a sequence of queries to hide the model's reasoning process.\nAsking the model if it missed anything on previous passes.\nRefer to the Description of available LLMs.\n5. Utilize External Tools\nCompensate for LLM weaknesses by using outputs from other tools. Text retrieval systems or code execution engines can be helpful. If a task can be done more reliably or efficiently with a tool, consider using it for better results:\nUse embeddings-based search for efficient knowledge retrieval.\nUse code execution for more accurate calculations or call external APIs.\nRefer to Offline Data Loaders.\n6. Test Changes Systematically\nMeasuring the impact of changes is essential for improvement. Define a comprehensive test suite (eval) to ensure that modifications yield a net positive performance:\nEvaluate model outputs with gold-standard answers.\nRefer to Evaluation.\nEach of the strategies listed above can be implemented with specific tactics. These tactics provide ideas for experimentation and improvement. Feel free to explore creative ideas beyond what's listed here.","markdown":"# How to Improve LLM Performance\n\nThis guide offers various strategies and techniques to improve the performance of your Language Model (LLM). You can experiment with these methods individually or in combination to achieve better results for your specific needs. Some strategies include:\n\n### \n\n1\\. Write Clear Instructions\n\nEnsure that your instructions are concise and clear. If the outputs are too lengthy, request brief responses. If you need expert-level writing, specify that. Minimizing guesswork for the LLM increases the likelihood of receiving the desired output. Consider the following:\n\n*   Include specific details in your query for more relevant answers.\n    \n*   Instruct the model to adopt a specific persona.\n    \n*   Use delimiters to indicate distinct parts of the input.\n    \n*   Specify the steps required to complete a task.\n    \n*   Provide examples.\n    \n*   Specify the desired length of the output.\n    \n*   Refer to the Evaluation Description of available LLMs.\n    \n\n### \n\n2\\. Provide Reference Text\n\nTo reduce the generation of fake answers, particularly on obscure topics, or to include citations and URLs, provide reference text that can assist the LLM. Here's what you can do:\n\n*   Instruct the model to answer using reference text.\n    \n*   Instruct the model to answer with citations from reference text.\n    \n*   Refer to Offline Data Loaders.\n    \n\n### \n\n3\\. Break Down Complex Tasks into Simpler Subtasks\n\nComplex tasks tend to have higher error rates. To enhance performance, break down complex tasks into simpler subtasks. You can:\n\n*   Use intent classification to identify the most relevant instructions for a user query.\n    \n*   For dialogue applications with long conversations, summarize or filter previous dialogue.\n    \n*   Summarize long documents piecewise and construct a full summary recursively.\n    \n*   Refer to the Description of available LLMs.\n    \n\n### \n\n4\\. Allow LLMs Time to \"Think\"\n\nLLMs may make more reasoning errors when rushed. Asking for a chain of reasoning before a response can help them reason their way to correct answers. Consider:\n\n*   Instructing the model to work out its solution before rushing to a conclusion.\n    \n*   Using an inner monologue or a sequence of queries to hide the model's reasoning process.\n    \n*   Asking the model if it missed anything on previous passes.\n    \n*   Refer to the Description of available LLMs.\n    \n\n### \n\n5\\. Utilize External Tools\n\nCompensate for LLM weaknesses by using outputs from other tools. Text retrieval systems or code execution engines can be helpful. If a task can be done more reliably or efficiently with a tool, consider using it for better results:\n\n*   Use embeddings-based search for efficient knowledge retrieval.\n    \n*   Use code execution for more accurate calculations or call external APIs.\n    \n*   Refer to Offline Data Loaders.\n    \n\n### \n\n6\\. Test Changes Systematically\n\nMeasuring the impact of changes is essential for improvement. Define a comprehensive test suite (eval) to ensure that modifications yield a net positive performance:\n\n*   Evaluate model outputs with gold-standard answers.\n    \n*   Refer to Evaluation.\n    \n\nEach of the strategies listed above can be implemented with specific tactics. These tactics provide ideas for experimentation and improvement. Feel free to explore creative ideas beyond what's listed here.","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps","loadedTime":"2025-10-17T18:30:39.591Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps","title":"Apps | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Apps | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1837","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901de4f28555812-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:39 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::xkmzd-1760725839344-dc013b9d9825"}},"screenshotUrl":null,"text":"Apps | StackAI\nAirtableAlgoliaAsanaAzure SQLBigQueryBoxClickupCodaCrunchbaseDatabricksE2BExa AIExcelFirecrawlFredGDocsGithubGmailGSheetsHightouchHubSpotHyperBrowserJiraKnowledge BaseLinkedInLoomMakeMCPMiroMongoDBMySQLNetSuiteNotionOracleOutlookOutreachPineconePitchbookPostgreSQLPower BIReductoRegexRunwayMLSalesforceSAPSerpAPIServiceNowSharePointSlackSnowflakeStackAIStripeSynapseTimeTypeformVlmWeaviateWeb SearchWolfram AlphaWorkdayYahoo FinanceYoutubeZapierZendesk\nPreviousLocal LLMNextAirtable\nWas this helpful?","markdown":"# Apps | StackAI\n\n[Airtable](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/airtable)[Algolia](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/algolia)[Asana](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/asana)[Azure SQL](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/azure-sql)[BigQuery](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/bigquery)[Box](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/box)[Clickup](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/clickup)[Coda](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/coda)[Crunchbase](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/crunchbase)[Databricks](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/databricks)[E2B](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/e2b)[Exa AI](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/exa-ai)[Excel](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/excel)[Firecrawl](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/firecrawl)[Fred](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/fred)[GDocs](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/gdocs)[Github](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/github)[Gmail](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/gmail)[GSheets](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/gsheets)[Hightouch](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/hightouch)[HubSpot](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/hubspot)[HyperBrowser](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/hyperbrowser)[Jira](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/jira)[Knowledge Base](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/knowledge-base)[LinkedIn](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/linkedin)[Loom](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/loom)[Make](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/make)[MCP](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/mcp)[Miro](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/miro)[MongoDB](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/mongodb)[MySQL](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/mysql)[NetSuite](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/netsuite)[Notion](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/notion)[Oracle](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/oracle)[Outlook](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/outlook)[Outreach](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/outreach)[Pinecone](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/pinecone)[Pitchbook](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/pitchbook)[PostgreSQL](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/postgresql)[Power BI](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/power-bi)[Reducto](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/reducto)[Regex](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/regex)[RunwayML](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/runwayml)[Salesforce](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/salesforce)[SAP](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/sap)[SerpAPI](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/serpapi)[ServiceNow](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/servicenow)[SharePoint](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/sharepoint)[Slack](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/slack)[Snowflake](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/snowflake)[StackAI](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/stackai)[Stripe](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/stripe)[Synapse](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/synapse)[Time](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/time)[Typeform](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/typeform)[Vlm](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/vlm)[Weaviate](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/weaviate)[Web Search](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/web-search)[Wolfram Alpha](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/wolfram-alpha)[Workday](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/workday)[Yahoo Finance](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/yahoo-finance)[Youtube](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/youtube)[Zapier](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/zapier)[Zendesk](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/zendesk)\n\n[PreviousLocal LLM](https://docs.stack-ai.com/stack-ai/workflow-builder/llms/local-llm)[NextAirtable](https://docs.stack-ai.com/stack-ai/workflow-builder/apps/airtable)\n\nWas this helpful?","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/llms/llms-hosted-on-azure-and-aws-bedrock","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/llms/llms-hosted-on-azure-and-aws-bedrock","loadedTime":"2025-10-17T18:30:39.790Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/llms/llms-hosted-on-azure-and-aws-bedrock","title":"LLMs Hosted on Azure & AWS Bedrock | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"LLMs Hosted on Azure & AWS Bedrock | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"0","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901de4d4b99389e-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:39 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"iad1::iad1::pjbp9-1760725838983-e4fc5fad88b4"}},"screenshotUrl":null,"text":"LLMs Hosted on Azure & AWS Bedrock\nMicrosoft Azure and AWS Bedrock offer the ability to host private clouds with OpenAI models. You can add these models in Stack AI using an \"Azure\" node or \"Bedrock\" node. Hosting models in Azure/Bedrock has benefits:\nAzure\nLower and Consistent Latency: Cloud hosted models are not affected by public API traffic. This is a great option if latency is a real concern.\nHigher Rate Limits: Models in Azure offer higher rate limits of up to 240,000 tokens per minute and 1440 requests per minute.\nData Privacy and Compliance: data sent to Azure is kept under the private cloud and is not sent to OpenAI or any external service. These models are covered under Azure's Business Associate Agreement (BAA) and are HIPPA compliant.\nAWS Bedrock\nAWS Security & Compliance: Bedrock leverages AWS’s security, IAM, and compliance features. You can use AWS IAM roles, VPC endpoints, and audit logging for enterprise-grade security.\nData Privacy & Residency: Data processed through Bedrock stays within AWS infrastructure. You can choose the AWS region for data residency requirements.\nHow It Works\nMicrosoft Azure\nAzure OpenAI Service: Azure provides access to OpenAI models (like GPT-3.5, GPT-4, etc.) through its Azure OpenAI Service.\nHow it works: You provision an Azure OpenAI resource, get an endpoint and API key, and can then use these credentials to access models via Azure’s API.\nAWS Bedrock\nAmazon Bedrock: AWS offers access to multiple foundation models (including Anthropic Claude, AI21, Cohere, and Amazon’s own Titan models) through the Amazon Bedrock service.\nHow it works: You provision an AWS Bedrock resource, get an endpoint and API key, and can then use these credentials to access the models you have enabled via AWS's API.\nLast updated 3 months ago","markdown":"# LLMs Hosted on Azure & AWS Bedrock\n\nMicrosoft Azure and AWS Bedrock offer the ability to host private clouds with OpenAI models. You can add these models in Stack AI using an \"Azure\" node or \"Bedrock\" node. Hosting models in Azure/Bedrock has benefits:\n\n#### \n\nAzure\n\n1.  **Lower and Consistent Latency:** Cloud hosted models are not affected by public API traffic. This is a great option if latency is a real concern.\n    \n2.  **Higher Rate Limits:** Models in Azure offer higher rate limits of up to 240,000 tokens per minute and 1440 requests per minute.\n    \n3.  **Data Privacy and Compliance:** data sent to Azure is kept under the private cloud and is not sent to OpenAI or any external service. These models are covered under Azure's Business Associate Agreement (BAA) and are HIPPA compliant.\n    \n\n#### \n\nAWS Bedrock\n\n1.  **AWS Security & Compliance:** Bedrock leverages AWS’s security, IAM, and compliance features. You can use AWS IAM roles, VPC endpoints, and audit logging for enterprise-grade security.\n    \n2.  **Data Privacy & Residency:** Data processed through Bedrock stays within AWS infrastructure. You can choose the AWS region for data residency requirements.\n    \n\n### \n\nHow It Works\n\n#### \n\nMicrosoft Azure\n\n*   **Azure OpenAI Service**: Azure provides access to OpenAI models (like GPT-3.5, GPT-4, etc.) through its Azure OpenAI Service.\n    \n*   **How it works**: You provision an Azure OpenAI resource, get an endpoint and API key, and can then use these credentials to access models via Azure’s API.\n    \n\n#### \n\nAWS Bedrock\n\n*   **Amazon Bedrock**: AWS offers access to multiple foundation models (including Anthropic Claude, AI21, Cohere, and Amazon’s own Titan models) through the Amazon Bedrock service.\n    \n*   **How it works**: You provision an AWS Bedrock resource, get an endpoint and API key, and can then use these credentials to access the models you have enabled via AWS's API.\n    \n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/loom","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/loom","loadedTime":"2025-10-17T18:30:40.026Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/loom","title":"Loom | StackAI","description":"Discover how to automate video workflows with the Loom node in StackAI. Learn about available actions, required inputs, configurations, and output examples.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Loom | StackAI"},{"property":"og:description","content":"Discover how to automate video workflows with the Loom node in StackAI. Learn about available actions, required inputs, configurations, and output examples."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"94","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901de525cf6d698-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:39 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::txfnc-1760725839775-a66187e96369"}},"screenshotUrl":null,"text":"Loom | StackAI\nDiscover how to automate video workflows with the Loom node in StackAI. Learn about available actions, required inputs, configurations, and output examples.\nWhat is Loom?\nLoom is a video messaging tool that enables users to create, share, and manage videos quickly and efficiently. Integrating Loom with StackAI allows you to automate video-related tasks, such as transcribing videos, extracting insights, or managing video content, directly within your workflows.\nExample of Usage\nSuppose you want to automatically transcribe a Loom video and use the transcript in a report. You can set up a workflow where the Loom node retrieves the video transcript, which is then processed by an LLM node and formatted for output.\nAvailable Actions\n1. Loom Transcript\nDescription: Retrieve the transcript of a Loom video for further processing or analysis.\nInputs:\nvideo_url (Required): The URL of the Loom video you want to transcribe. Example: \"https://www.loom.com/share/your-video-id\"\nConfigurations:\nNo additional configurations are required for this action.\nOutputs:\ntranscript (Always returned): The full text transcript of the Loom video. Example:\n\"Welcome to our product demo. In this video, we will walk through the main features...\"\nHow to Use in a Workflow:\nAdd the Loom node to your StackAI workflow.\nSelect the \"Loom Transcript\" action.\nEnter the Loom video URL as the required input.\nConnect the output to downstream nodes (e.g., LLM, Template, Output) for further processing.\nSummary Table\nAction\nRequired Inputs\nConfigurations\nOutputs\nLast updated 3 months ago","markdown":"# Loom | StackAI\n\nDiscover how to automate video workflows with the Loom node in StackAI. Learn about available actions, required inputs, configurations, and output examples.\n\n**What is Loom?**\n\nLoom is a video messaging tool that enables users to create, share, and manage videos quickly and efficiently. Integrating Loom with StackAI allows you to automate video-related tasks, such as transcribing videos, extracting insights, or managing video content, directly within your workflows.\n\n* * *\n\n**Example of Usage**\n\nSuppose you want to automatically transcribe a Loom video and use the transcript in a report. You can set up a workflow where the Loom node retrieves the video transcript, which is then processed by an LLM node and formatted for output.\n\n* * *\n\n**Available Actions**\n\n#### \n\n1\\. Loom Transcript\n\n**Description:** Retrieve the transcript of a Loom video for further processing or analysis.\n\n**Inputs:**\n\n*   **video\\_url** (Required): The URL of the Loom video you want to transcribe. _Example:_ `\"https://www.loom.com/share/your-video-id\"`\n    \n\n**Configurations:**\n\n*   No additional configurations are required for this action.\n    \n\n**Outputs:**\n\n*   **transcript** (Always returned): The full text transcript of the Loom video. _Example:_\n    \n    ```\n    \"Welcome to our product demo. In this video, we will walk through the main features...\"\n    ```\n    \n\n* * *\n\n**How to Use in a Workflow:**\n\n1.  Add the Loom node to your StackAI workflow.\n    \n2.  Select the \"Loom Transcript\" action.\n    \n3.  Enter the Loom video URL as the required input.\n    \n4.  Connect the output to downstream nodes (e.g., LLM, Template, Output) for further processing.\n    \n\n* * *\n\n**Summary Table**\n\nAction\n\nRequired Inputs\n\nConfigurations\n\nOutputs\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/llms/llm-provider-governance","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/llms/llm-provider-governance","loadedTime":"2025-10-17T18:30:39.901Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/llms/llm-provider-governance","title":"LLM Provider Governance | StackAI","description":"Control which LLMs your organization has access to, and where information is sent & stored.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"LLM Provider Governance | StackAI"},{"property":"og:description","content":"Control which LLMs your organization has access to, and where information is sent & stored."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"0","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901de4e5abc37a2-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:39 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"iad1::iad1::zkgft-1760725839130-98f262e89528"}},"screenshotUrl":null,"text":"LLM Provider Governance | StackAI\nControl which LLMs your organization has access to, and where information is sent & stored.\nLocal LLMs\nStack AI allows organizations to connect and use their own local LLMs (such as models hosted on private infrastructure or on-premise servers) instead of relying solely on cloud-based models like OpenAI or Bedrock.\nGovernance Benefits:\nData Privacy: Your data never leaves your infrastructure, ensuring compliance with strict privacy or regulatory requirements.\nCustom Control: You can select, update, or fine-tune models as needed, and restrict which users or workflows can access them.\nAuditability: All usage of the local LLM can be logged and monitored within your organization’s security perimeter.\nHow it works in Stack:\nAdmins can add a local LLM as a provider in the Stack AI admin console. See our guide.\nOnce added, the local LLM appears as an option in the workflow builder, just like any other provider.\nYou can set permissions to control which users or teams can access the local LLM.\nTurning Off Stack API Keys\nBy default, Stack AI provides hosted API keys for popular providers (like OpenAI, Anthropic, etc.) so users can get started quickly. However, for governance and security, organizations may want to require the use of their own API keys or connections.\nGovernance Benefits:\nCredential Control: Prevents users from accidentally or intentionally using Stack’s shared keys, ensuring all API usage is billed to and controlled by your organization.\nSecurity: Reduces risk of data leakage or misuse of shared credentials.\nCompliance: Ensures all API access is auditable and tied to your organization’s own accounts.\nHow it works in Stack:\nAdmins can disable Stack-provided API keys for any provider in the admin console.\nOnce disabled, users must add their own connection (API key) to use that provider in workflows.\nThis setting can be enforced globally or per-provider.\nDeactivating Certain Providers\nStack AI supports a wide range of providers (OpenAI, Bedrock, Google, Slack, etc.). For governance, you may want to restrict which providers are available to your users.\nGovernance Benefits:\nRisk Mitigation: Prevents use of unapproved or high-risk providers.\nSimplified Compliance: Ensures only vetted and compliant services are available.\nUser Experience: Reduces clutter and confusion by hiding unused or irrelevant providers.\nHow it works in Stack:\nAdmins can deactivate (hide or block) any provider from the admin console.\nDeactivated providers will not appear in the workflow builder or connection menus for end users.\nThis can be managed at the organization or workspace level.\nSummary Table\nFeature\nWhat It Does\nGovernance Benefit\nUse your own on-prem/private LLM\nData privacy, control, auditability\nRequire org-owned API keys for providers\nCredential control, security, compliance\nDeactivate Certain Providers\nHide/block specific providers from user access\nRisk mitigation, compliance, simplicity\nLast updated 3 months ago","markdown":"# LLM Provider Governance | StackAI\n\nControl which LLMs your organization has access to, and where information is sent & stored.\n\n### \n\nLocal LLMs\n\nStack AI allows organizations to connect and use their own local LLMs (such as models hosted on private infrastructure or on-premise servers) instead of relying solely on cloud-based models like OpenAI or Bedrock.\n\n**Governance Benefits:**\n\n*   **Data Privacy:** Your data never leaves your infrastructure, ensuring compliance with strict privacy or regulatory requirements.\n    \n*   **Custom Control:** You can select, update, or fine-tune models as needed, and restrict which users or workflows can access them.\n    \n*   **Auditability:** All usage of the local LLM can be logged and monitored within your organization’s security perimeter.\n    \n\n**How it works in Stack:**\n\n*   Admins can add a local LLM as a provider in the Stack AI admin console. See [our guide.](https://docs.stack-ai.com/stack-ai/workflow-builder/llms/local-llm)\n    \n*   Once added, the local LLM appears as an option in the workflow builder, just like any other provider.\n    \n*   You can set permissions to control which users or teams can access the local LLM.\n    \n\n* * *\n\n### \n\nTurning Off Stack API Keys\n\nBy default, Stack AI provides hosted API keys for popular providers (like OpenAI, Anthropic, etc.) so users can get started quickly. However, for governance and security, organizations may want to require the use of their own API keys or connections.\n\n**Governance Benefits:**\n\n*   **Credential Control:** Prevents users from accidentally or intentionally using Stack’s shared keys, ensuring all API usage is billed to and controlled by your organization.\n    \n*   **Security:** Reduces risk of data leakage or misuse of shared credentials.\n    \n*   **Compliance:** Ensures all API access is auditable and tied to your organization’s own accounts.\n    \n\n**How it works in Stack:**\n\n*   Admins can disable Stack-provided API keys for any provider in the admin console.\n    \n*   Once disabled, users must add their own connection (API key) to use that provider in workflows.\n    \n*   This setting can be enforced globally or per-provider.\n    \n\n* * *\n\n### \n\nDeactivating Certain Providers\n\nStack AI supports a wide range of providers (OpenAI, Bedrock, Google, Slack, etc.). For governance, you may want to restrict which providers are available to your users.\n\n**Governance Benefits:**\n\n*   **Risk Mitigation:** Prevents use of unapproved or high-risk providers.\n    \n*   **Simplified Compliance:** Ensures only vetted and compliant services are available.\n    \n*   **User Experience:** Reduces clutter and confusion by hiding unused or irrelevant providers.\n    \n\n**How it works in Stack:**\n\n*   Admins can deactivate (hide or block) any provider from the admin console.\n    \n*   Deactivated providers will not appear in the workflow builder or connection menus for end users.\n    \n*   This can be managed at the organization or workspace level.\n    \n\n* * *\n\n### \n\nSummary Table\n\nFeature\n\nWhat It Does\n\nGovernance Benefit\n\nUse your own on-prem/private LLM\n\nData privacy, control, auditability\n\nRequire org-owned API keys for providers\n\nCredential control, security, compliance\n\nDeactivate Certain Providers\n\nHide/block specific providers from user access\n\nRisk mitigation, compliance, simplicity\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/algolia","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/algolia","loadedTime":"2025-10-17T18:30:39.823Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/algolia","title":"Algolia | StackAI","description":"Learn how to use the Algolia node in Stack AI to perform advanced semantic and natural language searches on your Algolia index, with detailed input, configuration, and output examples.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Algolia | StackAI"},{"property":"og:description","content":"Learn how to use the Algolia node in Stack AI to perform advanced semantic and natural language searches on your Algolia index, with detailed input, configuration, and output examples."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"138","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901de501c12c5a5-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:39 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::62b7f-1760725839427-0f2886dc793e"}},"screenshotUrl":null,"text":"Algolia | StackAI\nLearn how to use the Algolia node in Stack AI to perform advanced semantic and natural language searches on your Algolia index, with detailed input, configuration, and output examples.\nThe Algolia Node in Stack AI allows you to search your Algolia index using natural language or semantic queries. This integration is ideal for retrieving relevant data, documents, or records from your Algolia-powered search infrastructure directly within your AI workflows.\nHow to use it?\nAdd the Algolia node to your Stack AI workflow to execute search queries against your Algolia index. Connect an input node or LLM node to provide the search query, and use the results in downstream nodes for further processing or display.\nExample of Usage\nSuppose you want to search for documentation related to \"API authentication\" in your Algolia index. You would connect an input node (where the user types their query) to the Algolia node, and the Algolia node will return the most relevant results.\nAvailable Actions\n1. Database Query (Algolia Search)\nDescription: Executes a search query against your Algolia index and returns matching results.\nInputs\nName\nType\nRequired\nDescription\nExample\nThe search query to execute against the Algolia index.\n\"how to implement authentication\" ,, \"database optimization\" ,, \"api documentation\"\nShowing 1-1 of 1 items\nExample Input:\n{ \"query\": \"api documentation\" }\nConfigurations\nThere are no additional configuration parameters required for the Algolia Database Query action. All you need is the search query input.\nOutputs\nName\nType\nRequired\nDescription\nExample\nThe search results from Algolia in JSON format.\n'[{\"title\": \"API Docs\", \"url\": \"https://...\"}]'\nShowing 1-1 of 1 items\nExample Output:\n{ \"results\": [ { \"title\": \"API Docs\", \"url\": \"https://docs.example.com/api\" }, { \"title\": \"Authentication Guide\", \"url\": \"https://docs.example.com/auth\" } ] } \nSummary Table\nAction Name\nRequired Inputs\nConfigurations\nOutputs\nLast updated 2 months ago","markdown":"# Algolia | StackAI\n\nLearn how to use the Algolia node in Stack AI to perform advanced semantic and natural language searches on your Algolia index, with detailed input, configuration, and output examples.\n\nThe **Algolia Node** in Stack AI allows you to search your Algolia index using natural language or semantic queries. This integration is ideal for retrieving relevant data, documents, or records from your Algolia-powered search infrastructure directly within your AI workflows.\n\n* * *\n\n## \n\nHow to use it?\n\nAdd the Algolia node to your Stack AI workflow to execute search queries against your Algolia index. Connect an input node or LLM node to provide the search query, and use the results in downstream nodes for further processing or display.\n\n* * *\n\n## \n\nExample of Usage\n\nSuppose you want to search for documentation related to \"API authentication\" in your Algolia index. You would connect an input node (where the user types their query) to the Algolia node, and the Algolia node will return the most relevant results.\n\n* * *\n\n## \n\nAvailable Actions\n\n### \n\n1\\. Database Query (Algolia Search)\n\n**Description:** Executes a search query against your Algolia index and returns matching results.\n\n* * *\n\n#### \n\nInputs\n\nName\n\nType\n\nRequired\n\nDescription\n\nExample\n\nThe search query to execute against the Algolia index.\n\n\"how to implement authentication\" ,, \"database optimization\" ,, \"api documentation\"\n\nShowing 1-1 of 1 items\n\n**Example Input:**\n\n```\n{\n  \"query\": \"api documentation\"\n}\n```\n\n* * *\n\n#### \n\nConfigurations\n\nThere are no additional configuration parameters required for the Algolia Database Query action. All you need is the search query input.\n\n* * *\n\n#### \n\nOutputs\n\nName\n\nType\n\nRequired\n\nDescription\n\nExample\n\nThe search results from Algolia in JSON format.\n\n'\\[{\"title\": \"API Docs\", \"url\": \"https://...\"}\\]'\n\nShowing 1-1 of 1 items\n\n**Example Output:**\n\n```\n{\n  \"results\": [\n    {\n      \"title\": \"API Docs\",\n      \"url\": \"https://docs.example.com/api\"\n    },\n    {\n      \"title\": \"Authentication Guide\",\n      \"url\": \"https://docs.example.com/auth\"\n    }\n  ]\n}\n```\n\n* * *\n\n## \n\nSummary Table\n\nAction Name\n\nRequired Inputs\n\nConfigurations\n\nOutputs\n\nLast updated 2 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/airtable","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/airtable","loadedTime":"2025-10-17T18:30:39.719Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/airtable","title":"Airtable | StackAI","description":"Query and manage your Airtable bases directly from StackAI workflows.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Airtable | StackAI"},{"property":"og:description","content":"Query and manage your Airtable bases directly from StackAI workflows."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"138","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901de4fbdd2573a-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:39 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::bbtl5-1760725839381-aabc2dc72471"}},"screenshotUrl":null,"text":"Airtable | StackAI\nQuery and manage your Airtable bases directly from StackAI workflows.\nThe Airtable node in StackAI enables seamless integration with your Airtable workspaces. You can perform database queries, retrieve records, and automate data management tasks as part of your workflow automation.\nUsage overview\nChoose the action that you'd like to perform in Airtable (query or write).\nEstablish a connection to Airtable by either signing in via the New Connection button or selecting an existing connection from the dropdown. The Airtable node requires a valid API key or OAuth connection to access your bases. Validate the connection is 'Healthy' with Test. \nFill out the parameters for the action that you'd like to take in Airtable by setting up the Inputs and Configurations (more details in dedicated sections below).\nThe node can be connected to input nodes (for dynamic queries), LLM nodes (for natural language queries), or other action nodes for advanced automation.\nAvailable Actions and Triggers\n1. Query Airtable\nDescription: Query an Airtable base using a structured query or natural language.\nInputs:\nQuery (string, required): \nThe query is a plain English question or instruction that describes what data you want from the Airtable table. For example, you might write:\n\"Employees in the Marketing department\"\n\"Employees hired after January 2024\"\n\"Employees with the title 'Manager'\"\nConfigurations:\nBase_id (string, required): The unique identifier of your Airtable base.\nExample: app1234567890\nYou can locate this in the URL on your Airtable browser: https://airtable.com/app1234567890/tbl...\nTable (string, required): The name of the table to query. \nOpen your Airtable base.\nLook at the tabs along the top (or left, depending on your layout). Each tab represents a table.\nThe table name is the label shown on each tab, e.g. Employees \nView (string, optional): Name of the view to use for filtering/sorting.\nOpen your Airtable base.\nNavigate to the specific table you're working with.\nAt the top left of the table, next to the table name, you’ll see a dropdown with the current view name (e.g., Grid view , Kanban , Calendar ).\nClick the dropdown to see all available views. The view you’re currently in is highlighted.\nAirtableSearchModeEnum (select, optional): \nDetermines how your query is interpreted and executed.\nFormula mode (\"formula\"): Translates your natural language query into Airtable formula syntax—ideal for precise, rule-based filtering (e.g., your query may be “Find all employees in the Sales department”).\nSemantic mode (\"semantic\"): Uses semantic search to find records by meaning, not exact wording—useful for broader, context-driven queries (e.g., your query may be “Show me people who work with customers”.)\nMax Records (integer, optional): Maximum number of records to return.\nExample: 100\nConfigurations:\nconnection_id (string, required): The connection ID for your Airtable account.\nExample: \"your-connection-id\"\nOutputs:\nrecords (array, required): List of records matching the query.\nEach record includes field values and record ID.\nExample:\n[ { \"id\": \"rec1234567890\", \"fields\": { \"Name\": \"Task 1\", \"Status\": \"Open\", \"Due Date\": \"2025-07-10\" } } ] \n2. Write to Airtable\nDescription:\nInsert or update records in an Airtable base.\nInputs:\nData (string, required): Your intent in plain English, describing what record you want to create and what values to set for each field.\nExamples:\nAdd an employee named Alice Johnson, email [email protected], department Engineering, and start date July 15, 2025.\nCreate a new product with name 'Widget X', price $99.99, and category 'Electronics'.\nTips\nBe as specific as possible about the fields and values you want to set.\nUse the field names as they appear in your Airtable table for best results.\nYou can add multiple fields in one sentence.\nConfigurations:\nBase Id (string, required): The unique identifier of your Airtable base.\nExample: app1234567890\nYou can locate this in the URL on your Airtable browser: https://airtable.com/app1234567890/tbl...\nTable (string, required): The name of the table to query. \nOpen your Airtable base.\nLook at the tabs along the top (or left, depending on your layout). Each tab represents a table.\nThe table name is the label shown on each tab, e.g. Employees \nView (string, optional): Expects either the name or the ID of a view in your Airtable table.\nOpen your Airtable base.\nNavigate to the specific table you're working with.\nAt the top left of the table, next to the table name, you’ll see a dropdown with the current view name (e.g., Grid view , Kanban , Calendar ).\nClick the dropdown to see all available views. The view you’re currently in is highlighted.\nIf you leave it blank, the default view (usually \"Grid view\") will be used.\nSpecifying a view can be useful if you want to restrict the write operation to records visible in that view \nOutputs:\nrecords (array, required): List of records that were created or updated.\nEach record includes field values and record ID.\nExample:\n[ { \"id\": \"rec0987654321\", \"fields\": { \"Name\": \"New Task\", \"Status\": \"In Progress\" } } ] \n3. Update Airtable Record\nDescription:\nUpdates the values of an existing record on Airtable.\nInputs:\nRecord Id (string, required): The unique identification number of the record you would like to modify. \nRetrieve Record ID from Airtable\nUsing the Query Airtable Node\nYou can retrieve a record by using the Query Airtable node.\nThis method automatically returns the record ID as a parameter.\nUsing a Formula Field in Airtable\nAdd a new Formula field to your table.\nEnter the formula: RECORD_ID()\nThe field will display the record ID for each record.\nCopy the ID from the relevant cell as needed.\nData (string, required): .Your intent in plain English, describing what part of the record you would like to update.\nExamples:\nChange 'X' column's entry to 100\nConfigurations:\nBase Id (string, required): The unique identifier of your Airtable base.\nExample: app1234567890\nYou can locate this in the URL on your Airtable browser: https://airtable.com/app1234567890/tbl...\nTable (string, required): The name of the table to query. \nOpen your Airtable base.\nLook at the tabs along the top (or left, depending on your layout). Each tab represents a table.\nThe table name is the label shown on each tab, e.g. Employees \n4. Delete Airtable Record\nDescription:\nDelete an existing record on Airtable.\nInputs:\nRecord Id (string, required): The unique identification number of the record you would like to modify. \nRetrieve Record ID from Airtable\nUsing the Query Airtable Node\nYou can retrieve a record by using the Query Airtable node.\nThis method automatically returns the record ID as a parameter.\nUsing a Formula Field in Airtable\nAdd a new Formula field to your table.\nEnter the formula: RECORD_ID()\nThe field will display the record ID for each record.\nCopy the ID from the relevant cell as needed.\nConfigurations:\nBase Id (string, required): The unique identifier of your Airtable base.\nExample: app1234567890\nYou can locate this in the URL on your Airtable browser: https://airtable.com/app1234567890/tbl...\nTable (string, required): The name of the table to query. \nOpen your Airtable base.\nLook at the tabs along the top (or left, depending on your layout). Each tab represents a table.\nThe table name is the label shown on each tab, e.g. Employees \nSummary Table of Actions\nAction Name\nDescription\nRequired Inputs\nRequired Configurations\nOutputs\nQuery records from a base/table\nInsert/update records in a table\nbase_id, table_name, records\nUpdate existing record in a table\nDelete a record in existing table\nLast updated 2 months ago","markdown":"# Airtable | StackAI\n\nQuery and manage your Airtable bases directly from StackAI workflows.\n\nThe Airtable node in StackAI enables seamless integration with your Airtable workspaces. You can perform database queries, retrieve records, and automate data management tasks as part of your workflow automation.\n\n### \n\nUsage overview\n\n1.  Choose the action that you'd like to perform in Airtable (query or write).\n    \n2.  Establish a connection to Airtable by either signing in via the **New Connection** button or selecting an existing connection from the dropdown. The Airtable node requires a valid API key or OAuth connection to access your bases. Validate the connection is 'Healthy' with **Test**.\n    \n3.  Fill out the parameters for the action that you'd like to take in Airtable by setting up the **Inputs** and **Configurations** (more details in dedicated sections below).\n    \n4.  The node can be connected to input nodes (for dynamic queries), LLM nodes (for natural language queries), or other action nodes for advanced automation.\n    \n\n### \n\nAvailable Actions and Triggers\n\n#### \n\n1\\. **Query Airtable**\n\n**Description:** Query an Airtable base using a structured query or natural language.\n\n**Inputs:**\n\n*   **Query** (string, required):\n    \n    *   The query is a plain English question or instruction that describes what data you want from the Airtable table. For example, you might write:\n        \n        *   \"Employees in the Marketing department\"\n            \n        *   \"Employees hired after January 2024\"\n            \n        *   \"Employees with the title 'Manager'\"\n            \n        \n    \n\n**Configurations:**\n\n*   **Base\\_id** (string, required): The unique identifier of your Airtable base.\n    \n    *   Example: `app1234567890`\n        \n    *   You can locate this in the URL on your Airtable browser: `https://airtable.com/app1234567890/tbl...`\n        \n    \n*   **Table** (string, required): The name of the table to query.\n    \n    *   Open your Airtable base.\n        \n    *   Look at the **tabs along the top** (or left, depending on your layout). Each tab represents a table.\n        \n    *   Th**e table name** is the label shown on each tab, e.g. `Employees`\n        \n    \n*   **View** (string, optional): Name of the view to use for filtering/sorting.\n    \n    *   Open your Airtable base.\n        \n    *   Navigate to the specific table you're working with.\n        \n    *   At the top left of the table, next to the table name, you’ll see a dropdown with the current view name (e.g., `Grid view` , `Kanban` , `Calendar` ).\n        \n    *   Click the dropdown to see all available views. The view you’re currently in is highlighted.\n        \n    \n*   **AirtableSearchModeEnum** (select, optional):\n    \n    *   Determines how your query is interpreted and executed.\n        \n    *   **Formula mode (\"formula\")**: Translates your natural language query into Airtable formula syntax—ideal for precise, rule-based filtering (e.g., your query may be “Find all employees in the Sales department”).\n        \n    *   **Semantic mode (\"semantic\")**: Uses semantic search to find records by meaning, not exact wording—useful for broader, context-driven queries (e.g., your query may be “Show me people who work with customers”.)\n        \n    \n*   **Max Records** (integer, optional): Maximum number of records to return.\n    \n    *   Example: `100`\n        \n    \n\n**Configurations:**\n\n*   **connection\\_id** (string, required): The connection ID for your Airtable account.\n    \n    *   Example: `\"your-connection-id\"`\n        \n    \n\n**Outputs:**\n\n*   **records** (array, required): List of records matching the query.\n    \n    *   Each record includes field values and record ID.\n        \n    *   Example:\n        \n        ```\n        [\n          {\n            \"id\": \"rec1234567890\",\n            \"fields\": {\n              \"Name\": \"Task 1\",\n              \"Status\": \"Open\",\n              \"Due Date\": \"2025-07-10\"\n            }\n          }\n        ]\n        ```\n        \n    \n\n* * *\n\n#### \n\n2\\. **Write to Airtable**\n\n**Description:**\n\nInsert or update records in an Airtable base.\n\n**Inputs:**\n\n*   **Data** (string, required): Your intent in plain English, describing what record you want to create and what values to set for each field.\n    \n    *   Examples:\n        \n        *   Add an employee named Alice Johnson, email [\\[email protected\\]](https://docs.stack-ai.com/cdn-cgi/l/email-protection), department Engineering, and start date July 15, 2025.\n            \n        *   Create a new product with name 'Widget X', price $99.99, and category 'Electronics'.\n            \n        \n    *   Tips\n        \n        *   Be as specific as possible about the fields and values you want to set.\n            \n        *   Use the field names as they appear in your Airtable table for best results.\n            \n        *   You can add multiple fields in one sentence.\n            \n        \n    \n\n**Configurations:**\n\n*   **Base Id** (string, required): The unique identifier of your Airtable base.\n    \n    *   Example: `app1234567890`\n        \n    *   You can locate this in the URL on your Airtable browser: `https://airtable.com/app1234567890/tbl...`\n        \n    \n*   **Table** (string, required): The name of the table to query.\n    \n    *   Open your Airtable base.\n        \n    *   Look at the **tabs along the top** (or left, depending on your layout). Each tab represents a table.\n        \n    *   Th**e table name** is the label shown on each tab, e.g. `Employees`\n        \n    \n*   **View** (string, optional): Expects either the **name** or the **ID** of a view in your Airtable table.\n    \n    *   Open your Airtable base.\n        \n    *   Navigate to the specific table you're working with.\n        \n    *   At the top left of the table, next to the table name, you’ll see a dropdown with the current view name (e.g., `Grid view` , `Kanban` , `Calendar` ).\n        \n    *   Click the dropdown to see all available views. The view you’re currently in is highlighted.\n        \n    \n    *   If you leave it blank, the default view (usually \"Grid view\") will be used.\n        \n    *   Specifying a view can be useful if you want to restrict the write operation to records visible in that view\n        \n    \n\n**Outputs:**\n\n*   **records** (array, required): List of records that were created or updated.\n    \n    *   Each record includes field values and record ID.\n        \n    *   Example:\n        \n        ```\n        [\n          {\n            \"id\": \"rec0987654321\",\n            \"fields\": {\n              \"Name\": \"New Task\",\n              \"Status\": \"In Progress\"\n            }\n          }\n        ]\n        ```\n        \n    \n\n* * *\n\n**3\\. Update Airtable Record**\n\n**Description:**\n\nUpdates the values of an existing record on Airtable.\n\n**Inputs:**\n\n*   **Record Id** (string, required): The unique identification number of the record you would like to modify.\n    \n    *   Retrieve Record ID from Airtable\n        \n        1.  Using the Query Airtable Node\n            \n            *   You can retrieve a record by using the _Query Airtable_ node.\n                \n            *   This method automatically returns the record ID as a parameter.\n                \n            \n        2.  Using a Formula Field in Airtable\n            \n            *   Add a new _Formula_ field to your table.\n                \n            *   Enter the formula: `RECORD_ID()`\n                \n            *   The field will display the record ID for each record.\n                \n            *   Copy the ID from the relevant cell as needed.\n                \n            \n        \n    \n*   **Data** (string, required): .Your intent in plain English, describing what part of the record you would like to update.\n    \n    *   Examples:\n        \n        *   Change 'X' column's entry to 100\n            \n        \n    \n\n**Configurations:**\n\n*   **Base Id** (string, required): The unique identifier of your Airtable base.\n    \n    *   Example: `app1234567890`\n        \n    *   You can locate this in the URL on your Airtable browser: `https://airtable.com/app1234567890/tbl...`\n        \n    \n*   **Table** (string, required): The name of the table to query.\n    \n    *   Open your Airtable base.\n        \n    *   Look at the **tabs along the top** (or left, depending on your layout). Each tab represents a table.\n        \n    *   Th**e table name** is the label shown on each tab, e.g. `Employees`\n        \n    \n\n* * *\n\n**4\\. Delete Airtable Record**\n\n**Description:**\n\nDelete an existing record on Airtable.\n\n**Inputs:**\n\n*   **Record Id** (string, required): The unique identification number of the record you would like to modify.\n    \n    *   Retrieve Record ID from Airtable\n        \n        1.  Using the Query Airtable Node\n            \n            *   You can retrieve a record by using the _Query Airtable_ node.\n                \n            *   This method automatically returns the record ID as a parameter.\n                \n            \n        2.  Using a Formula Field in Airtable\n            \n            *   Add a new _Formula_ field to your table.\n                \n            *   Enter the formula: `RECORD_ID()`\n                \n            *   The field will display the record ID for each record.\n                \n            *   Copy the ID from the relevant cell as needed.\n                \n            \n        \n    \n\n**Configurations:**\n\n*   **Base Id** (string, required): The unique identifier of your Airtable base.\n    \n    *   Example: `app1234567890`\n        \n    *   You can locate this in the URL on your Airtable browser: `https://airtable.com/app1234567890/tbl...`\n        \n    \n*   **Table** (string, required): The name of the table to query.\n    \n    *   Open your Airtable base.\n        \n    *   Look at the **tabs along the top** (or left, depending on your layout). Each tab represents a table.\n        \n    *   Th**e table name** is the label shown on each tab, e.g. `Employees`\n        \n    \n\n* * *\n\n**Summary Table of Actions**\n\nAction Name\n\nDescription\n\nRequired Inputs\n\nRequired Configurations\n\nOutputs\n\nQuery records from a base/table\n\nInsert/update records in a table\n\nbase\\_id, table\\_name, records\n\nUpdate existing record in a table\n\nDelete a record in existing table\n\nLast updated 2 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/llms/local-llm","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/llms/local-llm","loadedTime":"2025-10-17T18:30:39.985Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/llms/local-llm","title":"Local LLM | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Local LLM | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"0","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901de4efa7c16cb-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:39 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"iad1::iad1::w5fhh-1760725839254-af72414241e7"}},"screenshotUrl":null,"text":"Local LLM | StackAI\nThis guide will walk you through how to set a default connection for your preferred LLM provider. You'll also learn how to disable the use of StackAI API keys across providers, deactivate specific LLM providers, and manage other advanced configuration options.\nLet’s start!\n1. Creating a Default Connection\nNavigate to Settings on the bottom left of your screen, underneath your avatar. Then, select Feature Access from the menu.\nUnder the LLMs section, search for Local LLMs—you can follow the same steps for any other provider as well. If needed, this is also where you can disable specific LLM providers to prevent your users from accessing them.\nOnce you're in the tab for a specific LLM provider, you'll see a toggle to enable or disable the provider, as well as a \"New Connection\" button under Default Connection to define it as your primary connection.\nOnce you click the button, you can create a connection that will serve as the default for all LLMs from that provider within your workspace. This is especially useful because your users won’t need to manually enter an API key to use those models.ally.\n2. Using a Local LLM\nOnce the connection is set up, you can create a new project, choose your LLM provider, select the specific model you want to use, and start interacting with it immediately.\nYou won’t need to manually add the connection—your default connection will appear automatically at the bottom. If you prefer to use a different connection, you can create it directly from that section and select it for your project.\n3. Connections Manager\nAll your connections are stored in the Connections Manager tab. You can also create new connections from there, and easily select any of them when adding an LLM node to your project.\nYou can choose to make your connections either public or private, and you’re free to change the default connection at any time. Simply go to the Access Control tab in your Settings to update this preference.\n3. Disconnecting all StackAI’s API keys usage\nIf you'd like to prevent any unintended usage of LLMs without your API keys, you can disable all StackAI API Keys. This ensures that only LLMs configured to send data to your own servers are allowed. To do this, navigate to Settings > Feature Access > Other > General LLM Configuration.\nLast updated 3 months ago","markdown":"# Local LLM | StackAI\n\nThis guide will walk you through how to **set a default connection for your preferred LLM provider**. You'll also learn how to **disable the use of StackAI API keys across providers**, **deactivate specific LLM providers**, and manage other advanced configuration options.\n\nLet’s start!\n\n* * *\n\n### \n\n1\\. Creating a Default Connection\n\nNavigate to **Settings** on the bottom left of your screen, underneath your avatar. Then, select **Feature Access** from the menu.\n\nUnder the **LLMs** section, search for **Local LLMs**—you can follow the same steps for any other provider as well. If needed, this is also where you can **disable specific LLM providers** to prevent your users from accessing them.\n\nOnce you're in the tab for a specific LLM provider, you'll see a toggle to **enable or disable** the provider, as well as a **\"New Connection\"** button under Default Connection to define it as your primary connection.\n\nOnce you click the button, you can create a connection that will serve as the **default for all LLMs from that provider** within your workspace. This is especially useful because your users **won’t need to manually enter an API key** to use those models.ally.\n\n### \n\n2\\. Using a Local LLM\n\nOnce the connection is set up, you can **create a new project**, choose your **LLM provider**, select the **specific model** you want to use, and start **interacting with it immediately**.\n\nYou won’t need to manually add the connection—your **default connection will appear automatically at the bottom**. If you prefer to use a different connection, you can **create it directly from that section** and select it for your project.\n\n### \n\n3\\. Connections Manager\n\nAll your connections are stored in the **Connections Manager** tab. You can also **create new connections** from there, and easily **select any of them** when adding an LLM node to your project.\n\nYou can choose to make your connections either **public** or **private**, and you’re free to change the **default connection** at any time. Simply go to the **Access Control** tab in your **Settings** to update this preference.\n\n### \n\n3\\. Disconnecting all StackAI’s API keys usage\n\nIf you'd like to prevent any unintended usage of LLMs without your API keys, you can **disable all StackAI API Keys**. This ensures that only LLMs configured to send data to your own servers are allowed. To do this, navigate to **Settings > Feature Access > Other > General LLM Configuration**.\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/make","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/make","loadedTime":"2025-10-17T18:30:43.301Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/make","title":"Make | StackAI","description":"Learn how to use the Make (Integromat) node in StackAI to trigger webhooks and automate workflows with detailed input, configuration, and output examples.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Make | StackAI"},{"property":"og:description","content":"Learn how to use the Make (Integromat) node in StackAI to trigger webhooks and automate workflows with detailed input, configuration, and output examples."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"96","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901de62ec640a0b-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:42 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::m487n-1760725842430-7909917ce1fe"}},"screenshotUrl":null,"text":"Make | StackAI\nLearn how to use the Make (Integromat) node in StackAI to trigger webhooks and automate workflows with detailed input, configuration, and output examples.\nWhat is Make?\nMake (formerly Integromat) is a powerful automation platform that enables you to connect various apps and automate workflows. In StackAI, the Make node allows you to trigger webhooks, sending data to your Make scenarios and integrating StackAI with thousands of other services.\nHow to use it?\nThe Make node in StackAI is primarily used to trigger a webhook in your Make scenario. This is useful for sending data from StackAI to Make, where you can further process, route, or automate actions across your connected apps.\nExample of Usage\nSuppose you want to send user data from StackAI to a Make scenario for further processing. You would use the Make node to trigger a webhook with the relevant data payload.\nAvailable Actions\n1. Trigger Webhook\nDescription: Send a POST request to a Make webhook URL, optionally including a JSON payload. This action is commonly used to start a Make scenario from StackAI.\nInputs\nWebhook URL (Required)\nThe URL of your Make webhook.\nExample: https://hook.us2.make.com/qee6xwvm63a8jpctrgdnxgaj6hdd3v7q\nBody (Optional)\nThe JSON data payload to send with the webhook request.\nDescription (Optional)\nA human-readable description of the action being triggered.\nExample: \"Send new user signup data to Make\"\nConfigurations\nWebhook URL (Required)\nThis is the only required configuration. It must be a valid Make webhook URL.\nDescription (Optional)\nUsed for documentation or clarity within your workflow.\nOutputs\nStatus (Required)\nIndicates if the webhook call was successful or failed.\nExample: \"success\"\nMessage (Required)\nA descriptive message about the result of the webhook call.\nExample: \"Webhook triggered successfully\"\nStatus Code (Required)\nThe HTTP status code returned by the webhook endpoint.\nExample: 200\nResponse (Optional)\nThe JSON response data returned by the webhook, if any.\nHow to use it?\nObtain your Make webhook URL from your Make scenario.\nAdd the Make node to your StackAI workflow.\nEnter the webhook URL in the configuration.\n(Optional) Add a JSON body to send data.\n(Optional) Add a description for clarity.\nConnect the node to trigger the webhook as part of your workflow.\nExample of Usage\nScenario: Send new user signup data to Make for further automation.\nWebhook URL: https://hook.us2.make.com/qee6xwvm63a8jpctrgdnxgaj6hdd3v7q\nDescription: \"Send new user signup data to Make\"\nExpected Output:\nStatus: \"success\"\nMessage: \"Webhook triggered successfully\"\nStatus Code: 200\nResponse: (any data returned by your Make scenario)\nUse the Make node in StackAI to seamlessly connect your AI workflows with the vast automation capabilities of Make, enabling powerful integrations and streamlined processes.\nLast updated 3 months ago","markdown":"# Make | StackAI\n\nLearn how to use the Make (Integromat) node in StackAI to trigger webhooks and automate workflows with detailed input, configuration, and output examples.\n\n**What is Make?**\n\nMake (formerly Integromat) is a powerful automation platform that enables you to connect various apps and automate workflows. In StackAI, the Make node allows you to trigger webhooks, sending data to your Make scenarios and integrating StackAI with thousands of other services.\n\n* * *\n\n**How to use it?**\n\nThe Make node in StackAI is primarily used to trigger a webhook in your Make scenario. This is useful for sending data from StackAI to Make, where you can further process, route, or automate actions across your connected apps.\n\n* * *\n\n**Example of Usage**\n\nSuppose you want to send user data from StackAI to a Make scenario for further processing. You would use the Make node to trigger a webhook with the relevant data payload.\n\n* * *\n\n**Available Actions**\n\n#### \n\n1\\. Trigger Webhook\n\n**Description:** Send a POST request to a Make webhook URL, optionally including a JSON payload. This action is commonly used to start a Make scenario from StackAI.\n\n**Inputs**\n\n*   **Webhook URL** (Required)\n    \n    *   The URL of your Make webhook.\n        \n    *   Example: `https://hook.us2.make.com/qee6xwvm63a8jpctrgdnxgaj6hdd3v7q`\n        \n    \n*   **Body** (Optional)\n    \n    *   The JSON data payload to send with the webhook request.\n        \n    \n*   **Description** (Optional)\n    \n    *   A human-readable description of the action being triggered.\n        \n    *   Example: `\"Send new user signup data to Make\"`\n        \n    \n\n**Configurations**\n\n*   **Webhook URL** (Required)\n    \n    *   This is the only required configuration. It must be a valid Make webhook URL.\n        \n    \n*   **Description** (Optional)\n    \n    *   Used for documentation or clarity within your workflow.\n        \n    \n\n**Outputs**\n\n*   **Status** (Required)\n    \n    *   Indicates if the webhook call was successful or failed.\n        \n    *   Example: `\"success\"`\n        \n    \n*   **Message** (Required)\n    \n    *   A descriptive message about the result of the webhook call.\n        \n    *   Example: `\"Webhook triggered successfully\"`\n        \n    \n*   **Status Code** (Required)\n    \n    *   The HTTP status code returned by the webhook endpoint.\n        \n    *   Example: `200`\n        \n    \n*   **Response** (Optional)\n    \n    *   The JSON response data returned by the webhook, if any.\n        \n    \n\n* * *\n\n**How to use it?**\n\n1.  Obtain your Make webhook URL from your Make scenario.\n    \n2.  Add the Make node to your StackAI workflow.\n    \n3.  Enter the webhook URL in the configuration.\n    \n4.  (Optional) Add a JSON body to send data.\n    \n5.  (Optional) Add a description for clarity.\n    \n6.  Connect the node to trigger the webhook as part of your workflow.\n    \n\n* * *\n\n**Example of Usage**\n\n*   **Scenario:** Send new user signup data to Make for further automation.\n    \n*   **Webhook URL:** `https://hook.us2.make.com/qee6xwvm63a8jpctrgdnxgaj6hdd3v7q`\n    \n\n*   **Description:** `\"Send new user signup data to Make\"`\n    \n\n**Expected Output:**\n\n*   Status: `\"success\"`\n    \n*   Message: `\"Webhook triggered successfully\"`\n    \n*   Status Code: `200`\n    \n*   Response: (any data returned by your Make scenario)\n    \n\n* * *\n\nUse the Make node in StackAI to seamlessly connect your AI workflows with the vast automation capabilities of Make, enabling powerful integrations and streamlined processes.\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/api-reference/manager","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/api-reference/manager","loadedTime":"2025-10-17T18:30:44.901Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/api-reference/manager","title":"Manager | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Manager | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"166","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901de702e7c5968-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:44 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::x9ptz-1760725844555-f6bf85d54343"}},"screenshotUrl":null,"text":"Manager | StackAI\nGet User Conversations\nget\n/projects/{project_id}/manager/user-conversations\nGET /projects/{project_id}/manager/user-conversations HTTP/1.1 Host: api.stack-ai.com Accept: */*","markdown":"# Manager | StackAI\n\n### \n\nGet User Conversations\n\nget\n\n/projects/{project\\_id}/manager/user-conversations\n\n```\nGET /projects/{project_id}/manager/user-conversations HTTP/1.1\nHost: api.stack-ai.com\nAccept: */*\n```","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/api-reference/conversations","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/api-reference/conversations","loadedTime":"2025-10-17T18:30:45.394Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/api-reference/conversations","title":"Conversations | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Conversations | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1072","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901de7049dbc92c-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:44 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::dgdq2-1760725844584-b72d55942a13"}},"screenshotUrl":null,"text":"Conversations | StackAI\nGet Conversations\nget\n/projects/{project_id}/conversations\nGet Conversations Sso\nget\n/projects/{project_id}/sso/conversations\nArchive Conversation\nconversation_idstringRequired\nis_archivedbooleanOptionalDefault: true\npost\n/projects/{project_id}/conversations/{conversation_id}/archive\nDelete Conversation\nconversation_idstringRequired\ndelete\n/projects/{project_id}/conversations/{conversation_id}\nRename Conversation\nRename a conversation.\nArgs: conversation_id: The ID of the conversation to rename request: The request containing the new title project_metadata: The metadata of the project the conversation belongs to conversation_service: Service for managing conversations user_id: ID of the authenticated user\nReturns: The updated conversation\nconversation_idstringRequired\npost\n/projects/{project_id}/conversations/{conversation_id}/rename","markdown":"# Conversations | StackAI\n\n### \n\nGet Conversations\n\nget\n\n/projects/{project\\_id}/conversations\n\n### \n\nGet Conversations Sso\n\nget\n\n/projects/{project\\_id}/sso/conversations\n\n### \n\nArchive Conversation\n\nconversation\\_idstringRequired\n\nis\\_archivedbooleanOptionalDefault: `true`\n\npost\n\n/projects/{project\\_id}/conversations/{conversation\\_id}/archive\n\n### \n\nDelete Conversation\n\nconversation\\_idstringRequired\n\ndelete\n\n/projects/{project\\_id}/conversations/{conversation\\_id}\n\n### \n\nRename Conversation\n\nRename a conversation.\n\nArgs: conversation\\_id: The ID of the conversation to rename request: The request containing the new title project\\_metadata: The metadata of the project the conversation belongs to conversation\\_service: Service for managing conversations user\\_id: ID of the authenticated user\n\nReturns: The updated conversation\n\nconversation\\_idstringRequired\n\npost\n\n/projects/{project\\_id}/conversations/{conversation\\_id}/rename","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/api-reference/run-flow","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/api-reference/run-flow","loadedTime":"2025-10-17T18:30:45.685Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/api-reference/run-flow","title":"Run Flow | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Run Flow | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1073","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901de704b5d8287-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:44 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::9gpxz-1760725844575-9292b2b71856"}},"screenshotUrl":null,"text":"Run Flow | StackAI\nRun Deployed Flow\nRun a flow and get the result.\nversionintegerOptional\nVersion of the flow\nDefault: -1\nverbosebooleanOptional\nReturn the full model\nDefault: true\nobject · InputsOptional\nInput parameters for the flow\npost\n/inference/v0/run/{org_id}/{flow_id}\nStream Deployed Flow\nRun a flow and get the result streamed while the flow is running.\nversionintegerOptional\nVersion of the flow. -1 for the latest published version.\nDefault: -1\nprefixbooleanOptional\nAdd a prefix to the output\nDefault: false\ndeltabooleanOptional\nStream deltas instead of full output\nDefault: true\nssebooleanOptional\nUse server sent events instead of streaming response\nDefault: false\nverbosebooleanOptional\nReturn the full model\nDefault: true\nrun_draftbooleanOptional\nRun the draft version of the flow instead of the published one.\nDefault: false\nobject · InputsOptional\nInput parameters for the flow\npost\n/inference/v0/stream/{org_id}/{flow_id}\nStream Deployed Flow With Sso\nRun a flow and get the result streamed while the flow is running.\nversionintegerOptional\nVersion of the flow. -1 for the latest published version.\nDefault: -1\nprefixbooleanOptional\nAdd a prefix to the output\nDefault: false\ndeltabooleanOptional\nStream deltas instead of full output\nDefault: true\nssebooleanOptional\nUse server sent events instead of streaming response\nDefault: false\nverbosebooleanOptional\nReturn the full model\nDefault: true\nrun_draftbooleanOptional\nRun the draft version of the flow instead of the published one.\nDefault: false\ntokenstringRequired\nToken for authorization\nobject · InputsOptional\nInput parameters for the flow\npost\n/inference/v0/sso/stream/{org_id}/{flow_id}\nGive Feedback\nSend a feedback message for a given run.\nanyOptional\nInput parameters: feedback, inputs, outputs\npost\n/inference/v0/feedback/{org_id}/{flow_id}","markdown":"# Run Flow | StackAI\n\n### \n\nRun Deployed Flow\n\nRun a flow and get the result.\n\nversionintegerOptional\n\nVersion of the flow\n\nDefault: `-1`\n\nverbosebooleanOptional\n\nReturn the full model\n\nDefault: `true`\n\nobject · InputsOptional\n\nInput parameters for the flow\n\npost\n\n/inference/v0/run/{org\\_id}/{flow\\_id}\n\n### \n\nStream Deployed Flow\n\nRun a flow and get the result streamed while the flow is running.\n\nversionintegerOptional\n\nVersion of the flow. -1 for the latest published version.\n\nDefault: `-1`\n\nprefixbooleanOptional\n\nAdd a prefix to the output\n\nDefault: `false`\n\ndeltabooleanOptional\n\nStream deltas instead of full output\n\nDefault: `true`\n\nssebooleanOptional\n\nUse server sent events instead of streaming response\n\nDefault: `false`\n\nverbosebooleanOptional\n\nReturn the full model\n\nDefault: `true`\n\nrun\\_draftbooleanOptional\n\nRun the draft version of the flow instead of the published one.\n\nDefault: `false`\n\nobject · InputsOptional\n\nInput parameters for the flow\n\npost\n\n/inference/v0/stream/{org\\_id}/{flow\\_id}\n\n### \n\nStream Deployed Flow With Sso\n\nRun a flow and get the result streamed while the flow is running.\n\nversionintegerOptional\n\nVersion of the flow. -1 for the latest published version.\n\nDefault: `-1`\n\nprefixbooleanOptional\n\nAdd a prefix to the output\n\nDefault: `false`\n\ndeltabooleanOptional\n\nStream deltas instead of full output\n\nDefault: `true`\n\nssebooleanOptional\n\nUse server sent events instead of streaming response\n\nDefault: `false`\n\nverbosebooleanOptional\n\nReturn the full model\n\nDefault: `true`\n\nrun\\_draftbooleanOptional\n\nRun the draft version of the flow instead of the published one.\n\nDefault: `false`\n\ntokenstringRequired\n\nToken for authorization\n\nobject · InputsOptional\n\nInput parameters for the flow\n\npost\n\n/inference/v0/sso/stream/{org\\_id}/{flow\\_id}\n\n### \n\nGive Feedback\n\nSend a feedback message for a given run.\n\nanyOptional\n\nInput parameters: feedback, inputs, outputs\n\npost\n\n/inference/v0/feedback/{org\\_id}/{flow\\_id}","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/api-reference/messages","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/api-reference/messages","loadedTime":"2025-10-17T18:30:46.003Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/api-reference/messages","title":"Messages | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Messages | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"167","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901de703a42e5c7-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:44 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::s4dp2-1760725844560-48bfbd9cb5fa"}},"screenshotUrl":null,"text":"Messages | StackAI\nGet Conversation Messages\nGet all messages for a specific conversation branch.\nThe branch is determined by the conversation's last_message_id.\nconversation_idstringRequired\nget\n/projects/{project_id}/conversations/{conversation_id}/messages\nAppend Messages Sso\nAppend multiple messages to a given conversation.\nIf the conversation does not exist, it will be created with the first messages.\nArgs: conversation_id: ID of the conversation to append messages to project_id: ID of the project the conversation belongs to body: AppendMessagesBody message_service: Message service dependency conversation_service: Conversation service dependency\nReturns: The list of appended messages\nconversation_idstring · uuidRequired\npost\n/projects/{project_id}/conversations/{conversation_id}/messages\nGet Conversation Messages Sso\nGet all messages for a specific conversation branch.\nThe branch is determined by the conversation's last_message_id.\nconversation_idstringRequired\nget\n/projects/{project_id}/conversations/sso/{conversation_id}/messages\nAppend Messages\nAppend multiple messages to a given conversation.\nIf the conversation does not exist, it will be created with the first messages.\nArgs: conversation_id: ID of the conversation to append messages to project_id: ID of the project the conversation belongs to body: AppendMessagesBody message_service: Message service dependency conversation_service: Conversation service dependency\nReturns: The list of appended messages\nconversation_idstring · uuidRequired\npost\n/projects/{project_id}/conversations/sso/{conversation_id}/messages\nUpdate Message Feedback\npatch\n/projects/{project_id}/messages/{message_id}/feedback\nUpdate Message Feedback Sso\ntokenstringRequired\nToken for authorization\npatch\n/projects/{project_id}/messages/sso/{message_id}/feedback","markdown":"# Messages | StackAI\n\n### \n\nGet Conversation Messages\n\nGet all messages for a specific conversation branch.\n\nThe branch is determined by the conversation's last\\_message\\_id.\n\nconversation\\_idstringRequired\n\nget\n\n/projects/{project\\_id}/conversations/{conversation\\_id}/messages\n\n### \n\nAppend Messages Sso\n\nAppend multiple messages to a given conversation.\n\nIf the conversation does not exist, it will be created with the first messages.\n\nArgs: conversation\\_id: ID of the conversation to append messages to project\\_id: ID of the project the conversation belongs to body: AppendMessagesBody message\\_service: Message service dependency conversation\\_service: Conversation service dependency\n\nReturns: The list of appended messages\n\nconversation\\_idstring · uuidRequired\n\npost\n\n/projects/{project\\_id}/conversations/{conversation\\_id}/messages\n\n### \n\nGet Conversation Messages Sso\n\nGet all messages for a specific conversation branch.\n\nThe branch is determined by the conversation's last\\_message\\_id.\n\nconversation\\_idstringRequired\n\nget\n\n/projects/{project\\_id}/conversations/sso/{conversation\\_id}/messages\n\n### \n\nAppend Messages\n\nAppend multiple messages to a given conversation.\n\nIf the conversation does not exist, it will be created with the first messages.\n\nArgs: conversation\\_id: ID of the conversation to append messages to project\\_id: ID of the project the conversation belongs to body: AppendMessagesBody message\\_service: Message service dependency conversation\\_service: Conversation service dependency\n\nReturns: The list of appended messages\n\nconversation\\_idstring · uuidRequired\n\npost\n\n/projects/{project\\_id}/conversations/sso/{conversation\\_id}/messages\n\n### \n\nUpdate Message Feedback\n\npatch\n\n/projects/{project\\_id}/messages/{message\\_id}/feedback\n\n### \n\nUpdate Message Feedback Sso\n\ntokenstringRequired\n\nToken for authorization\n\npatch\n\n/projects/{project\\_id}/messages/sso/{message\\_id}/feedback","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/api-reference/tools","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/api-reference/tools","loadedTime":"2025-10-17T18:30:46.392Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/api-reference/tools","title":"Tools | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Tools | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1835","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901de70492ce5fc-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:44 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::r7lv9-1760725844567-0469ebdbd76a"}},"screenshotUrl":null,"text":"Tools | StackAI\nGet Custom Tools\nGet all custom tool providers for the user's organization.\nArgs: user_org: Current authenticated user service: Custom tool service instance\nReturns: List of custom tool providers\nCreate Custom Tool\nCreate a new custom tool provider.\nArgs: data: Provider creation data service: Custom tool service instance user_org: Current user's organization user: Current user profile\nReturns: Created custom tool provider\nUpdate Custom Tool\nUpdate an existing custom tool provider.\nArgs: provider_id: Provider ID to update data: Provider update data service: Custom tool service instance user_org: Current user's organization user: Current user profile\nReturns: Updated custom tool provider\nprovider_idstringRequired\nput\n/tools/custom/{provider_id}\nDelete Custom Tool\nDelete a custom tool provider.\nArgs: provider_id: Provider ID to delete user_org: Current user's organization service: Custom tool service instance\nReturns: None\nprovider_idstringRequired\ndelete\n/tools/custom/{provider_id}\nGet Stackai Tools\nGet all providers with tools created by StackAI's team.\nGet Stackai Providers\nGet all providers with tools created by StackAI's team.\nget\n/tools/stackai/actions\nGet Action By Provider And Id\nGet the data for a specific native action available and implemented by StackAI.\nprovider_idstringRequired\nget\n/tools/stackai/providers/{provider_id}/actions/{action_id}\nGet Action Inputs\nGet the input parameters for an action as a JSON schema.\nprovider_idstringRequired\nResponseobject · ResponseGetActionInputsToolsStackaiProvidersProviderIdActionsActionIdInputsGet\nget\n/tools/stackai/providers/{provider_id}/actions/{action_id}/inputs\nGet Action Outputs\nGet the output parameters for an action as a JSON schema.\nprovider_idstringRequired\nResponseobject · ResponseGetActionOutputsToolsStackaiProvidersProviderIdActionsActionIdOutputsGet\nget\n/tools/stackai/providers/{provider_id}/actions/{action_id}/outputs\nGet Provider Icon\nGet the icon for a specific provider.\nprovider_idstringRequired\nget\n/tools/stackai/{provider_id}/icon\nGet Action Options\nGet action options for a specific action and provider.\nArgs: options_request: Action and provider identifiers user_organization: The user organization\nReturns: List of schema strings for the action","markdown":"# Tools | StackAI\n\n### \n\nGet Custom Tools\n\nGet all custom tool providers for the user's organization.\n\nArgs: user\\_org: Current authenticated user service: Custom tool service instance\n\nReturns: List of custom tool providers\n\n### \n\nCreate Custom Tool\n\nCreate a new custom tool provider.\n\nArgs: data: Provider creation data service: Custom tool service instance user\\_org: Current user's organization user: Current user profile\n\nReturns: Created custom tool provider\n\n### \n\nUpdate Custom Tool\n\nUpdate an existing custom tool provider.\n\nArgs: provider\\_id: Provider ID to update data: Provider update data service: Custom tool service instance user\\_org: Current user's organization user: Current user profile\n\nReturns: Updated custom tool provider\n\nprovider\\_idstringRequired\n\nput\n\n/tools/custom/{provider\\_id}\n\n### \n\nDelete Custom Tool\n\nDelete a custom tool provider.\n\nArgs: provider\\_id: Provider ID to delete user\\_org: Current user's organization service: Custom tool service instance\n\nReturns: None\n\nprovider\\_idstringRequired\n\ndelete\n\n/tools/custom/{provider\\_id}\n\n### \n\nGet Stackai Tools\n\nGet all providers with tools created by StackAI's team.\n\n### \n\nGet Stackai Providers\n\nGet all providers with tools created by StackAI's team.\n\nget\n\n/tools/stackai/actions\n\n### \n\nGet Action By Provider And Id\n\nGet the data for a specific native action available and implemented by StackAI.\n\nprovider\\_idstringRequired\n\nget\n\n/tools/stackai/providers/{provider\\_id}/actions/{action\\_id}\n\n### \n\nGet Action Inputs\n\nGet the input parameters for an action as a JSON schema.\n\nprovider\\_idstringRequired\n\nResponseobject · ResponseGetActionInputsToolsStackaiProvidersProviderIdActionsActionIdInputsGet\n\nget\n\n/tools/stackai/providers/{provider\\_id}/actions/{action\\_id}/inputs\n\n### \n\nGet Action Outputs\n\nGet the output parameters for an action as a JSON schema.\n\nprovider\\_idstringRequired\n\nResponseobject · ResponseGetActionOutputsToolsStackaiProvidersProviderIdActionsActionIdOutputsGet\n\nget\n\n/tools/stackai/providers/{provider\\_id}/actions/{action\\_id}/outputs\n\n### \n\nGet Provider Icon\n\nGet the icon for a specific provider.\n\nprovider\\_idstringRequired\n\nget\n\n/tools/stackai/{provider\\_id}/icon\n\n### \n\nGet Action Options\n\nGet action options for a specific action and provider.\n\nArgs: options\\_request: Action and provider identifiers user\\_organization: The user organization\n\nReturns: List of schema strings for the action","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/api-reference/notifications","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/api-reference/notifications","loadedTime":"2025-10-17T18:30:46.199Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/api-reference/notifications","title":"Notifications | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Notifications | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"date":"Fri, 17 Oct 2025 18:30:43 GMT","content-type":"text/html; charset=utf-8","content-encoding":"br","cf-ray":"9901de69afac8157-SEA","cf-cache-status":"DYNAMIC","age":"1835","cache-control":"public, max-age=0, must-revalidate","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","referrer-policy":"no-referrer-when-downgrade","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"pdx1::iad1::xzvtx-1760725843502-68a1eabfe157","server":"cloudflare","alt-svc":"h3=\":443\"; ma=86400","x-firefox-spdy":"h2"}},"screenshotUrl":"https://api.apify.com/v2/key-value-stores/3K2WBdQQFTu6EGDhJ/records/SCREENSHOT-docs-stack-ai-com-stack-ai-api-reference-notifications-976268ab.jpg","text":"Notifications | StackAI\nGet All User Notifications\nGet notifications for a specific user.\nArgs:\nuser (UserProfile): The user profile dependency. organization (Organization): The organization dependency. notification_service (NotificationService): The notification service dependency\nReturns:\nlist[UserNotificationBase]: The list of notifications for the user.\nDelete Notification\nDelete a notification by its ID.\nArgs:\nnotification_id (str): The ID of the notification to delete. user (UserProfile): The user profile dependency. notification_service (NotificationService): The notification service dependency created_at (datetime.datetime): The created at date of the notification.\nReturns:\ndict: The response indicating the success of the deletion.\nnotification_idstring · uuidRequired\ncreated_atstring · date-timeRequired\ndelete\n/notifications/{notification_id}\nUpdate Notification\nnotification_idstring · uuidRequired\ncreated_atstring · date-timeRequired\npatch\n/notifications/{notification_id}\nDelete All User Notifications\nDelete all notifications for a specific user.\nArgs:\nuser (UserProfile): The user profile dependency. organization (Organization): The organization dependency notification_service (NotificationService): The notification service dependency\nReturns:\ndict: The response indicating the success of the deletion.\nResponseobject · ResponseDeleteAllUserNotificationsNotificationsAllDelete\ndelete\n/notifications/all/\nGet Users From Org By Role\nGet users from organization by role.\nnotification_idstring · uuidRequired\npost\n/notifications/{notification_id}/","markdown":"# Notifications | StackAI\n\n### \n\nGet All User Notifications\n\nGet notifications for a specific user.\n\n### \n\nArgs:\n\n```\nuser (UserProfile): The user profile dependency.\norganization (Organization): The organization dependency.\nnotification_service (NotificationService): The notification service dependency\n```\n\n### \n\nReturns:\n\n```\nlist[UserNotificationBase]: The list of notifications for the user.\n```\n\n### \n\nDelete Notification\n\nDelete a notification by its ID.\n\n### \n\nArgs:\n\n```\nnotification_id (str): The ID of the notification to delete.\nuser (UserProfile): The user profile dependency.\nnotification_service (NotificationService): The notification service dependency\ncreated_at (datetime.datetime): The created at date of the notification.\n```\n\n### \n\nReturns:\n\n```\ndict: The response indicating the success of the deletion.\n```\n\nnotification\\_idstring · uuidRequired\n\ncreated\\_atstring · date-timeRequired\n\ndelete\n\n/notifications/{notification\\_id}\n\n### \n\nUpdate Notification\n\nnotification\\_idstring · uuidRequired\n\ncreated\\_atstring · date-timeRequired\n\npatch\n\n/notifications/{notification\\_id}\n\n### \n\nDelete All User Notifications\n\nDelete all notifications for a specific user.\n\n### \n\nArgs:\n\n```\nuser (UserProfile): The user profile dependency.\norganization (Organization): The organization dependency\nnotification_service (NotificationService): The notification service dependency\n```\n\n### \n\nReturns:\n\n```\ndict: The response indicating the success of the deletion.\n```\n\nResponseobject · ResponseDeleteAllUserNotificationsNotificationsAllDelete\n\ndelete\n\n/notifications/all/\n\n### \n\nGet Users From Org By Role\n\nGet users from organization by role.\n\nnotification\\_idstring · uuidRequired\n\npost\n\n/notifications/{notification\\_id}/","debug":{"requestHandlerMode":"browser"}}
{"url":"https://docs.stack-ai.com/stack-ai/api-reference/analytics","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/api-reference/analytics","loadedTime":"2025-10-17T18:30:52.714Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/api-reference/analytics","title":"Analytics | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Analytics | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"174","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dea218aae602-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:52 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::bc2gj-1760725852563-c0d328df4f15"}},"screenshotUrl":null,"text":"Analytics | StackAI\nGet Analytics Data Api\nList with the flow run logs matching the given filters.\npageintegerOptionalDefault: 0\npage_sizeinteger · min: 1OptionalDefault: 25\nstart_dateany ofOptional\nstring · date-timeOptional\nor\nend_dateany ofOptional\nstring · date-timeOptional\nor\nget\n/analytics/org/{org_id}/flows/{flow_id}\nGet Storage Usage\nget\n/analytics/storage/total-usage","markdown":"# Analytics | StackAI\n\n### \n\nGet Analytics Data Api\n\nList with the flow run logs matching the given filters.\n\npageintegerOptionalDefault: `0`\n\npage\\_sizeinteger · min: 1OptionalDefault: `25`\n\nstart\\_dateany ofOptional\n\nstring · date-timeOptional\n\nor\n\nend\\_dateany ofOptional\n\nstring · date-timeOptional\n\nor\n\nget\n\n/analytics/org/{org\\_id}/flows/{flow\\_id}\n\n### \n\nGet Storage Usage\n\nget\n\n/analytics/storage/total-usage","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/bonus-features/share-workflow","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/bonus-features/share-workflow","loadedTime":"2025-10-17T18:30:52.782Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/bonus-features/share-workflow","title":"Share Workflow | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Share Workflow | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1289","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dea22ac072d4-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:52 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::d466t-1760725852553-7c57edcfb840"}},"screenshotUrl":null,"text":"Share Workflow | StackAI\nTo share your flow with other users, you can click on the Share button at the top-right of the flow builder, like shown below:\nThe shared flow will be a duplicate of your current flow when shared. Any subsequent changes to your flow will not be reflected to the shared flow, and vice-versa, changes to the shared flow will not be reflected to the original flow.\nLast updated 3 months ago","markdown":"# Share Workflow | StackAI\n\nTo share your flow with other users, you can click on the Share button at the top-right of the flow builder, like shown below:\n\nThe shared flow will be a duplicate of your current flow when shared. Any subsequent changes to your flow will not be reflected to the shared flow, and vice-versa, changes to the shared flow will not be reflected to the original flow.\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/project-management/exporting-and-importing-projects","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/project-management/exporting-and-importing-projects","loadedTime":"2025-10-17T18:30:52.926Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/project-management/exporting-and-importing-projects","title":"Exporting and Importing Projects | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Exporting and Importing Projects | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1849","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dea2ad83c9b7-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:52 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::lr5r6-1760725852647-23463cb48ae7"}},"screenshotUrl":null,"text":"Exporting and Importing Projects | StackAI\nExporting a Workflow\nIn the Dashboard view, go into \"Grid View\" and locate your project\nFrom here, click on the 3 dots of your project and select Export. \nA JSON file will be downloaded, this is the workflow that can be imported or saved locally. \nImporting a Workflow\nIn the Dashboard, on the drop down menu select \"Import Project\" and select your project.json. Your workflow will be added as a project in the the respective Dashboard.\nLast updated 2 months ago","markdown":"# Exporting and Importing Projects | StackAI\n\n### \n\nExporting a Workflow\n\n1.  In the Dashboard view, go into \"Grid View\" and locate your project\n    \n2.  From here, click on the 3 dots of your project and select Export.\n    \n3.  A JSON file will be downloaded, this is the workflow that can be imported or saved locally.\n    \n\n### \n\nImporting a Workflow\n\nIn the Dashboard, on the drop down menu select \"Import Project\" and select your project.json. Your workflow will be added as a project in the the respective Dashboard.\n\nLast updated 2 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/export-options/deploy-with-the-export-view","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/export-options/deploy-with-the-export-view","loadedTime":"2025-10-17T18:30:53.054Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/export-options/deploy-with-the-export-view","title":"Deploy with the Export View | StackAI","description":"Export your project as a chat assistant, a form, or an app. Run your project all at once on a csv file with the Batch Interface.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Deploy with the Export View | StackAI"},{"property":"og:description","content":"Export your project as a chat assistant, a form, or an app. Run your project all at once on a csv file with the Batch Interface."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1849","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dea42c089c3d-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:53 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::7ll22-1760725852888-edec5c897b37"}},"screenshotUrl":null,"text":"Deploy with the Export View\nExport your project as a chat assistant, a form, or an app. Run your project all at once on a csv file with the Batch Interface.\nUsers can select from a list of pre-built interfaces (chat assistant, form, batch processing interface, website chatbot) and deployment options (Slack, MSFT Teams), or use StackAI for the backend of their application by using API endpoints.\nUsers have complete control over interface customization, including built-in security features to protect data and access.\nLast updated 3 months ago","markdown":"# Deploy with the Export View\n\nExport your project as a chat assistant, a form, or an app. Run your project all at once on a csv file with the Batch Interface.\n\nUsers can select from a list of pre-built interfaces (chat assistant, form, batch processing interface, website chatbot) and deployment options (Slack, MSFT Teams), or use StackAI for the backend of their application by using API endpoints.\n\nUsers have complete control over interface customization, including built-in security features to protect data and access.\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/bonus-features/skip-a-node","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/bonus-features/skip-a-node","loadedTime":"2025-10-17T18:30:53.342Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/bonus-features/skip-a-node","title":"Skip a Node | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Skip a Node | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"0","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dea2893b7fb8-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:53 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"iad1::iad1::q4h4k-1760725852608-3d18a380f7f7"}},"screenshotUrl":null,"text":"Skip a Node | StackAI\nIf you have a node in your workflow that you aren't ready to use yet, try skipping the node! You can also use this feature if you want to test how your workflow would run without a node, or if you want to see just one branch of your workflow in action.\nTo skip any node, click on the three dots in the top right corner and select \"Skip node.\" Your node will be skipped when running your project. To undo this action, select \"Enable node.\"\nLast updated 2 months ago","markdown":"# Skip a Node | StackAI\n\nIf you have a node in your workflow that you aren't ready to use yet, try skipping the node! You can also use this feature if you want to test how your workflow would run without a node, or if you want to see just one branch of your workflow in action.\n\nTo skip any node, click on the three dots in the top right corner and select \"Skip node.\" Your node will be skipped when running your project. To undo this action, select \"Enable node.\"\n\nLast updated 2 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/bonus-features/replace-a-node","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/bonus-features/replace-a-node","loadedTime":"2025-10-17T18:30:53.638Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/bonus-features/replace-a-node","title":"Replace a Node | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Replace a Node | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"0","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dea25bb5c989-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:53 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"iad1::iad1::g4dsh-1760725852583-2e77c4982f24"}},"screenshotUrl":null,"text":"Replace a Node | StackAI\nIf you'd like to replace a node in your workflow with something else--say you would like to replace the Gmail node with Outlook--you can click on the three dots in the top right and select \"Replace node.\"\nLast updated 2 months ago","markdown":"# Replace a Node | StackAI\n\nIf you'd like to replace a node in your workflow with something else--say you would like to replace the Gmail node with Outlook--you can click on the three dots in the top right and select \"Replace node.\"\n\n![](https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3697023207-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FFSlso1Kjob5CLDrh0dVn%252Fuploads%252F9Kg82VrD9J1ROd89IGTY%252Freplace_node.gif%3Falt%3Dmedia%26token%3D5b31cb27-81d6-40a2-9afa-2120363f3713&width=768&dpr=4&quality=100&sign=b7954c1e&sv=2)\n\nLast updated 2 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/api-reference/triggers","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/api-reference/triggers","loadedTime":"2025-10-17T18:30:52.888Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/api-reference/triggers","title":"Triggers | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Triggers | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"174","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dea2083ec95f-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:52 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::xqw5c-1760725852561-c31f0649503b"}},"screenshotUrl":null,"text":"Triggers | StackAI\nGet Triggers\nget\n/projects/{project_id}/triggers\nCreate Trigger\npost\n/projects/{project_id}/triggers\nGet Trigger\nproject_trigger_idstring · uuidRequired\nget\n/triggers/{project_trigger_id}\nDelete Trigger\nproject_trigger_idstring · uuidRequired\ndelete\n/triggers/{project_trigger_id}\nEnable Trigger\nproject_trigger_idstring · uuidRequired\npost\n/triggers/{project_trigger_id}/enable\nDisable Trigger\nproject_trigger_idstring · uuidRequired\npost\n/triggers/{project_trigger_id}/disable\nGet Available Triggers By Provider\nGet the list of native triggers available and implemented by Stack AI.\nprovider_idstringRequired\nget\n/providers/{provider_id}/triggers\nGet Specific Trigger From Provider\nGet the data for a specific native trigger available and implemented by Stack AI.\nprovider_idstringRequired\nget\n/providers/{provider_id}/triggers/{trigger_id}/\nWebhook Trigger\nproject_trigger_idstring · uuidRequired\nprovider_idany ofOptional\npost\n/organizations/{org_id}/triggers/{project_trigger_id}/webhook/key/{api_key}\nWebhook Trigger Deprecated\nproject_trigger_idstring · uuidRequired\nprovider_idany ofOptional\npost\n/organizations/{org_id}/triggers/{project_trigger_id}/webook/key/{api_key}\nPolling Trigger\nproject_trigger_idstring · uuidRequired\npost\n/organizations/{org_id}/triggers/{project_trigger_id}/polling/key/{api_key}\nScheduled Trigger\nproject_trigger_idstring · uuidRequired\npost\n/organizations/{org_id}/triggers/{project_trigger_id}/scheduled/key/{api_key}","markdown":"# Triggers | StackAI\n\n### \n\nGet Triggers\n\nget\n\n/projects/{project\\_id}/triggers\n\n### \n\nCreate Trigger\n\npost\n\n/projects/{project\\_id}/triggers\n\n### \n\nGet Trigger\n\nproject\\_trigger\\_idstring · uuidRequired\n\nget\n\n/triggers/{project\\_trigger\\_id}\n\n### \n\nDelete Trigger\n\nproject\\_trigger\\_idstring · uuidRequired\n\ndelete\n\n/triggers/{project\\_trigger\\_id}\n\n### \n\nEnable Trigger\n\nproject\\_trigger\\_idstring · uuidRequired\n\npost\n\n/triggers/{project\\_trigger\\_id}/enable\n\n### \n\nDisable Trigger\n\nproject\\_trigger\\_idstring · uuidRequired\n\npost\n\n/triggers/{project\\_trigger\\_id}/disable\n\n### \n\nGet Available Triggers By Provider\n\nGet the list of native triggers available and implemented by Stack AI.\n\nprovider\\_idstringRequired\n\nget\n\n/providers/{provider\\_id}/triggers\n\n### \n\nGet Specific Trigger From Provider\n\nGet the data for a specific native trigger available and implemented by Stack AI.\n\nprovider\\_idstringRequired\n\nget\n\n/providers/{provider\\_id}/triggers/{trigger\\_id}/\n\n### \n\nWebhook Trigger\n\nproject\\_trigger\\_idstring · uuidRequired\n\nprovider\\_idany ofOptional\n\npost\n\n/organizations/{org\\_id}/triggers/{project\\_trigger\\_id}/webhook/key/{api\\_key}\n\n### \n\nWebhook Trigger Deprecated\n\nproject\\_trigger\\_idstring · uuidRequired\n\nprovider\\_idany ofOptional\n\npost\n\n/organizations/{org\\_id}/triggers/{project\\_trigger\\_id}/webook/key/{api\\_key}\n\n### \n\nPolling Trigger\n\nproject\\_trigger\\_idstring · uuidRequired\n\npost\n\n/organizations/{org\\_id}/triggers/{project\\_trigger\\_id}/polling/key/{api\\_key}\n\n### \n\nScheduled Trigger\n\nproject\\_trigger\\_idstring · uuidRequired\n\npost\n\n/organizations/{org\\_id}/triggers/{project\\_trigger\\_id}/scheduled/key/{api\\_key}","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/export-options/chat-assistant","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/export-options/chat-assistant","loadedTime":"2025-10-17T18:30:56.091Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/export-options/chat-assistant","title":"Chat Assistant | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Chat Assistant | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1851","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901deb57dc4ed75-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:55 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::9h9hb-1760725855639-94b2cb1dbfe8"}},"screenshotUrl":null,"text":"Chat Assistant | StackAI\nThe Chat Assistant interface is the classic chat interface many of your users will be familiar with. On the right side panel, you will see UI customization options.\nNote the Fields section. If your project has more than one input or output, you can choose which ones will interface with the user. The user will be able to enter text into only one of the inputs, and see the output of only one of the outputs in your project. Everything else will be hidden.\nConfiguration\nYou can customize some of the options for this interface:\nUser feedback: allow the user to give thumbs up or thumbs down feedback on chat responses, you will be able to see this feedback in the Manager View\nRelated results: shows the user suggestions for follow-up inputs to the chat assistant\nShow steps: shows the user what parts of your project are processing\nShow attachment icon: \nwhen enabled without a Files Node checked as an input, allows the user to attach images by clicking the attachment icon on the bottom left of the chat box denoted. \nenabled with a Files Node checked as an input, allows the user to attach any file.\nShow audio icon: allows the user to do voice-to-text instead of typing\nDefault loading message: shows a message while the chat assistant is thinking\nConversation Starters: shows the user example queries","markdown":"# Chat Assistant | StackAI\n\nThe **Chat Assistant** interface is the classic chat interface many of your users will be familiar with. On the right side panel, you will see UI customization options.\n\nNote the **Fields** section. If your project has more than one input or output, you can choose which ones will interface with the user. The user will be able to enter text into only one of the inputs, and see the output of only one of the outputs in your project. Everything else will be hidden.\n\n### \n\nConfiguration\n\nYou can customize some of the options for this interface:\n\n*   **User feedback:** allow the user to give thumbs up or thumbs down feedback on chat responses, you will be able to see this feedback in the Manager View\n    \n*   **Related results:** shows the user suggestions for follow-up inputs to the chat assistant\n    \n*   **Show steps:** shows the user what parts of your project are processing\n    \n*   **Show attachment icon:**\n    \n    *   when enabled without a [Files Node](https://docs.stack-ai.com/stack-ai/workflow-builder/inputs/files-node) checked as an input, allows the user to attach images by clicking the attachment icon on the bottom left of the chat box denoted.\n        \n    *   enabled with a [Files Node](https://docs.stack-ai.com/stack-ai/workflow-builder/inputs/files-node) checked as an input, allows the user to attach any file.\n        \n    \n*   **Show audio icon:** allows the user to do voice-to-text instead of typing\n    \n*   **Default loading message:** shows a message while the chat assistant is thinking\n    \n*   **Conversation Starters:** shows the user example queries","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/export-options/form","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/export-options/form","loadedTime":"2025-10-17T18:30:56.205Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/export-options/form","title":"Form | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Form | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1852","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901deb4fd791f6d-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:55 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::lz2nk-1760725855585-c0743d8dbf97"}},"screenshotUrl":null,"text":"Form | StackAI\nExport as a form if you'd like users to give your workflow specific types of information. This interface works best if you want the user to provide multiple different inputs, or want different inputs to be sent to different parts of your workflow.\nEach Input Node in your workflow will show up as its own text box in the Export View. \nChoose Form and customize your app's name, background photo, and UI.","markdown":"# Form | StackAI\n\nExport as a form if you'd like users to give your workflow specific types of information. This interface works best if you want the user to provide multiple different inputs, or want different inputs to be sent to different parts of your workflow.\n\nEach Input Node in your workflow will show up as its own text box in the Export View.\n\nChoose **Form** and customize your app's name, background photo, and UI.","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/export-options/slack-app","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/export-options/slack-app","loadedTime":"2025-10-17T18:30:56.701Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/export-options/slack-app","title":"Slack App | StackAI","description":"Integrate your chat agent as a chat app in Slack.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Slack App | StackAI"},{"property":"og:description","content":"Integrate your chat agent as a chat app in Slack."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1851","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901deb8b89f584e-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:56 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::6vgjf-1760725856255-bc2fe4330636"}},"screenshotUrl":null,"text":"Slack App | StackAI\nIntegrate your chat agent as a chat app in Slack.\nHow to Integrate\nSelect \"from an app manifest.\"\nSelect the workspace where you'd want the app installed.\nCopy and paste the YAML file into the app manifest field. You can create a YAML file in the export interface.\nClick 'Create'\nDo NOT click 'Install the App to Workspace.' Due to how Slack configures authentication, the application won't work. Instead, scroll down to App Credentials and find the Client ID, Client Secret, and Signing Secret.\nSave those credentials in Export View.\nInstall the Slack app in your workspace.\nDon't forget to publish your project! Your users will only be able to interact with the most recently published version of your project, not your project's drafts.\nLast updated 3 months ago","markdown":"# Slack App | StackAI\n\nIntegrate your chat agent as a chat app in Slack.\n\n### \n\nHow to Integrate\n\n2.  Select \"from an app manifest.\"\n    \n3.  Select the workspace where you'd want the app installed.\n    \n4.  Copy and paste the YAML file into the app manifest field. You can create a YAML file in the export interface.\n    \n5.  Click **'Create'**\n    \n6.  Do NOT click 'Install the App to Workspace.' Due to how Slack configures authentication, the application won't work. Instead, scroll down to App Credentials and find the Client ID, Client Secret, and Signing Secret.\n    \n7.  Save those credentials in Export View.\n    \n8.  Install the Slack app in your workspace.\n    \n9.  Don't forget to publish your project! Your users will only be able to interact with the most recently published version of your project, not your project's drafts.\n    \n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/export-options/landing-page-chatbot","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/export-options/landing-page-chatbot","loadedTime":"2025-10-17T18:30:56.800Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/export-options/landing-page-chatbot","title":"Landing Page Chatbot | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Landing Page Chatbot | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1852","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901deb8bebfdf73-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:56 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::c8xcx-1760725856177-e54090a50298"}},"screenshotUrl":null,"text":"Landing Page Chatbot | StackAI\nThe Landing Page Chatbot is a great export option if you'd like your users to be able to optionally interact with a chatbot while on your website. The chatbot will be available as an icon that opens a window.\nPublish your project first, then embed your chat assistant in your website by clicking the Embed button on the top right of the page. Paste the HTML or React code into the UI of your website. Each time you make changes to your project, remember to Publish them first so that the changes populate to the user side.\nConfiguration\nYou can customize some of the options for this interface:\nUser feedback: allow the user to give thumbs up or thumbs down feedback on chat responses, you will be able to see this feedback in the Manager View\nRelated results: shows the user suggestions for follow-up inputs to the chat assistant\nShow steps: shows the user what parts of your project are processing\nShow attachment icon: allows the user to attach files by clicking the attachment icon on the bottom left of the chat box\nShow audio icon: allows the user to do voice-to-text instead of typing\nDefault loading message: shows a message while the chat assistant is thinking\nWelcome Message: shows the user a welcome message before they've queries the chat assistant\nEnable clear chat: allows the user to clear the chat\nConversation Starters: shows the user example queries before the user has begun interacting\nIcon Message: shows a message above the icon of that chat assistant\nIf your chatbot is blocking your background:\nIf your Stack AI chatbot is blocking elements behind it after embedding it, you need to replace the script with standard HTML.\nPrerequisites\nHave a project ready, or create a new project.\nHave your project chatbot published.\nStep-by-step Guide:\nGet chatbot URL\nTo begin the process, you must go to the export section.\n- Navigate to Export. - Select Website Chatbot. - Get the `data-project-url` from the \"Embed in Website\" section.\nThe chatbot url will have the form https://www.stack-ai.com/embed/[org_id]/[public_key]/[flow_id].\nModify Script\nIn your HTML website, replace the chatbot script for the following HTML code:\n<!-- Iframe code --> <iframe id=\"iframeId\" src=\"[YOUR_CHATBOT_URL_HERE]\" width=\"350\" height=\"600\" frameborder=\"0\" style=\"position: fixed; z-index: 1; bottom: 15px; right: 15px; max-width: calc(100vw - 15px); max-height: calc(100vh - 15px);\" ></iframe> <!-- Script for handling the resizing --> <script> function handleMessage(event) { if (event.data.type === 'chatbotStateChange') { const iframe = document.getElementById('iframeId') if (iframe) { if (event.data.isClosed) { iframe.style.width = '60px' iframe.style.height = '60px' } else { iframe.style.width = '350px' iframe.style.height = '600px' } } } } // Attach event listener window.addEventListener('message', handleMessage) // If you want to clean up the event listener when the page unloads (optional) window.addEventListener('beforeunload', function () { window.removeEventListener('message', handleMessage) }) </script>\nFinally, replace your project url in place of [YOUR_CHATBOT_URL_HERE].\nLast updated 3 months ago","markdown":"# Landing Page Chatbot | StackAI\n\nThe **Landing Page Chatbot** is a great export option if you'd like your users to be able to optionally interact with a chatbot while on your website. The chatbot will be available as an icon that opens a window.\n\nPublish your project first, then embed your chat assistant in your website by clicking the **Embed** button on the top right of the page. Paste the HTML or React code into the UI of your website. Each time you make changes to your project, remember to **Publish** them first so that the changes populate to the user side.\n\n### \n\nConfiguration\n\nYou can customize some of the options for this interface:\n\n*   User feedback: allow the user to give thumbs up or thumbs down feedback on chat responses, you will be able to see this feedback in the Manager View\n    \n*   Related results: shows the user suggestions for follow-up inputs to the chat assistant\n    \n*   Show steps: shows the user what parts of your project are processing\n    \n*   Show attachment icon: allows the user to attach files by clicking the attachment icon on the bottom left of the chat box\n    \n*   Show audio icon: allows the user to do voice-to-text instead of typing\n    \n*   Default loading message: shows a message while the chat assistant is thinking\n    \n*   Welcome Message: shows the user a welcome message before they've queries the chat assistant\n    \n*   Enable clear chat: allows the user to clear the chat\n    \n*   Conversation Starters: shows the user example queries before the user has begun interacting\n    \n*   Icon Message: shows a message above the icon of that chat assistant\n    \n\n### \n\nIf your chatbot is blocking your background:\n\nIf your Stack AI chatbot is blocking elements behind it after embedding it, you need to replace the script with standard HTML.\n\n### \n\nPrerequisites\n\n*   Have a project ready, or create a new project.\n    \n*   Have your project chatbot published.\n    \n\n### \n\nStep-by-step Guide:\n\n1.  **Get chatbot URL**\n    \n\nTo begin the process, you must go to the export section.\n\n```\n- Navigate to Export.\n- Select Website Chatbot.\n- Get the `data-project-url` from the \"Embed in Website\" section.\n```\n\nThe chatbot url will have the form `https://www.stack-ai.com/embed/[org_id]/[public_key]/[flow_id]`.\n\n1.  **Modify Script**\n    \n\nIn your HTML website, replace the chatbot script for the following HTML code:\n\n```\n<!-- Iframe code -->\n<iframe\n  id=\"iframeId\"\n  src=\"[YOUR_CHATBOT_URL_HERE]\"\n  width=\"350\"\n  height=\"600\"\n  frameborder=\"0\"\n  style=\"position: fixed; z-index: 1; bottom: 15px; right: 15px; max-width: calc(100vw - 15px); max-height: calc(100vh - 15px);\"\n></iframe>\n\n<!-- Script for handling the resizing -->\n<script>\n  function handleMessage(event) {\n    if (event.data.type === 'chatbotStateChange') {\n      const iframe = document.getElementById('iframeId')\n      if (iframe) {\n        if (event.data.isClosed) {\n          iframe.style.width = '60px'\n          iframe.style.height = '60px'\n        } else {\n          iframe.style.width = '350px'\n          iframe.style.height = '600px'\n        }\n      }\n    }\n  }\n\n  // Attach event listener\n  window.addEventListener('message', handleMessage)\n\n  // If you want to clean up the event listener when the page unloads (optional)\n  window.addEventListener('beforeunload', function () {\n    window.removeEventListener('message', handleMessage)\n  })\n</script>\n```\n\nFinally, replace your project url in place of `[YOUR_CHATBOT_URL_HERE]`.\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/export-options/batch-run","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/export-options/batch-run","loadedTime":"2025-10-17T18:30:56.943Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/export-options/batch-run","title":"Batch Run | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Batch Run | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1851","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901deb8bead703c-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:56 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::tl49j-1760725856156-3f19681eb34e"}},"screenshotUrl":null,"text":"Batch Run | StackAI\nWhat is the Batch Run Interface?\nThe Batch Run Interface is an interface where you can run multiple executions in one go. This interface is particularly useful when you have a list of inputs you want to run your flow on, and you do not want to run them one at a time. This interface is similar to the Chat Assistant, but instead of one input, you can run many all at once using a CSV file.\nWith the Batch Run Interface, you will be able to:\nUpload a CSV with all the inputs for the executions you want to run\nRun all the executions in the CSV\nExport the results as a CSV file\nRun individual executions if required (go to the input you want and click Run there)\nHere are a few quick facts:\nThe inputs can be text fields of any length.\nMultiple inputs can be run at once if appearing in the flow (in-0, in-1, etc.).\nMultiple outputs can be generated as well for each execution (out-0, out-1, etc.).\nInputs can only be text for now.\nMultiple runs are executed in parallel, optimizing the overall latency.\nUploading a CSV\nOn the to left side of the \"Batch run\" page you will find the button to upload a CSV file with the inputs for the executions you want to run. You can also add inputs manually by clicking on \"Add Run\".\nIMPORTANT: include a header in your CSV with the name of the inputs so that the system can recognize them.\nClick on the \"Run Batch\" button to run all the executions in the CSV.\nOnce the executions are done, you can also download the results as a CSV file.\nBulk Upload\nIf you have a Files Node connected as input, you can expose it as an input to bulk upload a set of files, and do multiple simultaneous runs on you file inputs. To do this:\nMake sure a Files Node is connected as an input.\nIn the Batch Export interface, expose the input on the right side.\nYou will now see the 'Bulk Upload' option available.\nUpload a set of files. \nLast updated 2 months ago","markdown":"# Batch Run | StackAI\n\n### \n\nWhat is the Batch Run Interface?\n\nThe **Batch Run** Interface is an interface where you can run multiple executions in one go. This interface is particularly useful when you have a list of inputs you want to run your flow on, and you do not want to run them one at a time. This interface is similar to the Chat Assistant, but instead of one input, you can run many all at once using a CSV file.\n\nWith the Batch Run Interface, you will be able to:\n\n*   Upload a CSV with all the inputs for the executions you want to run\n    \n*   Run all the executions in the CSV\n    \n*   Export the results as a CSV file\n    \n*   Run individual executions if required (go to the input you want and click Run there)\n    \n\nHere are a few quick facts:\n\n*   The inputs can be text fields of any length.\n    \n*   Multiple inputs can be run at once if appearing in the flow (in-0, in-1, etc.).\n    \n*   Multiple outputs can be generated as well for each execution (out-0, out-1, etc.).\n    \n*   Inputs can only be text for now.\n    \n*   Multiple runs are executed in parallel, optimizing the overall latency.\n    \n\n### \n\nUploading a CSV\n\nOn the to left side of the **\"Batch run\"** page you will find the button to upload a CSV file with the inputs for the executions you want to run. You can also add inputs manually by clicking on \"Add Run\".\n\nIMPORTANT: include a header in your CSV with the name of the inputs so that the system can recognize them.\n\nClick on the \"Run Batch\" button to run all the executions in the CSV.\n\nOnce the executions are done, you can also download the results as a CSV file.\n\n### \n\nBulk Upload\n\nIf you have a Files Node connected as input, you can expose it as an input to bulk upload a set of files, and do multiple simultaneous runs on you file inputs. To do this:\n\n1.  Make sure a Files Node is connected as an input.\n    \n2.  In the Batch Export interface, expose the input on the right side.\n    \n3.  You will now see the 'Bulk Upload' option available.\n    \n4.  Upload a set of files.\n    \n\nLast updated 2 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/export-options/microsoft-teams","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/export-options/microsoft-teams","loadedTime":"2025-10-17T18:30:57.116Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/export-options/microsoft-teams","title":"Microsoft Teams | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Microsoft Teams | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1851","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901debbca5c81be-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:30:56 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::hbbz2-1760725856653-fd815def3fd1"}},"screenshotUrl":null,"text":"Microsoft Teams | StackAI\nConfigure your Microsoft Teams application to use your workflow within your workspace.\n1. Navigate to Azure Portal\nNavigate to Azure Portal to create your application.\nGo to Azure Portal\n2. New Registration\nSelect App registrations and Click on \"New Registration\" to create a new app.\n3. Register Application\nEnter the name of your app and select \"Accounts in any organizational directory\" and click on \"Register\".\n4. Application ID\nYour app is registered in Microsoft Entra ID. The app overview page appears.\nCopy the Application (client) ID from Microsoft Entra ID, and paste it in your configuration.\n5. Add Web Authentication\nIn the left pane, under Manage, select Authentication. Under Web, select Add URI.\nEnter https://token.botframework.com/.auth/web/redirect and Select Save.\n6. Configure Redirect URI\nEnter the redirect URI and enable Access tokens and ID tokens.\nThe redirect URI should be: {BASE_INFERENCE_URL}/auth-end\n7. Create a client secret\nIn the left pane, under Manage, select Certificates & secrets.\nUnder Client secrets, select + New client secret.\nThe Add a client secret window appears, enter the description and select Add.\nSelect Copy to clipboard to save the client secret value for further use.\n8. Add API permissions\nIn the left pane, select API permissions.\nSelect \"+ Add a permission\", then select Microsoft Graph.\nUnder \"What type of permissions does your application need?\", select Application permissions.\nUnder \"Select permissions\", expand User and select User.Read.All.\nClick \"Add permissions\" to save the changes.\n9. Add Application ID URI\nIn the left pane, under Manage, select Expose an API.\nUpdate the Application ID URI to api://api.stack-ai.com/<APP_ID> and select Save.\n10. Add a scope\nIn the left pane, under Manage, select Expose an API.\nSelect + Add a scope.\nEnter access_as_user as the Scope name.\nUnder Who can consent?, select Admins and users.\nUpdate the values for the rest of the fields as follows:\nEnter \"Teams can access the user's profile\" as Admin consent display name.\nEnter \"Allows Teams to call the app's web APIs as the current user\" as Admin consent description.\nEnter \"Teams can access the user profile and make requests on the user's behalf\" as User consent display name.\nEnter \"Enable Teams to call this app's APIs with the same rights as the user\" as User consent description.\nEnsure that State is set to Enabled.\nSelect Add scope.\n11. Add client application\nIn the left pane, under Manage, select Expose an API.\nUnder Authorized client applications, select + Add a client application.\nAdd Teams mobile or desktop and Teams web application:\nFor Teams mobile or desktop: Enter Client ID as 1fec8e78-bce4-4aaf-ab1b-5451cc387264\nFor Teams web: Enter Client ID as 5e3ce6c0-2b1f-4285-8d4b-75ee78787346\nSelect the Authorized scopes checkbox.\nSelect Add application.\n12. Create Azure Bot Resource\nGo to Home and select + Create a resource\nIn the search box, enter \"Azure Bot\" and select Enter\nSelect Azure Bot, then select Create\nFor the bot configuration:\nEnter a name for your bot in Bot handle\nSelect your Subscription from the dropdown\nSelect or create a Resource group\nUnder Pricing, select \"FO Free\" plan\nFor Microsoft App ID, select Type of App as \"Multi Tenant\"\nIn Creation type, select \"Use existing app registration\"\nEnter the App ID from your previous registration\n13. Add a Teams channel\nIn the left pane, select Channels.\nUnder Available Channels, select Microsoft Teams.\nSelect the checkbox to accept the Terms of Service and Apply.\n14. Add Messaging Endpoint\nIn the left pane, under Settings, select Configuration.\nReplace <YOUR_PROJECT_ID> with the workflow id in your URL.\nClick Apply to save the configuration.\n15. Save StackAI Interface\nGo back to StackAI's website and save the StackAI interface in the top right corner.\n16. Upload App to Teams\nNow, go to Microsoft Teams. On the left sidebar, click Apps. \nNow, go to 'Manage Your Apps'.\nClick, 'Upload an App.' Then, choose an option.\nHere, you will be prompted to upload your app's manifest. The manifest file should contain a JSON file, and two .PNG files, named color.png and outline.png. These two images will serve as the icons of your app. The JSON file must be named manifest.json. Feel free to use the following template, replace \"botId\" with the Microsoft App ID from step 4. \"id\" can be a randomly generated UUID, but must be unique to each bot you upload to Microsoft Teams.\n{ \"$schema\": \"https://developer.microsoft.com/json-schemas/teams/v1.19/MicrosoftTeams.schema.json\", \"manifestVersion\": \"1.19\", \"version\": \"1.0.0\", \"id\": \"25790e2c-b357-4a78-85ab-e6dfd826341b\", \"developer\": { \"name\": \"Stack AI\", \"websiteUrl\": \"https://www.stack-ai.com\", \"privacyUrl\": \"https://www.stack-ai.com/privacy\", \"termsOfUseUrl\": \"https://www.stack-ai.com/terms\" }, \"name\": { \"short\": \"Bot Name\", \"full\": \"Bot Name\" }, \"description\": { \"short\": \"Chatbot\", \"full\": \"Chatbot for Microsoft Teams\" }, \"icons\": { \"outline\": \"outline.png\", \"color\": \"color.png\" }, \"accentColor\": \"#ffffff\", \"bots\": [ { \"botId\": \"25790e2c-b357-4a78-85ab-e6dfd826341b\", \"needsChannelSelector\": false, \"isNotificationOnly\": false, \"scopes\": [ \"team\" ] } ], \"permissions\": [], \"validDomains\": [ \"api.stack-ai.com\" ] }\n17. Add App to a Channel\nOpen a channel where you'd like to use your chatbot. Click on apps.\nSelect your app and add it to the channel. Now you can reference your bot as if it's a member of your channel by typing @ and the name of your bot. \nDon't forget the publish if you make changes to your agent's workflow so that your bot is updated!\nLast updated 3 months ago","markdown":"# Microsoft Teams | StackAI\n\nConfigure your Microsoft Teams application to use your workflow within your workspace.\n\n## \n\n1\\. Navigate to Azure Portal\n\nNavigate to Azure Portal to create your application.\n\n[Go to Azure Portal](https://portal.azure.com/#home)\n\n## \n\n2\\. New Registration\n\nSelect App registrations and Click on \"New Registration\" to create a new app.\n\n## \n\n3\\. Register Application\n\nEnter the name of your app and select \"Accounts in any organizational directory\" and click on \"Register\".\n\n## \n\n4\\. Application ID\n\nYour app is registered in Microsoft Entra ID. The app overview page appears.\n\nCopy the Application (client) ID from Microsoft Entra ID, and paste it in your configuration.\n\n## \n\n5\\. Add Web Authentication\n\nIn the left pane, under Manage, select Authentication. Under Web, select Add URI.\n\nEnter https://token.botframework.com/.auth/web/redirect and Select Save.\n\n## \n\n6\\. Configure Redirect URI\n\nEnter the redirect URI and enable Access tokens and ID tokens.\n\nThe redirect URI should be: `{BASE_INFERENCE_URL}/auth-end`\n\n## \n\n7\\. Create a client secret\n\n1.  In the left pane, under Manage, select Certificates & secrets.\n    \n2.  Under Client secrets, select + New client secret.\n    \n3.  The Add a client secret window appears, enter the description and select Add.\n    \n\nSelect Copy to clipboard to save the client secret value for further use.\n\n## \n\n8\\. Add API permissions\n\n1.  In the left pane, select API permissions.\n    \n2.  Select \"+ Add a permission\", then select Microsoft Graph.\n    \n3.  Under \"What type of permissions does your application need?\", select Application permissions.\n    \n4.  Under \"Select permissions\", expand User and select [User.Read](http://user.read/).All.\n    \n5.  Click \"Add permissions\" to save the changes.\n    \n\n## \n\n9\\. Add Application ID URI\n\n1.  In the left pane, under Manage, select Expose an API.\n    \n2.  Update the Application ID URI to `api://api.stack-ai.com/<APP_ID>` and select Save.\n    \n\n## \n\n10\\. Add a scope\n\n1.  In the left pane, under Manage, select Expose an API.\n    \n2.  Select + Add a scope.\n    \n3.  Enter access\\_as\\_user as the Scope name.\n    \n4.  Under Who can consent?, select Admins and users.\n    \n\nUpdate the values for the rest of the fields as follows:\n\n*   Enter \"Teams can access the user's profile\" as Admin consent display name.\n    \n*   Enter \"Allows Teams to call the app's web APIs as the current user\" as Admin consent description.\n    \n*   Enter \"Teams can access the user profile and make requests on the user's behalf\" as User consent display name.\n    \n*   Enter \"Enable Teams to call this app's APIs with the same rights as the user\" as User consent description.\n    \n*   Ensure that State is set to Enabled.\n    \n*   Select Add scope.\n    \n\n## \n\n11\\. Add client application\n\n1.  In the left pane, under Manage, select Expose an API.\n    \n2.  Under Authorized client applications, select + Add a client application.\n    \n3.  Add Teams mobile or desktop and Teams web application:\n    \n    *   For Teams mobile or desktop: Enter Client ID as `1fec8e78-bce4-4aaf-ab1b-5451cc387264`\n        \n    *   For Teams web: Enter Client ID as `5e3ce6c0-2b1f-4285-8d4b-75ee78787346`\n        \n    \n4.  Select the Authorized scopes checkbox.\n    \n5.  Select Add application.\n    \n\n## \n\n12\\. Create Azure Bot Resource\n\n1.  Go to Home and select + Create a resource\n    \n2.  In the search box, enter \"Azure Bot\" and select Enter\n    \n3.  Select Azure Bot, then select Create\n    \n\nFor the bot configuration:\n\n*   Enter a name for your bot in Bot handle\n    \n*   Select your Subscription from the dropdown\n    \n*   Select or create a Resource group\n    \n*   Under Pricing, select \"FO Free\" plan\n    \n*   For Microsoft App ID, select Type of App as \"Multi Tenant\"\n    \n*   In Creation type, select \"Use existing app registration\"\n    \n*   Enter the App ID from your previous registration\n    \n\n## \n\n13\\. Add a Teams channel\n\n1.  In the left pane, select Channels.\n    \n2.  Under Available Channels, select Microsoft Teams.\n    \n3.  Select the checkbox to accept the Terms of Service and Apply.\n    \n\n## \n\n14\\. Add Messaging Endpoint\n\n1.  In the left pane, under Settings, select Configuration.\n    \n\n3.  Replace `<YOUR_PROJECT_ID>` with the workflow id in your URL.\n    \n\nClick **Apply** to save the configuration.\n\n## \n\n15\\. Save StackAI Interface\n\nGo back to StackAI's website and save the StackAI interface in the top right corner.\n\n## \n\n16\\. Upload App to Teams\n\nNow, go to Microsoft Teams. On the left sidebar, click Apps.\n\nNow, go to 'Manage Your Apps'.\n\nClick, 'Upload an App.' Then, choose an option.\n\nHere, you will be prompted to upload your app's manifest. The manifest file should contain a JSON file, and two .PNG files, named color.png and outline.png. These two images will serve as the icons of your app. The JSON file must be named manifest.json. Feel free to use the following template, replace `\"botId\"` with the Microsoft App ID from step 4. `\"id\"` can be a randomly generated UUID, but must be unique to each bot you upload to Microsoft Teams.\n\n```\n{\n  \"$schema\": \"https://developer.microsoft.com/json-schemas/teams/v1.19/MicrosoftTeams.schema.json\",\n  \"manifestVersion\": \"1.19\",\n  \"version\": \"1.0.0\",\n  \"id\": \"25790e2c-b357-4a78-85ab-e6dfd826341b\",\n  \"developer\": {\n    \"name\": \"Stack AI\",\n    \"websiteUrl\": \"https://www.stack-ai.com\",\n    \"privacyUrl\": \"https://www.stack-ai.com/privacy\",\n    \"termsOfUseUrl\": \"https://www.stack-ai.com/terms\"\n  },\n  \"name\": {\n    \"short\": \"Bot Name\",\n    \"full\": \"Bot Name\"\n  },\n  \"description\": {\n    \"short\": \"Chatbot\",\n    \"full\": \"Chatbot for Microsoft Teams\"\n  },\n  \"icons\": {\n    \"outline\": \"outline.png\",\n    \"color\": \"color.png\"\n  },\n  \"accentColor\": \"#ffffff\",\n  \"bots\": [\n    {\n      \"botId\": \"25790e2c-b357-4a78-85ab-e6dfd826341b\", \n      \"needsChannelSelector\": false,\n      \"isNotificationOnly\": false,\n      \"scopes\": [\n        \"team\"        \n      ]\n    }\n  ],  \n  \"permissions\": [],\n  \"validDomains\": [\n    \"api.stack-ai.com\"\n  ]\n}\n```\n\n## \n\n17\\. Add App to a Channel\n\nOpen a channel where you'd like to use your chatbot. Click on apps.\n\nSelect your app and add it to the channel. Now you can reference your bot as if it's a member of your channel by typing @ and the name of your bot.\n\nDon't forget the publish if you make changes to your agent's workflow so that your bot is updated!\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/export-options/security","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/export-options/security","loadedTime":"2025-10-17T18:31:00.460Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/export-options/security","title":"Security | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Security | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1854","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901ded25a8cd6b8-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:31:00 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::sgmnj-1760725860252-c7e30a37b36f"}},"screenshotUrl":null,"text":"Security | StackAI\nAll interfaces in StackAI give you the option to customize security protections.\nEnable Password Protection\nEnabling passwords allows you to set a password that users must enter in order to chat with the agent. This is a great option if your agent has access to restricted material or you only want to share the agent with your team.\nEnable SSO Protection\nEnabling SSO Protection allows selecting users and groups that will have access to your agent.\nAllowed Source URLs\nEnabling this allows specifying which source URLs the users can access your agent from.\nLast updated 3 months ago","markdown":"# Security | StackAI\n\nAll interfaces in StackAI give you the option to customize security protections.\n\n### \n\nEnable Password Protection\n\nEnabling passwords allows you to set a password that users must enter in order to chat with the agent. This is a great option if your agent has access to restricted material or you only want to share the agent with your team.\n\n### \n\nEnable SSO Protection\n\nEnabling SSO Protection allows selecting users and groups that will have access to your agent.\n\n### \n\nAllowed Source URLs\n\nEnabling this allows specifying which source URLs the users can access your agent from.\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/export-options/api","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/export-options/api","loadedTime":"2025-10-17T18:31:00.424Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/export-options/api","title":"API | StackAI","description":"Integrate your interface as an API.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"API | StackAI"},{"property":"og:description","content":"Integrate your interface as an API."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1856","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901ded24f96cede-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:31:00 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::9gpxz-1760725860259-75cd3dd39e3a"}},"screenshotUrl":null,"text":"API | StackAI\nIntegrate your interface as an API.\nOnce your flow is ready for production, you can deploy it as an API. Just click on deploy to get a production-ready version of your model.\nGet your RestAPI\nTo obtain your API just go to the Export View and select API.\nIn this section, you will receive a code snippet to call your flow via a POST request in Python, JavaScript, and cURL.\nimport requests API_URL = f\"https://stack-inference.com/inference/v0/run/<YOUR_ORG_ID>/<YOUR_FLOW_ID>\" headers = {'Authorization': 'Bearer YOUR_PUBLIC_KEY', 'Content-Type': 'application/json' } def query(payload): response = requests.post(API_URL, headers=headers, json=payload) return response.json() # you can add all your inputs here: body = {'in-0': 'text for in-0', 'audio2text-0': 'base64 of audio to send', 'string-0': 'long string to send', 'url-0': 'url of website to load'} output = query(body)\nSome quick facts:\nThis request receives all the inputs to the LLM as the body.\nThis request returns the value of all the outputs to the LLM as a JSON.\nThe API supports auto-scaling for a large volume of requests.\nStack protects this API with the Token of your organization\nLast updated 2 months ago","markdown":"# API | StackAI\n\nIntegrate your interface as an API.\n\nOnce your flow is ready for production, you can deploy it as an API. Just click on deploy to get a production-ready version of your model.\n\n## \n\nGet your RestAPI\n\nTo obtain your API just go to the Export View and select API.\n\nIn this section, you will receive a code snippet to call your flow via a POST request in **Python**, **JavaScript**, and **cURL**.\n\n```\nimport requests\n\nAPI_URL = f\"https://stack-inference.com/inference/v0/run/<YOUR_ORG_ID>/<YOUR_FLOW_ID>\"\nheaders = {'Authorization':\n 'Bearer YOUR_PUBLIC_KEY',\n 'Content-Type': 'application/json'\n}\n\ndef query(payload):\n response = requests.post(API_URL, headers=headers, json=payload)\n return response.json()\n\n# you can add all your inputs here:\nbody = {'in-0': 'text for in-0', 'audio2text-0': 'base64 of audio to send',\n'string-0': 'long string to send', 'url-0': 'url of website to load'}\n\noutput = query(body)\n```\n\nSome quick facts:\n\n*   This request receives all the inputs to the LLM as the body.\n    \n*   This request returns the value of all the outputs to the LLM as a JSON.\n    \n*   The API supports auto-scaling for a large volume of requests.\n    \n*   Stack protects this API with the Token of your organization\n    \n\nLast updated 2 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/other-views/analytics","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/other-views/analytics","loadedTime":"2025-10-17T18:31:00.499Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/other-views/analytics","title":"Analytics | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Analytics | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1854","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901ded26f0d3ec9-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:31:00 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::8gh5k-1760725860287-7f4ee12e9fda"}},"screenshotUrl":null,"text":"Analytics | StackAI\nThe Analytics View gives you a birds-eye view of you project's runs. In the top left corner, set a time range. The page will show you how many runs happened in that time, how many users there have been, errors that have happened, and how many tokens were used. \nThis is a great place to monitor usage, see what people are doing with your project, and ensure everything is working as intended. \nHere, you can also disable logs for your project. This has been proven useful for highly sensitive workflows (e.g., defense). Only admin role users have access to this feature.\nLast updated 2 months ago","markdown":"# Analytics | StackAI\n\nThe Analytics View gives you a birds-eye view of you project's runs. In the top left corner, set a time range. The page will show you how many runs happened in that time, how many users there have been, errors that have happened, and how many tokens were used.\n\nThis is a great place to monitor usage, see what people are doing with your project, and ensure everything is working as intended.\n\nHere, you can also disable logs for your project. This has been proven useful for highly sensitive workflows (e.g., defense). Only admin role users have access to this feature.\n\nLast updated 2 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/export-options/whatsapp-sms-with-twilio","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/export-options/whatsapp-sms-with-twilio","loadedTime":"2025-10-17T18:31:00.547Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/export-options/whatsapp-sms-with-twilio","title":"WhatsApp / SMS with Twilio | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"WhatsApp / SMS with Twilio | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1855","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901ded24c122082-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:31:00 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::nl99m-1760725860286-bc10d1c2f25a"}},"screenshotUrl":null,"text":"WhatsApp / SMS with Twilio\nWe provide a webhook to receive and send messages with Twilio to serve your chatbot over WhatsApp and/or SMS.\nWe are planning to add more functionality and are looking for feature requests. If you'd like to have a feature which we don't support yet, or want to provide some feedback, feel free to reach out to us directly to [[email protected]](mailto:[email protected])\nWhatsApp with Twilio\nUsing Twilio to set up a WhatsApp number involves a few steps. Here's a general outline to get started:\n1. Sign Up for Twilio and Enable WhatsApp Sandbox:\nSign up for a Twilio account if you haven't already.\nNavigate to the WhatsApp section in the Twilio Console.\nHere you'll find the WhatsApp Sandbox.\nWhile you're testing, you can use the sandbox environment provided by Twilio to send and receive messages without connecting to an official business profile. We'll show later how to connect to an official business profile.\n2. Test with Twilio Sandbox:\nYou'll see a sandbox number and a code.\nTo activate your personal number for testing, send the given code to the sandbox number from your personal WhatsApp.\nOnce activated, any messages sent to the sandbox number will be relayed to your Twilio account.\n3. Set Up Webhook to connect Twilio with Stack AI:\nTo make your number interactive (i.e., send and receive messages), let's set up a webhook that will connect Twilio to Stack AI.\nOnce you have built your Stack AI flow, click on 'Publish' at the top-right of the flow builder (next to the 'Run' button).\nOnce published, click on 'Export' at the top-right of the flow builder.\nYou will be prompted with the Export wizard.\nIn the Export tab, follow these steps:\nOn the top-left dropdown, select 'WhatsApp/SMS'.\n1.1. Select Input and Output node Make sure you select at least one input and one output. These will be used to receive (input) and send (output) messages to WhatsApp.\n1.2 Account SID. You can find your Account SID in Twilio's console. Please, select the LIVE credentials rather than the test ones.\n1.3 Auth Token. You can find your Auth Token in Twilio's console. Please, select the LIVE credentials rather than the test ones.\n1.2. Webhook URL. Finally, copy/paste Stack AI's webhook URL into Twilio's Sandbox Settings. If the webhook URL (starting with ) contains a placeholder <YOUR_API_KEY>, you need to click on 'Show Token' to display your API key. - Copy the webhook URL displayed. Make sure your API key is filled in.\nGo back to Twilio's \"Sandbox settings\" tab, and find the Sandbox Configuration section.\nPaste the webhook URL in the When a message comes in field, inside the Sandbox Configuration section.\nMake sure the Method is set to POST\nThe Status callback URL can be left blank.\nDevelop and Test your Application\nWhenever a user sends a message to your Twilio WhatsApp number, Twilio will make a request to your webhook URL. Your Stack AI flow can then decide how to respond, using Twilio to send a reply back to the user.\nSend a message to WhatsApp and confirm that you are receiving an answer from Stack AI.\nIf this doesn't work, repeat the previous steps or contact us at [email protected]\nMove to Production\nOnce you're done with sandbox testing, you can apply to have your business profile approved by WhatsApp.\nAfter you get approval, you'll connect your business profile with Twilio, and you can start sending messages to all users without them having to join the sandbox.\nAlways follow WhatsApp's policies and guidelines when sending and receiving messages. Avoid spammy behaviors as WhatsApp is strict, and misuse can lead to the banning of your business profile.\nAlways refer to the official Twilio and WhatsApp documentation for the most accurate and up-to-date information.\nFAQ\nMy StackAI WhatsApp bot stopped working after 24h.\nIf you are using Twilio's Sandbox, you will need to send a message, something along the lines of join solid-water send to activate for 24 more hours. Make sure you redo the Sandbox initialization that you can find on Twilio's website. Once your prototype is working, and you want to move it to production, check out the Move to Production Guide.\nLast updated 3 months ago","markdown":"# WhatsApp / SMS with Twilio\n\nWe provide a webhook to receive and send messages with Twilio to serve your chatbot over WhatsApp and/or SMS.\n\nWe are planning to add more functionality and are looking for feature requests. If you'd like to have a feature which we don't support yet, or want to provide some feedback, feel free to reach out to us directly to \\[[\\[email protected\\]](https://docs.stack-ai.com/cdn-cgi/l/email-protection)\\](mailto:[\\[email protected\\]](https://docs.stack-ai.com/cdn-cgi/l/email-protection))\n\n### \n\nWhatsApp with Twilio\n\nUsing Twilio to set up a WhatsApp number involves a few steps. Here's a general outline to get started:\n\n#### \n\n1\\. Sign Up for Twilio and Enable WhatsApp Sandbox:\n\n*   Sign up for a Twilio account if you haven't already.\n    \n*   Navigate to the WhatsApp section in the Twilio Console.\n    \n*   Here you'll find the WhatsApp Sandbox.\n    \n*   While you're testing, you can use the sandbox environment provided by Twilio to send and receive messages without connecting to an official business profile. We'll show later how to connect to an official business profile.\n    \n\n#### \n\n2\\. Test with Twilio Sandbox:\n\n*   You'll see a sandbox number and a code.\n    \n*   To activate your personal number for testing, send the given code to the sandbox number from your personal WhatsApp.\n    \n*   Once activated, any messages sent to the sandbox number will be relayed to your Twilio account.\n    \n\n#### \n\n3\\. Set Up Webhook to connect Twilio with Stack AI:\n\nTo make your number interactive (i.e., send and receive messages), let's set up a webhook that will connect Twilio to Stack AI.\n\n1.  Once you have built your Stack AI flow, **click on 'Publish'** at the top-right of the flow builder (next to the 'Run' button).\n    \n2.  Once published, **click on 'Export'** at the top-right of the flow builder.\n    \n3.  You will be prompted with the Export wizard.\n    \n\nIn the Export tab, follow these steps:\n\n1.  On the top-left dropdown, **select 'WhatsApp/SMS'.**\n    \n    1.1. **Select Input and Output node** Make sure you select at least one input and one output. These will be used to receive (input) and send (output) messages to WhatsApp.\n    \n    1.2 **Account SID**. You can find your Account SID in [Twilio's console](https://console.twilio.com/us1/account/keys-credentials/api-keys). Please, select the **LIVE** credentials rather than the test ones.\n    \n    1.3 **Auth Token**. You can find your Auth Token in [Twilio's console](https://console.twilio.com/us1/account/keys-credentials/api-keys). Please, select the **LIVE** credentials rather than the test ones.\n    \n    1.2. **Webhook URL.** Finally, copy/paste Stack AI's webhook URL into Twilio's Sandbox Settings. If the webhook URL (starting with ) contains a placeholder `<YOUR_API_KEY>`, you need to click on 'Show Token' to display your API key. - Copy the webhook URL displayed. Make sure your API key is filled in.\n    \n    1.  Go back to Twilio's \"Sandbox settings\" tab, and find the Sandbox Configuration section.\n        \n    2.  **Paste the webhook URL** in the `When a message comes in` field, inside the Sandbox Configuration section.\n        \n    3.  Make sure the Method is set to `POST`\n        \n    4.  The Status callback URL can be left `blank`.\n        \n    \n\n### \n\nDevelop and Test your Application\n\n*   Whenever a user sends a message to your Twilio WhatsApp number, Twilio will make a request to your webhook URL. Your Stack AI flow can then decide how to respond, using Twilio to send a reply back to the user.\n    \n*   Send a message to WhatsApp and confirm that you are receiving an answer from Stack AI.\n    \n*   If this doesn't work, repeat the previous steps or contact us at [_\\[email protected\\]_](https://docs.stack-ai.com/cdn-cgi/l/email-protection#ccbfb9bcbca3beb88cbfb8adafa7e1ada5e2afa3a1)\n    \n\n### \n\nMove to Production\n\n*   Once you're done with sandbox testing, you can apply to have your business profile approved by WhatsApp.\n    \n\n*   After you get approval, you'll connect your business profile with Twilio, and you can start sending messages to all users without them having to join the sandbox.\n    \n\nAlways follow WhatsApp's policies and guidelines when sending and receiving messages. Avoid spammy behaviors as WhatsApp is strict, and misuse can lead to the banning of your business profile.\n\nAlways refer to the official Twilio and WhatsApp documentation for the most accurate and up-to-date information.\n\n### \n\nFAQ\n\n**My StackAI WhatsApp bot stopped working after 24h.**\n\n*   If you are using Twilio's Sandbox, you will need to send a message, something along the lines of `join solid-water` send to activate for 24 more hours. Make sure you redo the Sandbox initialization that you can find on [Twilio's website](https://console.twilio.com/us1/develop/sms/try-it-out/whatsapp-learn?frameUrl=%2Fconsole%2Fsms%2Fwhatsapp%2Flearn%3Fx-target-region%3Dus1). Once your prototype is working, and you want to move it to production, check out the Move to Production Guide.\n    \n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/export-options/sharing-projects-and-backup","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/export-options/sharing-projects-and-backup","loadedTime":"2025-10-17T18:31:00.732Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/export-options/sharing-projects-and-backup","title":"Sharing Projects and Backup | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Sharing Projects and Backup | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1854","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901ded24ed0177d-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:31:00 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::vkrv8-1760725860258-5164d1329d71"}},"screenshotUrl":null,"text":"Sharing Projects and Backup | StackAI\nThank you for your continued interest in the StackAI platform. Below is a quick, 4-step guide on how to move your projects from an existing university account into your personal account.\n1. Create a personal StackAI account\nYou can create a personal StackAI account at https://www.stack-ai.com/auth/signup\n2. Export your existing projects\nNavigate to the folders where your projects are stored in. You can search for your folders by your name or email address.\nSelect Export Project from projects you would like to keep from the grid view.\n3. Import projects into your new personal account\nNavigate to your new personal account and import projects.\n4. Check for connections and files\nIf any collaborators at the university will still need access to your projects, ask them to duplicate the project as a template and share with others. Make sure to share the instructions in this email with others.\nIf your folder is private, you may need to share the folder with collaborators first.\nThe collaborators will be able to duplicate your projects by navigating to your folder.\nNote: For projects duplicated by others in the university or transferred to your personal account, any connected services (e.g. Google Drive, OneDrive, SharePoint, etc) that are tied to your university credentials will stop working once your university access is removed.\nTo keep these connections, transfer the documents into your personal storage (cloud or local) and re-establish these connections on your personal account.\nSimilarly, the collaborators at the university can transfer the documents into their personal storage and re-establish these connections.\nIf you have Files in the workflow, they will not transfer to the imported project. Click on the Files node and re-upload documents.\nLast updated 2 months ago","markdown":"# Sharing Projects and Backup | StackAI\n\nThank you for your continued interest in the StackAI platform. Below is a quick, 4-step guide on how to move your projects from an existing university account into your personal account.\n\n#### \n\n**1.** **Create a personal StackAI account**\n\nYou can create a personal StackAI account at [https://www.stack-ai.com/auth/signup](https://www.stack-ai.com/auth/signup)\n\n#### \n\n**2\\. Export your existing projects**\n\nNavigate to the folders where your projects are stored in. You can search for your folders by your name or email address.\n\nSelect **Export Project** from projects you would like to keep from the grid view.\n\n**3\\. Import projects into your new personal account**\n\nNavigate to your new personal account and import projects.\n\n#### \n\n**4\\. Check for connections and files**\n\nIf any collaborators at the university will still need access to your projects, ask them to duplicate the project as a template and share with others. Make sure to share the instructions in this email with others.\n\nIf your folder is private, you may need to share the folder with collaborators first.\n\nThe collaborators will be able to duplicate your projects by navigating to your folder.\n\n**Note**: For projects duplicated by others in the university or transferred to your personal account, **any connected services** (e.g. Google Drive, OneDrive, SharePoint, etc) that are tied to your university credentials will stop working once your university access is removed.\n\nTo keep these connections, transfer the documents into your personal storage (cloud or local) and re-establish these connections on your personal account.\n\nSimilarly, the collaborators at the university can transfer the documents into their personal storage and re-establish these connections.\n\nIf you have **Files** in the workflow, they will not transfer to the imported project. Click on the Files node and re-upload documents.\n\nLast updated 2 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/other-views/evaluator","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/other-views/evaluator","loadedTime":"2025-10-17T18:31:00.769Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/other-views/evaluator","title":"Evaluator | StackAI","description":"Evaluate your agent's performance with a LLM-as-a-judge","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Evaluator | StackAI"},{"property":"og:description","content":"Evaluate your agent's performance with a LLM-as-a-judge"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1853","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901ded24dc11fee-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:31:00 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::s4dp2-1760725860252-4efacbebce04"}},"screenshotUrl":null,"text":"Evaluator | StackAI\nEvaluate your agent's performance with a LLM-as-a-judge\nThe Evaluator View is similar to the batch interface, in that it allows running a CSV file of inputs on your agent, all at once. This view allows testing before a project goes live, and leverages a LLM to evaluate your agent's output.\nThere are two types of evaluation:\n1. Grading outputs based on criteria \nOn the right hand side, create an evaluator:\nSelect the output to evaluate\nAdd a system prompt - the evaluation logic\nGive it a name\nOnce the evaluator is created, a new column will appear in the table showing the evaluation results for each row.\nAdd as many evaluators as outputs in your workflow. Each one will evaluate a different output. Give each evaluator's model a system prompt and select which of your agent's outputs should be evaluated.\nYou can manually add rows to evaluate, or upload a CSV with all your scenarios to evaluate (click the 3 dots and then the upload CSV option). \n2. Comparing outputs to a gold standard answer \nClick 'Requires Expected Answer' to add a ground truth to your execution. This is the response you would expect from the AI model. The evaluator will then take it into consideration for the analysis.\nLast updated 2 months ago","markdown":"# Evaluator | StackAI\n\nEvaluate your agent's performance with a LLM-as-a-judge\n\nThe Evaluator View is similar to the batch interface, in that it allows running a CSV file of inputs on your agent, all at once. This view allows testing before a project goes live, and leverages a LLM to evaluate your agent's output.\n\nThere are two types of evaluation:\n\n### \n\n1\\. Grading outputs based on criteria\n\nOn the right hand side, create an evaluator:\n\n*   Select the output to evaluate\n    \n*   Add a system prompt - the evaluation logic\n    \n*   Give it a name\n    \n\nOnce the evaluator is created, a new column will appear in the table showing the evaluation results for each row.\n\nAdd as many evaluators as outputs in your workflow. Each one will evaluate a different output. Give each evaluator's model a system prompt and select which of your agent's outputs should be evaluated.\n\nYou can manually add rows to evaluate, or upload a CSV with all your scenarios to evaluate (click the 3 dots and then the upload CSV option).\n\n### \n\n2\\. Comparing outputs to a gold standard answer\n\nClick 'Requires Expected Answer' to add a ground truth to your execution. This is the response you would expect from the AI model. The evaluator will then take it into consideration for the analysis.\n\nLast updated 2 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/export-options/exposed-inputs","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/export-options/exposed-inputs","loadedTime":"2025-10-17T18:31:00.822Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/export-options/exposed-inputs","title":"Exposed Inputs | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Exposed Inputs | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1850","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901ded25f4d0826-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:31:00 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::t5vwf-1760725860245-239e639e97b5"}},"screenshotUrl":null,"text":"Exposed Inputs | StackAI\nYou can assign variables to your flow by adding query parameters to the URL of your interface. Each query parameter must be the id of the input to assign, replace hyphens for underscores.\nYou can assign values to inputs such as `in-1` by adding the query parameter `in_1`\nThis leads to embeds with the following structure:\n<iframe src=\"https://wwww.stack-ai.com/chat-assistant/orgId/token/flowId?in_1=example_text&in_2=second_text\" width=\"350\" height=\"600\" />\nThe following interfaces support variable assignment:\nChat Interface\nForm\nWebsite Chatbot\nAs part of your workflows, you can specify the following values as inputs in the request body:\nInput nodes translating in- to in_.\nUser ID for LLM Memory and Logs user_id\nIf the values for these inputs are not specified, the interface will use the values from the flow.\nLast updated 3 months ago","markdown":"# Exposed Inputs | StackAI\n\nYou can assign variables to your flow by adding query parameters to the URL of your interface. Each query parameter must be the id of the input to assign, replace hyphens for underscores.\n\nYou can assign values to inputs such as \\`in-1\\` by adding the query parameter \\`in\\_1\\`\n\nThis leads to embeds with the following structure:\n\n```\n<iframe\n  src=\"https://wwww.stack-ai.com/chat-assistant/orgId/token/flowId?in_1=example_text&in_2=second_text\"\n  width=\"350\"\n  height=\"600\"\n/>\n```\n\nThe following interfaces support variable assignment:\n\n*   **Chat Interface**\n    \n*   **Form**\n    \n*   **Website Chatbot**\n    \n\nAs part of your workflows, you can specify the following values as inputs in the request body:\n\n*   **Input nodes** translating `in-` to `in_`.\n    \n*   **User ID for LLM Memory and Logs** `user_id`\n    \n\nIf the values for these inputs are not specified, the interface will use the values from the flow.\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/technical-considerations/setting-up-your-googles-oauth2-credentials","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/technical-considerations/setting-up-your-googles-oauth2-credentials","loadedTime":"2025-10-17T18:31:00.611Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/technical-considerations/setting-up-your-googles-oauth2-credentials","title":"Setting up your Google's OAuth2 Credentials | StackAI","description":"This document instructs how to get your own OAuth2 credentials to use in Google Connections with user-provided credentials.","author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Setting up your Google's OAuth2 Credentials | StackAI"},{"property":"og:description","content":"This document instructs how to get your own OAuth2 credentials to use in Google Connections with user-provided credentials."},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1853","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901ded24fdb81ff-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:31:00 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::tj8cn-1760725860283-d9db55a41c49"}},"screenshotUrl":null,"text":"Setting up your Google's OAuth2 Credentials\nThis document instructs how to get your own OAuth2 credentials to use in Google Connections with user-provided credentials.\nPrerequisites\nTo connect your StackAI to Google services with user-provided credentials, follow these five steps:\nCreate a Google Cloud Console Project\nStart by creating a project in Google Cloud Console. If you already have one, you can skip ahead to the next section.\nIn the top navigation bar, open the project dropdown and click New Project or go directly to the New Project page\nEnter a Project name and choose a Location.\nClick Create to generate the project.\nConfirm that your new project is active by checking the project dropdown in the top navigation. If it’s not selected, switch to the project you just created.\nEnable the required APIs\nOnce your project is set up, you’ll need to enable the APIs that StackAI will use:\nIn the left menu, go to APIs & Services > Library.\nUse the search bar to find the APIs you need. For example, if you’re connecting to Google Drive, search for and select the Google Drive API.\nSelect ENABLE.\nConfigure the OAuth Consent Screen\nIf this is your first time using OAuth in your Google Cloud project, you'll need to configure the OAuth consent screen:\nFrom the left navigation menu, go to APIs & Services > OAuth consent screen. You’ll be redirected to the Google Auth Platform overview.\nOn the Overview tab, click Get started to begin configuring your OAuth screen.\nProvide an App name and a User support email for the consent screen, then click Next.\nFor the Audience, select Internal for user access within your organization's Google workspace or External for any user with a Google account. Refer to Google's User type documentation for more information on user types. Select Next to continue.\nSelect the email addresses Google should use to contact you about project updates, then click Next.\nReview and accept Google’s User Data Policy, then click Continue and Create.\nIn the left-hand menu, select Branding.\nIn the Authorized domains section, select Add domain and add stack-ai.com\nClick Save to finalize your consent screen setup. \nCreate Google OAuth client credentials\nNow you’ll generate the OAuth client credentials for your project:\nIn the APIs & Services section in the left menu, select Credentials.\nClick + Create credentials > OAuth client ID.\nIn the Application type dropdown, select Web application.\nGoogle will auto-generate a name. Update it to something meaningful so you can easily recognize it later.\nIn the Authorized redirect URIs field, add https://www.stack-ai.com/auth\nClick Create to generate the credentials.\nCreate the connection in StackAI\nWith the Google project and credentials fully configured, use them in StackAI.\nFrom Google's OAuth client created modal, copy the Client ID and Client Secret.\nIn StackAI, select to create a connection of type \"OAuth Credentials\" and fill your client id and secret.\nYou will be prompted to complete Google's authentication, and with that finished your connection is ready to use.\nTroubleshooting\nGoogle hasn't verified this app\nWhen using OAuth authentication, you may encounter the warning: “Google hasn’t verified this app.” To resolve it:\nIf your app User Type is Internal, create OAuth credentials from the same account you want to authenticate.\nIf your app User Type is External, you can add your email to the list of testers for the app: go to the Audience page and add the email you're signing in with to the list of Test users.\nIf you need to use credentials generated by another account (by a developer or another third party), follow the instructions in Google Cloud documentation | Authorization errors: Google hasn't verified this app.\nFor Google Cloud apps with Publishing status set to Testing and User type set to External, consent and tokens expire after seven days. Refer to Google Cloud Platform Console Help | Setting up your OAuth consent screen for more information. To resolve this, select Reconnect in StackAI's connections dashboard in your desired connection, and set new credentials for it.","markdown":"# Setting up your Google's OAuth2 Credentials\n\nThis document instructs how to get your own OAuth2 credentials to use in Google Connections with user-provided credentials.\n\n## \n\nPrerequisites\n\nTo connect your StackAI to Google services with user-provided credentials, follow these five steps:\n\n## \n\nCreate a Google Cloud Console Project\n\nStart by creating a project in Google Cloud Console. If you already have one, you can skip ahead to the [next section](https://docs.stack-ai.com/stack-ai/technical-considerations/setting-up-your-googles-oauth2-credentials#enable-the-required-apis).\n\n2.  In the top navigation bar, open the project dropdown and click **New Project** or go directly to the [New Project](https://console.cloud.google.com/projectcreate) page\n    \n3.  Enter a **Project name** and choose a **Location**.\n    \n4.  Click **Create** to generate the project.\n    \n5.  Confirm that your new project is active by checking the project dropdown in the top navigation. If it’s not selected, switch to the project you just created.\n    \n\n## \n\nEnable the required APIs\n\nOnce your project is set up, you’ll need to enable the APIs that StackAI will use:\n\n2.  In the left menu, go to **APIs & Services > Library**.\n    \n3.  Use the search bar to find the APIs you need. For example, if you’re connecting to Google Drive, search for and select the **Google Drive API**.\n    \n4.  Select **ENABLE**.\n    \n\n## \n\nConfigure the OAuth Consent Screen\n\nIf this is your first time using OAuth in your Google Cloud project, you'll need to [configure the OAuth consent screen](https://developers.google.com/workspace/guides/configure-oauth-consent):\n\n2.  From the left navigation menu, go to **APIs & Services > OAuth consent screen**. You’ll be redirected to the Google Auth Platform overview.\n    \n3.  On the **Overview** tab, click **Get started** to begin configuring your OAuth screen.\n    \n4.  Provide an **App name** and a **User support email** for the consent screen, then click **Next**.\n    \n5.  For the **Audience**, select **Internal** for user access within your organization's Google workspace or **External** for any user with a Google account. Refer to Google's [User type documentation](https://support.google.com/cloud/answer/15549945?sjid=17061891731152303663-EU#user-type) for more information on user types. Select **Next** to continue.\n    \n6.  Select the **email addresses** Google should use to contact you about project updates, then click **Next**.\n    \n7.  Review and accept Google’s **User Data Policy**, then click **Continue** and **Create**.\n    \n8.  In the left-hand menu, select **Branding**.\n    \n9.  In the **Authorized domains** section, select **Add domain** and add **stack-ai.com**\n    \n10.  Click **Save** to finalize your consent screen setup.\n    \n\n## \n\nCreate Google OAuth client credentials\n\nNow you’ll generate the OAuth client credentials for your project:\n\n2.  In the **APIs & Services** section in the left menu, select [**Credentials**](https://console.cloud.google.com/apis/credentials).\n    \n3.  Click **\\+ Create credentials** > **OAuth client ID**.\n    \n4.  In the **Application type** dropdown, select **Web application**.\n    \n5.  Google will auto-generate a name. Update it to something meaningful so you can easily recognize it later.\n    \n6.  In the **Authorized redirect URIs** field, add **https://www.stack-ai.com/auth**\n    \n7.  Click **Create** to generate the credentials.\n    \n\n## \n\nCreate the connection in StackAI\n\nWith the Google project and credentials fully configured, use them in StackAI.\n\n1.  From Google's **OAuth client created** modal, copy the **Client ID** and **Client Secret**.\n    \n2.  In StackAI, select to create a connection of type \"OAuth Credentials\" and fill your client id and secret.\n    \n3.  You will be prompted to complete Google's authentication, and with that finished your connection is ready to use.\n    \n\n## \n\nTroubleshooting\n\n### \n\nGoogle hasn't verified this app\n\nWhen using OAuth authentication, you may encounter the warning: **“Google hasn’t verified this app.”** To resolve it:\n\n*   If your app **User Type** is **Internal**, create OAuth credentials from the same account you want to authenticate.\n    \n*   If your app **User Type** is **External**, you can add your email to the list of testers for the app: go to the [**Audience**](https://console.cloud.google.com/auth/audience) page and add the email you're signing in with to the list of **Test users**.\n    \n\nIf you need to use credentials generated by another account (by a developer or another third party), follow the instructions in [Google Cloud documentation | Authorization errors: Google hasn't verified this app](https://developers.google.com/nest/device-access/reference/errors/authorization#google_hasnt_verified_this_app).\n\nFor Google Cloud apps with **Publishing status** set to **Testing** and **User type** set to **External**, consent and tokens expire after seven days. Refer to [Google Cloud Platform Console Help | Setting up your OAuth consent screen](https://support.google.com/cloud/answer/10311615?hl=en#zippy=%2Ctesting) for more information. To resolve this, select **Reconnect** in StackAI's connections dashboard in your desired connection, and set new credentials for it.","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/other-views/manager","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/other-views/manager","loadedTime":"2025-10-17T18:31:00.681Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/other-views/manager","title":"Manager | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Manager | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1854","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901ded23ffc062f-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:31:00 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::sl6wm-1760725860345-9b512f5a24e5"}},"screenshotUrl":null,"text":"Manager | StackAI\nThe Manager View allows an administrator to see all the conversations happening between users and agents, including the user's queries and the agent's answer. This is a great view to check out in order to understand more about how users are interacting with your agent. \nLast updated 3 months ago","markdown":"# Manager | StackAI\n\nThe Manager View allows an administrator to see all the conversations happening between users and agents, including the user's queries and the agent's answer. This is a great view to check out in order to understand more about how users are interacting with your agent.\n\nLast updated 3 months ago","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/technical-considerations/embeddings","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/technical-considerations/embeddings","loadedTime":"2025-10-17T18:31:04.305Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/technical-considerations/embeddings","title":"Embeddings | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Embeddings | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1856","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dee648c4c940-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:31:03 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::jgtw9-1760725863440-f5a842918564"}},"screenshotUrl":null,"text":"Embeddings | StackAI\nWhat is an embedding?\nEmbeddings are numerical representations of concepts converted to number sequences, which make it easy for computers to understand the relationships between those concepts. They are capable of capturing the context of a word in a document, its semantic and syntactic similarity, and its relation with other words.\nHow can I select different types of embeddings in Stack AI?\nEmbeddings can be selected by the user in two different section of Stack AI platform.\nThe most intuitive place is in a vector store. As explained in section, the input will be vectorized and indexed in a vector database for later usage in an AI model (so only the relevant chunks of the input are sent to the LLM).\nDocument search elements are also customizable with respect to their embeddings.\nWhich are the models available?\nBelow a list of the embeddings models integrated into Stack AI's platform.\nMODEL\nCOMPANY\nDESCRIPTION\nLINK\nnewest and most performant embedding models are now available, with lower costs, higher multilingual performance, and new parameters to control the overall size.\nOutperforms previous OpenAI's most capable model, Davinci, at most tasks, while being priced 99.8% lower\nOutperforms previous OpenAI's most capable model, Davinci, at most tasks, while being priced 99.8% lower\nEmbeddings based on Bidirectional Encoder Representations from Transformers (BERT)\nVertex AI PaLM API supports Gecko for Embeddings\nSentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search.","markdown":"# Embeddings | StackAI\n\n### \n\nWhat is an embedding?\n\nEmbeddings are numerical representations of concepts converted to number sequences, which make it easy for computers to understand the relationships between those concepts. They are capable of capturing the context of a word in a document, its semantic and syntactic similarity, and its relation with other words.\n\n### \n\nHow can I select different types of embeddings in Stack AI?\n\nEmbeddings can be selected by the user in two different section of Stack AI platform.\n\n*   The most intuitive place is in a `vector store`. As explained in section, the input will be vectorized and indexed in a vector database for later usage in an AI model (so only the relevant chunks of the input are sent to the LLM).\n    \n*   `Document search` elements are also customizable with respect to their embeddings.\n    \n\n### \n\nWhich are the models available?\n\nBelow a list of the embeddings models integrated into Stack AI's platform.\n\nMODEL\n\nCOMPANY\n\nDESCRIPTION\n\nLINK\n\nnewest and most performant embedding models are now available, with lower costs, higher multilingual performance, and new parameters to control the overall size.\n\nOutperforms previous OpenAI's most capable model, Davinci, at most tasks, while being priced 99.8% lower\n\nOutperforms previous OpenAI's most capable model, Davinci, at most tasks, while being priced 99.8% lower\n\nEmbeddings based on Bidirectional Encoder Representations from Transformers (BERT)\n\nVertex AI PaLM API supports Gecko for Embeddings\n\nSentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search.","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/api-reference/documents","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/api-reference/documents","loadedTime":"2025-10-17T18:31:04.797Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/api-reference/documents","title":"Documents | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Documents | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1856","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901deeb3d770934-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:31:04 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::jwtkd-1760725864255-f56e6e7f22ef"}},"screenshotUrl":null,"text":"Documents | StackAI\nList Files In User Bucket\nList the files in the user bucket.\norg_idstringRequired\nThe organization ID\nuser_idstringRequired\nThe user ID\nflow_idstringRequired\nThe flow ID of the document\nnode_idstringRequired\nThe node ID of the document\nget\n/documents/{org_id}/{flow_id}/{node_id}/{user_id}\nUpload To User Bucket\nUpload the file to the user bucket for a document node.\norg_idstringRequired\nThe organization ID\nuser_idstringRequired\nThe user ID\nflow_idstringRequired\nThe flow ID of the document\nnode_idstringRequired\nThe node ID of the document\nResponseobject · ResponseUploadToUserBucketDocumentsOrgIdFlowIdNodeIdUserIdPost\npost\n/documents/{org_id}/{flow_id}/{node_id}/{user_id}\nDelete From User Bucket\nDelete the file from the user bucket.\norg_idstringRequired\nThe organization ID\nuser_idstringRequired\nThe user ID\nflow_idstringRequired\nThe flow ID of the document\nnode_idstringRequired\nThe node ID of the document\ndelete\n/documents/{org_id}/{flow_id}/{node_id}/{user_id}\nDownload From User Bucket\nDownload the file from the user bucket.\norg_idstringRequired\nThe organization ID\nuser_idstringRequired\nThe user ID\nflow_idstringRequired\nThe flow ID of the document\nnode_idstringRequired\nThe node ID of the document\nget\n/documents/{org_id}/{flow_id}/{node_id}/{user_id}/file","markdown":"# Documents | StackAI\n\n### \n\nList Files In User Bucket\n\nList the files in the user bucket.\n\norg\\_idstringRequired\n\nThe organization ID\n\nuser\\_idstringRequired\n\nThe user ID\n\nflow\\_idstringRequired\n\nThe flow ID of the document\n\nnode\\_idstringRequired\n\nThe node ID of the document\n\nget\n\n/documents/{org\\_id}/{flow\\_id}/{node\\_id}/{user\\_id}\n\n### \n\nUpload To User Bucket\n\nUpload the file to the user bucket for a document node.\n\norg\\_idstringRequired\n\nThe organization ID\n\nuser\\_idstringRequired\n\nThe user ID\n\nflow\\_idstringRequired\n\nThe flow ID of the document\n\nnode\\_idstringRequired\n\nThe node ID of the document\n\nResponseobject · ResponseUploadToUserBucketDocumentsOrgIdFlowIdNodeIdUserIdPost\n\npost\n\n/documents/{org\\_id}/{flow\\_id}/{node\\_id}/{user\\_id}\n\n### \n\nDelete From User Bucket\n\nDelete the file from the user bucket.\n\norg\\_idstringRequired\n\nThe organization ID\n\nuser\\_idstringRequired\n\nThe user ID\n\nflow\\_idstringRequired\n\nThe flow ID of the document\n\nnode\\_idstringRequired\n\nThe node ID of the document\n\ndelete\n\n/documents/{org\\_id}/{flow\\_id}/{node\\_id}/{user\\_id}\n\n### \n\nDownload From User Bucket\n\nDownload the file from the user bucket.\n\norg\\_idstringRequired\n\nThe organization ID\n\nuser\\_idstringRequired\n\nThe user ID\n\nflow\\_idstringRequired\n\nThe flow ID of the document\n\nnode\\_idstringRequired\n\nThe node ID of the document\n\nget\n\n/documents/{org\\_id}/{flow\\_id}/{node\\_id}/{user\\_id}/file","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/api-reference/folders","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/api-reference/folders","loadedTime":"2025-10-17T18:31:05.011Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/api-reference/folders","title":"Folders | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Folders | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"1092","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901dee94e8fc991-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:31:04 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"iad1::iad1::t5769-1760725863932-dc5737672c0f"}},"screenshotUrl":null,"text":"Folders | StackAI\nGet User Personal Folder\nGet the user's personal folder if it exists.\nGet Folder\nDelete Folder\nDelete a folder in the current organization.\ndelete\n/folders/{folder_id}\nPatch Folder\nUpdate a folder in the current organization.\npatch\n/folders/{folder_id}\nQuery Folders\nGet all folders for the current user organization.\nArgs: offset (int): The offset of the folders to return as a number of rows. Defaults to 0. limit (int): The limit of the folders to return as a number of rows. Defaults to 100. query (str): The search query to filter folders by name. If provided, only folders whose names contain the query string will be returned.\nCreate Folder\nCreate a new folder in the current organization.","markdown":"# Folders | StackAI\n\n### \n\nGet User Personal Folder\n\nGet the user's personal folder if it exists.\n\n### \n\nGet Folder\n\n### \n\nDelete Folder\n\nDelete a folder in the current organization.\n\ndelete\n\n/folders/{folder\\_id}\n\n### \n\nPatch Folder\n\nUpdate a folder in the current organization.\n\npatch\n\n/folders/{folder\\_id}\n\n### \n\nQuery Folders\n\nGet all folders for the current user organization.\n\nArgs: offset (int): The offset of the folders to return as a number of rows. Defaults to 0. limit (int): The limit of the folders to return as a number of rows. Defaults to 100. query (str): The search query to filter folders by name. If provided, only folders whose names contain the query string will be returned.\n\n### \n\nCreate Folder\n\nCreate a new folder in the current organization.","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/technical-considerations/whitelisting-stackai-in-microsoft-entra","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/technical-considerations/whitelisting-stackai-in-microsoft-entra","loadedTime":"2025-10-17T18:31:09.703Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/technical-considerations/whitelisting-stackai-in-microsoft-entra","title":"Whitelisting StackAI in Microsoft Entra | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Whitelisting StackAI in Microsoft Entra | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"date":"Fri, 17 Oct 2025 18:31:05 GMT","content-type":"text/html; charset=utf-8","content-encoding":"br","cf-ray":"9901def38d1d8157-SEA","cf-cache-status":"DYNAMIC","age":"1858","cache-control":"public, max-age=0, must-revalidate","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","referrer-policy":"no-referrer-when-downgrade","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"HIT","x-vercel-id":"pdx1::iad1::sdtxs-1760725865566-cf418020d40e","server":"cloudflare","alt-svc":"h3=\":443\"; ma=86400","x-firefox-spdy":"h2"}},"screenshotUrl":"https://api.apify.com/v2/key-value-stores/3K2WBdQQFTu6EGDhJ/records/SCREENSHOT-docs-stack-ai-com-stack-ai-technical-considerations-whitelisting-stackai-in-microsoft-entra-7b5bcbe2.jpg","text":"Whitelisting StackAI in Microsoft Entra\nIf you are getting the following message when trying to make a connection, you need to follow the steps below to whitelist StackAI as a third-party app in Microsoft Entra. The following steps need to be completed by your Microsoft Entra administrator.\nWhitelisting StackAI (as a third-party OAuth2 App) in Microsoft Entra\nObtain the App Details Get the Application (Client) ID or the Publisher information from the third-party app vendor. Confirm the exact permissions (scopes) the app is requesting.\nReview Consent Settings in Entra ID Go to the Microsoft Entra admin center. Navigate to Identity > Applications > Enterprise applications. Search for the third-party app. If users have already tried to sign in, it may appear here.\nGrant Admin Consent (Recommended) Select the app in Enterprise applications. Go to Permissions or Permissions and consent. Click Grant admin consent for [Your Tenant]. Review the requested permissions and confirm. This step ensures all users can log in without being blocked by consent policies.\nAdjust User Consent Policies (If Needed) If users are being blocked from consenting to third-party apps: In the Entra admin center, go to Identity > Applications > User consent settings. Review the User consent for applications policy. You can allow users to consent to verified publishers, or only to apps requesting low-risk permissions. For stricter control, keep user consent disabled and rely on admin consent as above.\nConfirm Conditional Access and Security Settings If you have Conditional Access policies that restrict app access, ensure the third-party app is included as an allowed cloud app. Check for any permissions restrictions or app ban lists in Defender for Cloud Apps or similar tools. Notes You do not need to register the app yourself—the third-party app vendor registers their app with Microsoft and provides you with the necessary details. If you are using Microsoft Defender for Cloud Apps, you can explicitly allow or block OAuth apps in its portal. Always review the permissions requested by the app and ensure they align with your organization's security policies. Troubleshooting If the app does not appear in Enterprise applications, have a user attempt to sign in. This should trigger its appearance. If login is still blocked, check for tenant-wide restrictions on third-party app consent or additional security policies. By following these steps, you can whitelist and enable OAuth2 login for a third-party app in your Microsoft 365/Entra ID environment, ensuring users can access it as intended.\nLast updated 3 months ago","markdown":"# Whitelisting StackAI in Microsoft Entra\n\nIf you are getting the following message when trying to make a connection, you need to follow the steps below to whitelist StackAI as a third-party app in Microsoft Entra. The following steps need to be completed by your Microsoft Entra administrator.\n\n### \n\nWhitelisting StackAI (as a third-party OAuth2 App) in Microsoft Entra\n\n1.  Obtain the App Details Get the Application (Client) ID or the Publisher information from the third-party app vendor. Confirm the exact permissions (scopes) the app is requesting.\n    \n2.  Review Consent Settings in Entra ID Go to the Microsoft Entra admin center. Navigate to Identity > Applications > Enterprise applications. Search for the third-party app. If users have already tried to sign in, it may appear here.\n    \n3.  Grant Admin Consent (Recommended) Select the app in Enterprise applications. Go to Permissions or Permissions and consent. Click Grant admin consent for \\[Your Tenant\\]. Review the requested permissions and confirm. This step ensures all users can log in without being blocked by consent policies.\n    \n4.  Adjust User Consent Policies (If Needed) If users are being blocked from consenting to third-party apps: In the Entra admin center, go to Identity > Applications > User consent settings. Review the User consent for applications policy. You can allow users to consent to verified publishers, or only to apps requesting low-risk permissions. For stricter control, keep user consent disabled and rely on admin consent as above.\n    \n5.  Confirm Conditional Access and Security Settings If you have Conditional Access policies that restrict app access, ensure the third-party app is included as an allowed cloud app. Check for any permissions restrictions or app ban lists in Defender for Cloud Apps or similar tools. Notes You do not need to register the app yourself—the third-party app vendor registers their app with Microsoft and provides you with the necessary details. If you are using Microsoft Defender for Cloud Apps, you can explicitly allow or block OAuth apps in its portal. Always review the permissions requested by the app and ensure they align with your organization's security policies. Troubleshooting If the app does not appear in Enterprise applications, have a user attempt to sign in. This should trigger its appearance. If login is still blocked, check for tenant-wide restrictions on third-party app consent or additional security policies. By following these steps, you can whitelist and enable OAuth2 login for a third-party app in your Microsoft 365/Entra ID environment, ensuring users can access it as intended.\n    \n\nLast updated 3 months ago","debug":{"requestHandlerMode":"browser"}}
{"url":"https://docs.stack-ai.com/cdn-cgi/l/email-protection","crawl":{"loadedUrl":"https://docs.stack-ai.com/cdn-cgi/l/email-protection","loadedTime":"2025-10-17T18:31:16.665Z","referrerUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/apps/snowflake","depth":2,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/cdn-cgi/l/email-protection","title":"Email Protection | Cloudflare","description":null,"author":null,"keywords":null,"languageCode":"en-US","jsonLd":null,"headers":{"cf-ray":"9901df38fb38d644-IAD","content-type":"text/html; charset=UTF-8","date":"Fri, 17 Oct 2025 18:31:16 GMT","server":"cloudflare","x-content-type-options":"nosniff","x-frame-options":"DENY"}},"screenshotUrl":null,"text":"Email Protection | Cloudflare\nThe website from which you got to this page is protected by Cloudflare. Email addresses on that page have been hidden in order to keep them from being accessed by malicious bots. You must enable Javascript in your browser in order to decode the e-mail address.\nIf you have a website and are interested in protecting it in a similar way, you can sign up for Cloudflare.","markdown":"# Email Protection | Cloudflare\n\nThe website from which you got to this page is protected by Cloudflare. Email addresses on that page have been hidden in order to keep them from being accessed by malicious bots. **You must enable Javascript in your browser in order to decode the e-mail address**.\n\nIf you have a website and are interested in protecting it in a similar way, you can [sign up for Cloudflare](https://www.cloudflare.com/sign-up?utm_source=email_protection).","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/docs/api-reference/how-to-get-credentials","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/docs/api-reference/how-to-get-credentials","loadedTime":"2025-10-17T18:31:19.332Z","referrerUrl":"https://docs.stack-ai.com/stack-ai/api-reference/run-flow","depth":2,"httpStatusCode":404},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/docs/api-reference/how-to-get-credentials","title":"StackAI","description":null,"author":null,"keywords":null,"languageCode":null,"jsonLd":null,"headers":{"age":"0","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901df439efed673-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:31:19 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"60","x-vercel-cache":"MISS","x-vercel-id":"iad1::iad1::vktfj-1760725878387-a36d02a72884"}},"screenshotUrl":null,"text":"","markdown":"StackAI","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/docs/api-reference/how-to-get-flow-id","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/docs/api-reference/how-to-get-flow-id","loadedTime":"2025-10-17T18:31:19.755Z","referrerUrl":"https://docs.stack-ai.com/stack-ai/api-reference/run-flow","depth":2,"httpStatusCode":404},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/docs/api-reference/how-to-get-flow-id","title":"StackAI","description":null,"author":null,"keywords":null,"languageCode":null,"jsonLd":null,"headers":{"age":"0","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901df4349d4e5fe-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:31:19 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"60","x-vercel-cache":"MISS","x-vercel-id":"iad1::iad1::fntkl-1760725878314-2039882d1f23"}},"screenshotUrl":null,"text":"","markdown":"StackAI","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/project-management","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/project-management/the-project-dashboard","loadedTime":"2025-10-17T18:31:20.785Z","referrerUrl":"https://docs.stack-ai.com/stack-ai/project-management/exporting-and-importing-projects","depth":2,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/project-management/the-project-dashboard","title":"The Project Dashboard | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"The Project Dashboard | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"age":"0","alt-svc":"h3=\":443\"; ma=86400","cache-control":"public, max-age=0, must-revalidate","cf-cache-status":"DYNAMIC","cf-ray":"9901df4f9e368250-IAD","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","content-type":"text/html; charset=utf-8","date":"Fri, 17 Oct 2025 18:31:20 GMT","referrer-policy":"no-referrer-when-downgrade","server":"cloudflare","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"iad1::iad1::sf4qr-1760725880320-c35073fadbdc"}},"screenshotUrl":null,"text":"The Project Dashboard | StackAI\nCtrlK\nWas this helpful?","markdown":"# The Project Dashboard | StackAI\n\n[![Logo](https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Flogo%252FsUtqhkQsKnov95VheEnU%252FStackAI_Logo_Horizontal_OffBlackonWhite%2520%281%29.jpg%3Falt%3Dmedia%26token%3D0caf921c-ecea-4b89-8362-de136ae453df&width=260&dpr=4&quality=100&sign=f857c345&sv=2)![Logo](https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Flogo%252FMMUfiaC3YS6k23O3HxlS%252FStackAI_Logo_Horizontal_WhiteonOffBlack.jpg%3Falt%3Dmedia%26token%3Deaca6626-0dc7-49c4-a0d0-5542b445c58d&width=260&dpr=4&quality=100&sign=48884c2f&sv=2)](https://docs.stack-ai.com/stack-ai)\n\nCtrlK\n\nWas this helpful?","debug":{"requestHandlerMode":"http"}}
{"url":"https://docs.stack-ai.com/stack-ai/workflow-builder/knowledge-bases/knowledge-base-nodes","crawl":{"loadedUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/knowledge-bases/knowledge-base-nodes","loadedTime":"2025-10-17T18:31:18.762Z","referrerUrl":"https://docs.stack-ai.com/","depth":1,"httpStatusCode":200},"metadata":{"canonicalUrl":"https://docs.stack-ai.com/stack-ai/workflow-builder/knowledge-bases/knowledge-base-nodes","title":"Knowledge Base Nodes | StackAI","description":null,"author":null,"keywords":null,"languageCode":"en","openGraph":[{"property":"og:title","content":"Knowledge Base Nodes | StackAI"},{"property":"og:image","content":"https://docs.stack-ai.com/stack-ai/~gitbook/image?url=https%3A%2F%2F3621678242-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Forganizations%252F2asIZ16y1YqfkPhoidZ7%252Fsites%252Fsite_H5ZPw%252Fsocialpreview%252FwXnUt6riyYV2xT1p4Reb%252FAnnouncement%2520V1.png%3Falt%3Dmedia%26token%3D74ad1f33-67f3-4084-b792-c27c107738af&width=1200&height=630&sign=1cda439e&sv=2"}],"jsonLd":null,"headers":{"date":"Fri, 17 Oct 2025 18:30:32 GMT","content-type":"text/html; charset=utf-8","content-encoding":"br","cf-ray":"9901de1a4b2b8157-SEA","cf-cache-status":"DYNAMIC","age":"0","cache-control":"public, max-age=0, must-revalidate","strict-transport-security":"max-age=31536000","vary":"RSC, Next-Router-State-Tree, Next-Router-Prefetch, Next-Router-Segment-Prefetch, accept-encoding","content-security-policy":"default-src 'self' *; script-src 'self' 'unsafe-inline' 'unsafe-eval' *; style-src 'self' 'unsafe-inline' blob: *; img-src * 'self' blob: data:; connect-src *; font-src *; frame-src *; object-src 'none'; base-uri 'self' https://static-2v.gitbook.com; form-action 'self' https://static-2v.gitbook.com *; frame-ancestors https: ;","referrer-policy":"no-referrer-when-downgrade","x-content-type-options":"nosniff","x-gitbook-route-site":"docs.stack-ai.com/stack-ai/","x-gitbook-route-type":"static","x-gitbook-target":"2v","x-matched-path":"/sites/static/[mode]/[siteURL]/[siteData]/[pagePath]","x-nextjs-prerender":"1","x-nextjs-stale-time":"300","x-vercel-cache":"MISS","x-vercel-id":"pdx1::iad1::c47kk-1760725830798-561f4534f57a","server":"cloudflare","alt-svc":"h3=\":443\"; ma=86400","x-firefox-spdy":"h2"}},"screenshotUrl":"https://api.apify.com/v2/key-value-stores/3K2WBdQQFTu6EGDhJ/records/SCREENSHOT-docs-stack-ai-com-stack-ai-workflow-builder-knowledge-bases-knowledge-base-nodes-3c1a7b9a.jpg","text":"Knowledge Base Nodes | StackAI\nA knowledge base node performs a search or retrieval operation on a knowledge base of your choice, returning relevant document chunks or information in response to a query. The files uploaded to the Knowledge Base node can be reused across multiple flows. All created knowledge bases are automatically synced to the Knowledge Base Dashboard.\nNode Settings & Search Parameters\nClick on the node to change its settings.\nAt the top of the window, you will find a drop-down menu to select a Knowledge Base or choose documents to form a new Knowledge Base. You can select or de-select individual documents that you'd like to include.\nSettings + Search Parameters\nBelow that you will see the configurations for Settings and Search Parameters\nOutput Format: Choose between chunks, pages, and docs.\nQuery Strategy: Choose between Semantic, Keyword, and Hybrid.\nTop Results: Number of search results ranked by relevance.\nMax Characters: Limits the number of characters sent to the LLM.\nAnswer Multiple Questions: Get the answers from multiple questions in parallel.\nAdvanced Q&A: Handle questions to compare or summarize documents. By enabling this feature, the knowledge base search will automatically use \"retrieval utilities\" to select the best mechanism to answer the user questions depending on whether the question aims to: retrieve a fact, compare a set of documents, or summarize a document inside the knowledge base.\nRerank: Get more precise information retrieval. The knowledge base will divide its number of results in half with the most relevant results, using a sophisticated ranking algorithm. This will reduce token usage.\nQuery Transformation: Get more precise information retrieval. Forces the knowledge base to rewrite the user message as a better question. This increases the quality of the search results for the language model.\nAdvanced Upload Parameters\nSome nodes, like the Websites Node and Google Drive Node, will also allow you to specify Advanced Upload Parameters, settings for how you'd like your documents to be ingested. You can also control these parameters from the KB Dashboard.\nModel for Embeddings: as default, the text-embedding-3-large model from OpenAI is selected. However, you will have the option to select the following ones: azure-text-embedding-ada-002, bert-base-cased, all-mpnset-base, palm2 and more.\nChunking algorithm: by default, the system uses sentence. You can also choose naive.\nChunk overlap: by default, the system uses 500. You can also choose as many as you want up to 4500 by clicking the number and editing it.\nChunk length: by default, the system uses 2500. You can also choose as many as you want up to 4500 by clicking the number and editing it.\nAdvanced Data Extraction: For complex data like tables, images, charts. Enable it if you want to extract text from images that are present in your documents. By default, this option is deselected since it will increase the latency of your workflow (i.e., it will run slower).\nText in images (OCR): by default, this option is deselected. Enable it if you want to extract text from imgs that are present in your documents.\nEmbeddings API key: by default, the text field is empty. Stack AI's API key are used. If you would like to use yours, then include your API key in this text field.\nChunking Algorithms\nStackAI implements both sentence and naive chunking algorithms:\nNaive Algorithms are typically simpler and less sophisticated. They often rely on basic methods like searching for specific keywords or phrases. \nLack of Context Understanding: they usually don't understand the context or the structure of the language. For example, a naive algorithm might count the frequency of words without understanding their meaning or part of speech. \nSpeed and Efficiency: due to their simplicity, these algorithms can be faster and more efficient, especially for straightforward tasks. \nLimitations: naive algorithms are generally less accurate in complex language processing tasks. They might miss nuances, sarcasm, or idiomatic expressions.\nSentence Chunking Algorithms are more sophisticated. They involve breaking down text into syntactically correlated parts of words like noun phrases, verb phrases, etc. \nContext and Structure Understanding: sentence chunking algorithms understand the structure of a sentence. They analyze parts of speech and how words relate to each other in a sentence.\nAccuracy: they are more accurate in understanding the meaning and context of sentences. This makes them suitable for complex tasks like sentiment analysis, information extraction, and language translation. \nResource Intensity: these algorithms are usually more resource-intensive due to their complexity. They might require more computational power and time to process text.\nTo learn more about best practices with regard to chunking, see our guide to chunking here.\nFile Status\nYou will see a label for each document that you upload with the following icons:\nPending: the document is being processed and indexed.\n✅: the document was successfully indexed.\nError: the document could not be indexed (e.g., due to a formatting issue).\nMetadata Filter Strategy\nMetadata filtering helps narrow down the documents retrieved from a vector store. The filters operate on metadata associated with each document — like date, source, topic, etc.\nIf you want to surface as much information as possible, it is best to use no filter. In this case, no metadata constraints are applied. The system retrieves the top-k most relevant documents based on your search algorithm. This strategy is best to use when you don't have a very large knowledge base as it increases the likelihood that irrelevant documents will be retrieved.\nWith loose filtering, metadata is used as a soft constraint — the system prefers documents matching the filter, but still considers other documents. This gives you the best of both worlds and is best used when metadata is helpful but not critical.\nStrict filtering should be used for situations where you have many similar documents in your KB that you need to distinguish between. With a strict filter, metadata constraints are hard requirements — only documents matching the specified metadata are eligible for retrieval. When results must meet certain conditions — e.g. regulatory compliance, user access control, project-specific scopes — strict filtering is the way to go.\nQuery Strategy\nIn Retrieval-Augmented Generation (RAG), keyword-based search relies on traditional information retrieval techniques that match exact or fuzzy terms within documents. This approach works best when the query and content use consistent vocabulary, such as in legal, technical, or structured domains where terminology is predictable. It's especially useful when you know the precise terms you're looking for.\nSemantic querying, on the other hand, uses vector embeddings to represent the meaning of both queries and documents. It enables retrieval based on conceptual similarity, rather than exact keyword matches. This makes it well-suited for natural language questions, varied phrasing, and content where language is less standardized—such as customer support, internal knowledge bases, or conversational search. By focusing on meaning, semantic search improves recall, but may miss documents with exact keyword relevance.\nHybrid querying combines both strategies—typically by blending keyword and semantic relevance scores or performing multi-stage retrieval. This approach provides the benefits of both precision and flexibility, making it ideal for general-purpose RAG systems that must handle a variety of user intents and content types. While slightly more complex to implement, hybrid search often yields the most balanced and robust retrieval performance in production applications.\nTypical Workflow Structure\nA common pattern is:\nUser Input (Input Node): The user provides a question or prompt.\nKnowledge Base Node: Receives the user’s query (directly or via an LLM node) and retrieves relevant information from the knowledge base.\nLLM Node: Uses both the user’s input and the retrieved knowledge base content to generate a final, context-rich answer.\nHow the Interface Works\nA. Data Flow\nThe Knowledge Base node typically takes the user’s input as its query, searches the knowledge base, and outputs relevant text chunks.\nThe LLM node can reference the output of the Knowledge Base node in its prompt using the node’s ID.\nB. Connections (Edges)\nThe Input node is connected to the Knowledge Base node (for the query).\nThe Knowledge Base node is connected to the LLM node (providing retrieved content).\nThe LLM node is connected to the Output node (displaying the answer).\nC. Execution Order\nThe user submits a question.\nThe Knowledge Base node receives the question and retrieves relevant information.\nThe LLM node receives both the user’s question and the retrieved information, then generates a response.\nThe Output node displays the LLM’s answer.\nWhy Use This Pattern?\nRetrieval-Augmented Generation (RAG): This approach allows the LLM to ground its answers in specific, up-to-date, or proprietary knowledge, improving accuracy and relevance.\nSeparation of Concerns: The Knowledge Base node handles retrieval, while the LLM node handles synthesis and reasoning.\nKey Points\nThe LLM node does not “search” the knowledge base directly; it relies on the Knowledge Base node to do the retrieval.\nThe LLM node’s prompt must reference the Knowledge Base node’s output to use the retrieved information.\nAll node references must match actual node IDs in the workflow.\nAvailable Knowledge Bases\nDocuments\nWebsites\nTables\nData\nSharepoint\nGoogle Drive\nOneDrive\nDropbox\nAzure Blob Storage\nAWS S3\nNotion\nConfluence\nVeeva\nServiceNow\nJira\nLast updated 2 months ago","markdown":"# Knowledge Base Nodes | StackAI\n\nA knowledge base node performs a search or retrieval operation on a knowledge base of your choice, returning relevant document chunks or information in response to a query. The files uploaded to the Knowledge Base node can be reused across multiple flows. All created knowledge bases are automatically synced to the Knowledge Base Dashboard.\n\n* * *\n\n### \n\nNode Settings & Search Parameters\n\nClick on the node to change its settings.\n\nAt the top of the window, you will find a drop-down menu to select a Knowledge Base or choose documents to form a new Knowledge Base. You can select or de-select individual documents that you'd like to include.\n\n### \n\nSettings + Search Parameters\n\nBelow that you will see the configurations for **Settings** and **Search Parameters**\n\n*   **Output Format:** Choose between chunks, pages, and docs.\n    \n\n*   [**Query Strategy:**](https://docs.stack-ai.com/stack-ai/workflow-builder/knowledge-bases/knowledge-base-nodes#query-strategy) Choose between Semantic, Keyword, and Hybrid.\n    \n*   **Top Results:** Number of search results ranked by relevance.\n    \n*   **Max Characters:** Limits the number of characters sent to the LLM.\n    \n*   **Answer Multiple Questions:** Get the answers from multiple questions in parallel.\n    \n*   **Advanced Q&A:** Handle questions to compare or summarize documents. By enabling this feature, the knowledge base search will automatically use \"retrieval utilities\" to select the best mechanism to answer the user questions depending on whether the question aims to: retrieve a fact, compare a set of documents, or summarize a document inside the knowledge base.\n    \n*   **Rerank:** Get more precise information retrieval. The knowledge base will divide its number of results in half with the most relevant results, using a sophisticated ranking algorithm. This will reduce token usage.\n    \n*   **Query Transformation:** Get more precise information retrieval. Forces the knowledge base to rewrite the user message as a better question. This increases the quality of the search results for the language model.\n    \n\n### \n\nAdvanced Upload Parameters\n\nSome nodes, like the Websites Node and Google Drive Node, will also allow you to specify **Advanced Upload Parameters**, settings for how you'd like your documents to be ingested. You can also control these parameters from the KB Dashboard.\n\n*   **Model for Embeddings:** as default, the `text-embedding-3-large model` from OpenAI is selected. However, you will have the option to select the following ones: `azure-text-embedding-ada-002`, `bert-base-cased`, `all-mpnset-base`, `palm2` and more.\n    \n*   [**Chunking algorithm:**](https://docs.stack-ai.com/stack-ai/workflow-builder/knowledge-bases/knowledge-base-nodes#chunking-algorithms) by default, the system uses `sentence`. You can also choose `naive`.\n    \n*   **Chunk overlap:** by default, the system uses `500`. You can also choose as many as you want up to `4500` by clicking the number and editing it.\n    \n*   **Chunk length:** by default, the system uses `2500`. You can also choose as many as you want up to `4500` by clicking the number and editing it.\n    \n*   **Advanced Data Extraction:** For complex data like tables, images, charts. Enable it if you want to extract text from images that are present in your documents. By default, this option is deselected since it will increase the latency of your workflow (i.e., it will run slower).\n    \n*   **Text in images (OCR):** by default, this option is deselected. Enable it if you want to extract text from imgs that are present in your documents.\n    \n*   **Embeddings API key:** by default, the text field is empty. Stack AI's API key are used. If you would like to use yours, then include your API key in this text field.\n    \n\n### \n\nChunking Algorithms\n\nStackAI implements both `sentence` and `naive` chunking algorithms:\n\n**Naive Algorithms** are typically simpler and less sophisticated. They often rely on basic methods like searching for specific keywords or phrases.\n\n*   **Lack of Context Understanding:** they usually don't understand the context or the structure of the language. For example, a naive algorithm might count the frequency of words without understanding their meaning or part of speech.\n    \n*   **Speed and Efficiency:** due to their simplicity, these algorithms can be faster and more efficient, especially for straightforward tasks.\n    \n*   **Limitations:** naive algorithms are generally less accurate in complex language processing tasks. They might miss nuances, sarcasm, or idiomatic expressions.\n    \n\n**Sentence Chunking Algorithms** are more sophisticated. They involve breaking down text into syntactically correlated parts of words like noun phrases, verb phrases, etc.\n\n*   **Context and Structure Understanding:** sentence chunking algorithms understand the structure of a sentence. They analyze parts of speech and how words relate to each other in a sentence.\n    \n*   **Accuracy:** they are more accurate in understanding the meaning and context of sentences. This makes them suitable for complex tasks like sentiment analysis, information extraction, and language translation.\n    \n*   **Resource Intensity:** these algorithms are usually more resource-intensive due to their complexity. They might require more computational power and time to process text.\n    \n\nTo learn more about best practices with regard to chunking, see our guide to chunking [here](https://docs.stack-ai.com/stack-ai/best-practices/chunking).\n\n### \n\nFile Status\n\nYou will see a label for each document that you upload with the following icons:\n\n*   **Pending:** the document is being processed and indexed.\n    \n*   **✅:** the document was successfully indexed.\n    \n*   **Error:** the document could not be indexed (e.g., due to a formatting issue).\n    \n\n### \n\nMetadata Filter Strategy\n\n**Metadata filtering** helps narrow down the documents retrieved from a vector store. The filters operate on metadata associated with each document — like date, source, topic, etc.\n\nIf you want to surface as much information as possible, it is best to use **no filter**. In this case, no metadata constraints are applied. The system retrieves the top-k most relevant documents based on your search algorithm. This strategy is best to use when you don't have a very large knowledge base as it increases the likelihood that irrelevant documents will be retrieved.\n\nWith **loose filtering**, metadata is used as a soft constraint — the system prefers documents matching the filter, but still considers other documents. This gives you the best of both worlds and is best used when metadata is helpful but not critical.\n\n**Strict filtering** should be used for situations where you have many similar documents in your KB that you need to distinguish between. With a strict filter, metadata constraints are hard requirements — only documents matching the specified metadata are eligible for retrieval. When results must meet certain conditions — e.g. regulatory compliance, user access control, project-specific scopes — strict filtering is the way to go.\n\n### \n\nQuery Strategy\n\nIn Retrieval-Augmented Generation (RAG), **keyword-based search** relies on traditional information retrieval techniques that match exact or fuzzy terms within documents. This approach works best when the query and content use consistent vocabulary, such as in legal, technical, or structured domains where terminology is predictable. It's especially useful when you know the precise terms you're looking for.\n\n**Semantic querying**, on the other hand, uses vector embeddings to represent the meaning of both queries and documents. It enables retrieval based on conceptual similarity, rather than exact keyword matches. This makes it well-suited for natural language questions, varied phrasing, and content where language is less standardized—such as customer support, internal knowledge bases, or conversational search. By focusing on meaning, semantic search improves recall, but may miss documents with exact keyword relevance.\n\n**Hybrid querying** combines both strategies—typically by blending keyword and semantic relevance scores or performing multi-stage retrieval. This approach provides the benefits of both precision and flexibility, making it ideal for general-purpose RAG systems that must handle a variety of user intents and content types. While slightly more complex to implement, hybrid search often yields the most balanced and robust retrieval performance in production applications.\n\n### \n\nTypical Workflow Structure\n\nA common pattern is:\n\n1.  **User Input** (Input Node): The user provides a question or prompt.\n    \n2.  **Knowledge Base Node**: Receives the user’s query (directly or via an LLM node) and retrieves relevant information from the knowledge base.\n    \n3.  **LLM Node**: Uses both the user’s input and the retrieved knowledge base content to generate a final, context-rich answer.\n    \n\n* * *\n\n### \n\nHow the Interface Works\n\n**A. Data Flow**\n\n*   The Knowledge Base node typically takes the user’s input as its query, searches the knowledge base, and outputs relevant text chunks.\n    \n*   The LLM node can reference the output of the Knowledge Base node in its prompt using the node’s ID.\n    \n\n**B. Connections (Edges)**\n\n*   The Input node is connected to the Knowledge Base node (for the query).\n    \n*   The Knowledge Base node is connected to the LLM node (providing retrieved content).\n    \n*   The LLM node is connected to the Output node (displaying the answer).\n    \n\n**C. Execution Order**\n\n1.  The user submits a question.\n    \n2.  The Knowledge Base node receives the question and retrieves relevant information.\n    \n3.  The LLM node receives both the user’s question and the retrieved information, then generates a response.\n    \n4.  The Output node displays the LLM’s answer.\n    \n\n* * *\n\n### \n\nWhy Use This Pattern?\n\n*   **Retrieval-Augmented Generation (RAG)**: This approach allows the LLM to ground its answers in specific, up-to-date, or proprietary knowledge, improving accuracy and relevance.\n    \n*   **Separation of Concerns**: The Knowledge Base node handles retrieval, while the LLM node handles synthesis and reasoning.\n    \n\n* * *\n\n### \n\nKey Points\n\n*   The LLM node does not “search” the knowledge base directly; it relies on the Knowledge Base node to do the retrieval.\n    \n*   The LLM node’s prompt must reference the Knowledge Base node’s output to use the retrieved information.\n    \n*   All node references must match actual node IDs in the workflow.\n    \n\n* * *\n\n### \n\nAvailable Knowledge Bases\n\n*   Documents\n    \n*   Websites\n    \n*   Tables\n    \n*   Data\n    \n*   Sharepoint\n    \n*   Google Drive\n    \n*   OneDrive\n    \n*   Dropbox\n    \n*   Azure Blob Storage\n    \n*   AWS S3\n    \n*   Notion\n    \n*   Confluence\n    \n*   Veeva\n    \n*   ServiceNow\n    \n*   Jira\n    \n\nLast updated 2 months ago","debug":{"requestHandlerMode":"browser"}}